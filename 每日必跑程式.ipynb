{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gargile/Taiwan_Stock/blob/main/%E6%AF%8F%E6%97%A5%E5%BF%85%E8%B7%91%E7%A8%8B%E5%BC%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kfSM3m911ys",
        "outputId": "13925835-f1fc-42ca-ec1b-0b494b4eeefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: No `pyproject.toml` found in current directory or any parent directory\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "\n",
        "# å®‰è£è³‡æ–™è™•ç†å’Œåˆ†æå¥—ä»¶\n",
        "!pip install pandas numpy -q\n",
        "\n",
        "# å®‰è£è¦–è¦ºåŒ–å¥—ä»¶\n",
        "!pip install matplotlib seaborn mplfinance -q\n",
        "!pip install chineseize-matplotlib -q\n",
        "\n",
        "# å®‰è£è³‡æ–™ç²å–å¥—ä»¶\n",
        "!pip install yfinance requests lxml html5lib -q\n",
        "!pip install twstock -q\n",
        "\n",
        "# å®‰è£å°ç£è‚¡å¸‚ç›¸é—œå¥—ä»¶æ¬¸\n",
        "!pip install shioaji[speed] -q\n",
        "!uv add shioaji --extra speed -q\n",
        "!pip install pandas-market-calendars pytz -q\n",
        "\n",
        "# å®‰è£ç•°æ­¥å’Œé€šçŸ¥ç›¸é—œå¥—ä»¶\n",
        "!pip install python-telegram-bot aiohttp nest-asyncio -q\n",
        "!pip install discord-webhook -q\n",
        "!pip install python-dotenv -q\n",
        "\n",
        "# æª¢æŸ¥å·²å®‰è£çš„å¥—ä»¶\n",
        "get_ipython().system('pip list | grep -E \"yfinance|mplfinance|pandas|numpy|matplotlib|plotly|shioaji|beautifulsoup4\"')\n",
        "# -*- coding: utf-8 -*-\n",
        "!pip install mplfinance chineseize_matplotlib yfinance pandas numpy matplotlib plotly discord-webhook requests aiohttp python-telegram-bot nest-asyncio -q\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…·\n",
        "=======================\n",
        "åŠŸèƒ½ï¼š\n",
        "- è‡ªå‹•ç²å–å°è‚¡æ¸…å–®\n",
        "- æ‰¹æ¬¡ä¸‹è¼‰æ­·å²æ•¸æ“š\n",
        "- æŠ€è¡“æŒ‡æ¨™åˆ†æ\n",
        "- ç¶œåˆè©•åˆ†æ’å\n",
        "- è‡ªå‹•é€šçŸ¥æ¨é€\n",
        "- åœ–è¡¨ç”Ÿæˆèˆ‡å ±å‘ŠåŒ¯å‡º\n",
        "\n",
        "ä½œè€…ï¼šè‚¡ç¥¨åˆ†æç³»çµ±\n",
        "ç‰ˆæœ¬ï¼šv2.1\n",
        "æ›´æ–°æ—¥æœŸï¼š2025-08-08\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. åŸºç¤ Python æ¨™æº–åº«\n",
        "# ==============================================================================\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import platform\n",
        "import re\n",
        "import glob\n",
        "import asyncio\n",
        "import warnings\n",
        "from io import StringIO\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "import logging\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ•¸æ“šè™•ç†èˆ‡ç§‘å­¸è¨ˆç®—\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. ç¬¬ä¸‰æ–¹å¥—ä»¶ - ç¶²è·¯è«‹æ±‚èˆ‡ç•°æ­¥è™•ç†\n",
        "# ==============================================================================\n",
        "import requests\n",
        "import aiohttp\n",
        "import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥æ”¯æ´ Jupyter ç’°å¢ƒ\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. ç¬¬ä¸‰æ–¹å¥—ä»¶ - é‡‘èæ•¸æ“šæº\n",
        "# ==============================================================================\n",
        "import yfinance as yf\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ•¸æ“šå¯è¦–åŒ–\n",
        "# ==============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "import mplfinance as mpf\n",
        "import plotly.graph_objects as go\n",
        "from pathlib import Path\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ™‚å€èˆ‡é€šçŸ¥\n",
        "# ==============================================================================\n",
        "import pytz\n",
        "from discord_webhook import DiscordWebhook\n",
        "import telegram\n",
        "# ==============================================================================\n",
        "# 7. ä¸­æ–‡å­—é«”æ”¯æ´\n",
        "# ==============================================================================\n",
        "try:\n",
        "    import chineseize_matplotlib\n",
        "    chineseize_matplotlib.chineseize()\n",
        "    print(\"âœ… å·²è¼‰å…¥ chineseize_matplotlib ä¸­æ–‡å­—é«”æ”¯æ´\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ æœªå®‰è£ chineseize_matplotlibï¼Œå°‡ä½¿ç”¨è‡ªå®šç¾©å­—é«”è¨­å®š\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 8. å…¨åŸŸè¨­å®š\n",
        "# ==============================================================================\n",
        "# è­¦å‘Šéæ¿¾\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# æ™‚å€è¨­å®š\n",
        "taipei_tz = pytz.timezone('Asia/Taipei')\n",
        "\n",
        "\n",
        "# --- ç›®éŒ„è¨­å®š ---\n",
        "BASE_DIR = os.getcwd() # <--- æ–°å¢é€™ä¸€è¡Œ\n",
        "CACHE_DIR = 'cache'\n",
        "RESULTS_DIR = 'results'\n",
        "CHARTS_DIR = os.path.join(RESULTS_DIR, 'charts')\n",
        "STOCK_LIST_PATH = os.path.join(CACHE_DIR, 'stock_list.csv')\n",
        "HISTORY_DATA_CACHE_DIR = os.path.join(CACHE_DIR, 'history_data')\n",
        "ETF_LIST_PATH = os.path.join(CACHE_DIR, 'etf_list.csv')\n",
        "# --- åˆå§‹åŒ–ç›®éŒ„ ---\n",
        "# ç¢ºä¿ç›®éŒ„æ˜¯ç›¸å°æ–¼ BASE_DIR å»ºç«‹çš„ï¼Œé€™æ¨£æ›´ç©©å¥\n",
        "for directory in [os.path.join(BASE_DIR, CACHE_DIR),\n",
        "                  os.path.join(BASE_DIR, RESULTS_DIR),\n",
        "                  os.path.join(BASE_DIR, CHARTS_DIR),\n",
        "                  os.path.join(BASE_DIR, HISTORY_DATA_CACHE_DIR)]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ... å¾ŒçºŒç¨‹å¼ç¢¼ ...\n",
        "\n",
        "# åˆå§‹åŒ–ç›®éŒ„\n",
        "for directory in [CACHE_DIR, RESULTS_DIR, CHARTS_DIR, HISTORY_DATA_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# 9. é€šè¨Šèˆ‡é€šçŸ¥è¨­å®š\n",
        "# ==============================================================================\n",
        "# å»ºè­°å°‡ä¾†ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ– .env æª”æ¡ˆç®¡ç†å¯†é‘°ï¼Œä»¥ç­–å®‰å…¨\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]  # æ”¯æ´å¤šç”¨æˆ¶é€šçŸ¥\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 10. æ—¥èªŒç³»çµ±è¨­å®š\n",
        "# ==============================================================================\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"stock_analysis.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ==============================================================================\n",
        "# 11. å­—é«”èˆ‡ç’°å¢ƒè¨­å®šå‡½å¼\n",
        "# ==============================================================================\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "\n",
        "    æ”¯æ´çš„ä½œæ¥­ç³»çµ±ï¼š\n",
        "    - Windows: Microsoft JhengHei, Microsoft YaHei, SimHei\n",
        "    - macOS: PingFang HK, PingFang SC, Heiti TC\n",
        "    - Linux: Noto Sans CJK / WenQuanYi Zen Hei\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            # Windows ç³»çµ±å­—é«”è¨­å®šï¼ˆåŒ…å«ç¹é«”ä¸­æ–‡å„ªå…ˆï¼‰\n",
        "            font_candidates = [\n",
        "                'Microsoft JhengHei',  # å¾®è»Ÿæ­£é»‘é«”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰\n",
        "                'Microsoft YaHei',     # å¾®è»Ÿé›…é»‘ï¼ˆç°¡é«”ä¸­æ–‡ï¼‰\n",
        "                'Arial Unicode MS',    # è¬åœ‹ç¢¼å­—é«”\n",
        "                'SimHei',              # é»‘é«”\n",
        "                'KaiTi'                # æ¥·é«”\n",
        "            ]\n",
        "\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    # æ¸¬è©¦å­—é«”æ˜¯å¦å¯ç”¨\n",
        "                    test_fig, test_ax = plt.subplots(figsize=(1, 1))\n",
        "                    test_ax.text(0.5, 0.5, 'æ¸¬è©¦', fontname=font)\n",
        "                    plt.close(test_fig)\n",
        "\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        elif system == 'Darwin':  # macOS\n",
        "            # macOS ç³»çµ±å­—é«”è¨­å®š\n",
        "            font_candidates = [\n",
        "                'PingFang HK',      # è˜‹æ–¹-é¦™æ¸¯\n",
        "                'PingFang SC',      # è˜‹æ–¹-ç°¡é«”ä¸­æ–‡\n",
        "                'PingFang TC',      # è˜‹æ–¹-ç¹é«”ä¸­æ–‡\n",
        "                'Heiti TC',         # é»‘é«”-ç¹é«”ä¸­æ–‡\n",
        "                'Heiti SC',         # é»‘é«”-ç°¡é«”ä¸­æ–‡\n",
        "                'STHeiti'           # è¯æ–‡é»‘é«”\n",
        "            ]\n",
        "\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        else:  # Linux å’Œå…¶ä»–ç³»çµ±\n",
        "            # Linux ç³»çµ±å­—é«”è·¯å¾‘\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/ukai.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/uming.ttc',\n",
        "                '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'\n",
        "            ]\n",
        "\n",
        "            found_font_path = None\n",
        "            for path in font_paths:\n",
        "                if os.path.exists(path):\n",
        "                    found_font_path = path\n",
        "                    break\n",
        "\n",
        "            if found_font_path:\n",
        "                try:\n",
        "                    font_manager.fontManager.addfont(found_font_path)\n",
        "                    font_prop = font_manager.FontProperties(fname=found_font_path)\n",
        "                    font_name = font_prop.get_name()\n",
        "                    plt.rcParams['font.sans-serif'] = [font_name]\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"è¼‰å…¥å­—é«”å¤±æ•—: {e}\")\n",
        "                    font_name = \"DejaVu Sans\"\n",
        "            else:\n",
        "                print(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                font_name = \"DejaVu Sans\"\n",
        "\n",
        "        # è¨­å®š matplotlib åƒæ•¸\n",
        "        plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¢ºé¡¯ç¤ºè² è™Ÿ\n",
        "\n",
        "        # è¨­å®šå­—é«”å¤§å°\n",
        "        plt.rcParams['font.size'] = 10\n",
        "        plt.rcParams['axes.titlesize'] = 12\n",
        "        plt.rcParams['axes.labelsize'] = 10\n",
        "        plt.rcParams['xtick.labelsize'] = 9\n",
        "        plt.rcParams['ytick.labelsize'] = 9\n",
        "        plt.rcParams['legend.fontsize'] = 9\n",
        "\n",
        "        # è¨­å®šåœ–è¡¨å“è³ª\n",
        "        plt.rcParams['figure.dpi'] = 100\n",
        "        plt.rcParams['savefig.dpi'] = 150\n",
        "        plt.rcParams['savefig.bbox'] = 'tight'\n",
        "\n",
        "        if font_name and font_name != \"DejaVu Sans\":\n",
        "            print(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name} ({system})\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ä½¿ç”¨é è¨­å­—é«”: {font_name}\")\n",
        "            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"\n",
        "    æª¢æŸ¥åŸ·è¡Œç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶\n",
        "    \"\"\"\n",
        "    print(\"ğŸ” æª¢æŸ¥åŸ·è¡Œç’°å¢ƒ...\")\n",
        "    print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
        "    print(f\"ä½œæ¥­ç³»çµ±: {platform.system()} {platform.release()}\")\n",
        "    print(f\"ç•¶å‰æ™‚å€: {taipei_tz}\")\n",
        "\n",
        "    # æª¢æŸ¥é‡è¦å¥—ä»¶ç‰ˆæœ¬\n",
        "    required_packages = {\n",
        "        'pandas': pd.__version__,\n",
        "        'numpy': np.__version__,\n",
        "        'matplotlib': plt.matplotlib.__version__,\n",
        "        'requests': requests.__version__,\n",
        "        'yfinance': getattr(yf, '__version__', 'Unknown'),\n",
        "        'aiohttp': aiohttp.__version__,\n",
        "        'pytz': pytz.__version__\n",
        "    }\n",
        "\n",
        "    print(\"\\nğŸ“¦ å¥—ä»¶ç‰ˆæœ¬:\")\n",
        "    for package, version in required_packages.items():\n",
        "        print(f\"  {package}: {version}\")\n",
        "\n",
        "    # æª¢æŸ¥ç›®éŒ„æ¬Šé™\n",
        "    print(f\"\\nğŸ“ å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "    directories_status = {\n",
        "        'å¿«å–ç›®éŒ„': (CACHE_DIR, os.access(CACHE_DIR, os.W_OK)),\n",
        "        'çµæœç›®éŒ„': (RESULTS_DIR, os.access(RESULTS_DIR, os.W_OK)),\n",
        "        'åœ–è¡¨ç›®éŒ„': (CHARTS_DIR, os.access(CHARTS_DIR, os.W_OK))\n",
        "    }\n",
        "\n",
        "    for name, (path, writable) in directories_status.items():\n",
        "        status = 'âœ…' if writable else 'âŒ'\n",
        "        print(f\"{name}: {path} {status}\")\n",
        "\n",
        "    # æª¢æŸ¥ç¶²è·¯é€£ç·šï¼ˆç°¡å–®æ¸¬è©¦ï¼‰\n",
        "    try:\n",
        "        response = requests.get('https://httpbin.org/status/200', timeout=5)\n",
        "        network_status = 'âœ…' if response.status_code == 200 else 'âŒ'\n",
        "    except:\n",
        "        network_status = 'âŒ'\n",
        "\n",
        "    print(f\"ç¶²è·¯é€£ç·š: {network_status}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "def get_current_time():\n",
        "    \"\"\"\n",
        "    ç²å–ç•¶å‰å°åŒ—æ™‚é–“\n",
        "    \"\"\"\n",
        "    return datetime.now(taipei_tz)\n",
        "\n",
        "def format_timestamp(dt=None):\n",
        "    \"\"\"\n",
        "    æ ¼å¼åŒ–æ™‚é–“æˆ³è¨˜\n",
        "    \"\"\"\n",
        "    if dt is None:\n",
        "        dt = get_current_time()\n",
        "    return dt.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
        "\n",
        "# ==============================================================================\n",
        "# 12. ç¨‹å¼åˆå§‹åŒ–\n",
        "# ==============================================================================\n",
        "def initialize_application():\n",
        "    \"\"\"\n",
        "    æ‡‰ç”¨ç¨‹å¼åˆå§‹åŒ–\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· v2.1\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # æª¢æŸ¥ç’°å¢ƒ\n",
        "    check_environment()\n",
        "\n",
        "    # è¨­å®šä¸­æ–‡å­—é«”\n",
        "    set_chinese_font()\n",
        "\n",
        "    # è¨˜éŒ„å•Ÿå‹•æ™‚é–“\n",
        "    start_time = get_current_time()\n",
        "    logger.info(f\"æ‡‰ç”¨ç¨‹å¼å•Ÿå‹• - {format_timestamp(start_time)}\")\n",
        "    logger.info(f\"å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "\n",
        "    print(f\"âœ… åˆå§‹åŒ–å®Œæˆ - {format_timestamp(start_time)}\\n\")\n",
        "\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸\n",
        "# ==============================================================================\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram\n",
        "    try:\n",
        "        url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "        payload = {\"chat_id\": TELEGRAM_CHAT_ID, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "        await session.post(url_msg, json=payload, timeout=20)\n",
        "        logger.info(\"Telegram æ‘˜è¦ç™¼é€æˆåŠŸã€‚\")\n",
        "\n",
        "        if files:\n",
        "            url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "            for file_path in files:\n",
        "                if os.path.exists(file_path):\n",
        "                    data = aiohttp.FormData()\n",
        "                    data.add_field('chat_id', TELEGRAM_CHAT_ID)\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                        await session.post(url_photo, data=data, timeout=60)\n",
        "            logger.info(f\"Telegram åœ–æª”ç™¼é€æˆåŠŸ ({len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord\n",
        "    if MESSAGING_AVAILABLE:\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            if files:\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        with open(file_path, 'rb') as f:\n",
        "                            webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "    else:\n",
        "        logger.warning(\"Discord é€šçŸ¥åŠŸèƒ½æœªå•Ÿç”¨ï¼ˆå¥—ä»¶æœªå®‰è£ï¼‰\")\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        if taipei_tz:\n",
        "            current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        else:\n",
        "            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "\n",
        "ğŸ“Š TOP 5 æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f}\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "print(\"âœ… ç’°å¢ƒè¨­å®šå®Œæˆï¼\")\n",
        "print(f\"ğŸ“ å·¥ä½œç›®éŒ„: {BASE_DIR}\")\n",
        "print(f\"ğŸ“Š åœ–è¡¨ç›®éŒ„: {CHARTS_DIR}\")\n",
        "print(f\"ğŸ”” é€šçŸ¥åŠŸèƒ½: {'å·²å•Ÿç”¨' if MESSAGING_AVAILABLE else 'éƒ¨åˆ†å•Ÿç”¨ï¼ˆåƒ… Telegramï¼‰'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä¸Šé¢æ˜¯å®‰è£ç¨‹å¼ç¢¼"
      ],
      "metadata": {
        "id": "GlFqLBsVPgaJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lAv54yeW2Dqi",
        "outputId": "9157591e-b286-4ea0-96a9-5dd57fa50c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ å°è‚¡æŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\n",
            "â° é–‹å§‹æ™‚é–“: 2025-08-13 10:23:53\n",
            "ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\n",
            "ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªè‚¡ç¥¨\n",
            "============================================================\n",
            "ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\n",
            "\n",
            "================================================================================\n",
            "                              ğŸ† å°è‚¡æŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨                              \n",
            "================================================================================\n",
            "ğŸ“ˆ åˆ†ææ™‚é–“: 2025-08-13 10:39:23\n",
            "ğŸ“Š æˆåŠŸåˆ†æ: 539 æ”¯è‚¡ç¥¨\n",
            "ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\n",
            "================================================================================\n",
            "æ’å  ä»£ç¢¼      è‚¡ç¥¨åç¨±        è©•åˆ†      åƒ¹æ ¼        æ¼²è·Œ%     å»ºè­°        æˆäº¤é‡(å¼µ)      \n",
            "--------------------------------------------------------------------------------\n",
            "1   1409    æ–°çº–          70.0    13.80     +9.52   è²·é€²        2230        \n",
            "2   5314    ä¸–ç´€*         70.0    86.70     +6.51   è²·é€²        12278       \n",
            "3   2355    æ•¬éµ¬          69.5    35.10     +3.39   è²·é€²        3164        \n",
            "4   6919    åº·éœˆ*         69.5    136.00    +11.93  è²·é€²        13687       \n",
            "5   2338    å…‰ç½©          69.0    35.50     +9.57   è²·é€²        4536        \n",
            "6   8249    è±å…‰          69.0    57.20     +5.93   è²·é€²        4563        \n",
            "7   1304    å°èš          68.0    10.95     +6.31   è²·é€²        2578        \n",
            "8   1308    äºèš          68.0    12.55     +5.02   è²·é€²        1712        \n",
            "9   6213    è¯èŒ‚          68.0    103.50    +14.11  è²·é€²        19866       \n",
            "10  3661    ä¸–èŠ¯-KY       67.0    4150.00   +11.86  è²·é€²        2301        \n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\n",
            "================================================================================\n",
            "\n",
            "1. æ–°çº– (1409) - è©•åˆ†: 70.0\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 13.80\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +9.52%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 67.2 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=46.2, D=36.8\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 2230å¼µ/æ—¥ (çˆ†é‡)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "2. ä¸–ç´€* (5314) - è©•åˆ†: 70.0\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 86.70\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +6.51%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 68.1 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=73.3, D=63.6\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 12278å¼µ/æ—¥ (æ”¾é‡)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "3. æ•¬éµ¬ (2355) - è©•åˆ†: 69.5\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 35.10\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +3.39%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 64.6 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=55.5, D=50.1\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 3164å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "4. åº·éœˆ* (6919) - è©•åˆ†: 69.5\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 136.00\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +11.93%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 51.6 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=51.5, D=46.4\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 13687å¼µ/æ—¥ (ç¸®é‡)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "5. å…‰ç½© (2338) - è©•åˆ†: 69.0\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 35.50\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +9.57%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 69.8 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=71.5, D=53.8\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 4536å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "================================================================================\n",
            "âš ï¸  æŠ•è³‡æé†’:\n",
            "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\n",
            "â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\n",
            "â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\n",
            "â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\n",
            "================================================================================\n",
            "\n",
            "ğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\n",
            "ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\n",
            "\n",
            "â° ç¨‹å¼åŸ·è¡Œå®Œæˆ: 2025-08-13 10:39:24\n",
            "============================================================\n",
            "âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\n",
            "ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "import nest_asyncio\n",
        "\n",
        "# å®‰è£ nest_asyncioï¼ˆå¦‚æœå°šæœªå®‰è£ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥å…è¨±åµŒå¥—äº‹ä»¶å¾ªç’°\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()  # ä¿®æ­£ï¼šä½¿ç”¨ copy() é¿å…è­¦å‘Š\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()  # ä¿®æ­£ï¼šä½¿ç”¨ copy()\n",
        "                df.loc[:, 'market'] = market_name  # ä¿®æ­£ï¼šä½¿ç”¨ .loc è¨­å®šå€¼\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)].copy()\n",
        "\n",
        "            # ä¿®æ­£ï¼šä½¿ç”¨ .loc è¨­å®š yahoo_symbol\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨è‚¡ç¥¨æ¸…å–®\")\n",
        "\n",
        "            # æ“´å±•çŸ¥åè‚¡ç¥¨åˆ—è¡¨\n",
        "            famous_stocks = [\n",
        "                {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2412', 'stock_name': 'ä¸­è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2412.TW', 'industry': 'é€šä¿¡'},\n",
        "                {'stock_id': '1301', 'stock_name': 'å°å¡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1301.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '1303', 'stock_name': 'å—äº', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1303.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '2308', 'stock_name': 'å°é”é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2308.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2002', 'stock_name': 'ä¸­é‹¼', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2002.TW', 'industry': 'é‹¼éµ'},\n",
        "                {'stock_id': '2886', 'stock_name': 'å…†è±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2886.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2891.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '3008', 'stock_name': 'å¤§ç«‹å…‰', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3008.TW', 'industry': 'å…‰å­¸'},\n",
        "                {'stock_id': '2357', 'stock_name': 'è¯ç¢©', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2357.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2382', 'stock_name': 'å»£é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2382.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2395', 'stock_name': 'ç ”è¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2395.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '3711', 'stock_name': 'æ—¥æœˆå…‰æŠ•æ§', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3711.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2409', 'stock_name': 'å‹é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2409.TW', 'industry': 'é¢æ¿'},\n",
        "                {'stock_id': '2884', 'stock_name': 'ç‰å±±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2884.TW', 'industry': 'é‡‘è'},\n",
        "                # æ–°å¢æ›´å¤šè‚¡ç¥¨\n",
        "                {'stock_id': '2474', 'stock_name': 'å¯æˆ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2474.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2408', 'stock_name': 'å—äºç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2408.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2301', 'stock_name': 'å…‰å¯¶ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2301.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2207', 'stock_name': 'å’Œæ³°è»Š', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2207.TW', 'industry': 'æ±½è»Š'},\n",
        "                {'stock_id': '1216', 'stock_name': 'çµ±ä¸€', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1216.TW', 'industry': 'é£Ÿå“'},\n",
        "                {'stock_id': '1101', 'stock_name': 'å°æ³¥', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1101.TW', 'industry': 'æ°´æ³¥'},\n",
        "                {'stock_id': '2105', 'stock_name': 'æ­£æ–°', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2105.TW', 'industry': 'æ©¡è† '},\n",
        "                {'stock_id': '2912', 'stock_name': 'çµ±ä¸€è¶…', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2912.TW', 'industry': 'è²¿æ˜“ç™¾è²¨'},\n",
        "                {'stock_id': '2885', 'stock_name': 'å…ƒå¤§é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2885.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2892', 'stock_name': 'ç¬¬ä¸€é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2892.TW', 'industry': 'é‡‘è'},\n",
        "            ]\n",
        "\n",
        "            df = pd.DataFrame(famous_stocks)\n",
        "            logger.info(f\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_info.get('stock_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºå‰ååï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æ - å‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºå‰ååå„ªè³ªè‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† å‰ {len(top_stocks)} åå„ªè³ªè‚¡ç¥¨:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\" if price_change < 0 else \"â¡ï¸\"\n",
        "\n",
        "            # å»ºè­°ç¬¦è™Ÿ\n",
        "            rec_symbol = \"ğŸš€\" if \"å¼·åŠ›è²·\" in rec_text else \"ğŸ“ˆ\" if \"è²·\" in rec_text else \"ğŸ“Š\" if \"æŒæœ‰\" in rec_text else \"ğŸ“‰\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {stock_name} ({stock_id})\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f} ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   â­ è©•åˆ†: {score:.1f}/100\")\n",
        "            message_parts.append(f\"   {rec_symbol} å»ºè­°: {rec_text}\")\n",
        "            message_parts.append(f\"   ğŸ“Š æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # æ·»åŠ ä¸»è¦æŠ€è¡“æŒ‡æ¨™\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            rsi_value = tech.get('rsi_value', 50)\n",
        "            macd_signal = tech.get('macd_signal', 'ä¸­æ€§')\n",
        "            message_parts.append(f\"   ğŸ” RSI: {rsi_value:.1f} | MACD: {macd_signal}\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_score = sum(r.get('combined_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('combined_score', 0) >= 70])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ“Š å¹³å‡åˆ†æ•¸: {avg_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†è‚¡ç¥¨ (â‰¥70): {high_score_count}\")\n",
        "\n",
        "            # å»ºè­°åˆ†å¸ƒ\n",
        "            recommendations = {}\n",
        "            for result in top_stocks:\n",
        "                rec = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "                recommendations[rec] = recommendations.get(rec, 0) + 1\n",
        "\n",
        "            if recommendations:\n",
        "                message_parts.append(\"   ğŸ“ˆ å‰ååå»ºè­°åˆ†å¸ƒ:\")\n",
        "                for rec, count in recommendations.items():\n",
        "                    message_parts.append(f\"      {rec}: {count}\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        message_parts.append(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{score:<8.1f}{current_price:<10.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {stock_name} ({stock_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† å°è‚¡åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ å°è‚¡æŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQcFPQMbKs2j"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYVE8CMr_4sD"
      },
      "source": [
        "ä¸Šé¢æ˜¯å°è‚¡é¸æ“‡æ¯æ—¥1000å¼µï¼Œè©•åˆ†æœ€å„ªå‰åå"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnj0aFDO_54D",
        "outputId": "ea081105-5677-4771-a6b7-a1f6a2f6cd65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ å°è‚¡ETFæŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\n",
            "â° é–‹å§‹æ™‚é–“: 2025-08-13 10:39:25\n",
            "ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\n",
            "ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªETF\n",
            "============================================================\n",
            "ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰ETFï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\n",
            "\n",
            "================================================================================\n",
            "                            ğŸ† å°è‚¡ETFæŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨                             \n",
            "================================================================================\n",
            "ğŸ“ˆ åˆ†ææ™‚é–“: 2025-08-13 10:40:03\n",
            "ğŸ“Š æˆåŠŸåˆ†æ: 1 æ”¯è‚¡ç¥¨\n",
            "ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\n",
            "================================================================================\n",
            "æ’å  ä»£ç¢¼      è‚¡ç¥¨åç¨±        è©•åˆ†      åƒ¹æ ¼        æ¼²è·Œ%     å»ºè­°        æˆäº¤é‡(å¼µ)      \n",
            "--------------------------------------------------------------------------------\n",
            "1   2883    å‡±åŸºé‡‘         44.0    15.60     +0.65   æŒæœ‰        22077       \n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\n",
            "================================================================================\n",
            "\n",
            "1. å‡±åŸºé‡‘ (2883) - è©•åˆ†: 44.0\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 15.60\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +0.65%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: æŒæœ‰\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­ç­‰\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 57.7 (ä¸­æ€§)\n",
            "   MACD: å¤šé ­\n",
            "   KD: K=84.7, D=86.5\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: ç›¤æ•´\n",
            "ğŸ“ˆ æˆäº¤é‡: 22077å¼µ/æ—¥ (ç¸®é‡)\n",
            "\n",
            "================================================================================\n",
            "âš ï¸  æŠ•è³‡æé†’:\n",
            "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\n",
            "â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\n",
            "â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\n",
            "â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\n",
            "================================================================================\n",
            "\n",
            "ğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\n",
            "ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\n",
            "\n",
            "â° ç¨‹å¼åŸ·è¡Œå®Œæˆ: 2025-08-13 10:40:04\n",
            "============================================================\n",
            "âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\n",
            "ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "import nest_asyncio\n",
        "\n",
        "# å®‰è£ nest_asyncioï¼ˆå¦‚æœå°šæœªå®‰è£ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥å…è¨±åµŒå¥—äº‹ä»¶å¾ªç’°\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.etf_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_etfs(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£ETFæ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.etf_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.etf_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥ETFåˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.etf_list_path, dtype={'etf_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°ETFæ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_etfs_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df.loc[:, 'market'] = market_name\n",
        "                all_etfs_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} ETFåˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_etfs_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•ETFæ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_etf_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_etfs_df, ignore_index=True)\n",
        "            df[['etf_id', 'etf_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "\n",
        "            # ç¯©é¸ETFï¼šåªä¿ç•™4ä½æ•¸å­—ä»£ç¢¼ä¸”åç¨±åŒ…å«ETFç›¸é—œé—œéµå­—çš„é …ç›®\n",
        "            df = df[df['etf_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "\n",
        "            # åªä¿ç•™ETFç›¸é—œçš„è­‰åˆ¸\n",
        "            etf_keywords = ['ETF', 'ETN', 'æŒ‡æ•¸', 'åŸºé‡‘', 'å‚˜å‹', 'æœŸè²¨', 'åå‘', 'æ§“æ¡¿']\n",
        "            df = df[df['etf_name'].str.contains('|'.join(etf_keywords), na=False)].copy()\n",
        "\n",
        "            # æ’é™¤ä¸€èˆ¬è‚¡ç¥¨å’Œå…¶ä»–éETFå•†å“\n",
        "            exclude_keywords = ['è³¼', 'ç‰›', 'ç†Š', 'èªè³¼', 'èªå”®', 'æ¬Šè­‰', 'å­˜è¨—æ†‘è­‰', 'TDR']\n",
        "            df = df[~df['etf_name'].str.contains('|'.join(exclude_keywords), na=False)].copy()\n",
        "\n",
        "            # è¨­å®šYahoo Financeç¬¦è™Ÿ\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['etf_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['etf_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['etf_id', 'etf_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(\n",
        "                columns={'ç”¢æ¥­åˆ¥': 'category', 'etf_id': 'etf_id', 'etf_name': 'etf_name'})\n",
        "            final_df = final_df.drop_duplicates(subset=['etf_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.etf_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯ETFæ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_etf_list()\n",
        "\n",
        "    def _get_backup_etf_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨ETFæ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨ETFæ¸…å–®\")\n",
        "\n",
        "            # å°ç£ä¸»è¦ETFåˆ—è¡¨\n",
        "            famous_etfs = [\n",
        "                # å¸‚å€¼å‹ETF\n",
        "                {'etf_id': '0050', 'etf_name': 'å…ƒå¤§å°ç£50', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '0050.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '0056', 'etf_name': 'å…ƒå¤§é«˜è‚¡æ¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '0056.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '006208', 'etf_name': 'å¯Œé‚¦å°50', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '006208.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00878', 'etf_name': 'åœ‹æ³°æ°¸çºŒé«˜è‚¡æ¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00878.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00881', 'etf_name': 'åœ‹æ³°å°ç£5G+', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00881.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # é«˜è‚¡æ¯ETF\n",
        "                {'etf_id': '00713', 'etf_name': 'å…ƒå¤§å°ç£é«˜æ¯ä½æ³¢', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00713.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00701', 'etf_name': 'åœ‹æ³°ä½æ³¢å‹•', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00701.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00692', 'etf_name': 'å¯Œé‚¦å…¬å¸æ²»ç†', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00692.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00900', 'etf_name': 'å¯Œé‚¦ç‰¹é¸é«˜è‚¡æ¯30', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00900.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00919', 'etf_name': 'ç¾¤ç›Šå°ç£ç²¾é¸é«˜æ¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00919.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # ç§‘æŠ€é¡ETF\n",
        "                {'etf_id': '00757', 'etf_name': 'çµ±ä¸€FANG+', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00757.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00861', 'etf_name': 'å…ƒå¤§å…¨çƒæœªä¾†é€šè¨Š', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00861.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00876', 'etf_name': 'å…ƒå¤§æœªä¾†é—œéµç§‘æŠ€', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00876.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # å‚µåˆ¸å‹ETF\n",
        "                {'etf_id': '00679B', 'etf_name': 'å…ƒå¤§ç¾å‚µ20å¹´', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00679B.TW', 'category': 'å‚µåˆ¸å‹ETF'},\n",
        "                {'etf_id': '00687B', 'etf_name': 'åœ‹æ³°20å¹´ç¾å‚µ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00687B.TW', 'category': 'å‚µåˆ¸å‹ETF'},\n",
        "                {'etf_id': '00720B', 'etf_name': 'å…ƒå¤§æŠ•è³‡ç´šå…¬å¸å‚µ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00720B.TW', 'category': 'å‚µåˆ¸å‹ETF'},\n",
        "                {'etf_id': '00751B', 'etf_name': 'å…ƒå¤§AAAè‡³Aå…¬å¸å‚µ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00751B.TW', 'category': 'å‚µåˆ¸å‹ETF'},\n",
        "\n",
        "                # åœ‹éš›è‚¡ç¥¨ETF\n",
        "                {'etf_id': '00646', 'etf_name': 'å…ƒå¤§S&P500', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00646.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00662', 'etf_name': 'å¯Œé‚¦NASDAQ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00662.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00670L', 'etf_name': 'å¯Œé‚¦NASDAQæ­£2', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00670L.TW', 'category': 'æ§“æ¡¿å‹ETF'},\n",
        "                {'etf_id': '00672L', 'etf_name': 'å…ƒå¤§S&P500æ­£2', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00672L.TW', 'category': 'æ§“æ¡¿å‹ETF'},\n",
        "\n",
        "                # åå‘ETF\n",
        "                {'etf_id': '00632R', 'etf_name': 'å…ƒå¤§å°ç£50å1', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00632R.TW', 'category': 'åå‘å‹ETF'},\n",
        "                {'etf_id': '00673R', 'etf_name': 'å…ƒå¤§S&P500å1', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00673R.TW', 'category': 'åå‘å‹ETF'},\n",
        "\n",
        "                # ä¸­å°å‹ETF\n",
        "                {'etf_id': '0051', 'etf_name': 'å…ƒå¤§ä¸­å‹100', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '0051.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '006201', 'etf_name': 'å…ƒå¤§å¯Œæ«ƒ50', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '006201.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # ESGç›¸é—œETF\n",
        "                {'etf_id': '00850', 'etf_name': 'å…ƒå¤§å°ç£ESGæ°¸çºŒ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00850.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00888', 'etf_name': 'æ°¸è±å°ç£ESG', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00888.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # ç”¢æ¥­å‹ETF\n",
        "                {'etf_id': '00891', 'etf_name': 'ä¸­ä¿¡é—œéµåŠå°é«”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00891.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00892', 'etf_name': 'å¯Œé‚¦å°ç£åŠå°é«”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00892.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00896', 'etf_name': 'ä¸­ä¿¡ç¶ èƒ½åŠé›»å‹•è»Š', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00896.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "            ]\n",
        "\n",
        "            df = pd.DataFrame(famous_etfs)\n",
        "            logger.info(f\"å‚™ç”¨ETFæ¸…å–®åŒ…å« {len(df)} æ”¯ETF\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, etf_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=etf_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{etf_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{etf_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{etf_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        etf_name = stock_info['etf_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {etf_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'etf_name': etf_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'etf_name': etf_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'etf_name': etf_name,\n",
        "                'etf_id': stock_info.get('etf_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {etf_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'etf_name': etf_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_etfs()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºå‰ååï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ† å°è‚¡ETFæŠ€è¡“åˆ†æ - å‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºå‰ååå„ªè³ªè‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† å‰ {len(top_stocks)} åå„ªè³ªè‚¡ç¥¨:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\" if price_change < 0 else \"â¡ï¸\"\n",
        "\n",
        "            # å»ºè­°ç¬¦è™Ÿ\n",
        "            rec_symbol = \"ğŸš€\" if \"å¼·åŠ›è²·\" in rec_text else \"ğŸ“ˆ\" if \"è²·\" in rec_text else \"ğŸ“Š\" if \"æŒæœ‰\" in rec_text else \"ğŸ“‰\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {etf_name} ({etf_id})\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f} ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   â­ è©•åˆ†: {score:.1f}/100\")\n",
        "            message_parts.append(f\"   {rec_symbol} å»ºè­°: {rec_text}\")\n",
        "            message_parts.append(f\"   ğŸ“Š æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # æ·»åŠ ä¸»è¦æŠ€è¡“æŒ‡æ¨™\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            rsi_value = tech.get('rsi_value', 50)\n",
        "            macd_signal = tech.get('macd_signal', 'ä¸­æ€§')\n",
        "            message_parts.append(f\"   ğŸ” RSI: {rsi_value:.1f} | MACD: {macd_signal}\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_score = sum(r.get('combined_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('combined_score', 0) >= 70])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ“Š å¹³å‡åˆ†æ•¸: {avg_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†è‚¡ç¥¨ (â‰¥70): {high_score_count}\")\n",
        "\n",
        "            # å»ºè­°åˆ†å¸ƒ\n",
        "            recommendations = {}\n",
        "            for result in top_stocks:\n",
        "                rec = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "                recommendations[rec] = recommendations.get(rec, 0) + 1\n",
        "\n",
        "            if recommendations:\n",
        "                message_parts.append(\"   ğŸ“ˆ å‰ååå»ºè­°åˆ†å¸ƒ:\")\n",
        "                for rec, count in recommendations.items():\n",
        "                    message_parts.append(f\"      {rec}: {count}\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        message_parts.append(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ† å°è‚¡ETFæŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{etf_id:<8}{etf_name:<12}{score:<8.1f}{current_price:<10.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {etf_name} ({etf_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† å°è‚¡ETFåˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ å°è‚¡ETFæŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªETF\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰ETFï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGaMyvmZKupb"
      },
      "source": [
        "ä¸Šé¢æ˜¯å°ç£çš„ETFé¸è‚¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJPsAK8mK_G0",
        "outputId": "a65f57de-82bb-48cb-948f-ded5031d3e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ ç¾è‚¡æŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\n",
            "â° é–‹å§‹æ™‚é–“: 2025-08-13 10:40:05\n",
            "ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\n",
            "ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªè‚¡ç¥¨\n",
            "============================================================\n",
            "ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰ç¾è‚¡ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\n",
            "\n",
            "================================================================================\n",
            "                              ğŸ† ç¾è‚¡æŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨                              \n",
            "================================================================================\n",
            "ğŸ“ˆ åˆ†ææ™‚é–“: 2025-08-13 10:44:23\n",
            "ğŸ“Š æˆåŠŸåˆ†æ: 438 æ”¯è‚¡ç¥¨\n",
            "ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\n",
            "================================================================================\n",
            "æ’å  ä»£ç¢¼      è‚¡ç¥¨åç¨±        è©•åˆ†      åƒ¹æ ¼        æ¼²è·Œ%     å»ºè­°        æˆäº¤é‡(å¼µ)      \n",
            "--------------------------------------------------------------------------------\n",
            "1   DAL     Delta Air   70.0    58.44     +10.54  è²·é€²        7951        \n",
            "2   UAL     United Air  70.0    98.47     +12.33  è²·é€²        7151        \n",
            "3   GEN     Gen Digita  69.0    31.85     +11.44  è²·é€²        3724        \n",
            "4   TGT     Target Cor  68.5    106.26    +3.74   è²·é€²        5002        \n",
            "5   PEP     PepsiCo     68.0    146.87    +5.32   è²·é€²        9209        \n",
            "6   ALB     Albemarle   67.5    77.98     +14.26  è²·é€²        5929        \n",
            "7   DVN     Devon Ener  67.5    33.32     +3.13   è²·é€²        8026        \n",
            "8   DHR     Danaher Co  67.0    205.72    +3.36   è²·é€²        4651        \n",
            "9   APTV    Aptiv       66.0    71.70     +10.68  è²·é€²        2767        \n",
            "10  MS      Morgan Sta  66.0    147.29    +4.86   è²·é€²        5348        \n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\n",
            "================================================================================\n",
            "\n",
            "1. Delta Air Lines (DAL) - è©•åˆ†: 70.0\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 58.44\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +10.54%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 58.9 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=66.1, D=56.6\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 7951å¼µ/æ—¥ (æ”¾é‡)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "2. United Airlines Holdings (UAL) - è©•åˆ†: 70.0\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 98.47\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +12.33%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 64.9 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=74.2, D=63.3\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 7151å¼µ/æ—¥ (æ”¾é‡)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "3. Gen Digital (GEN) - è©•åˆ†: 69.0\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 31.85\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +11.44%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 58.6 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=83.4, D=57.3\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 3724å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "4. Target Corporation (TGT) - è©•åˆ†: 68.5\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 106.26\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +3.74%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 46.9 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=66.0, D=65.5\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 5002å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "5. PepsiCo (PEP) - è©•åˆ†: 68.0\n",
            "--------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 146.87\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +5.32%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 52.7 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=85.4, D=73.5\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 9209å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "================================================================================\n",
            "âš ï¸  æŠ•è³‡æé†’:\n",
            "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\n",
            "â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\n",
            "â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\n",
            "â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\n",
            "================================================================================\n",
            "\n",
            "ğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\n",
            "ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\n",
            "\n",
            "â° ç¨‹å¼åŸ·è¡Œå®Œæˆ: 2025-08-13 10:44:26\n",
            "============================================================\n",
            "âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\n",
            "ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "import nest_asyncio\n",
        "\n",
        "# å®‰è£ nest_asyncioï¼ˆå¦‚æœå°šæœªå®‰è£ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥å…è¨±åµŒå¥—äº‹ä»¶å¾ªç’°\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_us_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–ç¾è‚¡è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥ç¾è‚¡è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾ç¶²è·¯ç²å–æœ€æ–°ç¾è‚¡æ¸…å–®...\")\n",
        "        all_stocks_df = []\n",
        "\n",
        "        # ä½¿ç”¨å¤šå€‹æ•¸æ“šæºç²å–ç¾è‚¡æ¸…å–®\n",
        "        try:\n",
        "            # æ–¹æ³•1: ä½¿ç”¨ yfinance ç²å– S&P 500 æˆåˆ†è‚¡\n",
        "            import yfinance as yf\n",
        "\n",
        "            # ç²å– S&P 500 æˆåˆ†è‚¡\n",
        "            sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "            sp500_df = pd.read_html(sp500_url)[0]\n",
        "            sp500_df = sp500_df.rename(columns={\n",
        "                'Symbol': 'stock_id',\n",
        "                'Security': 'stock_name',\n",
        "                'GICS Sector': 'industry'\n",
        "            })\n",
        "            sp500_df['market'] = 'NYSE/NASDAQ'\n",
        "            sp500_df['yahoo_symbol'] = sp500_df['stock_id']\n",
        "            all_stocks_df.append(sp500_df[['stock_id', 'stock_name', 'market', 'industry', 'yahoo_symbol']])\n",
        "\n",
        "            # ç²å– NASDAQ 100 æˆåˆ†è‚¡\n",
        "            nasdaq100_url = \"https://en.wikipedia.org/wiki/NASDAQ-100\"\n",
        "            nasdaq100_df = pd.read_html(nasdaq100_url)[4]  # é€šå¸¸æ˜¯ç¬¬4å€‹è¡¨æ ¼\n",
        "            nasdaq100_df = nasdaq100_df.rename(columns={\n",
        "                'Ticker': 'stock_id',\n",
        "                'Company': 'stock_name',\n",
        "                'GICS Sector': 'industry'\n",
        "            })\n",
        "            nasdaq100_df['market'] = 'NASDAQ'\n",
        "            nasdaq100_df['yahoo_symbol'] = nasdaq100_df['stock_id']\n",
        "            all_stocks_df.append(nasdaq100_df[['stock_id', 'stock_name', 'market', 'industry', 'yahoo_symbol']])\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å¾ç¶²è·¯ç²å–ç¾è‚¡æ¸…å–®å¤±æ•—: {e}\")\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨ç¾è‚¡æ¸…å–®\")\n",
        "            return self._get_backup_us_stock_list()\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•ç¾è‚¡æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_us_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "\n",
        "            # æ¸…ç†æ•¸æ“š\n",
        "            df = df.dropna(subset=['stock_id', 'stock_name']).copy()\n",
        "\n",
        "            # éæ¿¾ç¾è‚¡è‚¡ç¥¨ä»£ç¢¼ï¼ˆé€šå¸¸æ˜¯1-5å€‹å­—æ¯ï¼‰\n",
        "            df = df[df['stock_id'].str.match(r'^[A-Z]{1,5}$', na=False)].copy()\n",
        "\n",
        "            # æ’é™¤ETFã€åŸºé‡‘ç­‰éè‚¡ç¥¨å•†å“\n",
        "            exclude_keywords = ['ETF', 'Fund', 'Trust', 'LP', 'Inc.', 'Corp.', 'Ltd.']\n",
        "            # ä½†ä¿ç•™å…¬å¸åç¨±ä¸­å¸¸è¦‹çš„ Inc., Corp. ç­‰\n",
        "            exclude_pattern = r'\\b(ETF|Fund|Trust|LP)\\b'\n",
        "            df = df[~df['stock_name'].str.contains(exclude_pattern, case=False, na=False)].copy()\n",
        "\n",
        "            # å»é‡ä¸¦æ•´ç†\n",
        "            df = df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "\n",
        "            # å¡«å……ç¼ºå¤±çš„è¡Œæ¥­è³‡è¨Š\n",
        "            df['industry'] = df['industry'].fillna('å…¶ä»–')\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'industry', 'yahoo_symbol']]\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯ç¾è‚¡æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†ç¾è‚¡æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_us_stock_list()\n",
        "\n",
        "    def _get_backup_us_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨ç¾è‚¡æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨ç¾è‚¡æ¸…å–®\")\n",
        "\n",
        "            # ç¾åœ‹çŸ¥åè‚¡ç¥¨åˆ—è¡¨\n",
        "            famous_us_stocks = [\n",
        "            # ç§‘æŠ€è‚¡ (FAANG + å…¶ä»–)\n",
        "            {'stock_id': 'AAPL', 'stock_name': 'Apple Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'AAPL', 'industry': 'Technology'},\n",
        "            {'stock_id': 'MSFT', 'stock_name': 'Microsoft Corporation', 'market': 'NASDAQ', 'yahoo_symbol': 'MSFT', 'industry': 'Technology'},\n",
        "            {'stock_id': 'GOOGL', 'stock_name': 'Alphabet Inc. Class A', 'market': 'NASDAQ', 'yahoo_symbol': 'GOOGL', 'industry': 'Technology'},\n",
        "            {'stock_id': 'AMZN', 'stock_name': 'Amazon.com Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'AMZN', 'industry': 'Consumer Discretionary'},\n",
        "            {'stock_id': 'META', 'stock_name': 'Meta Platforms Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'META', 'industry': 'Technology'},\n",
        "            {'stock_id': 'TSLA', 'stock_name': 'Tesla Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'TSLA', 'industry': 'Consumer Discretionary'},\n",
        "            {'stock_id': 'NVDA', 'stock_name': 'NVIDIA Corporation', 'market': 'NASDAQ', 'yahoo_symbol': 'NVDA', 'industry': 'Technology'},\n",
        "            {'stock_id': 'NFLX', 'stock_name': 'Netflix Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'NFLX', 'industry': 'Communication Services'},\n",
        "\n",
        "            # å‚³çµ±å¤§å‹è‚¡\n",
        "            {'stock_id': 'BRK.B', 'stock_name': 'Berkshire Hathaway Inc. Class B', 'market': 'NYSE', 'yahoo_symbol': 'BRK-B', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'JPM', 'stock_name': 'JPMorgan Chase & Co.', 'market': 'NYSE', 'yahoo_symbol': 'JPM', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'JNJ', 'stock_name': 'Johnson & Johnson', 'market': 'NYSE', 'yahoo_symbol': 'JNJ', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'V', 'stock_name': 'Visa Inc.', 'market': 'NYSE', 'yahoo_symbol': 'V', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'PG', 'stock_name': 'Procter & Gamble Co.', 'market': 'NYSE', 'yahoo_symbol': 'PG', 'industry': 'Consumer Staples'},\n",
        "            {'stock_id': 'UNH', 'stock_name': 'UnitedHealth Group Inc.', 'market': 'NYSE', 'yahoo_symbol': 'UNH', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'HD', 'stock_name': 'Home Depot Inc.', 'market': 'NYSE', 'yahoo_symbol': 'HD', 'industry': 'Consumer Discretionary'},\n",
        "            {'stock_id': 'MA', 'stock_name': 'Mastercard Inc.', 'market': 'NYSE', 'yahoo_symbol': 'MA', 'industry': 'Financial Services'},\n",
        "\n",
        "            # å·¥æ¥­è‚¡\n",
        "            {'stock_id': 'BA', 'stock_name': 'Boeing Co.', 'market': 'NYSE', 'yahoo_symbol': 'BA', 'industry': 'Industrials'},\n",
        "            {'stock_id': 'CAT', 'stock_name': 'Caterpillar Inc.', 'market': 'NYSE', 'yahoo_symbol': 'CAT', 'industry': 'Industrials'},\n",
        "            {'stock_id': 'MMM', 'stock_name': '3M Co.', 'market': 'NYSE', 'yahoo_symbol': 'MMM', 'industry': 'Industrials'},\n",
        "            {'stock_id': 'GE', 'stock_name': 'General Electric Co.', 'market': 'NYSE', 'yahoo_symbol': 'GE', 'industry': 'Industrials'},\n",
        "\n",
        "            # èƒ½æºè‚¡\n",
        "            {'stock_id': 'XOM', 'stock_name': 'Exxon Mobil Corporation', 'market': 'NYSE', 'yahoo_symbol': 'XOM', 'industry': 'Energy'},\n",
        "            {'stock_id': 'CVX', 'stock_name': 'Chevron Corporation', 'market': 'NYSE', 'yahoo_symbol': 'CVX', 'industry': 'Energy'},\n",
        "\n",
        "            # é‡‘èè‚¡\n",
        "            {'stock_id': 'BAC', 'stock_name': 'Bank of America Corp.', 'market': 'NYSE', 'yahoo_symbol': 'BAC', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'WFC', 'stock_name': 'Wells Fargo & Co.', 'market': 'NYSE', 'yahoo_symbol': 'WFC', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'GS', 'stock_name': 'Goldman Sachs Group Inc.', 'market': 'NYSE', 'yahoo_symbol': 'GS', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'MS', 'stock_name': 'Morgan Stanley', 'market': 'NYSE', 'yahoo_symbol': 'MS', 'industry': 'Financial Services'},\n",
        "\n",
        "            # æ¶ˆè²»è‚¡\n",
        "            {'stock_id': 'KO', 'stock_name': 'Coca-Cola Co.', 'market': 'NYSE', 'yahoo_symbol': 'KO', 'industry': 'Consumer Staples'},\n",
        "            {'stock_id': 'PEP', 'stock_name': 'PepsiCo Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'PEP', 'industry': 'Consumer Staples'},\n",
        "            {'stock_id': 'WMT', 'stock_name': 'Walmart Inc.', 'market': 'NYSE', 'yahoo_symbol': 'WMT', 'industry': 'Consumer Staples'},\n",
        "            {'stock_id': 'MCD', 'stock_name': 'McDonald\\'s Corp.', 'market': 'NYSE', 'yahoo_symbol': 'MCD', 'industry': 'Consumer Discretionary'},\n",
        "\n",
        "            # é†«ç™‚ä¿å¥è‚¡\n",
        "            {'stock_id': 'PFE', 'stock_name': 'Pfizer Inc.', 'market': 'NYSE', 'yahoo_symbol': 'PFE', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'ABBV', 'stock_name': 'AbbVie Inc.', 'market': 'NYSE', 'yahoo_symbol': 'ABBV', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'MRK', 'stock_name': 'Merck & Co. Inc.', 'market': 'NYSE', 'yahoo_symbol': 'MRK', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'LLY', 'stock_name': 'Eli Lilly and Co.', 'market': 'NYSE', 'yahoo_symbol': 'LLY', 'industry': 'Healthcare'},\n",
        "\n",
        "            # é€šä¿¡è‚¡\n",
        "            {'stock_id': 'T', 'stock_name': 'AT&T Inc.', 'market': 'NYSE', 'yahoo_symbol': 'T', 'industry': 'Communication Services'},\n",
        "            {'stock_id': 'VZ', 'stock_name': 'Verizon Communications Inc.', 'market': 'NYSE', 'yahoo_symbol': 'VZ', 'industry': 'Communication Services'},\n",
        "\n",
        "            # åŠå°é«”è‚¡\n",
        "            {'stock_id': 'AMD', 'stock_name': 'Advanced Micro Devices Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'AMD', 'industry': 'Technology'},\n",
        "            {'stock_id': 'INTC', 'stock_name': 'Intel Corporation', 'market': 'NASDAQ', 'yahoo_symbol': 'INTC', 'industry': 'Technology'},\n",
        "            {'stock_id': 'QCOM', 'stock_name': 'Qualcomm Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'QCOM', 'industry': 'Technology'},\n",
        "\n",
        "            # å…¶ä»–çŸ¥åç§‘æŠ€è‚¡\n",
        "            {'stock_id': 'CRM', 'stock_name': 'Salesforce Inc.', 'market': 'NYSE', 'yahoo_symbol': 'CRM', 'industry': 'Technology'},\n",
        "            {'stock_id': 'ORCL', 'stock_name': 'Oracle Corporation', 'market': 'NYSE', 'yahoo_symbol': 'ORCL', 'industry': 'Technology'},\n",
        "            {'stock_id': 'ADBE', 'stock_name': 'Adobe Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'ADBE', 'industry': 'Technology'},\n",
        "            {'stock_id': 'PYPL', 'stock_name': 'PayPal Holdings Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'PYPL', 'industry': 'Financial Services'},\n",
        "\n",
        "            # é›»å‹•è»Šç›¸é—œ\n",
        "            {'stock_id': 'NIO', 'stock_name': 'NIO Inc.', 'market': 'NYSE', 'yahoo_symbol': 'NIO', 'industry': 'Consumer Discretionary'},\n",
        "            {'stock_id': 'RIVN', 'stock_name': 'Rivian Automotive Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'RIVN', 'industry': 'Consumer Discretionary'},\n",
        "\n",
        "            # æ–°èˆˆç§‘æŠ€è‚¡\n",
        "            {'stock_id': 'PLTR', 'stock_name': 'Palantir Technologies Inc.', 'market': 'NYSE', 'yahoo_symbol': 'PLTR', 'industry': 'Technology'},\n",
        "            {'stock_id': 'SNOW', 'stock_name': 'Snowflake Inc.', 'market': 'NYSE', 'yahoo_symbol': 'SNOW', 'industry': 'Technology'},\n",
        "            ]\n",
        "\n",
        "            df = pd.DataFrame(famous_us_stocks)\n",
        "            logger.info(f\"å‚™ç”¨ç¾è‚¡æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨ç¾è‚¡æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_info.get('stock_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_us_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºå‰ååï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ† ç¾è‚¡æŠ€è¡“åˆ†æ - å‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºå‰ååå„ªè³ªè‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† å‰ {len(top_stocks)} åå„ªè³ªè‚¡ç¥¨:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\" if price_change < 0 else \"â¡ï¸\"\n",
        "\n",
        "            # å»ºè­°ç¬¦è™Ÿ\n",
        "            rec_symbol = \"ğŸš€\" if \"å¼·åŠ›è²·\" in rec_text else \"ğŸ“ˆ\" if \"è²·\" in rec_text else \"ğŸ“Š\" if \"æŒæœ‰\" in rec_text else \"ğŸ“‰\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {stock_name} ({stock_id})\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f} ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   â­ è©•åˆ†: {score:.1f}/100\")\n",
        "            message_parts.append(f\"   {rec_symbol} å»ºè­°: {rec_text}\")\n",
        "            message_parts.append(f\"   ğŸ“Š æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # æ·»åŠ ä¸»è¦æŠ€è¡“æŒ‡æ¨™\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            rsi_value = tech.get('rsi_value', 50)\n",
        "            macd_signal = tech.get('macd_signal', 'ä¸­æ€§')\n",
        "            message_parts.append(f\"   ğŸ” RSI: {rsi_value:.1f} | MACD: {macd_signal}\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_score = sum(r.get('combined_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('combined_score', 0) >= 70])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ“Š å¹³å‡åˆ†æ•¸: {avg_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†è‚¡ç¥¨ (â‰¥70): {high_score_count}\")\n",
        "\n",
        "            # å»ºè­°åˆ†å¸ƒ\n",
        "            recommendations = {}\n",
        "            for result in top_stocks:\n",
        "                rec = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "                recommendations[rec] = recommendations.get(rec, 0) + 1\n",
        "\n",
        "            if recommendations:\n",
        "                message_parts.append(\"   ğŸ“ˆ å‰ååå»ºè­°åˆ†å¸ƒ:\")\n",
        "                for rec, count in recommendations.items():\n",
        "                    message_parts.append(f\"      {rec}: {count}\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        message_parts.append(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ† ç¾è‚¡æŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{score:<8.1f}{current_price:<10.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {stock_name} ({stock_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† ç¾è‚¡åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ ç¾è‚¡æŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰ç¾è‚¡ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DksukWJ0S61E"
      },
      "source": [
        "ä¸Šé¢æ˜¯ç¾è‚¡ç¯©é¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoUaEt1wTCMp",
        "outputId": "8461e726-ef3a-4fc9-a95c-d35be79d9873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ ç¾è‚¡ETFæŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\n",
            "â° é–‹å§‹æ™‚é–“: 2025-08-13 10:44:26\n",
            "ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\n",
            "ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªç¾è‚¡ETF/æœŸè²¨/è²´é‡‘å±¬\n",
            "ğŸ“Š æ¶µè“‹: ETFã€æ§“æ¡¿ETFã€åå‘ETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰\n",
            "======================================================================\n",
            "ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰ç¾è‚¡ETF/æœŸè²¨/è²´é‡‘å±¬ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:HTTP Error 401: \n",
            "ERROR:yfinance:$UGLD: possibly delisted; no price data found  (period=5d)\n",
            "WARNING:__main__:âœ— UGLD ç„¡æ•¸æ“š\n",
            "ERROR:yfinance:$DGLD: possibly delisted; no price data found  (period=5d)\n",
            "WARNING:__main__:âœ— DGLD ç„¡æ•¸æ“š\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "                                      ğŸ† ç¾è‚¡ETFæŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªæ¨™çš„                                       \n",
            "====================================================================================================\n",
            "ğŸ“ˆ åˆ†ææ™‚é–“: 2025-08-13 10:45:10\n",
            "ğŸ“Š æˆåŠŸåˆ†æ: 71 æ”¯ETF/æœŸè²¨/è²´é‡‘å±¬\n",
            "ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\n",
            "====================================================================================================\n",
            "æ’å  ä»£ç¢¼      æ¨™çš„åç¨±                é¡åˆ¥             è©•åˆ†      åƒ¹æ ¼        æ¼²è·Œ%     å»ºè­°        æˆäº¤é‡(å¼µ)      \n",
            "----------------------------------------------------------------------------------------------------\n",
            "1   FNGU    Bank Of Montreal M  3å€æ§“æ¡¿ETF        69.0    $26.41    +10.18  è²·é€²        5394        \n",
            "2   XLY     The Consumer Discr  éå¿…éœ€æ¶ˆè²»ETF       65.0    $226.74   +3.58   è²·é€²        6021        \n",
            "3   TQQQ    ProShares UltraPro  3å€æ§“æ¡¿ETF        61.5    $94.72    +10.60  è²·é€²        61980       \n",
            "4   SVXY    ProShares Short VI  åå‘æ³¢å‹•ç‡ETF       60.5    $46.95    +4.87   è²·é€²        1437        \n",
            "5   QQQ     Invesco QQQ Trust   ç§‘æŠ€æŒ‡æ•¸ETF        58.5    $580.05   +3.53   æŒæœ‰        44338       \n",
            "6   VEA     Vanguard FTSE Deve  å·²é–‹ç™¼å¸‚å ´ETF       57.5    $58.44    +2.71   æŒæœ‰        11118       \n",
            "7   UPRO    ProShares UltraPro  3å€æ§“æ¡¿ETF        57.5    $101.21   +6.84   æŒæœ‰        5197        \n",
            "8   SPXL    Direxion Daily S&P  3å€æ§“æ¡¿ETF        57.5    $192.15   +6.85   æŒæœ‰        2742        \n",
            "9   EFA     iShares MSCI EAFE   æ­æ¾³é æ±ETF        57.5    $91.09    +3.00   æŒæœ‰        13359       \n",
            "10  ICLN    iShares Global Cle  æ¸…æ½”èƒ½æºETF        57.0    $13.77    +1.32   æŒæœ‰        3059        \n",
            "====================================================================================================\n",
            "\n",
            "ğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\n",
            "====================================================================================================\n",
            "\n",
            "1. Bank Of Montreal MicroSectors F (FNGU) - è©•åˆ†: 69.0\n",
            "   ğŸ·ï¸ é¡åˆ¥: 3å€æ§“æ¡¿ETF\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: $26.41\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +10.18%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 61.8 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=68.5, D=59.7\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 5394å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "2. The Consumer Discretionary Select Sector SPDR Fund (XLY) - è©•åˆ†: 65.0\n",
            "   ğŸ·ï¸ é¡åˆ¥: éå¿…éœ€æ¶ˆè²»ETF\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: $226.74\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +3.58%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 50.3 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=81.1, D=74.4\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 6021å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "3. ProShares UltraPro QQQ (TQQQ) - è©•åˆ†: 61.5\n",
            "   ğŸ·ï¸ é¡åˆ¥: 3å€æ§“æ¡¿ETF\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: $94.72\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +10.60%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 63.0 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=92.2, D=84.2\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 61980å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "4. ProShares Short VIX Short-Term Futures ETF (SVXY) - è©•åˆ†: 60.5\n",
            "   ğŸ·ï¸ é¡åˆ¥: åå‘æ³¢å‹•ç‡ETF\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: $46.95\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +4.87%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: è²·é€²\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­é«˜\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 61.3 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=92.0, D=83.2\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: å¼·å‹¢ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 1437å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šå¼·å‹¢ä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "5. Invesco QQQ Trust (QQQ) - è©•åˆ†: 58.5\n",
            "   ğŸ·ï¸ é¡åˆ¥: ç§‘æŠ€æŒ‡æ•¸ETF\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: $580.05\n",
            "ğŸ“ˆ 5æ—¥æ¼²è·Œ: +3.53%\n",
            "ğŸ¯ æŠ•è³‡å»ºè­°: æŒæœ‰\n",
            "ğŸ“Š ä¿¡å¿ƒåº¦: ä¸­ç­‰\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 64.2 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   KD: K=94.1, D=87.3\n",
            "ğŸ“Š è¶¨å‹¢åˆ†æ: ä¸Šæ¼²\n",
            "ğŸ“ˆ æˆäº¤é‡: 44338å¼µ/æ—¥ (æ­£å¸¸)\n",
            "ğŸ’¡ å»ºè­°åŸå› : åƒ¹æ ¼è¶¨å‹¢ï¼šä¸Šæ¼², MACDå‡ºç¾é»ƒé‡‘äº¤å‰\n",
            "\n",
            "====================================================================================================\n",
            "ğŸ“Š é¡åˆ¥çµ±è¨ˆåˆ†æ:\n",
            "é¡åˆ¥                  æ•¸é‡      å¹³å‡åˆ†æ•¸        æœ€é«˜åˆ†       \n",
            "--------------------------------------------------\n",
            "éå¿…éœ€æ¶ˆè²»ETF            1       65.0        65.0      \n",
            "åå‘æ³¢å‹•ç‡ETF            1       60.5        60.5      \n",
            "ç§‘æŠ€æŒ‡æ•¸ETF             1       58.5        58.5      \n",
            "å·²é–‹ç™¼å¸‚å ´ETF            1       57.5        57.5      \n",
            "æ­æ¾³é æ±ETF             1       57.5        57.5      \n",
            "3å€æ§“æ¡¿ETF             8       57.1        69.0      \n",
            "æ¸…æ½”èƒ½æºETF             1       57.0        57.0      \n",
            "å‰µæ–°ç§‘æŠ€ETF             1       56.0        56.0      \n",
            "ä¸­åœ‹ETF               1       56.0        56.0      \n",
            "å°åº¦ETF               1       55.0        55.0      \n",
            "æ—¥æœ¬ETF               1       55.0        55.0      \n",
            "æ¯”ç‰¹å¹£æœŸè²¨ETF            1       55.0        55.0      \n",
            "ç™½éŠ€ç¤¦æ¥­ETF             1       54.0        54.0      \n",
            "å°å‹è‚¡ETF              1       53.5        53.5      \n",
            "é»ƒé‡‘ç¤¦æ¥­ETF             1       53.0        53.0      \n",
            "å°å‹é»ƒé‡‘ç¤¦æ¥­ETF           1       53.0        53.0      \n",
            "å¤§ç›¤æŒ‡æ•¸ETF             2       52.5        52.5      \n",
            "å…¨å¸‚å ´ETF              1       52.5        52.5      \n",
            "æ–°èˆˆå¸‚å ´ETF             2       52.5        52.5      \n",
            "èƒ½æºæ¥­ETF              1       52.5        52.5      \n",
            "ç§‘æŠ€æ¥­ETF              1       52.5        52.5      \n",
            "æˆ¿åœ°ç”¢ETF              3       52.0        55.0      \n",
            "ç¶œåˆå‚µåˆ¸ETF             1       52.0        52.0      \n",
            "åŸºå› ç§‘æŠ€ETF             1       51.5        51.5      \n",
            "ä¸­æœŸåœ‹å‚µETF             1       51.0        51.0      \n",
            "é•·æœŸåœ‹å‚µETF             1       51.0        51.0      \n",
            "æŠ•è³‡ç´šå‚µåˆ¸ETF            1       51.0        51.0      \n",
            "é»ƒé‡‘ETF               2       51.0        51.0      \n",
            "3å€æ§“æ¡¿å‚µåˆ¸ETF           1       51.0        51.0      \n",
            "å¿…éœ€æ¶ˆè²»ETF             1       51.0        51.0      \n",
            "å·´è¥¿ETF               1       51.0        51.0      \n",
            "é“ç“ŠæŒ‡æ•¸ETF             1       50.0        50.0      \n",
            "2å€åå‘åŸæ²¹ETF           1       50.0        50.0      \n",
            "é‡‘èæ¥­ETF              1       49.0        49.0      \n",
            "é†«ç™‚ä¿å¥ETF             1       49.0        49.0      \n",
            "åŸææ–™ETF              1       49.0        49.0      \n",
            "å·¥æ¥­ETF               1       49.0        49.0      \n",
            "ä¸­åœ‹ç¶²è·¯ETF             1       49.0        49.0      \n",
            "åŠå°é«”ETF              1       48.5        48.5      \n",
            "èˆªç©ºæ¥­ETF              1       48.5        48.5      \n",
            "3å€åå‘ETF             6       48.2        51.0      \n",
            "åŸæ²¹æœŸè²¨ETF             1       48.0        48.0      \n",
            "ç¾å…ƒæŒ‡æ•¸ETF             1       48.0        48.0      \n",
            "é«˜æ”¶ç›Šå‚µåˆ¸ETF            1       47.5        47.5      \n",
            "ä¸­åœ‹å¤§å‹è‚¡ETF            1       47.0        47.0      \n",
            "2å€æ§“æ¡¿åŸæ²¹ETF           1       46.0        46.0      \n",
            "ç™½éŠ€ETF               1       45.0        45.0      \n",
            "åå‘æ¯”ç‰¹å¹£æœŸè²¨ETF          1       45.0        45.0      \n",
            "çŸ­æœŸåœ‹å‚µETF             1       42.5        42.5      \n",
            "æ³¢å‹•ç‡ETF              3       39.5        40.5      \n",
            "å…¬ç”¨äº‹æ¥­ETF             1       38.5        38.5      \n",
            "å¤©ç„¶æ°£æœŸè²¨ETF            1       34.0        34.0      \n",
            "\n",
            "====================================================================================================\n",
            "âš ï¸  æŠ•è³‡æé†’:\n",
            "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\n",
            "â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºæ¨™çš„\n",
            "â€¢ åŒ…å«ETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰å¤šå…ƒåŒ–æŠ•è³‡å·¥å…·\n",
            "â€¢ æ§“æ¡¿ETFå’Œåå‘ETFå…·æœ‰è¼ƒé«˜é¢¨éšªï¼Œè«‹è¬¹æ…æ“ä½œ\n",
            "â€¢ æœŸè²¨å•†å“æ³¢å‹•è¼ƒå¤§ï¼Œé©åˆæœ‰ç¶“é©—çš„æŠ•è³‡è€…\n",
            "â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\n",
            "â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\n",
            "====================================================================================================\n",
            "\n",
            "ğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\n",
            "ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\n",
            "\n",
            "â° ç¨‹å¼åŸ·è¡Œå®Œæˆ: 2025-08-13 10:45:12\n",
            "======================================================================\n",
            "âœ… ç¾è‚¡ETFåˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\n",
            "ğŸ† å‰ååå„ªè³ªæ¨™çš„å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\n",
            "ğŸ“Š æ¶µè“‹å¤šç¨®æŠ•è³‡å·¥å…·ï¼šETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "class USETFAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–ç¾è‚¡ETFåˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.us_etfs = None\n",
        "        self.etf_list_path = \"us_etfs_cache.csv\"\n",
        "\n",
        "    def _get_comprehensive_us_etf_list(self) -> pd.DataFrame:\n",
        "        \"\"\"ç²å–å®Œæ•´ç¾è‚¡ETFæ¸…å–® - åŒ…å«å„é¡å‹ETFå’ŒæœŸè²¨\"\"\"\n",
        "        try:\n",
        "            logger.info(\"å»ºç«‹å®Œæ•´ç¾è‚¡ETF/æœŸè²¨/è²´é‡‘å±¬æ¸…å–®...\")\n",
        "\n",
        "            # å®Œæ•´ç¾è‚¡ETFå’ŒæœŸè²¨åˆ—è¡¨\n",
        "            us_etfs = [\n",
        "                # å¤§ç›¤æŒ‡æ•¸ETF\n",
        "                {'etf_id': 'SPY', 'etf_name': 'SPDR S&P 500 ETF Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'SPY', 'category': 'å¤§ç›¤æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'QQQ', 'etf_name': 'Invesco QQQ Trust', 'market': 'NASDAQ', 'yahoo_symbol': 'QQQ', 'category': 'ç§‘æŠ€æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'IWM', 'etf_name': 'iShares Russell 2000 ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'IWM', 'category': 'å°å‹è‚¡ETF'},\n",
        "                {'etf_id': 'VTI', 'etf_name': 'Vanguard Total Stock Market ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VTI', 'category': 'å…¨å¸‚å ´ETF'},\n",
        "                {'etf_id': 'VOO', 'etf_name': 'Vanguard S&P 500 ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VOO', 'category': 'å¤§ç›¤æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'DIA', 'etf_name': 'SPDR Dow Jones Industrial Average ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'DIA', 'category': 'é“ç“ŠæŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'VEA', 'etf_name': 'Vanguard FTSE Developed Markets ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VEA', 'category': 'å·²é–‹ç™¼å¸‚å ´ETF'},\n",
        "                {'etf_id': 'VWO', 'etf_name': 'Vanguard FTSE Emerging Markets ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VWO', 'category': 'æ–°èˆˆå¸‚å ´ETF'},\n",
        "\n",
        "                # æ§“æ¡¿ETF\n",
        "                {'etf_id': 'TQQQ', 'etf_name': 'ProShares UltraPro QQQ', 'market': 'NASDAQ', 'yahoo_symbol': 'TQQQ', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'UPRO', 'etf_name': 'ProShares UltraPro S&P500', 'market': 'NYSE Arca', 'yahoo_symbol': 'UPRO', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'SPXL', 'etf_name': 'Direxion Daily S&P 500 Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'SPXL', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'TNA', 'etf_name': 'Direxion Daily Small Cap Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TNA', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'TECL', 'etf_name': 'Direxion Daily Technology Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TECL', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'SOXL', 'etf_name': 'Direxion Daily Semiconductor Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'SOXL', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'LABU', 'etf_name': 'Direxion Daily S&P Biotech Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'LABU', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'FNGU', 'etf_name': 'MicroSectors FANG+ Index 3X Leveraged ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'FNGU', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "\n",
        "                # åå‘ETF\n",
        "                {'etf_id': 'SQQQ', 'etf_name': 'ProShares UltraPro Short QQQ', 'market': 'NASDAQ', 'yahoo_symbol': 'SQQQ', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'SPXS', 'etf_name': 'Direxion Daily S&P 500 Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'SPXS', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'TZA', 'etf_name': 'Direxion Daily Small Cap Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TZA', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'SOXS', 'etf_name': 'Direxion Daily Semiconductor Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'SOXS', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'LABD', 'etf_name': 'Direxion Daily S&P Biotech Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'LABD', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'FNGD', 'etf_name': 'MicroSectors FANG+ Index -3X Inverse Leveraged ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'FNGD', 'category': '3å€åå‘ETF'},\n",
        "\n",
        "                # æ³¢å‹•ç‡ETF\n",
        "                {'etf_id': 'UVXY', 'etf_name': 'ProShares Ultra VIX Short-Term Futures ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'UVXY', 'category': 'æ³¢å‹•ç‡ETF'},\n",
        "                {'etf_id': 'VXX', 'etf_name': 'iPath Series B S&P 500 VIX Short-Term Futures ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'VXX', 'category': 'æ³¢å‹•ç‡ETF'},\n",
        "                {'etf_id': 'SVXY', 'etf_name': 'ProShares Short VIX Short-Term Futures ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'SVXY', 'category': 'åå‘æ³¢å‹•ç‡ETF'},\n",
        "                {'etf_id': 'VIXY', 'etf_name': 'ProShares VIX Short-Term Futures ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VIXY', 'category': 'æ³¢å‹•ç‡ETF'},\n",
        "\n",
        "                # å‚µåˆ¸ETF\n",
        "                {'etf_id': 'TLT', 'etf_name': 'iShares 20+ Year Treasury Bond ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'TLT', 'category': 'é•·æœŸåœ‹å‚µETF'},\n",
        "                {'etf_id': 'IEF', 'etf_name': 'iShares 7-10 Year Treasury Bond ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'IEF', 'category': 'ä¸­æœŸåœ‹å‚µETF'},\n",
        "                {'etf_id': 'SHY', 'etf_name': 'iShares 1-3 Year Treasury Bond ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'SHY', 'category': 'çŸ­æœŸåœ‹å‚µETF'},\n",
        "                {'etf_id': 'HYG', 'etf_name': 'iShares iBoxx $ High Yield Corporate Bond ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'HYG', 'category': 'é«˜æ”¶ç›Šå‚µåˆ¸ETF'},\n",
        "                {'etf_id': 'LQD', 'etf_name': 'iShares iBoxx $ Investment Grade Corporate Bond ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'LQD', 'category': 'æŠ•è³‡ç´šå‚µåˆ¸ETF'},\n",
        "                {'etf_id': 'AGG', 'etf_name': 'iShares Core U.S. Aggregate Bond ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'AGG', 'category': 'ç¶œåˆå‚µåˆ¸ETF'},\n",
        "                {'etf_id': 'TMF', 'etf_name': 'Direxion Daily 20+ Year Treasury Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TMF', 'category': '3å€æ§“æ¡¿å‚µåˆ¸ETF'},\n",
        "                {'etf_id': 'TMV', 'etf_name': 'Direxion Daily 20+ Year Treasury Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TMV', 'category': '3å€åå‘å‚µåˆ¸ETF'},\n",
        "\n",
        "                # è²´é‡‘å±¬ETF\n",
        "                {'etf_id': 'GLD', 'etf_name': 'SPDR Gold Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'GLD', 'category': 'é»ƒé‡‘ETF'},\n",
        "                {'etf_id': 'SLV', 'etf_name': 'iShares Silver Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'SLV', 'category': 'ç™½éŠ€ETF'},\n",
        "                {'etf_id': 'PPLT', 'etf_name': 'abrdn Physical Platinum Shares ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'PPLT', 'category': 'é‰‘é‡‘ETF'},\n",
        "                {'etf_id': 'PALL', 'etf_name': 'abrdn Physical Palladium Shares ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'PALL', 'category': 'éˆ€é‡‘ETF'},\n",
        "                {'etf_id': 'IAU', 'etf_name': 'iShares Gold Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'IAU', 'category': 'é»ƒé‡‘ETF'},\n",
        "                {'etf_id': 'UGLD', 'etf_name': 'VelocityShares 3x Long Gold ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'UGLD', 'category': '3å€æ§“æ¡¿é»ƒé‡‘ETF'},\n",
        "                {'etf_id': 'DGLD', 'etf_name': 'VelocityShares 3x Inverse Gold ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'DGLD', 'category': '3å€åå‘é»ƒé‡‘ETF'},\n",
        "\n",
        "                # è²´é‡‘å±¬æœŸè²¨\n",
        "                {'etf_id': 'GC=F', 'etf_name': 'Gold Futures', 'market': 'COMEX', 'yahoo_symbol': 'GC=F', 'category': 'é»ƒé‡‘æœŸè²¨'},\n",
        "                {'etf_id': 'SI=F', 'etf_name': 'Silver Futures', 'market': 'COMEX', 'yahoo_symbol': 'SI=F', 'category': 'ç™½éŠ€æœŸè²¨'},\n",
        "                {'etf_id': 'PL=F', 'etf_name': 'Platinum Futures', 'market': 'NYMEX', 'yahoo_symbol': 'PL=F', 'category': 'é‰‘é‡‘æœŸè²¨'},\n",
        "                {'etf_id': 'PA=F', 'etf_name': 'Palladium Futures', 'market': 'NYMEX', 'yahoo_symbol': 'PA=F', 'category': 'éˆ€é‡‘æœŸè²¨'},\n",
        "\n",
        "                # èƒ½æºæœŸè²¨\n",
        "                {'etf_id': 'CL=F', 'etf_name': 'Crude Oil Futures', 'market': 'NYMEX', 'yahoo_symbol': 'CL=F', 'category': 'åŸæ²¹æœŸè²¨'},\n",
        "                {'etf_id': 'NG=F', 'etf_name': 'Natural Gas Futures', 'market': 'NYMEX', 'yahoo_symbol': 'NG=F', 'category': 'å¤©ç„¶æ°£æœŸè²¨'},\n",
        "                {'etf_id': 'RB=F', 'etf_name': 'Gasoline Futures', 'market': 'NYMEX', 'yahoo_symbol': 'RB=F', 'category': 'æ±½æ²¹æœŸè²¨'},\n",
        "                {'etf_id': 'HO=F', 'etf_name': 'Heating Oil Futures', 'market': 'NYMEX', 'yahoo_symbol': 'HO=F', 'category': 'ç‡ƒæ²¹æœŸè²¨'},\n",
        "\n",
        "                # åŸç‰©æ–™æœŸè²¨ETF\n",
        "                {'etf_id': 'USO', 'etf_name': 'United States Oil Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'USO', 'category': 'åŸæ²¹æœŸè²¨ETF'},\n",
        "                {'etf_id': 'UNG', 'etf_name': 'United States Natural Gas Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'UNG', 'category': 'å¤©ç„¶æ°£æœŸè²¨ETF'},\n",
        "                {'etf_id': 'DBA', 'etf_name': 'Invesco DB Agriculture Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'DBA', 'category': 'è¾²ç”¢å“æœŸè²¨ETF'},\n",
        "                {'etf_id': 'DBC', 'etf_name': 'Invesco DB Commodity Index Tracking Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'DBC', 'category': 'å•†å“æœŸè²¨ETF'},\n",
        "                {'etf_id': 'DBB', 'etf_name': 'Invesco DB Base Metals Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'DBB', 'category': 'åŸºæœ¬é‡‘å±¬æœŸè²¨ETF'},\n",
        "                {'etf_id': 'CORN', 'etf_name': 'Teucrium Corn Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'CORN', 'category': 'ç‰ç±³æœŸè²¨ETF'},\n",
        "                {'etf_id': 'WEAT', 'etf_name': 'Teucrium Wheat Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'WEAT', 'category': 'å°éº¥æœŸè²¨ETF'},\n",
        "                {'etf_id': 'SOYB', 'etf_name': 'Teucrium Soybean Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'SOYB', 'category': 'å¤§è±†æœŸè²¨ETF'},\n",
        "                {'etf_id': 'UCO', 'etf_name': 'ProShares Ultra Bloomberg Crude Oil', 'market': 'NYSE Arca', 'yahoo_symbol': 'UCO', 'category': '2å€æ§“æ¡¿åŸæ²¹ETF'},\n",
        "                {'etf_id': 'SCO', 'etf_name': 'ProShares UltraShort Bloomberg Crude Oil', 'market': 'NYSE Arca', 'yahoo_symbol': 'SCO', 'category': '2å€åå‘åŸæ²¹ETF'},\n",
        "\n",
        "                # è¾²ç”¢å“æœŸè²¨\n",
        "                {'etf_id': 'ZC=F', 'etf_name': 'Corn Futures', 'market': 'CBOT', 'yahoo_symbol': 'ZC=F', 'category': 'ç‰ç±³æœŸè²¨'},\n",
        "                {'etf_id': 'ZS=F', 'etf_name': 'Soybean Futures', 'market': 'CBOT', 'yahoo_symbol': 'ZS=F', 'category': 'å¤§è±†æœŸè²¨'},\n",
        "                {'etf_id': 'ZW=F', 'etf_name': 'Wheat Futures', 'market': 'CBOT', 'yahoo_symbol': 'ZW=F', 'category': 'å°éº¥æœŸè²¨'},\n",
        "                {'etf_id': 'CT=F', 'etf_name': 'Cotton Futures', 'market': 'ICE', 'yahoo_symbol': 'CT=F', 'category': 'æ£‰èŠ±æœŸè²¨'},\n",
        "                {'etf_id': 'SB=F', 'etf_name': 'Sugar Futures', 'market': 'ICE', 'yahoo_symbol': 'SB=F', 'category': 'ç³–æœŸè²¨'},\n",
        "                {'etf_id': 'KC=F', 'etf_name': 'Coffee Futures', 'market': 'ICE', 'yahoo_symbol': 'KC=F', 'category': 'å’–å•¡æœŸè²¨'},\n",
        "                {'etf_id': 'CC=F', 'etf_name': 'Cocoa Futures', 'market': 'ICE', 'yahoo_symbol': 'CC=F', 'category': 'å¯å¯æœŸè²¨'},\n",
        "\n",
        "                # å·¥æ¥­é‡‘å±¬æœŸè²¨\n",
        "                {'etf_id': 'HG=F', 'etf_name': 'Copper Futures', 'market': 'COMEX', 'yahoo_symbol': 'HG=F', 'category': 'éŠ…æœŸè²¨'},\n",
        "\n",
        "                # ç”¢æ¥­é¡ETF\n",
        "                {'etf_id': 'XLF', 'etf_name': 'Financial Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLF', 'category': 'é‡‘èæ¥­ETF'},\n",
        "                {'etf_id': 'XLE', 'etf_name': 'Energy Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLE', 'category': 'èƒ½æºæ¥­ETF'},\n",
        "                {'etf_id': 'XLK', 'etf_name': 'Technology Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLK', 'category': 'ç§‘æŠ€æ¥­ETF'},\n",
        "                {'etf_id': 'XLV', 'etf_name': 'Health Care Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLV', 'category': 'é†«ç™‚ä¿å¥ETF'},\n",
        "                {'etf_id': 'XLI', 'etf_name': 'Industrial Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLI', 'category': 'å·¥æ¥­ETF'},\n",
        "                {'etf_id': 'XLY', 'etf_name': 'Consumer Discretionary Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLY', 'category': 'éå¿…éœ€æ¶ˆè²»ETF'},\n",
        "                {'etf_id': 'XLP', 'etf_name': 'Consumer Staples Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLP', 'category': 'å¿…éœ€æ¶ˆè²»ETF'},\n",
        "                {'etf_id': 'XLU', 'etf_name': 'Utilities Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLU', 'category': 'å…¬ç”¨äº‹æ¥­ETF'},\n",
        "                {'etf_id': 'XLB', 'etf_name': 'Materials Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLB', 'category': 'åŸææ–™ETF'},\n",
        "                {'etf_id': 'XLRE', 'etf_name': 'Real Estate Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLRE', 'category': 'æˆ¿åœ°ç”¢ETF'},\n",
        "                {'etf_id': 'SOXX', 'etf_name': 'iShares Semiconductor ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'SOXX', 'category': 'åŠå°é«”ETF'},\n",
        "\n",
        "                # åœ‹éš›å¸‚å ´ETF\n",
        "                {'etf_id': 'EEM', 'etf_name': 'iShares MSCI Emerging Markets ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'EEM', 'category': 'æ–°èˆˆå¸‚å ´ETF'},\n",
        "                {'etf_id': 'EFA', 'etf_name': 'iShares MSCI EAFE ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'EFA', 'category': 'æ­æ¾³é æ±ETF'},\n",
        "                {'etf_id': 'FXI', 'etf_name': 'iShares China Large-Cap ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'FXI', 'category': 'ä¸­åœ‹å¤§å‹è‚¡ETF'},\n",
        "                {'etf_id': 'EWJ', 'etf_name': 'iShares MSCI Japan ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'EWJ', 'category': 'æ—¥æœ¬ETF'},\n",
        "                {'etf_id': 'EWZ', 'etf_name': 'iShares MSCI Brazil ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'EWZ', 'category': 'å·´è¥¿ETF'},\n",
        "                {'etf_id': 'INDA', 'etf_name': 'iShares MSCI India ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'INDA', 'category': 'å°åº¦ETF'},\n",
        "                {'etf_id': 'RSX', 'etf_name': 'VanEck Russia ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'RSX', 'category': 'ä¿„ç¾…æ–¯ETF'},\n",
        "\n",
        "                # æˆ¿åœ°ç”¢ETF\n",
        "                {'etf_id': 'VNQ', 'etf_name': 'Vanguard Real Estate ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VNQ', 'category': 'æˆ¿åœ°ç”¢ETF'},\n",
        "                {'etf_id': 'IYR', 'etf_name': 'iShares U.S. Real Estate ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'IYR', 'category': 'æˆ¿åœ°ç”¢ETF'},\n",
        "\n",
        "                # åŠ å¯†è²¨å¹£ç›¸é—œETF\n",
        "                {'etf_id': 'BITO', 'etf_name': 'ProShares Bitcoin Strategy ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'BITO', 'category': 'æ¯”ç‰¹å¹£æœŸè²¨ETF'},\n",
        "                {'etf_id': 'BITI', 'etf_name': 'ProShares Short Bitcoin Strategy ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'BITI', 'category': 'åå‘æ¯”ç‰¹å¹£æœŸè²¨ETF'},\n",
        "\n",
        "                # å‰µæ–°ç§‘æŠ€ETF\n",
        "                {'etf_id': 'ARKK', 'etf_name': 'ARK Innovation ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'ARKK', 'category': 'å‰µæ–°ç§‘æŠ€ETF'},\n",
        "                {'etf_id': 'ARKQ', 'etf_name': 'ARK Autonomous Technology & Robotics ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'ARKQ', 'category': 'è‡ªå‹•åŒ–ç§‘æŠ€ETF'},\n",
        "                {'etf_id': 'ARKW', 'etf_name': 'ARK Next Generation Internet ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'ARKW', 'category': 'ç¶²è·¯ç§‘æŠ€ETF'},\n",
        "                {'etf_id': 'ARKG', 'etf_name': 'ARK Genomic Revolution ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'ARKG', 'category': 'åŸºå› ç§‘æŠ€ETF'},\n",
        "\n",
        "                # æ³¢å‹•ç‡æŒ‡æ•¸\n",
        "                {'etf_id': 'VIX', 'etf_name': 'CBOE Volatility Index', 'market': 'CBOE', 'yahoo_symbol': '^VIX', 'category': 'æ³¢å‹•ç‡æŒ‡æ•¸'},\n",
        "\n",
        "                # å¤–åŒ¯ETF\n",
        "                {'etf_id': 'UUP', 'etf_name': 'Invesco DB US Dollar Index Bullish Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'UUP', 'category': 'ç¾å…ƒæŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'UDN', 'etf_name': 'Invesco DB US Dollar Index Bearish Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'UDN', 'category': 'åå‘ç¾å…ƒæŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'FXE', 'etf_name': 'Invesco CurrencyShares Euro Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'FXE', 'category': 'æ­å…ƒETF'},\n",
        "                {'etf_id': 'FXY', 'etf_name': 'Invesco CurrencyShares Japanese Yen Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'FXY', 'category': 'æ—¥åœ“ETF'},\n",
        "\n",
        "                # å…¶ä»–ç†±é–€ETF\n",
        "                {'etf_id': 'JETS', 'etf_name': 'U.S. Global Jets ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'JETS', 'category': 'èˆªç©ºæ¥­ETF'},\n",
        "                {'etf_id': 'ICLN', 'etf_name': 'iShares Global Clean Energy ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'ICLN', 'category': 'æ¸…æ½”èƒ½æºETF'},\n",
        "                                {'etf_id': 'BOTZ', 'etf_name': 'Global X Robotics & Artificial Intelligence ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'BOTZ', 'category': 'æ©Ÿå™¨äººAI ETF'},\n",
        "                {'etf_id': 'CLOU', 'etf_name': 'Global X Cloud Computing ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'CLOU', 'category': 'é›²ç«¯é‹ç®—ETF'},\n",
        "                {'etf_id': 'ESPO', 'etf_name': 'VanEck Video Gaming and eSports ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'ESPO', 'category': 'é›»ç«¶éŠæˆ²ETF'},\n",
        "                {'etf_id': 'LIT', 'etf_name': 'Global X Lithium & Battery Tech ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'LIT', 'category': 'é‹°é›»æ± ETF'},\n",
        "                {'etf_id': 'KWEB', 'etf_name': 'KraneShares CSI China Internet ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'KWEB', 'category': 'ä¸­åœ‹ç¶²è·¯ETF'},\n",
        "                {'etf_id': 'MCHI', 'etf_name': 'iShares MSCI China ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'MCHI', 'category': 'ä¸­åœ‹ETF'},\n",
        "                {'etf_id': 'GDX', 'etf_name': 'VanEck Gold Miners ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'GDX', 'category': 'é»ƒé‡‘ç¤¦æ¥­ETF'},\n",
        "                {'etf_id': 'GDXJ', 'etf_name': 'VanEck Junior Gold Miners ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'GDXJ', 'category': 'å°å‹é»ƒé‡‘ç¤¦æ¥­ETF'},\n",
        "                {'etf_id': 'SIL', 'etf_name': 'Global X Silver Miners ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'SIL', 'category': 'ç™½éŠ€ç¤¦æ¥­ETF'},\n",
        "            ]\n",
        "\n",
        "            # é©—è­‰æ¯å€‹æ¨™çš„æ˜¯å¦å¯ä»¥å¾ yfinance ç²å–æ•¸æ“š\n",
        "            validated_etfs = self._validate_symbols_with_yfinance(us_etfs)\n",
        "\n",
        "            df = pd.DataFrame(validated_etfs)\n",
        "            logger.info(f\"å®Œæ•´ç¾è‚¡ETFæ¸…å–®åŒ…å« {len(df)} æ”¯å·²é©—è­‰çš„ETF/æœŸè²¨/è²´é‡‘å±¬\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆç¾è‚¡ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def _validate_symbols_with_yfinance(self, etf_list: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"ä½¿ç”¨ yfinance é©—è­‰æ¨™çš„æ˜¯å¦æœ‰æ•ˆ\"\"\"\n",
        "        logger.info(\"é–‹å§‹é©—è­‰æ¨™çš„æœ‰æ•ˆæ€§...\")\n",
        "        validated_etfs = []\n",
        "\n",
        "        def validate_single_symbol(etf_info):\n",
        "            \"\"\"é©—è­‰å–®ä¸€æ¨™çš„\"\"\"\n",
        "            try:\n",
        "                symbol = etf_info['yahoo_symbol']\n",
        "                ticker = yf.Ticker(symbol)\n",
        "\n",
        "                # å˜—è©¦ç²å–æœ€è¿‘5å¤©çš„æ•¸æ“šä¾†é©—è­‰æ¨™çš„æ˜¯å¦æœ‰æ•ˆ\n",
        "                hist = ticker.history(period=\"5d\")\n",
        "\n",
        "                if not hist.empty and len(hist) > 0:\n",
        "                    # ç²å–åŸºæœ¬ä¿¡æ¯\n",
        "                    info = ticker.info\n",
        "\n",
        "                    # æ›´æ–°æ¨™çš„åç¨±ï¼ˆå¦‚æœ yfinance æä¾›äº†æ›´æº–ç¢ºçš„åç¨±ï¼‰\n",
        "                    if 'longName' in info and info['longName']:\n",
        "                        etf_info['etf_name'] = info['longName']\n",
        "                    elif 'shortName' in info and info['shortName']:\n",
        "                        etf_info['etf_name'] = info['shortName']\n",
        "\n",
        "                    # æ·»åŠ é¡å¤–ä¿¡æ¯\n",
        "                    etf_info['last_price'] = float(hist['Close'].iloc[-1]) if not hist['Close'].empty else None\n",
        "                    etf_info['volume'] = int(hist['Volume'].iloc[-1]) if not hist['Volume'].empty else None\n",
        "                    etf_info['validated'] = True\n",
        "                    etf_info['validation_date'] = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
        "\n",
        "                    logger.debug(f\"âœ“ {symbol} é©—è­‰æˆåŠŸ\")\n",
        "                    return etf_info\n",
        "                else:\n",
        "                    logger.warning(f\"âœ— {symbol} ç„¡æ•¸æ“š\")\n",
        "                    return None\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"âœ— {etf_info['yahoo_symbol']} é©—è­‰å¤±æ•—: {e}\")\n",
        "                return None\n",
        "\n",
        "        # ä½¿ç”¨å¤šç·šç¨‹åŠ é€Ÿé©—è­‰éç¨‹\n",
        "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "            future_to_etf = {executor.submit(validate_single_symbol, etf): etf for etf in etf_list}\n",
        "\n",
        "            for future in as_completed(future_to_etf):\n",
        "                result = future.result()\n",
        "                if result is not None:\n",
        "                    validated_etfs.append(result)\n",
        "\n",
        "        logger.info(f\"é©—è­‰å®Œæˆ: {len(validated_etfs)}/{len(etf_list)} å€‹æ¨™çš„æœ‰æ•ˆ\")\n",
        "        return validated_etfs\n",
        "\n",
        "    def get_us_etfs(self, force_update=False):\n",
        "        \"\"\"ç²å–ç¾è‚¡ETFæ¸…å–® - ä½¿ç”¨çœŸå¯¦æ•¸æ“š\"\"\"\n",
        "        if not force_update and os.path.exists(self.etf_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.etf_list_path)) < 86400:  # 24å°æ™‚å¿«å–\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥ç¾è‚¡ETFåˆ—è¡¨\")\n",
        "                return pd.read_csv(self.etf_list_path, dtype={'etf_id': str})\n",
        "\n",
        "        logger.info(\"ç²å–ç¾è‚¡ETFæ¸…å–® - ä½¿ç”¨ yfinance çœŸå¯¦æ•¸æ“šé©—è­‰...\")\n",
        "\n",
        "        try:\n",
        "            # ç²å–ä¸¦é©—è­‰ETFæ¸…å–®\n",
        "            df = self._get_comprehensive_us_etf_list()\n",
        "\n",
        "            if not df.empty:\n",
        "                # ä¿å­˜åˆ°å¿«å–\n",
        "                df.to_csv(self.etf_list_path, index=False)\n",
        "                logger.info(f\"æˆåŠŸç²å–ä¸¦é©—è­‰ {len(df)} æ”¯ç¾è‚¡ETFæ¸…å–®ä¸¦ä¿å­˜å¿«å–\")\n",
        "\n",
        "                # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯\n",
        "                category_counts = df['category'].value_counts()\n",
        "                logger.info(\"æ¨™çš„é¡åˆ¥çµ±è¨ˆ:\")\n",
        "                for category, count in category_counts.items():\n",
        "                    logger.info(f\"  {category}: {count} æ”¯\")\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç²å–ç¾è‚¡ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            # å¦‚æœé©—è­‰å¤±æ•—ï¼Œè¿”å›åŸºæœ¬æ¸…å–®\n",
        "            return pd.DataFrame([\n",
        "                {'etf_id': 'SPY', 'etf_name': 'SPDR S&P 500 ETF Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'SPY', 'category': 'å¤§ç›¤æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'QQQ', 'etf_name': 'Invesco QQQ Trust', 'market': 'NASDAQ', 'yahoo_symbol': 'QQQ', 'category': 'ç§‘æŠ€æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'GLD', 'etf_name': 'SPDR Gold Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'GLD', 'category': 'é»ƒé‡‘ETF'},\n",
        "            ])\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, etf_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–ETFæ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=etf_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{etf_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{etf_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{etf_id}] ç²å–æ•¸æ“šå¤±æ•—\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "            df['MA60'] = df['Close'].rolling(window=60).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_etf_async(self, session: aiohttp.ClientSession, etf_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯ETF\"\"\"\n",
        "        symbol = etf_info['yahoo_symbol']\n",
        "        etf_name = etf_info['etf_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æETF: {etf_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–ETFæ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'etf_name': etf_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„ETFæ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'etf_name': etf_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'etf_name': etf_name,\n",
        "                'etf_id': etf_info.get('etf_id', ''),\n",
        "                'market': etf_info.get('market', ''),\n",
        "                'category': etf_info.get('category', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {etf_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æETF {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'etf_name': etf_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_etfs(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰ETFï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´ETFæ¸…å–®\n",
        "            if self.us_etfs is None:\n",
        "                self.us_etfs = self.get_us_etfs()\n",
        "\n",
        "            if self.us_etfs.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–ETFæ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.us_etfs)} æ”¯ETFï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, etf_info in self.us_etfs.iterrows():\n",
        "                    task = self.analyze_etf_async(session, etf_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æETFæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºå‰ååï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ† ç¾è‚¡ETFæŠ€è¡“åˆ†æ - å‰ååå„ªè³ªæ¨™çš„\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯ETF/æœŸè²¨/è²´é‡‘å±¬\")\n",
        "        message_parts.append(f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªæ¨™çš„\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºå‰ååå„ªè³ªæ¨™çš„\n",
        "        top_etfs = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† å‰ {len(top_etfs)} åå„ªè³ªæ¨™çš„:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_etfs, 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            category = result.get('category', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\" if price_change < 0 else \"â¡ï¸\"\n",
        "\n",
        "            # å»ºè­°ç¬¦è™Ÿ\n",
        "            rec_symbol = \"ğŸš€\" if \"å¼·åŠ›è²·\" in rec_text else \"ğŸ“ˆ\" if \"è²·\" in rec_text else \"ğŸ“Š\" if \"æŒæœ‰\" in rec_text else \"ğŸ“‰\"\n",
        "\n",
        "            # é¡åˆ¥ç¬¦è™Ÿ\n",
        "            category_symbol = \"ğŸ›ï¸\" if \"æŒ‡æ•¸\" in category else \"âš¡\" if \"æ§“æ¡¿\" in category else \"ğŸ”„\" if \"åå‘\" in category else \"ğŸ¥‡\" if \"é»ƒé‡‘\" in category else \"ğŸ›¢ï¸\" if \"åŸæ²¹\" in category else \"ğŸŒ¾\" if \"è¾²ç”¢å“\" in category else \"ğŸ“Š\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {etf_name[:25]} ({etf_id})\")\n",
        "            message_parts.append(f\"   {category_symbol} é¡åˆ¥: {category}\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: ${current_price:.2f} ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   â­ è©•åˆ†: {score:.1f}/100\")\n",
        "            message_parts.append(f\"   {rec_symbol} å»ºè­°: {rec_text}\")\n",
        "            message_parts.append(f\"   ğŸ“Š æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # æ·»åŠ ä¸»è¦æŠ€è¡“æŒ‡æ¨™\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            rsi_value = tech.get('rsi_value', 50)\n",
        "            macd_signal = tech.get('macd_signal', 'ä¸­æ€§')\n",
        "            message_parts.append(f\"   ğŸ” RSI: {rsi_value:.1f} | MACD: {macd_signal}\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_score = sum(r.get('combined_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('combined_score', 0) >= 70])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ“Š å¹³å‡åˆ†æ•¸: {avg_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†æ¨™çš„ (â‰¥70): {high_score_count}\")\n",
        "\n",
        "            # å»ºè­°åˆ†å¸ƒ\n",
        "            recommendations = {}\n",
        "            for result in top_etfs:\n",
        "                rec = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "                recommendations[rec] = recommendations.get(rec, 0) + 1\n",
        "\n",
        "            if recommendations:\n",
        "                message_parts.append(\"   ğŸ“ˆ å‰ååå»ºè­°åˆ†å¸ƒ:\")\n",
        "                for rec, count in recommendations.items():\n",
        "                    message_parts.append(f\"      {rec}: {count}\")\n",
        "\n",
        "            # é¡åˆ¥åˆ†å¸ƒ\n",
        "            categories = {}\n",
        "            for result in top_etfs:\n",
        "                cat = result.get('category', 'Unknown')\n",
        "                categories[cat] = categories.get(cat, 0) + 1\n",
        "\n",
        "            if categories:\n",
        "                message_parts.append(\"   ğŸ·ï¸ å‰ååé¡åˆ¥åˆ†å¸ƒ:\")\n",
        "                for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):\n",
        "                    message_parts.append(f\"      {cat}: {count}\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºæ¨™çš„\")\n",
        "        message_parts.append(\"â€¢ åŒ…å«ETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰å¤šå…ƒåŒ–æ¨™çš„\")\n",
        "        message_parts.append(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "        message_parts.append(\"â€¢ æ§“æ¡¿å’Œåå‘ETFé¢¨éšªè¼ƒé«˜ï¼Œè«‹è¬¹æ…æ“ä½œ\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"ğŸ† ç¾è‚¡ETFæŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªæ¨™çš„\".center(100))\n",
        "        print(\"=\" * 100)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯ETF/æœŸè²¨/è²´é‡‘å±¬\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªæ¨™çš„\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'æ¨™çš„åç¨±':<20}{'é¡åˆ¥':<15}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 100)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_etfs = successful_results[:limit]\n",
        "        for i, result in enumerate(top_etfs, 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')[:18]  # é™åˆ¶é•·åº¦\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            category = result.get('category', 'Unknown')[:13]  # é™åˆ¶é•·åº¦\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{etf_id:<8}{etf_name:<20}{category:<15}{score:<8.1f}${current_price:<9.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        for i, result in enumerate(top_etfs[:5], 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            category = result.get('category', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {etf_name} ({etf_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(f\"   ğŸ·ï¸ é¡åˆ¥: {category}\")\n",
        "            print(\"-\" * 60)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: ${result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        # é¡åˆ¥çµ±è¨ˆ\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"ğŸ“Š é¡åˆ¥çµ±è¨ˆåˆ†æ:\")\n",
        "        categories = {}\n",
        "        for result in successful_results:\n",
        "            cat = result.get('category', 'Unknown')\n",
        "            if cat not in categories:\n",
        "                categories[cat] = {'count': 0, 'avg_score': 0, 'scores': []}\n",
        "            categories[cat]['count'] += 1\n",
        "            categories[cat]['scores'].append(result.get('combined_score', 0))\n",
        "\n",
        "        for cat, data in categories.items():\n",
        "            data['avg_score'] = sum(data['scores']) / len(data['scores'])\n",
        "\n",
        "        sorted_categories = sorted(categories.items(), key=lambda x: x[1]['avg_score'], reverse=True)\n",
        "\n",
        "        print(f\"{'é¡åˆ¥':<20}{'æ•¸é‡':<8}{'å¹³å‡åˆ†æ•¸':<12}{'æœ€é«˜åˆ†':<10}\")\n",
        "        print(\"-\" * 50)\n",
        "        for cat, data in sorted_categories:\n",
        "            print(f\"{cat:<20}{data['count']:<8}{data['avg_score']:<12.1f}{max(data['scores']):<10.1f}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºæ¨™çš„\")\n",
        "        print(\"â€¢ åŒ…å«ETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰å¤šå…ƒåŒ–æŠ•è³‡å·¥å…·\")\n",
        "        print(\"â€¢ æ§“æ¡¿ETFå’Œåå‘ETFå…·æœ‰è¼ƒé«˜é¢¨éšªï¼Œè«‹è¬¹æ…æ“ä½œ\")\n",
        "        print(\"â€¢ æœŸè²¨å•†å“æ³¢å‹•è¼ƒå¤§ï¼Œé©åˆæœ‰ç¶“é©—çš„æŠ•è³‡è€…\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† ç¾è‚¡ETFåˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ - ä¿®æ”¹é€™éƒ¨åˆ†\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            # Discord é™åˆ¶ 2000 å­—ç¬¦ï¼Œéœ€è¦åˆ†å‰²è¨Šæ¯\n",
        "            max_discord_length = 1900  # ç•™ä¸€äº›ç·©è¡ç©ºé–“\n",
        "\n",
        "            if len(message) <= max_discord_length:\n",
        "                # è¨Šæ¯ä¸é•·ï¼Œç›´æ¥ç™¼é€\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "                response = webhook.execute()\n",
        "                if response.ok:\n",
        "                    logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "                else:\n",
        "                    logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "            else:\n",
        "                # è¨Šæ¯å¤ªé•·ï¼Œåˆ†å‰²ç™¼é€\n",
        "                lines = message.split('\\n')\n",
        "                current_chunk = \"\"\n",
        "                chunk_count = 1\n",
        "\n",
        "                for line in lines:\n",
        "                    # æª¢æŸ¥åŠ å…¥é€™è¡Œå¾Œæ˜¯å¦è¶…éé™åˆ¶\n",
        "                    test_chunk = current_chunk + line + '\\n'\n",
        "                    if len(f\"```\\n{test_chunk}\\n```\") > max_discord_length:\n",
        "                        # ç™¼é€ç•¶å‰å¡Š\n",
        "                        if current_chunk.strip():\n",
        "                            header = f\"ğŸ† ç¾è‚¡ETFåˆ†æå ±å‘Š (ç¬¬{chunk_count}éƒ¨åˆ†)\\n\\n\"\n",
        "                            chunk_content = header + current_chunk.strip()\n",
        "                            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk_content}\\n```\")\n",
        "                            response = webhook.execute()\n",
        "                            if response.ok:\n",
        "                                logger.info(f\"Discord é€šçŸ¥ç¬¬{chunk_count}éƒ¨åˆ†ç™¼é€æˆåŠŸ\")\n",
        "                            else:\n",
        "                                logger.error(f\"Discord é€šçŸ¥ç¬¬{chunk_count}éƒ¨åˆ†å¤±æ•—: {response.status_code}\")\n",
        "                            chunk_count += 1\n",
        "                            await asyncio.sleep(1)  # é¿å…ç™¼é€å¤ªå¿«\n",
        "\n",
        "                        # é–‹å§‹æ–°å¡Š\n",
        "                        current_chunk = line + '\\n'\n",
        "                    else:\n",
        "                        current_chunk = test_chunk\n",
        "\n",
        "                # ç™¼é€æœ€å¾Œä¸€å¡Š\n",
        "                if current_chunk.strip():\n",
        "                    header = f\"ğŸ† ç¾è‚¡ETFåˆ†æå ±å‘Š (ç¬¬{chunk_count}éƒ¨åˆ†)\\n\\n\"\n",
        "                    chunk_content = header + current_chunk.strip()\n",
        "                    webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk_content}\\n```\")\n",
        "                    response = webhook.execute()\n",
        "                    if response.ok:\n",
        "                        logger.info(f\"Discord é€šçŸ¥ç¬¬{chunk_count}éƒ¨åˆ†ç™¼é€æˆåŠŸ\")\n",
        "                    else:\n",
        "                        logger.error(f\"Discord é€šçŸ¥ç¬¬{chunk_count}éƒ¨åˆ†å¤±æ•—: {response.status_code}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ ç¾è‚¡ETFæŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªç¾è‚¡ETF/æœŸè²¨/è²´é‡‘å±¬\")\n",
        "        print(\"ğŸ“Š æ¶µè“‹: ETFã€æ§“æ¡¿ETFã€åå‘ETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = USETFAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨ETFåˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰ç¾è‚¡ETF/æœŸè²¨/è²´é‡‘å±¬ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_etfs()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"âœ… ç¾è‚¡ETFåˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªæ¨™çš„å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "        print(\"ğŸ“Š æ¶µè“‹å¤šç¨®æŠ•è³‡å·¥å…·ï¼šETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¾è‚¡ETFåˆ†æç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbUbI3hrsVGD",
        "outputId": "ec34dfe3-56ca-4552-bab0-8b451e71e060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ å°è‚¡é¸è‚¡å…¬å¼åˆ†æç¨‹å¼å•Ÿå‹•\n",
            "â° é–‹å§‹æ™‚é–“: 2025-08-13 10:45:12\n",
            "ğŸ“Š é¸è‚¡æ¢ä»¶:\n",
            "   â€¢ 5æ—¥æ¼²å¹… >9.5% (40åˆ†)\n",
            "   â€¢ é‡æ¯” >1.5 (30åˆ†)\n",
            "   â€¢ åƒ¹æ ¼ 20-500å…ƒ (20åˆ†)\n",
            "   â€¢ æˆäº¤é‡ >1000å¼µ/æ—¥ (10åˆ†)\n",
            "   â€¢ é–€æª»åˆ†æ•¸: â‰¥70åˆ†\n",
            "ğŸ¯ ç›®æ¨™: æ‰¾å‡ºç¬¦åˆé¸è‚¡å…¬å¼çš„å¼·å‹¢è‚¡ç¥¨\n",
            "======================================================================\n",
            "ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡ï¼ˆæ‡‰ç”¨é¸è‚¡å…¬å¼ç¯©é¸ï¼‰...\n",
            "\n",
            "==========================================================================================\n",
            "                                       ğŸ¯ å°è‚¡é¸è‚¡å…¬å¼ç¯©é¸çµæœ                                       \n",
            "==========================================================================================\n",
            "ğŸ“ˆ åˆ†ææ™‚é–“: 2025-08-13 10:57:58\n",
            "ğŸ† ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶: 138 æ”¯è‚¡ç¥¨\n",
            "ğŸ“Š é¸è‚¡æ¢ä»¶: æ¼²å¹…>9.5%(40åˆ†) + é‡æ¯”>1.5(30åˆ†) + åƒ¹æ ¼20-500å…ƒ(20åˆ†) + æˆäº¤é‡>1000å¼µ(10åˆ†) â‰¥70åˆ†\n",
            "==========================================================================================\n",
            "æ’å  ä»£ç¢¼      è‚¡ç¥¨åç¨±        é¸è‚¡åˆ†æ•¸    åƒ¹æ ¼        æ¼²è·Œ%       é‡æ¯”      æˆäº¤é‡(å¼µ)      \n",
            "------------------------------------------------------------------------------------------\n",
            "1   4576    å¤§éŠ€å¾®ç³»çµ±       110     125.50    +11.06    1.79    1821        \n",
            "2   8374    ç¾…æ˜‡          110     112.00    +11.44    1.80    2982        \n",
            "3   3217    å„ªç¾¤          110     181.00    +10.70    1.55    1364        \n",
            "4   1409    æ–°çº–          105     13.80     +9.52     5.71    2242        \n",
            "5   1717    é•·èˆˆ          105     31.90     +12.92    3.03    3278        \n",
            "6   1802    å°ç»          105     29.85     +27.84    1.75    111652      \n",
            "7   1810    å’Œæˆ          105     21.45     +17.21    2.92    3143        \n",
            "8   2313    è¯é€š          105     73.30     +13.64    1.68    16325       \n",
            "9   2464    ç›Ÿç«‹          105     64.60     +9.68     1.79    4141        \n",
            "10  2630    äºèˆª          105     59.60     +29.00    2.01    17417       \n",
            "==========================================================================================\n",
            "\n",
            "ğŸ“Š è©³ç´°é¸è‚¡åˆ†æå ±å‘Š (å‰äº”å):\n",
            "==========================================================================================\n",
            "\n",
            "1. å¤§éŠ€å¾®ç³»çµ± (4576) - é¸è‚¡åˆ†æ•¸: 110/100\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 125.50å…ƒ\n",
            "ğŸš€ 5æ—¥æ¼²å¹…: +11.06%\n",
            "ğŸ“Š é‡æ¯”: 1.79\n",
            "ğŸ“ˆ æˆäº¤é‡: 1821å¼µ/æ—¥\n",
            "ğŸ¯ é¸è‚¡å…¬å¼è©•åˆ†æ˜ç´°:\n",
            "   æ¼²å¹…è©•åˆ†: 40/40\n",
            "   é‡æ¯”è©•åˆ†: 30/30\n",
            "   åƒ¹æ ¼åˆç†æ€§: 20/20\n",
            "   æµå‹•æ€§è©•åˆ†: 10/10\n",
            "   åŠ åˆ†é …ç›®: +10 (æŠ€è¡“æŒ‡æ¨™è‰¯å¥½, å¼·å‹¢ä¸Šæ¼²è¶¨å‹¢)\n",
            "âœ… ç¬¦åˆæ¢ä»¶: 5æ—¥æ¼²å¹…é” 11.06% (>9.5%), é‡æ¯”é” 1.79 (æ”¾é‡), åƒ¹æ ¼åˆç† 125.50å…ƒ (20-500å…ƒ)\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 67.3 (ä¸­æ€§)\n",
            "   MACD: å¤šé ­\n",
            "   è¶¨å‹¢: å¼·å‹¢ä¸Šæ¼²\n",
            "\n",
            "2. ç¾…æ˜‡ (8374) - é¸è‚¡åˆ†æ•¸: 110/100\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 112.00å…ƒ\n",
            "ğŸš€ 5æ—¥æ¼²å¹…: +11.44%\n",
            "ğŸ“Š é‡æ¯”: 1.80\n",
            "ğŸ“ˆ æˆäº¤é‡: 2982å¼µ/æ—¥\n",
            "ğŸ¯ é¸è‚¡å…¬å¼è©•åˆ†æ˜ç´°:\n",
            "   æ¼²å¹…è©•åˆ†: 40/40\n",
            "   é‡æ¯”è©•åˆ†: 30/30\n",
            "   åƒ¹æ ¼åˆç†æ€§: 20/20\n",
            "   æµå‹•æ€§è©•åˆ†: 10/10\n",
            "   åŠ åˆ†é …ç›®: +10 (æŠ€è¡“æŒ‡æ¨™è‰¯å¥½, å¼·å‹¢ä¸Šæ¼²è¶¨å‹¢)\n",
            "âœ… ç¬¦åˆæ¢ä»¶: 5æ—¥æ¼²å¹…é” 11.44% (>9.5%), é‡æ¯”é” 1.80 (æ”¾é‡), åƒ¹æ ¼åˆç† 112.00å…ƒ (20-500å…ƒ)\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 62.5 (ä¸­æ€§)\n",
            "   MACD: å¤šé ­\n",
            "   è¶¨å‹¢: å¼·å‹¢ä¸Šæ¼²\n",
            "\n",
            "3. å„ªç¾¤ (3217) - é¸è‚¡åˆ†æ•¸: 110/100\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 181.00å…ƒ\n",
            "ğŸš€ 5æ—¥æ¼²å¹…: +10.70%\n",
            "ğŸ“Š é‡æ¯”: 1.55\n",
            "ğŸ“ˆ æˆäº¤é‡: 1364å¼µ/æ—¥\n",
            "ğŸ¯ é¸è‚¡å…¬å¼è©•åˆ†æ˜ç´°:\n",
            "   æ¼²å¹…è©•åˆ†: 40/40\n",
            "   é‡æ¯”è©•åˆ†: 30/30\n",
            "   åƒ¹æ ¼åˆç†æ€§: 20/20\n",
            "   æµå‹•æ€§è©•åˆ†: 10/10\n",
            "   åŠ åˆ†é …ç›®: +10 (æŠ€è¡“æŒ‡æ¨™è‰¯å¥½, å¼·å‹¢ä¸Šæ¼²è¶¨å‹¢)\n",
            "âœ… ç¬¦åˆæ¢ä»¶: 5æ—¥æ¼²å¹…é” 10.70% (>9.5%), é‡æ¯”é” 1.55 (æ”¾é‡), åƒ¹æ ¼åˆç† 181.00å…ƒ (20-500å…ƒ)\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 67.5 (ä¸­æ€§)\n",
            "   MACD: å¤šé ­\n",
            "   è¶¨å‹¢: å¼·å‹¢ä¸Šæ¼²\n",
            "\n",
            "4. æ–°çº– (1409) - é¸è‚¡åˆ†æ•¸: 105/100\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 13.80å…ƒ\n",
            "ğŸš€ 5æ—¥æ¼²å¹…: +9.52%\n",
            "ğŸ“Š é‡æ¯”: 5.71\n",
            "ğŸ“ˆ æˆäº¤é‡: 2242å¼µ/æ—¥\n",
            "ğŸ¯ é¸è‚¡å…¬å¼è©•åˆ†æ˜ç´°:\n",
            "   æ¼²å¹…è©•åˆ†: 40/40\n",
            "   é‡æ¯”è©•åˆ†: 30/30\n",
            "   åƒ¹æ ¼åˆç†æ€§: 15/20\n",
            "   æµå‹•æ€§è©•åˆ†: 10/10\n",
            "   åŠ åˆ†é …ç›®: +10 (æŠ€è¡“æŒ‡æ¨™è‰¯å¥½, å¼·å‹¢ä¸Šæ¼²è¶¨å‹¢)\n",
            "âœ… ç¬¦åˆæ¢ä»¶: 5æ—¥æ¼²å¹…é” 9.52% (>9.5%), é‡æ¯”é” 5.71 (çˆ†é‡), ä½åƒ¹è‚¡ 13.80å…ƒ\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 67.2 (ä¸­æ€§)\n",
            "   MACD: é»ƒé‡‘äº¤å‰\n",
            "   è¶¨å‹¢: å¼·å‹¢ä¸Šæ¼²\n",
            "\n",
            "5. é•·èˆˆ (1717) - é¸è‚¡åˆ†æ•¸: 105/100\n",
            "------------------------------------------------------------\n",
            "ğŸ’° ç•¶å‰åƒ¹æ ¼: 31.90å…ƒ\n",
            "ğŸš€ 5æ—¥æ¼²å¹…: +12.92%\n",
            "ğŸ“Š é‡æ¯”: 3.03\n",
            "ğŸ“ˆ æˆäº¤é‡: 3278å¼µ/æ—¥\n",
            "ğŸ¯ é¸è‚¡å…¬å¼è©•åˆ†æ˜ç´°:\n",
            "   æ¼²å¹…è©•åˆ†: 40/40\n",
            "   é‡æ¯”è©•åˆ†: 30/30\n",
            "   åƒ¹æ ¼åˆç†æ€§: 20/20\n",
            "   æµå‹•æ€§è©•åˆ†: 10/10\n",
            "   åŠ åˆ†é …ç›®: +5 (å¼·å‹¢ä¸Šæ¼²è¶¨å‹¢)\n",
            "âœ… ç¬¦åˆæ¢ä»¶: 5æ—¥æ¼²å¹…é” 12.92% (>9.5%), é‡æ¯”é” 3.03 (çˆ†é‡), åƒ¹æ ¼åˆç† 31.90å…ƒ (20-500å…ƒ)\n",
            "ğŸ” æŠ€è¡“æŒ‡æ¨™:\n",
            "   RSI: 83.7 (è¶…è²·)\n",
            "   MACD: å¤šé ­\n",
            "   è¶¨å‹¢: å¼·å‹¢ä¸Šæ¼²\n",
            "\n",
            "==========================================================================================\n",
            "ğŸ¯ é¸è‚¡å…¬å¼èªªæ˜:\n",
            "â€¢ æ¼²å¹…æ¬Šé‡40%: 5æ—¥æ¼²å¹…>9.5%ç²40åˆ†ï¼Œ>7%ç²30åˆ†ï¼Œ>5%ç²20åˆ†ï¼Œ>3%ç²10åˆ†\n",
            "â€¢ é‡æ¯”æ¬Šé‡30%: é‡æ¯”>2.0æˆ–>1.5ç²30åˆ†ï¼Œ>1.2ç²20åˆ†ï¼Œ>1.0ç²20åˆ†\n",
            "â€¢ åƒ¹æ ¼åˆç†æ€§20%: 20-500å…ƒç²20åˆ†ï¼Œå…¶ä»–åƒ¹ä½æŒ‰åˆç†æ€§çµ¦åˆ†\n",
            "â€¢ æµå‹•æ€§10%: æˆäº¤é‡>1000å¼µ/æ—¥ç²10åˆ†\n",
            "â€¢ æŠ€è¡“æŒ‡æ¨™å’Œè¶¨å‹¢åˆ†æå¯é¡å¤–åŠ åˆ†\n",
            "â€¢ ç¸½åˆ†â‰¥70åˆ†æ‰ç¬¦åˆé¸è‚¡æ¢ä»¶\n",
            "\n",
            "âš ï¸ æŠ•è³‡æé†’:\n",
            "â€¢ æœ¬é¸è‚¡å…¬å¼å°ˆé–€ç¯©é¸å¼·å‹¢ä¸Šæ¼²ä¸”æœ‰é‡é…åˆçš„è‚¡ç¥¨\n",
            "â€¢ å·²ç¬¦åˆå¤šé‡æŠ€è¡“æ¢ä»¶ï¼Œä½†æŠ•è³‡ä»æœ‰é¢¨éšª\n",
            "â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œè¨­å®šåœæé»\n",
            "â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\n",
            "==========================================================================================\n",
            "\n",
            "ğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\n",
            "ğŸ“± æ­£åœ¨ç™¼é€é¸è‚¡çµæœåˆ° Telegram å’Œ Discord...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:discord_webhook.webhook:Webhook status code 400: {\"content\": [\"Must be 2000 or fewer in length.\"]}\n",
            "ERROR:__main__:Discord é€šçŸ¥å¤±æ•—: 400 b'{\"content\": [\"Must be 2000 or fewer in length.\"]}'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "â° ç¨‹å¼åŸ·è¡Œå®Œæˆ: 2025-08-13 10:57:59\n",
            "======================================================================\n",
            "âœ… é¸è‚¡å…¬å¼åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\n",
            "ğŸ¯ æ‰¾åˆ° 138 æ”¯ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢è‚¡ç¥¨\n",
            "ğŸ† ç¬¦åˆé¸è‚¡å…¬å¼çš„å„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "import nest_asyncio\n",
        "\n",
        "# å®‰è£ nest_asyncioï¼ˆå¦‚æœå°šæœªå®‰è£ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥å…è¨±åµŒå¥—äº‹ä»¶å¾ªç’°\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "def stock_selection_formula(stock_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    è‚¡ç¥¨é¸è‚¡å…¬å¼è©•åˆ†ç³»çµ±\n",
        "    æ ¹æ“šæ¼²å¹…ã€é‡æ¯”ã€åƒ¹æ ¼åˆç†æ€§ã€æµå‹•æ€§é€²è¡Œè©•åˆ†\n",
        "    \"\"\"\n",
        "    try:\n",
        "        score = 0\n",
        "        details = {\n",
        "            'total_score': 0,\n",
        "            'criteria_scores': {},\n",
        "            'meets_threshold': False,\n",
        "            'selection_reasons': []\n",
        "        }\n",
        "\n",
        "        # ç²å–æ•¸æ“š\n",
        "        price_change_5d = stock_data.get('price_change_5d', 0)\n",
        "        current_price = stock_data.get('current_price', 0)\n",
        "        volume_analysis = stock_data.get('volume_analysis', {})\n",
        "        volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "        avg_volume_lots = volume_analysis.get('avg_volume_lots', 0)\n",
        "\n",
        "        # 1. æ¼²å¹…æ¬Šé‡ (40%)\n",
        "        price_score = 0\n",
        "        if price_change_5d > 9.5:\n",
        "            price_score = 40\n",
        "            details['selection_reasons'].append(f\"5æ—¥æ¼²å¹…é” {price_change_5d:.2f}% (>9.5%)\")\n",
        "        elif price_change_5d > 7.0:\n",
        "            price_score = 30\n",
        "            details['selection_reasons'].append(f\"5æ—¥æ¼²å¹… {price_change_5d:.2f}% (>7.0%)\")\n",
        "        elif price_change_5d > 5.0:\n",
        "            price_score = 20\n",
        "            details['selection_reasons'].append(f\"5æ—¥æ¼²å¹… {price_change_5d:.2f}% (>5.0%)\")\n",
        "        elif price_change_5d > 3.0:\n",
        "            price_score = 10\n",
        "\n",
        "        details['criteria_scores']['æ¼²å¹…è©•åˆ†'] = price_score\n",
        "        score += price_score\n",
        "\n",
        "        # 2. é‡æ¯”æ¬Šé‡ (30%)\n",
        "        volume_score = 0\n",
        "        if volume_ratio > 2.0:\n",
        "            volume_score = 30\n",
        "            details['selection_reasons'].append(f\"é‡æ¯”é” {volume_ratio:.2f} (çˆ†é‡)\")\n",
        "        elif volume_ratio > 1.5:\n",
        "            volume_score = 30\n",
        "            details['selection_reasons'].append(f\"é‡æ¯”é” {volume_ratio:.2f} (æ”¾é‡)\")\n",
        "        elif volume_ratio > 1.2:\n",
        "            volume_score = 20\n",
        "            details['selection_reasons'].append(f\"é‡æ¯” {volume_ratio:.2f} (æº«å’Œæ”¾é‡)\")\n",
        "        elif volume_ratio > 1.0:\n",
        "            volume_score = 20\n",
        "        elif volume_ratio > 0.8:\n",
        "            volume_score = 10\n",
        "\n",
        "        details['criteria_scores']['é‡æ¯”è©•åˆ†'] = volume_score\n",
        "        score += volume_score\n",
        "\n",
        "        # 3. åƒ¹æ ¼åˆç†æ€§ (20%)\n",
        "        price_score_reasonable = 0\n",
        "        if 20 <= current_price <= 500:\n",
        "            price_score_reasonable = 20\n",
        "            details['selection_reasons'].append(f\"åƒ¹æ ¼åˆç† {current_price:.2f}å…ƒ (20-500å…ƒ)\")\n",
        "        elif 10 <= current_price < 20:\n",
        "            price_score_reasonable = 15\n",
        "            details['selection_reasons'].append(f\"ä½åƒ¹è‚¡ {current_price:.2f}å…ƒ\")\n",
        "        elif 500 < current_price <= 1000:\n",
        "            price_score_reasonable = 15\n",
        "            details['selection_reasons'].append(f\"ä¸­é«˜åƒ¹è‚¡ {current_price:.2f}å…ƒ\")\n",
        "        elif 5 <= current_price < 10:\n",
        "            price_score_reasonable = 10\n",
        "        elif 1000 < current_price <= 2000:\n",
        "            price_score_reasonable = 10\n",
        "\n",
        "        details['criteria_scores']['åƒ¹æ ¼åˆç†æ€§'] = price_score_reasonable\n",
        "        score += price_score_reasonable\n",
        "\n",
        "        # 4. æµå‹•æ€§ (10%)\n",
        "        liquidity_score = 0\n",
        "        if avg_volume_lots > 5000:\n",
        "            liquidity_score = 10\n",
        "            details['selection_reasons'].append(f\"é«˜æµå‹•æ€§ {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "        elif avg_volume_lots > 2000:\n",
        "            liquidity_score = 10\n",
        "            details['selection_reasons'].append(f\"è‰¯å¥½æµå‹•æ€§ {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "        elif avg_volume_lots > 1000:\n",
        "            liquidity_score = 10\n",
        "            details['selection_reasons'].append(f\"åŸºæœ¬æµå‹•æ€§ {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "        elif avg_volume_lots > 500:\n",
        "            liquidity_score = 5\n",
        "\n",
        "        details['criteria_scores']['æµå‹•æ€§è©•åˆ†'] = liquidity_score\n",
        "        score += liquidity_score\n",
        "\n",
        "        # ç¸½åˆ†å’Œæ˜¯å¦ç¬¦åˆé–€æª»\n",
        "        details['total_score'] = score\n",
        "        details['meets_threshold'] = score >= 70\n",
        "\n",
        "        # é¡å¤–åŠ åˆ†æ¢ä»¶\n",
        "        bonus_score = 0\n",
        "        bonus_reasons = []\n",
        "\n",
        "        # æŠ€è¡“æŒ‡æ¨™åŠ åˆ†\n",
        "        technical_analysis = stock_data.get('technical_analysis', {})\n",
        "        rsi_value = technical_analysis.get('rsi_value', 50)\n",
        "        macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "\n",
        "        if 30 <= rsi_value <= 70 and macd_signal in ['é»ƒé‡‘äº¤å‰', 'å¤šé ­']:\n",
        "            bonus_score += 5\n",
        "            bonus_reasons.append(\"æŠ€è¡“æŒ‡æ¨™è‰¯å¥½\")\n",
        "\n",
        "        # è¶¨å‹¢åŠ åˆ†\n",
        "        trend_analysis = stock_data.get('trend_analysis', {})\n",
        "        trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "        if 'å¼·å‹¢ä¸Šæ¼²' in trend:\n",
        "            bonus_score += 5\n",
        "            bonus_reasons.append(\"å¼·å‹¢ä¸Šæ¼²è¶¨å‹¢\")\n",
        "        elif 'ä¸Šæ¼²' in trend:\n",
        "            bonus_score += 3\n",
        "            bonus_reasons.append(\"ä¸Šæ¼²è¶¨å‹¢\")\n",
        "\n",
        "        details['bonus_score'] = bonus_score\n",
        "        details['bonus_reasons'] = bonus_reasons\n",
        "        details['final_score'] = score + bonus_score\n",
        "        details['meets_threshold'] = (score + bonus_score) >= 70\n",
        "\n",
        "        return details\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¸è‚¡å…¬å¼è¨ˆç®—éŒ¯èª¤: {e}\")\n",
        "        return {\n",
        "            'total_score': 0,\n",
        "            'final_score': 0,\n",
        "            'criteria_scores': {},\n",
        "            'meets_threshold': False,\n",
        "            'selection_reasons': ['è¨ˆç®—éŒ¯èª¤'],\n",
        "            'bonus_score': 0,\n",
        "            'bonus_reasons': []\n",
        "        }\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'selection_threshold': 70,  # é¸è‚¡é–€æª»åˆ†æ•¸\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()  # ä¿®æ­£ï¼šä½¿ç”¨ copy() é¿å…è­¦å‘Š\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()  # ä¿®æ­£ï¼šä½¿ç”¨ copy()\n",
        "                df.loc[:, 'market'] = market_name  # ä¿®æ­£ï¼šä½¿ç”¨ .loc è¨­å®šå€¼\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)].copy()\n",
        "\n",
        "            # ä¿®æ­£ï¼šä½¿ç”¨ .loc è¨­å®š yahoo_symbol\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨è‚¡ç¥¨æ¸…å–®\")\n",
        "\n",
        "            # æ“´å±•çŸ¥åè‚¡ç¥¨åˆ—è¡¨\n",
        "            famous_stocks = [\n",
        "                {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2412', 'stock_name': 'ä¸­è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2412.TW', 'industry': 'é€šä¿¡'},\n",
        "                {'stock_id': '1301', 'stock_name': 'å°å¡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1301.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '1303', 'stock_name': 'å—äº', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1303.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '2308', 'stock_name': 'å°é”é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2308.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2002', 'stock_name': 'ä¸­é‹¼', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2002.TW', 'industry': 'é‹¼éµ'},\n",
        "                {'stock_id': '2886', 'stock_name': 'å…†è±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2886.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2891.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '3008', 'stock_name': 'å¤§ç«‹å…‰', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3008.TW', 'industry': 'å…‰å­¸'},\n",
        "                {'stock_id': '2357', 'stock_name': 'è¯ç¢©', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2357.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2382', 'stock_name': 'å»£é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2382.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2395', 'stock_name': 'ç ”è¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2395.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '3711', 'stock_name': 'æ—¥æœˆå…‰æŠ•æ§', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3711.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2409', 'stock_name': 'å‹é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2409.TW', 'industry': 'é¢æ¿'},\n",
        "                {'stock_id': '2884', 'stock_name': 'ç‰å±±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2884.TW', 'industry': 'é‡‘è'},\n",
        "                # æ–°å¢æ›´å¤šè‚¡ç¥¨\n",
        "                {'stock_id': '2474', 'stock_name': 'å¯æˆ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2474.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2408', 'stock_name': 'å—äºç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2408.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2301', 'stock_name': 'å…‰å¯¶ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2301.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2207', 'stock_name': 'å’Œæ³°è»Š', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2207.TW', 'industry': 'æ±½è»Š'},\n",
        "                {'stock_id': '1216', 'stock_name': 'çµ±ä¸€', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1216.TW', 'industry': 'é£Ÿå“'},\n",
        "                {'stock_id': '1101', 'stock_name': 'å°æ³¥', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1101.TW', 'industry': 'æ°´æ³¥'},\n",
        "                {'stock_id': '2105', 'stock_name': 'æ­£æ–°', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2105.TW', 'industry': 'æ©¡è† '},\n",
        "                {'stock_id': '2912', 'stock_name': 'çµ±ä¸€è¶…', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2912.TW', 'industry': 'è²¿æ˜“ç™¾è²¨'},\n",
        "                {'stock_id': '2885', 'stock_name': 'å…ƒå¤§é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2885.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2892', 'stock_name': 'ç¬¬ä¸€é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2892.TW', 'industry': 'é‡‘è'},\n",
        "            ]\n",
        "\n",
        "            df = pd.DataFrame(famous_stocks)\n",
        "            logger.info(f\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨ï¼ˆåŠ å…¥é¸è‚¡å…¬å¼ï¼‰\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            # å»ºç«‹è‚¡ç¥¨æ•¸æ“šå­—å…¸ç”¨æ–¼é¸è‚¡å…¬å¼\n",
        "            stock_data = {\n",
        "                'price_change_5d': price_change,\n",
        "                'current_price': current_price,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'trend_analysis': trend_analysis\n",
        "            }\n",
        "\n",
        "            # æ‡‰ç”¨é¸è‚¡å…¬å¼\n",
        "            selection_result = stock_selection_formula(stock_data)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_info.get('stock_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'selection_result': selection_result,  # æ–°å¢é¸è‚¡å…¬å¼çµæœ\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            # è¨˜éŒ„æ˜¯å¦ç¬¦åˆé¸è‚¡æ¢ä»¶\n",
        "            selection_status = \"âœ… ç¬¦åˆ\" if selection_result['meets_threshold'] else \"âŒ ä¸ç¬¦åˆ\"\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - é¸è‚¡å…¬å¼: {selection_status} ({selection_result['final_score']}/100)\")\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥é¸è‚¡å…¬å¼ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸å’Œé¸è‚¡å…¬å¼ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "            selection_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                # æª¢æŸ¥æ˜¯å¦ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶\n",
        "                                selection_result = result.get('selection_result', {})\n",
        "                                if selection_result.get('meets_threshold', False):\n",
        "                                    results[result['symbol']] = result\n",
        "                                else:\n",
        "                                    selection_filtered_count += 1\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - ç¬¦åˆé¸è‚¡å…¬å¼: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - é¸è‚¡å…¬å¼æ·˜æ±°: {selection_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºç¬¦åˆé¸è‚¡å…¬å¼çš„è‚¡ç¥¨ï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•ç¬¦åˆé¸è‚¡å…¬å¼çš„åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰é¸è‚¡å…¬å¼åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and\n",
        "               result.get('selection_result', {}).get('meets_threshold', False)\n",
        "        ]\n",
        "\n",
        "        # æŒ‰é¸è‚¡å…¬å¼æœ€çµ‚åˆ†æ•¸æ’åº\n",
        "        successful_results.sort(key=lambda x: x.get('selection_result', {}).get('final_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ¯ å°è‚¡é¸è‚¡å…¬å¼ç¯©é¸çµæœ\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ† ç¬¦åˆæ¢ä»¶: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(f\"ğŸ“Š é¸è‚¡æ¢ä»¶:\")\n",
        "        message_parts.append(f\"   â€¢ 5æ—¥æ¼²å¹… >9.5% (40åˆ†)\")\n",
        "        message_parts.append(f\"   â€¢ é‡æ¯” >1.5 (30åˆ†)\")\n",
        "        message_parts.append(f\"   â€¢ åƒ¹æ ¼ 20-500å…ƒ (20åˆ†)\")\n",
        "        message_parts.append(f\"   â€¢ æˆäº¤é‡ >1000å¼µ (10åˆ†)\")\n",
        "        message_parts.append(f\"   â€¢ é–€æª»åˆ†æ•¸: â‰¥70åˆ†\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "            message_parts.append(\"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–ç­‰å¾…æ›´å¥½çš„å¸‚å ´æ™‚æ©Ÿ\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† ç¬¦åˆé¸è‚¡å…¬å¼çš„å„ªè³ªè‚¡ç¥¨ (å‰{len(top_stocks)}å):\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            selection_result = result.get('selection_result', {})\n",
        "            final_score = selection_result.get('final_score', 0)\n",
        "            selection_reasons = selection_result.get('selection_reasons', [])\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            volume_ratio = volume_info.get('volume_ratio', 1.0)\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸš€\" if price_change > 15 else \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {stock_name} ({stock_id})\")\n",
        "            message_parts.append(f\"   ğŸ¯ é¸è‚¡åˆ†æ•¸: {final_score}/100\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f}å…ƒ ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   ğŸ“Š é‡æ¯”: {volume_ratio:.2f} | æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # é¡¯ç¤ºé¸è‚¡åŸå› ï¼ˆå‰3å€‹ï¼‰\n",
        "            if selection_reasons:\n",
        "                reasons_text = \" | \".join(selection_reasons[:3])\n",
        "                message_parts.append(f\"   âœ… ç¬¦åˆæ¢ä»¶: {reasons_text}\")\n",
        "\n",
        "            # è©³ç´°è©•åˆ†\n",
        "            criteria_scores = selection_result.get('criteria_scores', {})\n",
        "            message_parts.append(f\"   ğŸ“‹ è©•åˆ†æ˜ç´°: æ¼²å¹…{criteria_scores.get('æ¼²å¹…è©•åˆ†', 0)} | é‡æ¯”{criteria_scores.get('é‡æ¯”è©•åˆ†', 0)} | åƒ¹æ ¼{criteria_scores.get('åƒ¹æ ¼åˆç†æ€§', 0)} | æµå‹•æ€§{criteria_scores.get('æµå‹•æ€§è©•åˆ†', 0)}\")\n",
        "\n",
        "            # åŠ åˆ†é …ç›®\n",
        "            bonus_score = selection_result.get('bonus_score', 0)\n",
        "            if bonus_score > 0:\n",
        "                bonus_reasons = selection_result.get('bonus_reasons', [])\n",
        "                message_parts.append(f\"   â­ åŠ åˆ†: +{bonus_score}åˆ† ({', '.join(bonus_reasons)})\")\n",
        "\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_selection_score = sum(r.get('selection_result', {}).get('final_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('selection_result', {}).get('final_score', 0) >= 80])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ¯ å¹³å‡é¸è‚¡åˆ†æ•¸: {avg_selection_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†è‚¡ç¥¨ (â‰¥80): {high_score_count}\")\n",
        "\n",
        "            # æ¼²å¹…åˆ†å¸ƒ\n",
        "            price_changes = [r.get('price_change_5d', 0) for r in top_stocks]\n",
        "            avg_change = sum(price_changes) / len(price_changes) if price_changes else 0\n",
        "            max_change = max(price_changes) if price_changes else 0\n",
        "\n",
        "            message_parts.append(f\"   ğŸ“ˆ å¹³å‡æ¼²å¹…: {avg_change:.2f}%\")\n",
        "            message_parts.append(f\"   ğŸš€ æœ€é«˜æ¼²å¹…: {max_change:.2f}%\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"ğŸ¯ é¸è‚¡å…¬å¼èªªæ˜:\")\n",
        "        message_parts.append(\"â€¢ æ¼²å¹…æ¬Šé‡40%: 5æ—¥æ¼²å¹…>9.5%ç²æ»¿åˆ†\")\n",
        "        message_parts.append(\"â€¢ é‡æ¯”æ¬Šé‡30%: é‡æ¯”>1.5ç²æ»¿åˆ†\")\n",
        "        message_parts.append(\"â€¢ åƒ¹æ ¼åˆç†æ€§20%: 20-500å…ƒç²æ»¿åˆ†\")\n",
        "        message_parts.append(\"â€¢ æµå‹•æ€§10%: >1000å¼µ/æ—¥ç²æ»¿åˆ†\")\n",
        "        message_parts.append(\"â€¢ æŠ€è¡“æŒ‡æ¨™å’Œè¶¨å‹¢å¯é¡å¤–åŠ åˆ†\")\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬é¸è‚¡å…¬å¼åƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸å‡ºç¬¦åˆå¤šé‡æ¢ä»¶çš„å¼·å‹¢è‚¡\")\n",
        "        message_parts.append(\"â€¢ è«‹æ³¨æ„é¢¨éšªæ§åˆ¶ï¼Œé©ç•¶åˆ†æ•£æŠ•è³‡\")\n",
        "        message_parts.append(\"â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœï¼ˆé¸è‚¡å…¬å¼ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•ç¬¦åˆé¸è‚¡å…¬å¼çš„åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾ç¬¦åˆé¸è‚¡å…¬å¼çš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and\n",
        "               result.get('selection_result', {}).get('meets_threshold', False)\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('selection_result', {}).get('final_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 90)\n",
        "        print(\"ğŸ¯ å°è‚¡é¸è‚¡å…¬å¼ç¯©é¸çµæœ\".center(90))\n",
        "        print(\"=\" * 90)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ† ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ“Š é¸è‚¡æ¢ä»¶: æ¼²å¹…>9.5%(40åˆ†) + é‡æ¯”>1.5(30åˆ†) + åƒ¹æ ¼20-500å…ƒ(20åˆ†) + æˆäº¤é‡>1000å¼µ(10åˆ†) â‰¥70åˆ†\")\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "            print(\"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–ç­‰å¾…æ›´å¥½çš„å¸‚å ´æ™‚æ©Ÿ\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'é¸è‚¡åˆ†æ•¸':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<10}{'é‡æ¯”':<8}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 90)\n",
        "\n",
        "        # é¡¯ç¤ºç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            selection_result = result.get('selection_result', {})\n",
        "            final_score = selection_result.get('final_score', 0)\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            volume_ratio = volume_info.get('volume_ratio', 1.0)\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{final_score:<8.0f}{current_price:<10.2f}{price_change:<+10.2f}{volume_ratio:<8.2f}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°é¸è‚¡åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            selection_result = result.get('selection_result', {})\n",
        "            final_score = selection_result.get('final_score', 0)\n",
        "            criteria_scores = selection_result.get('criteria_scores', {})\n",
        "            selection_reasons = selection_result.get('selection_reasons', [])\n",
        "            bonus_score = selection_result.get('bonus_score', 0)\n",
        "            bonus_reasons = selection_result.get('bonus_reasons', [])\n",
        "\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {stock_name} ({stock_id}) - é¸è‚¡åˆ†æ•¸: {final_score}/100\")\n",
        "            print(\"-\" * 60)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}å…ƒ\")\n",
        "            print(f\"ğŸš€ 5æ—¥æ¼²å¹…: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ“Š é‡æ¯”: {volume_analysis.get('volume_ratio', 1.0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # é¸è‚¡å…¬å¼è©•åˆ†æ˜ç´°\n",
        "            print(f\"ğŸ¯ é¸è‚¡å…¬å¼è©•åˆ†æ˜ç´°:\")\n",
        "            print(f\"   æ¼²å¹…è©•åˆ†: {criteria_scores.get('æ¼²å¹…è©•åˆ†', 0)}/40\")\n",
        "            print(f\"   é‡æ¯”è©•åˆ†: {criteria_scores.get('é‡æ¯”è©•åˆ†', 0)}/30\")\n",
        "            print(f\"   åƒ¹æ ¼åˆç†æ€§: {criteria_scores.get('åƒ¹æ ¼åˆç†æ€§', 0)}/20\")\n",
        "            print(f\"   æµå‹•æ€§è©•åˆ†: {criteria_scores.get('æµå‹•æ€§è©•åˆ†', 0)}/10\")\n",
        "            if bonus_score > 0:\n",
        "                print(f\"   åŠ åˆ†é …ç›®: +{bonus_score} ({', '.join(bonus_reasons)})\")\n",
        "\n",
        "            # ç¬¦åˆæ¢ä»¶èªªæ˜\n",
        "            if selection_reasons:\n",
        "                print(f\"âœ… ç¬¦åˆæ¢ä»¶: {', '.join(selection_reasons[:3])}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   è¶¨å‹¢: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 90)\n",
        "        print(\"ğŸ¯ é¸è‚¡å…¬å¼èªªæ˜:\")\n",
        "        print(\"â€¢ æ¼²å¹…æ¬Šé‡40%: 5æ—¥æ¼²å¹…>9.5%ç²40åˆ†ï¼Œ>7%ç²30åˆ†ï¼Œ>5%ç²20åˆ†ï¼Œ>3%ç²10åˆ†\")\n",
        "        print(\"â€¢ é‡æ¯”æ¬Šé‡30%: é‡æ¯”>2.0æˆ–>1.5ç²30åˆ†ï¼Œ>1.2ç²20åˆ†ï¼Œ>1.0ç²20åˆ†\")\n",
        "        print(\"â€¢ åƒ¹æ ¼åˆç†æ€§20%: 20-500å…ƒç²20åˆ†ï¼Œå…¶ä»–åƒ¹ä½æŒ‰åˆç†æ€§çµ¦åˆ†\")\n",
        "        print(\"â€¢ æµå‹•æ€§10%: æˆäº¤é‡>1000å¼µ/æ—¥ç²10åˆ†\")\n",
        "        print(\"â€¢ æŠ€è¡“æŒ‡æ¨™å’Œè¶¨å‹¢åˆ†æå¯é¡å¤–åŠ åˆ†\")\n",
        "        print(\"â€¢ ç¸½åˆ†â‰¥70åˆ†æ‰ç¬¦åˆé¸è‚¡æ¢ä»¶\")\n",
        "        print(\"\\nâš ï¸ æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬é¸è‚¡å…¬å¼å°ˆé–€ç¯©é¸å¼·å‹¢ä¸Šæ¼²ä¸”æœ‰é‡é…åˆçš„è‚¡ç¥¨\")\n",
        "        print(\"â€¢ å·²ç¬¦åˆå¤šé‡æŠ€è¡“æ¢ä»¶ï¼Œä½†æŠ•è³‡ä»æœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œè¨­å®šåœæé»\")\n",
        "        print(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ¯ é¸è‚¡å…¬å¼ç¯©é¸çµæœ (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸ¯ å°è‚¡é¸è‚¡å…¬å¼åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ“Š é¸è‚¡æ¢ä»¶:\")\n",
        "        print(\"   â€¢ 5æ—¥æ¼²å¹… >9.5% (40åˆ†)\")\n",
        "        print(\"   â€¢ é‡æ¯” >1.5 (30åˆ†)\")\n",
        "        print(\"   â€¢ åƒ¹æ ¼ 20-500å…ƒ (20åˆ†)\")\n",
        "        print(\"   â€¢ æˆäº¤é‡ >1000å¼µ/æ—¥ (10åˆ†)\")\n",
        "        print(\"   â€¢ é–€æª»åˆ†æ•¸: â‰¥70åˆ†\")\n",
        "        print(\"ğŸ¯ ç›®æ¨™: æ‰¾å‡ºç¬¦åˆé¸è‚¡å…¬å¼çš„å¼·å‹¢è‚¡ç¥¨\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡ï¼ˆæ‡‰ç”¨é¸è‚¡å…¬å¼ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªæ‰¾åˆ°ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶çš„è‚¡ç¥¨\"\n",
        "            print(error_message)\n",
        "            print(\"ğŸ’¡ å¯èƒ½åŸå› ï¼š\")\n",
        "            print(\"   â€¢ ç•¶å‰å¸‚å ´æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢è‚¡\")\n",
        "            print(\"   â€¢ é¸è‚¡æ¢ä»¶éæ–¼åš´æ ¼\")\n",
        "            print(\"   â€¢ å»ºè­°èª¿æ•´ç¯©é¸åƒæ•¸æˆ–ç­‰å¾…æ›´å¥½çš„å¸‚å ´æ™‚æ©Ÿ\")\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message + \"\\n\\nğŸ’¡ å»ºè­°ç­‰å¾…æ›´å¥½çš„å¸‚å ´æ™‚æ©Ÿæˆ–èª¿æ•´é¸è‚¡æ¢ä»¶\")\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é¸è‚¡çµæœåˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"âœ… é¸è‚¡å…¬å¼åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(f\"ğŸ¯ æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢è‚¡ç¥¨\")\n",
        "        print(\"ğŸ† ç¬¦åˆé¸è‚¡å…¬å¼çš„å„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ é¸è‚¡ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmIVDBrJ6NSf"
      },
      "source": [
        "ä¸Šé¢å¯å‚³è¨Šå¯ç™¼å ±å‘Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q3AcBn43rd6",
        "outputId": "fd3d4335-0ac3-4c65-af39-e47f829d5775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ é–‹å§‹å°è‚¡æŠ€è¡“åˆ†æ...\n",
            "ğŸ“Š ä½¿ç”¨ç´” pandas/numpy è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
            "ğŸ“± å°‡è‡ªå‹•ç™¼é€åˆ†æçµæœåˆ° Telegram å’Œ Discord\n",
            "--------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                 ğŸ¯ æœ€çµ‚ç¯©é¸å„ªè³ªè‚¡ç¥¨æ¸…å–® ğŸ¯                                 \n",
            "================================================================================\n",
            "æ’å  ä»£ç¢¼     åç¨±          åˆ†æ•¸     åƒ¹æ ¼        å»ºè­°        ç”¢æ¥­             \n",
            "--------------------------------------------------------------------------------\n",
            "1   4440   å®œæ–°å¯¦æ¥­        81.9   17.60     å¼·åŠ›è²·å…¥      ç´¡ç¹”çº–ç¶­           \n",
            "2   4510   é«˜é‹’          81.9   51.90     å¼·åŠ›è²·å…¥      é›»æ©Ÿæ©Ÿæ¢°           \n",
            "3   6213   è¯èŒ‚          80.9   104.00    å¼·åŠ›è²·å…¥      é›»å­é›¶çµ„ä»¶æ¥­         \n",
            "4   1711   æ°¸å…‰          80.4   17.50     å¼·åŠ›è²·å…¥      åŒ–å­¸å·¥æ¥­           \n",
            "5   1773   å‹ä¸€          80.4   137.00    å¼·åŠ›è²·å…¥      åŒ–å­¸å·¥æ¥­           \n",
            "6   4571   éˆèˆˆ-KY       80.4   181.50    å¼·åŠ›è²·å…¥      é›»æ©Ÿæ©Ÿæ¢°           \n",
            "7   6221   æ™‰æ³°          80.4   53.40     å¼·åŠ›è²·å…¥      è³‡è¨Šæœå‹™æ¥­          \n",
            "8   6609   ç€§æ¾¤ç§‘         79.5   44.70     å¼·åŠ›è²·å…¥      é›»æ©Ÿæ©Ÿæ¢°           \n",
            "9   4927   æ³°é¼-KY       78.9   26.80     å¼·åŠ›è²·å…¥      é›»å­é›¶çµ„ä»¶æ¥­         \n",
            "10  3217   å„ªç¾¤          78.9   180.00    å¼·åŠ›è²·å…¥      é›»å­é›¶çµ„ä»¶æ¥­         \n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "                                   ğŸ“Š è©³ç´°åˆ†æå ±å‘Š ğŸ“Š                                   \n",
            "================================================================================\n",
            "\n",
            "å ±å‘Š #1: 4440 - å®œæ–°å¯¦æ¥­\n",
            "--------------------------------------------------\n",
            "ç¶œåˆè©•åˆ†: 81.9\n",
            "æœ€æ–°æ”¶ç›¤åƒ¹: 17.60 å…ƒ\n",
            "ç”¢æ¥­é¡åˆ¥: ç´¡ç¹”çº–ç¶­\n",
            "æ¨è–¦è¡Œå‹•: å¼·åŠ›è²·å…¥\n",
            "ä¿¡å¿ƒåº¦: 63.8%\n",
            "æ¨è–¦ç†ç”±: å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\n",
            "è¶¨å‹¢: ä¸Šæ¼² (5æ—¥æ¼²è·Œ: 3.83%)\n",
            "RSI: 56.7 (åå¤š)\n",
            "MACD: å¼·åŠ›è²·é€²\n",
            "KD: K=34.8, D=29.5\n",
            "--------------------------------------------------\n",
            "\n",
            "å ±å‘Š #2: 4510 - é«˜é‹’\n",
            "--------------------------------------------------\n",
            "ç¶œåˆè©•åˆ†: 81.9\n",
            "æœ€æ–°æ”¶ç›¤åƒ¹: 51.90 å…ƒ\n",
            "ç”¢æ¥­é¡åˆ¥: é›»æ©Ÿæ©Ÿæ¢°\n",
            "æ¨è–¦è¡Œå‹•: å¼·åŠ›è²·å…¥\n",
            "ä¿¡å¿ƒåº¦: 63.8%\n",
            "æ¨è–¦ç†ç”±: å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\n",
            "è¶¨å‹¢: ä¸Šæ¼² (5æ—¥æ¼²è·Œ: 5.92%)\n",
            "RSI: 61.3 (åå¤š)\n",
            "MACD: å¼·åŠ›è²·é€²\n",
            "KD: K=74.0, D=72.2\n",
            "--------------------------------------------------\n",
            "\n",
            "å ±å‘Š #3: 6213 - è¯èŒ‚\n",
            "--------------------------------------------------\n",
            "ç¶œåˆè©•åˆ†: 80.9\n",
            "æœ€æ–°æ”¶ç›¤åƒ¹: 104.00 å…ƒ\n",
            "ç”¢æ¥­é¡åˆ¥: é›»å­é›¶çµ„ä»¶æ¥­\n",
            "æ¨è–¦è¡Œå‹•: å¼·åŠ›è²·å…¥\n",
            "ä¿¡å¿ƒåº¦: 61.8%\n",
            "æ¨è–¦ç†ç”±: å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\n",
            "è¶¨å‹¢: ä¸Šæ¼² (5æ—¥æ¼²è·Œ: 14.66%)\n",
            "RSI: 65.3 (åå¤š)\n",
            "MACD: å¼·åŠ›è²·é€²\n",
            "KD: K=67.1, D=46.2\n",
            "--------------------------------------------------\n",
            "\n",
            "å ±å‘Š #4: 1711 - æ°¸å…‰\n",
            "--------------------------------------------------\n",
            "ç¶œåˆè©•åˆ†: 80.4\n",
            "æœ€æ–°æ”¶ç›¤åƒ¹: 17.50 å…ƒ\n",
            "ç”¢æ¥­é¡åˆ¥: åŒ–å­¸å·¥æ¥­\n",
            "æ¨è–¦è¡Œå‹•: å¼·åŠ›è²·å…¥\n",
            "ä¿¡å¿ƒåº¦: 60.8%\n",
            "æ¨è–¦ç†ç”±: å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\n",
            "è¶¨å‹¢: ä¸Šæ¼² (5æ—¥æ¼²è·Œ: 5.42%)\n",
            "RSI: 64.6 (åå¤š)\n",
            "MACD: å¼·åŠ›è²·é€²\n",
            "KD: K=65.9, D=65.8\n",
            "--------------------------------------------------\n",
            "\n",
            "å ±å‘Š #5: 1773 - å‹ä¸€\n",
            "--------------------------------------------------\n",
            "ç¶œåˆè©•åˆ†: 80.4\n",
            "æœ€æ–°æ”¶ç›¤åƒ¹: 137.00 å…ƒ\n",
            "ç”¢æ¥­é¡åˆ¥: åŒ–å­¸å·¥æ¥­\n",
            "æ¨è–¦è¡Œå‹•: å¼·åŠ›è²·å…¥\n",
            "ä¿¡å¿ƒåº¦: 60.8%\n",
            "æ¨è–¦ç†ç”±: å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\n",
            "è¶¨å‹¢: ä¸Šæ¼² (5æ—¥æ¼²è·Œ: 9.16%)\n",
            "RSI: 53.1 (åå¤š)\n",
            "MACD: å¼·åŠ›è²·é€²\n",
            "KD: K=75.4, D=65.6\n",
            "--------------------------------------------------\n",
            "================================================================================\n",
            "\n",
            "ğŸ“± åˆ†æçµæœå·²ç™¼é€åˆ° Telegram å’Œ Discord\n",
            "\n",
            "ğŸ“Š åœ–è¡¨æª”æ¡ˆå·²ä¿å­˜è‡³: charts\n",
            "   - 4440_å®œæ–°å¯¦æ¥­_20250813_031929.png\n",
            "   - 4510_é«˜é‹’_20250813_031929.png\n",
            "   - 6213_è¯èŒ‚_20250813_031930.png\n",
            "   - 1711_æ°¸å…‰_20250813_031931.png\n",
            "   - 1773_å‹ä¸€_20250813_031931.png\n",
            "\n",
            "âœ… åˆ†æå®Œæˆï¼æ‰¾åˆ° 1200 æ”¯å„ªè³ªè‚¡ç¥¨\n",
            "ğŸ“Š ç”Ÿæˆäº† 5 å€‹åœ–è¡¨æª”æ¡ˆ\n",
            "ğŸ“± é€šçŸ¥å·²ç™¼é€åˆ° Telegram å’Œ Discord\n",
            "\n",
            "============================================================\n",
            "ğŸ“ˆ è©³ç´°åˆ†æçµæœ\n",
            "============================================================\n",
            "\n",
            "1. å®œæ–°å¯¦æ¥­ (4440)\n",
            "   ç¶œåˆè©•åˆ†: 81.9\n",
            "   ç•¶å‰åƒ¹æ ¼: 17.60\n",
            "   æŠ•è³‡å»ºè­°: å¼·åŠ›è²·å…¥\n",
            "   å»ºè­°ç†ç”±: å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\n",
            "   è¶¨å‹¢: ä¸Šæ¼² (5æ—¥æ¼²è·Œ: 3.83%)\n",
            "   RSI: 56.7 (åå¤š)\n",
            "   MACD: å¼·åŠ›è²·é€²\n",
            "   KD: K=34.8, D=29.5\n",
            "\n",
            "2. é«˜é‹’ (4510)\n",
            "   ç¶œåˆè©•åˆ†: 81.9\n",
            "   ç•¶å‰åƒ¹æ ¼: 51.90\n",
            "   æŠ•è³‡å»ºè­°: å¼·åŠ›è²·å…¥\n",
            "   å»ºè­°ç†ç”±: å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\n",
            "   è¶¨å‹¢: ä¸Šæ¼² (5æ—¥æ¼²è·Œ: 5.92%)\n",
            "   RSI: 61.3 (åå¤š)\n",
            "   MACD: å¼·åŠ›è²·é€²\n",
            "   KD: K=74.0, D=72.2\n",
            "\n",
            "3. è¯èŒ‚ (6213)\n",
            "   ç¶œåˆè©•åˆ†: 80.9\n",
            "   ç•¶å‰åƒ¹æ ¼: 104.00\n",
            "   æŠ•è³‡å»ºè­°: å¼·åŠ›è²·å…¥\n",
            "   å»ºè­°ç†ç”±: å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\n",
            "   è¶¨å‹¢: ä¸Šæ¼² (5æ—¥æ¼²è·Œ: 14.66%)\n",
            "   RSI: 65.3 (åå¤š)\n",
            "   MACD: å¼·åŠ›è²·é€²\n",
            "   KD: K=67.1, D=46.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import mplfinance as mpf\n",
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import glob\n",
        "import sys\n",
        "import traceback\n",
        "import requests\n",
        "from io import StringIO\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "import pytz\n",
        "import nest_asyncio\n",
        "from discord_webhook import DiscordWebhook\n",
        "import telegram\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥æ”¯æ´ Jupyter ç’°å¢ƒ\n",
        "nest_asyncio.apply()\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# è¨­å®šæ™‚å€\n",
        "taipei_tz = pytz.timezone('Asia/Taipei')\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å»ºç«‹åœ–è¡¨ç›®éŒ„\n",
        "CHARTS_DIR = \"charts\"\n",
        "os.makedirs(CHARTS_DIR, exist_ok=True)\n",
        "\n",
        "# è‚¡ç¥¨æ¸…å–®å¿«å–è·¯å¾‘\n",
        "STOCK_LIST_PATH = \"taiwan_stocks.csv\"\n",
        "\n",
        "# ==============================================================================\n",
        "# å…¨åŸŸå¸¸æ•¸èˆ‡å¯†é‘°ç®¡ç†\n",
        "# ==============================================================================\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸\n",
        "# ==============================================================================\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            await session.post(url_msg, json=payload, timeout=20)\n",
        "            logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        data = aiohttp.FormData()\n",
        "                        data.add_field('chat_id', str(chat_id))\n",
        "                        with open(file_path, 'rb') as f:\n",
        "                            data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                            await session.post(url_photo, data=data, timeout=60)\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "        if files:\n",
        "            for file_path in files:\n",
        "                if os.path.exists(file_path):\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "        response = webhook.execute()\n",
        "        if response.ok:\n",
        "            logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "        else:\n",
        "            logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "\n",
        "ğŸ“Š TOP 5 æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f}\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "def get_stock_symbols() -> List[str]:\n",
        "    \"\"\"ç²å–è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨\"\"\"\n",
        "    taiwan_stocks = StockAnalyzer().get_taiwan_stocks()\n",
        "    return taiwan_stocks['yahoo_symbol'].tolist()\n",
        "\n",
        "class TechnicalIndicators:\n",
        "    \"\"\"ç´” pandas/numpy æŠ€è¡“æŒ‡æ¨™è¨ˆç®—é¡\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def sma(data: pd.Series, window: int) -> pd.Series:\n",
        "        \"\"\"ç°¡å–®ç§»å‹•å¹³å‡ç·š\"\"\"\n",
        "        return data.rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "    @staticmethod\n",
        "    def ema(data: pd.Series, window: int) -> pd.Series:\n",
        "        \"\"\"æŒ‡æ•¸ç§»å‹•å¹³å‡ç·š\"\"\"\n",
        "        return data.ewm(span=window, adjust=False).mean()\n",
        "\n",
        "    @staticmethod\n",
        "    def rsi(data: pd.Series, window: int = 14) -> pd.Series:\n",
        "        \"\"\"ç›¸å°å¼·å¼±æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            delta = data.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=window, min_periods=1).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "            # é¿å…é™¤é›¶éŒ¯èª¤\n",
        "            rs = gain / loss.replace(0, np.nan)\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi.fillna(50)  # å¡«å…… NaN ç‚ºä¸­æ€§å€¼ 50\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®— RSI æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series([50] * len(data), index=data.index)\n",
        "\n",
        "    @staticmethod\n",
        "    def macd(data: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
        "        \"\"\"MACD æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            ema_fast = TechnicalIndicators.ema(data, fast)\n",
        "            ema_slow = TechnicalIndicators.ema(data, slow)\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            signal_line = TechnicalIndicators.ema(macd_line, signal)\n",
        "            histogram = macd_line - signal_line\n",
        "            return macd_line, signal_line, histogram\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®— MACD æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zeros = pd.Series([0] * len(data), index=data.index)\n",
        "            return zeros, zeros, zeros\n",
        "\n",
        "    @staticmethod\n",
        "    def bollinger_bands(data: pd.Series, window: int = 20, num_std: float = 2) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
        "        \"\"\"å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            sma = TechnicalIndicators.sma(data, window)\n",
        "            std = data.rolling(window=window, min_periods=1).std()\n",
        "            upper_band = sma + (std * num_std)\n",
        "            lower_band = sma - (std * num_std)\n",
        "            return upper_band, sma, lower_band\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            sma = TechnicalIndicators.sma(data, window)\n",
        "            return sma, sma, sma\n",
        "\n",
        "    @staticmethod\n",
        "    def stochastic(high: pd.Series, low: pd.Series, close: pd.Series,\n",
        "                   k_window: int = 14, d_window: int = 3) -> Tuple[pd.Series, pd.Series]:\n",
        "        \"\"\"KD éš¨æ©ŸæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=k_window, min_periods=1).min()\n",
        "            highest_high = high.rolling(window=k_window, min_periods=1).max()\n",
        "\n",
        "            # é¿å…é™¤é›¶éŒ¯èª¤\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low).replace(0, np.nan))\n",
        "            k_percent = k_percent.fillna(50)\n",
        "\n",
        "            # å¹³æ»‘åŒ– K å€¼\n",
        "            k_smooth = k_percent.rolling(window=d_window, min_periods=1).mean()\n",
        "            d_smooth = k_smooth.rolling(window=d_window, min_periods=1).mean()\n",
        "\n",
        "            return k_smooth, d_smooth\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®— KD æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            default_series = pd.Series([50] * len(close), index=close.index)\n",
        "            return default_series, default_series\n",
        "\n",
        "    @staticmethod\n",
        "    def williams_r(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:\n",
        "        \"\"\"å¨å»‰æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            highest_high = high.rolling(window=window, min_periods=1).max()\n",
        "            lowest_low = low.rolling(window=window, min_periods=1).min()\n",
        "            wr = -100 * (highest_high - close) / (highest_high - lowest_low).replace(0, np.nan)\n",
        "            return wr.fillna(-50)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®—å¨å»‰æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series([-50] * len(close), index=close.index)\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.taiwan_stocks = None\n",
        "        self.tech_indicators = TechnicalIndicators()\n",
        "        self.stock_data = {}\n",
        "        self.technical_indicators = {}\n",
        "        self.config = {\n",
        "            'top_n': 10,\n",
        "            'score_weights': {\n",
        "                'rsi': 0.3,\n",
        "                'macd': 0.3,\n",
        "                'volume': 0.2,\n",
        "                'price_trend': 0.2\n",
        "            }\n",
        "        }\n",
        "        self.stocks_df = pd.DataFrame()\n",
        "\n",
        "    def get_stock_symbols(self) -> List[str]:\n",
        "        \"\"\"ç²å–è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨\"\"\"\n",
        "        taiwan_stocks = self.get_taiwan_stocks()\n",
        "        return taiwan_stocks['yahoo_symbol'].tolist()\n",
        "\n",
        "    def standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "            return pd.DataFrame()\n",
        "        df = df.copy()\n",
        "        if df.index.name is not None and 'date' in df.index.name.lower():\n",
        "            df = df.reset_index()\n",
        "        column_mapping = {\n",
        "            'Date': 'Date', 'date': 'Date', 'æ—¥æœŸ': 'Date',\n",
        "            'Open': 'Open', 'open': 'Open', 'é–‹ç›¤åƒ¹': 'Open',\n",
        "            'High': 'High', 'high': 'High', 'æœ€é«˜åƒ¹': 'High',\n",
        "            'Low': 'Low', 'low': 'Low', 'æœ€ä½åƒ¹': 'Low',\n",
        "            'Close': 'Close', 'close': 'Close', 'æ”¶ç›¤åƒ¹': 'Close', 'Adj Close': 'Close',\n",
        "            'Volume': 'Volume', 'volume': 'Volume', 'æˆäº¤é‡': 'Volume',\n",
        "        }\n",
        "        rename_dict = {col: column_mapping.get(col, col) for col in df.columns}\n",
        "        df.rename(columns=rename_dict, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=False):\n",
        "        if not force_update and os.path.exists(STOCK_LIST_PATH):\n",
        "            if (time.time() - os.path.getmtime(STOCK_LIST_PATH)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(STOCK_LIST_PATH, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0]\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:]\n",
        "                df['market'] = market_name\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œç¨‹åºçµ‚æ­¢ã€‚\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "        df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "        df = df[df['stock_id'].str.match(r'^\\d{4}$')].copy()\n",
        "        exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "        df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)]\n",
        "        df['yahoo_symbol'] = df.apply(\n",
        "            lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "        final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "        final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "        final_df.to_csv(STOCK_LIST_PATH, index=False)\n",
        "        logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "        return final_df\n",
        "\n",
        "    def fetch_yfinance_data(self, symbol: str, period: str = '1y', interval: str = '1d') -> Optional[pd.DataFrame]:\n",
        "        \"\"\"ç²å– Yahoo Finance æ•¸æ“š\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            df = ticker.history(period=period, interval=interval)\n",
        "\n",
        "            if df.empty:\n",
        "                logger.warning(f\"ç„¡æ³•ç²å– {symbol} çš„æ•¸æ“š\")\n",
        "                return None\n",
        "\n",
        "            # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º\n",
        "            numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "            for col in numeric_columns:\n",
        "                if col in df.columns:\n",
        "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "            # ç§»é™¤ NaN å€¼\n",
        "            df = df.dropna()\n",
        "\n",
        "            if len(df) < 20:  # è‡³å°‘éœ€è¦20å¤©æ•¸æ“š\n",
        "                logger.warning(f\"{symbol} æ•¸æ“šä¸è¶³ï¼Œåªæœ‰ {len(df)} å¤©\")\n",
        "                return None\n",
        "\n",
        "            logger.info(f\"æˆåŠŸç²å– {symbol} æ•¸æ“šï¼Œå…± {len(df)} ç­†è¨˜éŒ„\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç²å– {symbol} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return None\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ - ç´” pandas ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            df = df.copy()\n",
        "\n",
        "            # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º\n",
        "            for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
        "                if col in df.columns:\n",
        "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "            # ç§»é™¤ NaN å€¼\n",
        "            df = df.dropna()\n",
        "\n",
        "            if len(df) < 20:  # éœ€è¦è¶³å¤ çš„æ•¸æ“šè¨ˆç®—æŒ‡æ¨™\n",
        "                logger.warning(\"æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•è¨ˆç®—æ‰€æœ‰æŠ€è¡“æŒ‡æ¨™\")\n",
        "                return df\n",
        "\n",
        "            # è¨ˆç®—ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = self.tech_indicators.sma(df['Close'], 5)\n",
        "            df['MA10'] = self.tech_indicators.sma(df['Close'], 10)\n",
        "            df['MA20'] = self.tech_indicators.sma(df['Close'], 20)\n",
        "            df['MA60'] = self.tech_indicators.sma(df['Close'], 60)\n",
        "\n",
        "            # è¨ˆç®— EMA\n",
        "            df['EMA12'] = self.tech_indicators.ema(df['Close'], 12)\n",
        "            df['EMA26'] = self.tech_indicators.ema(df['Close'], 26)\n",
        "\n",
        "            # è¨ˆç®— RSI\n",
        "            df['RSI'] = self.tech_indicators.rsi(df['Close'], 14)\n",
        "\n",
        "            # è¨ˆç®— MACD\n",
        "            macd, macd_signal, macd_hist = self.tech_indicators.macd(df['Close'])\n",
        "            df['MACD'] = macd\n",
        "            df['MACD_signal'] = macd_signal\n",
        "            df['Histogram'] = macd_hist\n",
        "\n",
        "            # è¨ˆç®—å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.tech_indicators.bollinger_bands(df['Close'])\n",
        "            df['BB_upper'] = bb_upper\n",
        "            df['BB_middle'] = bb_middle\n",
        "            df['BB_lower'] = bb_lower\n",
        "\n",
        "            # è¨ˆç®— KD æŒ‡æ¨™\n",
        "            k_percent, d_percent = self.tech_indicators.stochastic(\n",
        "                df['High'], df['Low'], df['Close']\n",
        "            )\n",
        "            df['K'] = k_percent\n",
        "            df['D'] = d_percent\n",
        "\n",
        "            # è¨ˆç®—å¨å»‰æŒ‡æ¨™\n",
        "            df['Williams_R'] = self.tech_indicators.williams_r(\n",
        "                df['High'], df['Low'], df['Close']\n",
        "            )\n",
        "\n",
        "            # è¨ˆç®—æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            df['Volume_MA5'] = self.tech_indicators.sma(df['Volume'], 5)\n",
        "            df['Volume_MA20'] = self.tech_indicators.sma(df['Volume'], 20)\n",
        "\n",
        "            # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ–ç‡\n",
        "            df['Price_Change'] = df['Close'].pct_change()\n",
        "            df['Price_Change_5d'] = df['Close'].pct_change(periods=5)\n",
        "\n",
        "            logger.info(\"æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å®Œæˆ\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return df\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ - å®Œå…¨ä¿®å¾©ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç„¡æ³•åˆ¤æ–·', 'strength': 0, 'score': 50}\n",
        "\n",
        "            # ç¢ºä¿å¿…è¦çš„æ¬„ä½å­˜åœ¨\n",
        "            required_columns = ['Close', 'MA5', 'MA20']\n",
        "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "            if missing_columns:\n",
        "                logger.warning(f\"ç¼ºå°‘å¿…è¦çš„åˆ—é€²è¡Œè¶¨å‹¢åˆ†æ: {missing_columns}\")\n",
        "                return {'trend': 'ç„¡æ³•åˆ¤æ–·', 'strength': 0, 'score': 50}\n",
        "\n",
        "            # ç²å–æœ€æ–°æ•¸æ“šï¼Œç¢ºä¿æ²’æœ‰ NaN\n",
        "            latest_data = df.dropna().tail(10)\n",
        "            if latest_data.empty:\n",
        "                return {'trend': 'ç„¡æ³•åˆ¤æ–·', 'strength': 0, 'score': 50}\n",
        "\n",
        "            # ä½¿ç”¨ .iloc[-1] ç²å–æ¨™é‡å€¼ï¼Œé¿å… Series å¸ƒæ—å€¼å•é¡Œ\n",
        "            current_price = float(latest_data['Close'].iloc[-1])\n",
        "            ma5_current = float(latest_data['MA5'].iloc[-1]) if not pd.isna(latest_data['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(latest_data['MA20'].iloc[-1]) if not pd.isna(latest_data['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ– - ä½¿ç”¨æ¨™é‡é‹ç®—\n",
        "            price_change_5d = 0\n",
        "            price_change_10d = 0\n",
        "\n",
        "            if len(latest_data) >= 6:\n",
        "                old_price_5d = float(latest_data['Close'].iloc[-6])\n",
        "                price_change_5d = (current_price - old_price_5d) / old_price_5d * 100\n",
        "\n",
        "            if len(df) >= 11:\n",
        "                old_price_10d = float(df['Close'].iloc[-11])\n",
        "                price_change_10d = (current_price - old_price_10d) / old_price_10d * 100\n",
        "\n",
        "            # è¶¨å‹¢åˆ¤æ–·é‚è¼¯ - ä½¿ç”¨æ¨™é‡æ¯”è¼ƒ\n",
        "            trend_score = 50  # ä¸­æ€§èµ·å§‹åˆ†æ•¸\n",
        "            trend = 'ç›¤æ•´'\n",
        "\n",
        "            # MA æ’åˆ—åˆ¤æ–·\n",
        "            if current_price > ma5_current and ma5_current > ma20_current:\n",
        "                trend_score += 15\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "            elif current_price < ma5_current and ma5_current < ma20_current:\n",
        "                trend_score -= 15\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–åˆ¤æ–·\n",
        "            if price_change_5d > 3:\n",
        "                trend_score += 10\n",
        "            elif price_change_5d < -3:\n",
        "                trend_score -= 10\n",
        "\n",
        "            if price_change_10d > 5:\n",
        "                trend_score += 10\n",
        "            elif price_change_10d < -5:\n",
        "                trend_score -= 10\n",
        "\n",
        "            # è¨ˆç®—è¶¨å‹¢å¼·åº¦\n",
        "            if 'MA60' in df.columns and not pd.isna(latest_data['MA60'].iloc[-1]):\n",
        "                ma60_current = float(latest_data['MA60'].iloc[-1])\n",
        "                if current_price > ma60_current:\n",
        "                    trend_score += 5\n",
        "                else:\n",
        "                    trend_score -= 5\n",
        "\n",
        "            # é™åˆ¶åˆ†æ•¸ç¯„åœ\n",
        "            trend_score = max(0, min(100, trend_score))\n",
        "\n",
        "            # è¨ˆç®—å¼·åº¦\n",
        "            strength = abs(price_change_5d) + abs(price_change_10d)\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'score': trend_score,\n",
        "                'price_change_5d': price_change_5d,\n",
        "                'price_change_10d': price_change_10d,\n",
        "                'current_price': current_price,\n",
        "                'ma5': ma5_current,\n",
        "                'ma20': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'trend': 'ç„¡æ³•åˆ¤æ–·', 'strength': 0, 'score': 50}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ - å®Œå…¨ä¿®å¾©ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "            # ç¢ºä¿ Volume æ¬„ä½å­˜åœ¨ä¸”ç‚ºæ•¸å€¼å‹\n",
        "            if 'Volume' not in df.columns:\n",
        "                logger.warning(\"ç¼ºå°‘ Volume æ¬„ä½\")\n",
        "                return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "            # æ¸…ç†æ•¸æ“š\n",
        "            df_clean = df.dropna(subset=['Volume', 'Close']).copy()\n",
        "            if len(df_clean) < 10:\n",
        "                return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "            # è½‰æ›ç‚ºæ•¸å€¼å‹ä¸¦ç§»é™¤ç•°å¸¸å€¼\n",
        "            df_clean['Volume'] = pd.to_numeric(df_clean['Volume'], errors='coerce')\n",
        "            df_clean['Close'] = pd.to_numeric(df_clean['Close'], errors='coerce')\n",
        "            df_clean = df_clean.dropna(subset=['Volume', 'Close'])\n",
        "\n",
        "            if df_clean.empty:\n",
        "                return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "            # è¨ˆç®—æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            df_clean['Volume_MA5'] = df_clean['Volume'].rolling(window=5, min_periods=1).mean()\n",
        "            df_clean['Volume_MA20'] = df_clean['Volume'].rolling(window=min(20, len(df_clean)), min_periods=1).mean()\n",
        "\n",
        "            # ç²å–æœ€æ–°æ•¸æ“š - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            recent_data = df_clean.tail(10)\n",
        "            current_volume = float(recent_data['Volume'].iloc[-1])\n",
        "            volume_ma5 = float(recent_data['Volume_MA5'].iloc[-1])\n",
        "            volume_ma20 = float(recent_data['Volume_MA20'].iloc[-1])\n",
        "\n",
        "            # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ– - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            price_changes = recent_data['Close'].pct_change().fillna(0)\n",
        "            latest_price_change = float(price_changes.iloc[-1]) if len(price_changes) > 0 else 0\n",
        "\n",
        "            # åƒ¹é‡é…åˆåˆ†æ - ä½¿ç”¨æ¨™é‡æ¯”è¼ƒ\n",
        "            score = 50  # ä¸­æ€§åˆ†æ•¸\n",
        "            volume_trend = 'æ­£å¸¸'\n",
        "\n",
        "            try:\n",
        "                # æˆäº¤é‡è¶¨å‹¢åˆ¤æ–·\n",
        "                if current_volume > volume_ma5 * 1.2:  # æ”¾é‡\n",
        "                    if latest_price_change > 0.02:  # åƒ¹æ¼²é‡å¢\n",
        "                        score += 20\n",
        "                        volume_trend = 'åƒ¹æ¼²é‡å¢'\n",
        "                    elif latest_price_change < -0.02:  # åƒ¹è·Œé‡å¢\n",
        "                        score -= 15\n",
        "                        volume_trend = 'åƒ¹è·Œé‡å¢'\n",
        "                    else:\n",
        "                        score += 5\n",
        "                        volume_trend = 'æ”¾é‡'\n",
        "\n",
        "                elif current_volume < volume_ma5 * 0.8:  # ç¸®é‡\n",
        "                    if latest_price_change > 0.02:  # åƒ¹æ¼²é‡ç¸®\n",
        "                        score -= 10\n",
        "                        volume_trend = 'åƒ¹æ¼²é‡ç¸®'\n",
        "                    elif latest_price_change < -0.02:  # åƒ¹è·Œé‡ç¸®\n",
        "                        score += 10\n",
        "                        volume_trend = 'åƒ¹è·Œé‡ç¸®'\n",
        "                    else:\n",
        "                        volume_trend = 'ç¸®é‡'\n",
        "\n",
        "                # æª¢æŸ¥é€£çºŒæ”¾é‡ - ä½¿ç”¨ numpy é™£åˆ—é¿å… Series å•é¡Œ\n",
        "                recent_volumes = recent_data['Volume'].tail(3).values\n",
        "                if len(recent_volumes) >= 3:\n",
        "                    high_volume_count = np.sum(recent_volumes > volume_ma20 * 1.5)\n",
        "                    if high_volume_count >= 2:\n",
        "                        score += 10\n",
        "\n",
        "                # é™åˆ¶åˆ†æ•¸ç¯„åœ\n",
        "                score = max(0, min(100, score))\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"åƒ¹é‡é…åˆåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                score = 50\n",
        "                volume_trend = 'ç„¡æ³•åˆ¤æ–·'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'score': score,\n",
        "                'current_volume': current_volume,\n",
        "                'volume_ma5': volume_ma5,\n",
        "                'volume_ma20': volume_ma20,\n",
        "\n",
        "                'volume_ratio': current_volume / volume_ma20 if volume_ma20 > 0 else 1\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ - å®Œå…¨ä¿®å¾©ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {'rsi_signal': 'ä¸­æ€§', 'macd_signal': 'ä¸­æ€§', 'kd_signal': 'ä¸­æ€§', 'bb_signal': 'ä¸­æ€§', 'score': 50}\n",
        "\n",
        "            # ç²å–æœ€æ–°æ•¸æ“š\n",
        "            latest = df.dropna().tail(1)\n",
        "            if latest.empty:\n",
        "                return {'rsi_signal': 'ä¸­æ€§', 'macd_signal': 'ä¸­æ€§', 'kd_signal': 'ä¸­æ€§', 'bb_signal': 'ä¸­æ€§', 'score': 50}\n",
        "\n",
        "            score = 50\n",
        "            signals = {}\n",
        "\n",
        "            # RSI åˆ†æ - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            if 'RSI' in latest.columns and not pd.isna(latest['RSI'].iloc[0]):\n",
        "                rsi_value = float(latest['RSI'].iloc[0])\n",
        "                if rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value < 50:\n",
        "                    signals['rsi_signal'] = 'åç©º'\n",
        "                    score -= 5\n",
        "                elif rsi_value > 50:\n",
        "                    signals['rsi_signal'] = 'åå¤š'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = rsi_value\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ç„¡æ•¸æ“š'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            if all(col in latest.columns for col in ['MACD', 'MACD_signal']) and \\\n",
        "               not pd.isna(latest['MACD'].iloc[0]) and not pd.isna(latest['MACD_signal'].iloc[0]):\n",
        "                macd_value = float(latest['MACD'].iloc[0])\n",
        "                signal_value = float(latest['MACD_signal'].iloc[0])\n",
        "\n",
        "                if macd_value > signal_value and macd_value > 0:\n",
        "                    signals['macd_signal'] = 'å¼·åŠ›è²·é€²'\n",
        "                    score += 15\n",
        "                elif macd_value > signal_value:\n",
        "                    signals['macd_signal'] = 'è²·é€²'\n",
        "                    score += 10\n",
        "                elif macd_value < signal_value and macd_value < 0:\n",
        "                    signals['macd_signal'] = 'å¼·åŠ›è³£å‡º'\n",
        "                    score -= 15\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'è³£å‡º'\n",
        "                    score -= 10\n",
        "\n",
        "                signals['macd_value'] = macd_value\n",
        "                signals['macd_signal_value'] = signal_value\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ç„¡æ•¸æ“š'\n",
        "                signals['macd_value'] = 0\n",
        "                signals['macd_signal_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            if all(col in latest.columns for col in ['K', 'D']) and \\\n",
        "               not pd.isna(latest['K'].iloc[0]) and not pd.isna(latest['D'].iloc[0]):\n",
        "                k_value = float(latest['K'].iloc[0])\n",
        "                d_value = float(latest['D'].iloc[0])\n",
        "\n",
        "                if k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 12\n",
        "                elif k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 12\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'è²·é€²'\n",
        "                    score += 8\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'è³£å‡º'\n",
        "                    score -= 8\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ç„¡æ•¸æ“š'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            if all(col in latest.columns for col in ['Close', 'BB_upper', 'BB_lower', 'BB_middle']) and \\\n",
        "               all(not pd.isna(latest[col].iloc[0]) for col in ['Close', 'BB_upper', 'BB_lower', 'BB_middle']):\n",
        "                close_price = float(latest['Close'].iloc[0])\n",
        "                bb_upper = float(latest['BB_upper'].iloc[0])\n",
        "                bb_lower = float(latest['BB_lower'].iloc[0])\n",
        "                bb_middle = float(latest['BB_middle'].iloc[0])\n",
        "\n",
        "                if close_price <= bb_lower:\n",
        "                    signals['bb_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif close_price >= bb_upper:\n",
        "                    signals['bb_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif close_price > bb_middle:\n",
        "                    signals['bb_signal'] = 'åå¤š'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'åç©º'\n",
        "                    score -= 5\n",
        "\n",
        "                signals['bb_position'] = (close_price - bb_lower) / (bb_upper - bb_lower) if (bb_upper - bb_lower) > 0 else 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ç„¡æ•¸æ“š'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            # å¨å»‰æŒ‡æ¨™åˆ†æ\n",
        "            if 'Williams_R' in latest.columns and not pd.isna(latest['Williams_R'].iloc[0]):\n",
        "                wr_value = float(latest['Williams_R'].iloc[0])\n",
        "                if wr_value < -80:\n",
        "                    score += 8\n",
        "                elif wr_value > -20:\n",
        "                    score -= 8\n",
        "                signals['williams_r'] = wr_value\n",
        "            else:\n",
        "                signals['williams_r'] = -50\n",
        "\n",
        "            # é™åˆ¶åˆ†æ•¸ç¯„åœ\n",
        "            score = max(0, min(100, score))\n",
        "\n",
        "            return {\n",
        "                **signals,\n",
        "                'score': score\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'rsi_signal': 'ä¸­æ€§', 'macd_signal': 'ä¸­æ€§', 'kd_signal': 'ä¸­æ€§', 'bb_signal': 'ä¸­æ€§', 'score': 50}\n",
        "\n",
        "    def analyze_stock(self, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"å®Œæ•´è‚¡ç¥¨åˆ†æ\"\"\"\n",
        "        try:\n",
        "            stock_id = stock_info.get('stock_id', '')\n",
        "            stock_name = stock_info.get('stock_name', '')\n",
        "            df = stock_info.get('data')\n",
        "\n",
        "            if df is None or df.empty:\n",
        "                logger.warning(f\"{stock_name} ç„¡æ•¸æ“šå¯åˆ†æ\")\n",
        "                return {'success': False, 'error': 'ç„¡æ•¸æ“š'}\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # å„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # ç¶œåˆè©•åˆ†è¨ˆç®— - ä½¿ç”¨æ¨™é‡é‹ç®—\n",
        "            trend_score = float(trend_analysis.get('score', 50))\n",
        "            volume_score = float(volume_analysis.get('score', 50))\n",
        "            technical_score = float(technical_analysis.get('score', 50))\n",
        "\n",
        "            # åŠ æ¬Šè¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = (trend_score * 0.4 + volume_score * 0.3 + technical_score * 0.3)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼å’ŒåŸºæœ¬è³‡è¨Š\n",
        "            latest_data = df_with_indicators.dropna().tail(1)\n",
        "            if not latest_data.empty:\n",
        "                current_price = float(latest_data['Close'].iloc[0])\n",
        "                current_volume = float(latest_data['Volume'].iloc[0]) if 'Volume' in latest_data.columns else 0\n",
        "            else:\n",
        "                current_price = 0\n",
        "                current_volume = 0\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            result = {\n",
        "                'success': True,\n",
        "                'stock_id': stock_id,\n",
        "                'stock_name': stock_name,\n",
        "                'current_price': current_price,\n",
        "                'current_volume': current_volume,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'data_df': df_with_indicators,\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'market': stock_info.get('market', '')\n",
        "            }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_info.get('stock_name', '')} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'success': False, 'error': str(e)}\n",
        "\n",
        "    def generate_recommendation(self, score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, str]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            # åŸºæ–¼ç¶œåˆåˆ†æ•¸çš„å»ºè­°\n",
        "            if score >= 75:\n",
        "                action = \"å¼·åŠ›è²·å…¥\"\n",
        "                reason = \"å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\"\n",
        "            elif score >= 65:\n",
        "                action = \"è²·å…¥\"\n",
        "                reason = \"æŠ€è¡“é¢åå¤šï¼Œå»ºè­°é€¢ä½è²·å…¥\"\n",
        "            elif score >= 55:\n",
        "                action = \"æŒæœ‰\"\n",
        "                reason = \"ç›¤æ•´æ ¼å±€ï¼Œå¯æŒæœ‰è§€æœ›\"\n",
        "            elif score >= 45:\n",
        "                action = \"è§€æœ›\"\n",
        "                reason = \"è¶¨å‹¢ä¸æ˜ç¢ºï¼Œå»ºè­°è§€æœ›\"\n",
        "            elif score >= 35:\n",
        "                action = \"æ¸›ç¢¼\"\n",
        "                reason = \"æŠ€è¡“é¢è½‰å¼±ï¼Œå»ºè­°æ¸›ç¢¼\"\n",
        "            else:\n",
        "                action = \"è³£å‡º\"\n",
        "                reason = \"å¤šé …æŒ‡æ¨™é¡¯ç¤ºä¸‹è·Œè¶¨å‹¢\"\n",
        "\n",
        "            # åŠ å…¥ç‰¹æ®Šæƒ…æ³åˆ¤æ–·\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "\n",
        "            if rsi_signal == 'è¶…è³£' and trend != 'ä¸‹è·Œ':\n",
        "                action = \"é€¢ä½è²·å…¥\"\n",
        "                reason += \"ï¼ŒRSIé¡¯ç¤ºè¶…è³£\"\n",
        "            elif rsi_signal == 'è¶…è²·' and score < 70:\n",
        "                action = \"ç²åˆ©äº†çµ\"\n",
        "                reason += \"ï¼ŒRSIé¡¯ç¤ºè¶…è²·\"\n",
        "\n",
        "            return {\n",
        "                'action': action,\n",
        "                'reason': reason,\n",
        "                'confidence': min(100, abs(score - 50) * 2)  # ä¿¡å¿ƒåº¦\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'action': 'è§€æœ›', 'reason': 'åˆ†æç•°å¸¸', 'confidence': 0}\n",
        "\n",
        "    def advanced_multi_criteria_filter(self, analysis_results: Dict) -> Dict:\n",
        "        \"\"\"é€²éšå¤šé‡æ¢ä»¶ç¯©é¸\"\"\"\n",
        "        try:\n",
        "            if not analysis_results:\n",
        "                logger.warning(\"æ²’æœ‰åˆ†æçµæœå¯ä¾›ç¯©é¸\")\n",
        "                return {}\n",
        "\n",
        "            filtered_stocks = {}\n",
        "\n",
        "            for stock_id, result in analysis_results.items():\n",
        "                try:\n",
        "                    # åŸºæœ¬æ¢ä»¶æª¢æŸ¥\n",
        "                    if not result.get('success', False):\n",
        "                        continue\n",
        "\n",
        "                    score = float(result.get('combined_score', 0))\n",
        "                    trend_analysis = result.get('trend_analysis', {})\n",
        "                    technical_analysis = result.get('technical_analysis', {})\n",
        "                    volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "                    # ç¯©é¸æ¢ä»¶\n",
        "                    conditions_met = 0\n",
        "                    total_conditions = 6\n",
        "\n",
        "                    # 1. ç¶œåˆåˆ†æ•¸æ¢ä»¶\n",
        "                    if score >= 55:\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 2. è¶¨å‹¢æ¢ä»¶\n",
        "                    trend = trend_analysis.get('trend', '')\n",
        "                    if trend in ['ä¸Šæ¼²', 'ç›¤æ•´']:\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 3. RSI æ¢ä»¶ - é¿å…æ¥µç«¯è¶…è²·\n",
        "                    rsi_value = technical_analysis.get('rsi_value', 50)\n",
        "                    if 20 <= rsi_value <= 75:  # ä¸è¦æ¥µç«¯è¶…è²·æˆ–è¶…è³£\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 4. MACD æ¢ä»¶\n",
        "                    macd_signal = technical_analysis.get('macd_signal', '')\n",
        "                    if macd_signal in ['è²·é€²', 'å¼·åŠ›è²·é€²']:\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 5. æˆäº¤é‡æ¢ä»¶\n",
        "                    volume_trend = volume_analysis.get('volume_trend', '')\n",
        "                    if volume_trend in ['åƒ¹æ¼²é‡å¢', 'æ”¾é‡', 'æ­£å¸¸']:\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 6. åƒ¹æ ¼è¶¨å‹¢æ¢ä»¶\n",
        "                    price_change_5d = trend_analysis.get('price_change_5d', 0)\n",
        "                    if price_change_5d >= -5:  # è¿‘æœŸè·Œå¹…ä¸è¶…é5%\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # è‡³å°‘æ»¿è¶³ 4/6 æ¢ä»¶æ‰ç´å…¥\n",
        "                    if conditions_met >= 4:\n",
        "                        filtered_stocks[stock_id] = result\n",
        "                        logger.info(f\"{result.get('stock_name', '')} é€šéç¯©é¸ ({conditions_met}/{total_conditions})\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"ç¯©é¸è‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # æŒ‰ç¶œåˆåˆ†æ•¸æ’åº\n",
        "            sorted_stocks = dict(sorted(\n",
        "                filtered_stocks.items(),\n",
        "                key=lambda x: x[1].get('combined_score', 0),\n",
        "                reverse=True\n",
        "            ))\n",
        "\n",
        "            logger.info(f\"ç¯©é¸å®Œæˆï¼Œå…± {len(sorted_stocks)} æ”¯è‚¡ç¥¨é€šéæ¢ä»¶\")\n",
        "            return sorted_stocks\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"é€²éšç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def print_advanced_filtered_stocks(self, filtered_results):\n",
        "        \"\"\"è¼¸å‡ºç¯©é¸çµæœ\"\"\"\n",
        "        try:\n",
        "            # å…ˆæª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™\n",
        "            if not filtered_results:\n",
        "                print(\"\\n\".join([\n",
        "                    \"âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\",\n",
        "                    \"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–å¢åŠ åˆ†æè‚¡ç¥¨æ•¸é‡\",\n",
        "                    \"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\"\n",
        "                ]))\n",
        "                return\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"ğŸ¯ æœ€çµ‚ç¯©é¸å„ªè³ªè‚¡ç¥¨æ¸…å–® ğŸ¯\".center(80))\n",
        "            print(\"=\"*80)\n",
        "            print(f\"{'æ’å':<4}{'ä»£ç¢¼':<7}{'åç¨±':<12}{'åˆ†æ•¸':<7}{'åƒ¹æ ¼':<10}{'å»ºè­°':<10}{'ç”¢æ¥­':<15}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "            # è¼¸å‡ºæ¯æ”¯è‚¡ç¥¨çš„è³‡è¨Š\n",
        "            for i, (stock_id, stock) in enumerate(list(filtered_results.items())[:10], 1):\n",
        "                print(\n",
        "                    f\"{i:<4}\"\n",
        "                    f\"{stock_id:<7}\"\n",
        "                    f\"{stock['stock_name'][:10]:<12}\"\n",
        "                    f\"{stock['combined_score']:<7.1f}\"\n",
        "                    f\"{stock['current_price']:<10.2f}\"\n",
        "                    f\"{stock['recommendation']['action'][:8]:<10}\"\n",
        "                    f\"{stock.get('industry', '')[:12]:<15}\"\n",
        "                )\n",
        "            print(\"=\" * 80)\n",
        "\n",
        "            # è¼¸å‡ºè©³ç´°å ±å‘Š\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"ğŸ“Š è©³ç´°åˆ†æå ±å‘Š ğŸ“Š\".center(80))\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            for i, (stock_id, stock) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "                print(f\"\\nå ±å‘Š #{i}: {stock_id} - {stock['stock_name']}\")\n",
        "                print(\"-\" * 50)\n",
        "                print(f\"ç¶œåˆè©•åˆ†: {stock['combined_score']:.1f}\")\n",
        "                print(f\"æœ€æ–°æ”¶ç›¤åƒ¹: {stock['current_price']:.2f} å…ƒ\")\n",
        "                print(f\"ç”¢æ¥­é¡åˆ¥: {stock.get('industry', 'æœªåˆ†é¡')}\")\n",
        "                print(f\"æ¨è–¦è¡Œå‹•: {stock['recommendation']['action']}\")\n",
        "                print(f\"ä¿¡å¿ƒåº¦: {stock['recommendation']['confidence']:.1f}%\")\n",
        "                print(f\"æ¨è–¦ç†ç”±: {stock['recommendation']['reason']}\")\n",
        "\n",
        "                # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "                tech = stock['technical_analysis']\n",
        "                trend = stock['trend_analysis']\n",
        "                print(f\"è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')} (5æ—¥æ¼²è·Œ: {trend.get('price_change_5d', 0):.2f}%)\")\n",
        "                print(f\"RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "                print(f\"MACD: {tech.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "                print(f\"KD: K={tech.get('k_value', 50):.1f}, D={tech.get('d_value', 50):.1f}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "            print(\"=\" * 80)\n",
        "            print(\"\\nğŸ“± åˆ†æçµæœå·²ç™¼é€åˆ° Telegram å’Œ Discord\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¼¸å‡ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            print(\"\\n\".join([\n",
        "                \"âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\",\n",
        "                \"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–å¢åŠ åˆ†æè‚¡ç¥¨æ•¸é‡\",\n",
        "                \"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\"\n",
        "            ]))\n",
        "\n",
        "    def create_stock_chart(self, stock_data: Dict, save_path: str = None) -> str:\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨åœ–è¡¨ - å¢å¼·ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            df = stock_data['data_df'].copy()\n",
        "            stock_name = stock_data['stock_name']\n",
        "            stock_id = stock_data['stock_id']\n",
        "\n",
        "            if df.empty or len(df) < 20:\n",
        "                logger.warning(f\"æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•ç¹ªè£½ {stock_name} åœ–è¡¨\")\n",
        "                return None\n",
        "\n",
        "            # æº–å‚™æ•¸æ“š\n",
        "            df = df.dropna().tail(60)  # å–æœ€è¿‘60å¤©\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "\n",
        "            # è¨­å®šåœ–è¡¨æ¨£å¼\n",
        "            mc = mpf.make_marketcolors(up='r', down='g', inherit=True)\n",
        "            s = mpf.make_mpf_style(marketcolors=mc, gridstyle='-', y_on_right=False)\n",
        "\n",
        "            # æ·»åŠ æŠ€è¡“æŒ‡æ¨™\n",
        "            apds = []\n",
        "\n",
        "            # æ·»åŠ ç§»å‹•å¹³å‡ç·š\n",
        "            if all(col in df.columns for col in ['MA5', 'MA20', 'MA60']):\n",
        "                apds.append(mpf.make_addplot(df['MA5'], color='orange', width=1.5, alpha=0.8))\n",
        "                apds.append(mpf.make_addplot(df['MA20'], color='blue', width=1.5, alpha=0.8))\n",
        "                apds.append(mpf.make_addplot(df['MA60'], color='purple', width=1, alpha=0.7))\n",
        "\n",
        "            # æ·»åŠ å¸ƒæ—å¸¶\n",
        "            if all(col in df.columns for col in ['BB_upper', 'BB_lower']):\n",
        "                apds.append(mpf.make_addplot(df['BB_upper'], color='gray', width=0.8, alpha=0.5, linestyle='--'))\n",
        "                apds.append(mpf.make_addplot(df['BB_lower'], color='gray', width=0.8, alpha=0.5, linestyle='--'))\n",
        "\n",
        "            # æ·»åŠ æˆäº¤é‡\n",
        "            if 'Volume' in df.columns:\n",
        "                apds.append(mpf.make_addplot(df['Volume'], panel=1, type='bar', alpha=0.7, color='lightblue'))\n",
        "                if 'Volume_MA20' in df.columns:\n",
        "                    apds.append(mpf.make_addplot(df['Volume_MA20'], panel=1, color='red', width=1))\n",
        "\n",
        "            # æ·»åŠ  RSI\n",
        "            if 'RSI' in df.columns:\n",
        "                apds.append(mpf.make_addplot(df['RSI'], panel=2, color='purple', width=1.2))\n",
        "                # RSI è¶…è²·è¶…è³£ç·š\n",
        "                rsi_70 = pd.Series([70] * len(df), index=df.index)\n",
        "                rsi_30 = pd.Series([30] * len(df), index=df.index)\n",
        "                apds.append(mpf.make_addplot(rsi_70, panel=2, color='red', width=0.8, linestyle='--', alpha=0.7))\n",
        "                apds.append(mpf.make_addplot(rsi_30, panel=2, color='green', width=0.8, linestyle='--', alpha=0.7))\n",
        "\n",
        "            # è¨­å®šæª”æ¡ˆè·¯å¾‘\n",
        "            if save_path is None:\n",
        "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "                save_path = os.path.join(CHARTS_DIR, f\"{stock_id}_{stock_name}_{timestamp}.png\")\n",
        "\n",
        "            # ç²å–åˆ†æçµæœç”¨æ–¼æ¨™é¡Œ\n",
        "            current_price = stock_data.get('current_price', 0)\n",
        "            combined_score = stock_data.get('combined_score', 0)\n",
        "            recommendation = stock_data.get('recommendation', {}).get('action', 'è§€æœ›')\n",
        "\n",
        "            # ç¹ªè£½åœ–è¡¨\n",
        "            mpf.plot(\n",
        "                df,\n",
        "                type='candle',\n",
        "                style=s,\n",
        "                addplot=apds,\n",
        "                volume=False,  # æˆ‘å€‘æ‰‹å‹•æ·»åŠ æˆäº¤é‡\n",
        "                title=f\"{stock_name} ({stock_id}) - åƒ¹æ ¼: {current_price:.2f} | è©•åˆ†: {combined_score:.1f} | å»ºè­°: {recommendation}\",\n",
        "                ylabel='åƒ¹æ ¼ (TWD)',\n",
        "                ylabel_lower='æˆäº¤é‡',\n",
        "                figsize=(14, 10),\n",
        "                savefig=dict(fname=save_path, dpi=150, bbox_inches='tight'),\n",
        "                tight_layout=True,\n",
        "                panel_ratios=(3, 1, 1)  # ä¸»åœ–:æˆäº¤é‡:RSI = 3:1:1\n",
        "            )\n",
        "\n",
        "            logger.info(f\"æˆåŠŸå‰µå»º {stock_name} åœ–è¡¨: {save_path}\")\n",
        "            return save_path\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å‰µå»ºåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    async def run_analysis(self):\n",
        "        \"\"\"åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹ - æ•´åˆé€šçŸ¥åŠŸèƒ½\"\"\"\n",
        "        try:\n",
        "            logger.info(\"é–‹å§‹è‚¡ç¥¨åˆ†ææµç¨‹...\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ¸…å–®\n",
        "            stocks_df = self.get_taiwan_stocks()\n",
        "            if stocks_df.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return\n",
        "\n",
        "            # é™åˆ¶åˆ†ææ•¸é‡\n",
        "            stocks_to_analyze = stocks_df.head(2000)  # åˆ†æå‰50æ”¯è‚¡ç¥¨\n",
        "            logger.info(f\"å°‡åˆ†æ {len(stocks_to_analyze)} æ”¯è‚¡ç¥¨\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            analysis_results = {}\n",
        "            for _, stock in stocks_to_analyze.iterrows():\n",
        "                try:\n",
        "                    symbol = stock['yahoo_symbol']\n",
        "                    logger.info(f\"æ­£åœ¨ç²å– {stock['stock_name']} ({symbol}) æ•¸æ“š...\")\n",
        "\n",
        "                    df = self.fetch_yfinance_data(symbol)\n",
        "                    if df is not None and not df.empty:\n",
        "                        stock_info = stock.to_dict()\n",
        "                        stock_info['data'] = df\n",
        "\n",
        "                        # åˆ†æè‚¡ç¥¨\n",
        "                        result = self.analyze_stock(stock_info)\n",
        "                        if result.get('success', False):\n",
        "                            analysis_results[stock['stock_id']] = result\n",
        "                            logger.info(f\"å®Œæˆ {stock['stock_name']} åˆ†æï¼Œè©•åˆ†: {result.get('combined_score', 0):.1f}\")\n",
        "\n",
        "                    # é¿å…è«‹æ±‚éæ–¼é »ç¹\n",
        "                    await asyncio.sleep(0.5)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"åˆ†æ {stock['stock_name']} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # é€²éšç¯©é¸\n",
        "            filtered_results = self.advanced_multi_criteria_filter(analysis_results)\n",
        "\n",
        "            # è¼¸å‡ºçµæœ\n",
        "            self.print_advanced_filtered_stocks(filtered_results)\n",
        "\n",
        "            # ç”Ÿæˆåœ–è¡¨\n",
        "            chart_files = []\n",
        "            for stock_id, result in list(filtered_results.items())[:5]:  # åªç‚ºå‰5åç”Ÿæˆåœ–è¡¨\n",
        "                try:\n",
        "                    chart_path = self.create_stock_chart(result)\n",
        "                    if chart_path and os.path.exists(chart_path):\n",
        "                        chart_files.append(chart_path)\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"ç”Ÿæˆ {result.get('stock_name', '')} åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "            # ç™¼é€é€šçŸ¥\n",
        "            try:\n",
        "                async with aiohttp.ClientSession() as session:\n",
        "                    # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "                    message = format_notification_message(filtered_results)\n",
        "\n",
        "                    # ç™¼é€é€šçŸ¥å’Œåœ–è¡¨\n",
        "                    await send_notification(session, message, chart_files)\n",
        "                    logger.info(\"é€šçŸ¥ç™¼é€å®Œæˆ\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç™¼é€é€šçŸ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "            if chart_files:\n",
        "                logger.info(f\"æˆåŠŸç”Ÿæˆ {len(chart_files)} å€‹åœ–è¡¨æª”æ¡ˆ\")\n",
        "                print(f\"\\nğŸ“Š åœ–è¡¨æª”æ¡ˆå·²ä¿å­˜è‡³: {CHARTS_DIR}\")\n",
        "                for chart_file in chart_files:\n",
        "                    print(f\"   - {os.path.basename(chart_file)}\")\n",
        "            else:\n",
        "                logger.warning(\"æœªç”Ÿæˆä»»ä½•åœ–è¡¨æª”æ¡ˆ\")\n",
        "\n",
        "            return filtered_results, chart_files\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åŸ·è¡Œåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {}, []\n",
        "\n",
        "# ä¸»ç¨‹å¼\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼ - æ•´åˆé€šçŸ¥åŠŸèƒ½\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ é–‹å§‹å°è‚¡æŠ€è¡“åˆ†æ...\")\n",
        "        print(\"ğŸ“Š ä½¿ç”¨ç´” pandas/numpy è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\")\n",
        "        print(\"ğŸ“± å°‡è‡ªå‹•ç™¼é€åˆ†æçµæœåˆ° Telegram å’Œ Discord\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        analyzer = StockAnalyzer()\n",
        "        results, charts = await analyzer.run_analysis()\n",
        "\n",
        "        if results:\n",
        "            print(f\"\\nâœ… åˆ†æå®Œæˆï¼æ‰¾åˆ° {len(results)} æ”¯å„ªè³ªè‚¡ç¥¨\")\n",
        "            print(f\"ğŸ“Š ç”Ÿæˆäº† {len(charts)} å€‹åœ–è¡¨æª”æ¡ˆ\")\n",
        "            print(f\"ğŸ“± é€šçŸ¥å·²ç™¼é€åˆ° Telegram å’Œ Discord\")\n",
        "\n",
        "            # é¡¯ç¤ºè©³ç´°åˆ†æçµæœ\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"ğŸ“ˆ è©³ç´°åˆ†æçµæœ\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            for i, (stock_id, result) in enumerate(list(results.items())[:3], 1):\n",
        "                print(f\"\\n{i}. {result['stock_name']} ({stock_id})\")\n",
        "                print(f\"   ç¶œåˆè©•åˆ†: {result['combined_score']:.1f}\")\n",
        "                print(f\"   ç•¶å‰åƒ¹æ ¼: {result['current_price']:.2f}\")\n",
        "                print(f\"   æŠ•è³‡å»ºè­°: {result['recommendation']['action']}\")\n",
        "                print(f\"   å»ºè­°ç†ç”±: {result['recommendation']['reason']}\")\n",
        "\n",
        "                # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "                tech = result['technical_analysis']\n",
        "                trend = result['trend_analysis']\n",
        "                print(f\"   è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')} (5æ—¥æ¼²è·Œ: {trend.get('price_change_5d', 0):.2f}%)\")\n",
        "                print(f\"   RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "                print(f\"   MACD: {tech.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "                print(f\"   KD: K={tech.get('k_value', 50):.1f}, D={tech.get('d_value', 50):.1f}\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\nâŒ æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "            print(\"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–å¢åŠ åˆ†æè‚¡ç¥¨æ•¸é‡\")\n",
        "\n",
        "            # å³ä½¿æ²’æœ‰çµæœä¹Ÿç™¼é€é€šçŸ¥\n",
        "            try:\n",
        "                async with aiohttp.ClientSession() as session:\n",
        "                    message = format_notification_message({})\n",
        "                    await send_notification(session, message)\n",
        "                    print(\"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç™¼é€ç©ºçµæœé€šçŸ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                error_message = f\"\"\"\n",
        "ğŸš¨ å°è‚¡åˆ†æç¨‹å¼åŸ·è¡ŒéŒ¯èª¤\n",
        "\n",
        "âŒ éŒ¯èª¤è¨Šæ¯: {str(e)}\n",
        "â° æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "è«‹æª¢æŸ¥ç¨‹å¼ç‹€æ…‹ä¸¦é‡æ–°åŸ·è¡Œã€‚\n",
        "\"\"\"\n",
        "                await send_notification(session, error_message)\n",
        "                logger.info(\"éŒ¯èª¤é€šçŸ¥å·²ç™¼é€\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "# åŸ·è¡Œç¨‹å¼\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6sgSzOBcZNx"
      },
      "source": [
        "ä¸Šé¢å¯ç™¼è¨Šdiscordæœ‰è¨Šæ¯ä¸”æœ‰åœ–ï¼Œtelgramæœ‰è¨Šæ¯ä¸”æœ‰åœ–ï¼Œçµ‚ç«¯æœ‰å ±å‘Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVCEg_gGR-rW"
      },
      "outputs": [],
      "source": [
        "!pip install mplfinance chineseize_matplotlib yfinance pandas numpy matplotlib plotly discord-webhook requests aiohttp python-telegram-bot nest-asyncio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOP5NOQk_fs2",
        "outputId": "551a5a4a-3970-4b11-e1aa-c924a071c1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å·²è¼‰å…¥ chineseize_matplotlib ä¸­æ–‡å­—é«”æ”¯æ´\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install mplfinance chineseize_matplotlib yfinance pandas numpy matplotlib plotly discord-webhook requests aiohttp python-telegram-bot nest-asyncio -q\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…·\n",
        "=======================\n",
        "åŠŸèƒ½ï¼š\n",
        "- è‡ªå‹•ç²å–å°è‚¡æ¸…å–®\n",
        "- æ‰¹æ¬¡ä¸‹è¼‰æ­·å²æ•¸æ“š\n",
        "- æŠ€è¡“æŒ‡æ¨™åˆ†æ\n",
        "- ç¶œåˆè©•åˆ†æ’å\n",
        "- è‡ªå‹•é€šçŸ¥æ¨é€\n",
        "- åœ–è¡¨ç”Ÿæˆèˆ‡å ±å‘ŠåŒ¯å‡º\n",
        "\n",
        "ä½œè€…ï¼šè‚¡ç¥¨åˆ†æç³»çµ±\n",
        "ç‰ˆæœ¬ï¼šv2.1\n",
        "æ›´æ–°æ—¥æœŸï¼š2025-08-08\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. åŸºç¤ Python æ¨™æº–åº«\n",
        "# ==============================================================================\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import platform\n",
        "import re\n",
        "import glob\n",
        "import asyncio\n",
        "import warnings\n",
        "from io import StringIO\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "import logging\n",
        "import random\n",
        "# ==============================================================================\n",
        "# 2. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ•¸æ“šè™•ç†èˆ‡ç§‘å­¸è¨ˆç®—\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. ç¬¬ä¸‰æ–¹å¥—ä»¶ - ç¶²è·¯è«‹æ±‚èˆ‡ç•°æ­¥è™•ç†\n",
        "# ==============================================================================\n",
        "import requests\n",
        "import aiohttp\n",
        "import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥æ”¯æ´ Jupyter ç’°å¢ƒ\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. ç¬¬ä¸‰æ–¹å¥—ä»¶ - é‡‘èæ•¸æ“šæº\n",
        "# ==============================================================================\n",
        "import yfinance as yf\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ•¸æ“šå¯è¦–åŒ–\n",
        "# ==============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "import mplfinance as mpf\n",
        "import plotly.graph_objects as go\n",
        "from pathlib import Path\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ™‚å€èˆ‡é€šçŸ¥\n",
        "# ==============================================================================\n",
        "import pytz\n",
        "from discord_webhook import DiscordWebhook\n",
        "import telegram\n",
        "# ==============================================================================\n",
        "# 7. ä¸­æ–‡å­—é«”æ”¯æ´\n",
        "# ==============================================================================\n",
        "try:\n",
        "    import chineseize_matplotlib\n",
        "    chineseize_matplotlib.chineseize()\n",
        "    print(\"âœ… å·²è¼‰å…¥ chineseize_matplotlib ä¸­æ–‡å­—é«”æ”¯æ´\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ æœªå®‰è£ chineseize_matplotlibï¼Œå°‡ä½¿ç”¨è‡ªå®šç¾©å­—é«”è¨­å®š\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 8. å…¨åŸŸè¨­å®š\n",
        "# ==============================================================================\n",
        "# è­¦å‘Šéæ¿¾\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# æ™‚å€è¨­å®š\n",
        "taipei_tz = pytz.timezone('Asia/Taipei')\n",
        "\n",
        "# ç›®éŒ„çµæ§‹è¨­å®š\n",
        "CACHE_DIR = 'cache'\n",
        "RESULTS_DIR = 'results'\n",
        "CHARTS_DIR = os.path.join(RESULTS_DIR, 'charts')\n",
        "STOCK_LIST_PATH = os.path.join(CACHE_DIR, 'stock_list.csv')\n",
        "HISTORY_DATA_CACHE_DIR = os.path.join(CACHE_DIR, 'history_data')\n",
        "\n",
        "# åˆå§‹åŒ–ç›®éŒ„\n",
        "for directory in [CACHE_DIR, RESULTS_DIR, CHARTS_DIR, HISTORY_DATA_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# 9. é€šè¨Šèˆ‡é€šçŸ¥è¨­å®š\n",
        "# ==============================================================================\n",
        "# å»ºè­°å°‡ä¾†ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ– .env æª”æ¡ˆç®¡ç†å¯†é‘°ï¼Œä»¥ç­–å®‰å…¨\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]  # æ”¯æ´å¤šç”¨æˆ¶é€šçŸ¥\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "# æ–°å¢æ­¤è¡Œï¼šå…¨åŸŸé€šçŸ¥é–‹é—œ\n",
        "# è¨­å®šç‚º True ä»¥å•Ÿç”¨ Telegram å’Œ Discord é€šçŸ¥ï¼Œè¨­å®šç‚º False å‰‡åœç”¨æ‰€æœ‰é€šçŸ¥\n",
        "\n",
        "MESSAGING_AVAILABLE = True\n",
        "# ==============================================================================\n",
        "# 10. æ—¥èªŒç³»çµ±è¨­å®š\n",
        "# ==============================================================================\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"stock_analysis.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ==============================================================================\n",
        "# 11. å­—é«”èˆ‡ç’°å¢ƒè¨­å®šå‡½å¼\n",
        "# ==============================================================================\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "\n",
        "    æ”¯æ´çš„ä½œæ¥­ç³»çµ±ï¼š\n",
        "    - Windows: Microsoft JhengHei, Microsoft YaHei, SimHei\n",
        "    - macOS: PingFang HK, PingFang SC, Heiti TC\n",
        "    - Linux: Noto Sans CJK / WenQuanYi Zen Hei\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            # Windows ç³»çµ±å­—é«”è¨­å®šï¼ˆåŒ…å«ç¹é«”ä¸­æ–‡å„ªå…ˆï¼‰\n",
        "            font_candidates = [\n",
        "                'Microsoft JhengHei',  # å¾®è»Ÿæ­£é»‘é«”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰\n",
        "                'Microsoft YaHei',     # å¾®è»Ÿé›…é»‘ï¼ˆç°¡é«”ä¸­æ–‡ï¼‰\n",
        "                'Arial Unicode MS',    # è¬åœ‹ç¢¼å­—é«”\n",
        "                'SimHei',              # é»‘é«”\n",
        "                'KaiTi'                # æ¥·é«”\n",
        "            ]\n",
        "\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    # æ¸¬è©¦å­—é«”æ˜¯å¦å¯ç”¨\n",
        "                    test_fig, test_ax = plt.subplots(figsize=(1, 1))\n",
        "                    test_ax.text(0.5, 0.5, 'æ¸¬è©¦', fontname=font)\n",
        "                    plt.close(test_fig)\n",
        "\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        elif system == 'Darwin':  # macOS\n",
        "            # macOS ç³»çµ±å­—é«”è¨­å®š\n",
        "            font_candidates = [\n",
        "                'PingFang HK',      # è˜‹æ–¹-é¦™æ¸¯\n",
        "                'PingFang SC',      # è˜‹æ–¹-ç°¡é«”ä¸­æ–‡\n",
        "                'PingFang TC',      # è˜‹æ–¹-ç¹é«”ä¸­æ–‡\n",
        "                'Heiti TC',         # é»‘é«”-ç¹é«”ä¸­æ–‡\n",
        "                'Heiti SC',         # é»‘é«”-ç°¡é«”ä¸­æ–‡\n",
        "                'STHeiti'           # è¯æ–‡é»‘é«”\n",
        "            ]\n",
        "\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        else:  # Linux å’Œå…¶ä»–ç³»çµ±\n",
        "            # Linux ç³»çµ±å­—é«”è·¯å¾‘\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/ukai.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/uming.ttc',\n",
        "                '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'\n",
        "            ]\n",
        "\n",
        "            found_font_path = None\n",
        "            for path in font_paths:\n",
        "                if os.path.exists(path):\n",
        "                    found_font_path = path\n",
        "                    break\n",
        "\n",
        "            if found_font_path:\n",
        "                try:\n",
        "                    font_manager.fontManager.addfont(found_font_path)\n",
        "                    font_prop = font_manager.FontProperties(fname=found_font_path)\n",
        "                    font_name = font_prop.get_name()\n",
        "                    plt.rcParams['font.sans-serif'] = [font_name]\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"è¼‰å…¥å­—é«”å¤±æ•—: {e}\")\n",
        "                    font_name = \"DejaVu Sans\"\n",
        "            else:\n",
        "                print(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                font_name = \"DejaVu Sans\"\n",
        "\n",
        "        # è¨­å®š matplotlib åƒæ•¸\n",
        "        plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¢ºé¡¯ç¤ºè² è™Ÿ\n",
        "\n",
        "        # è¨­å®šå­—é«”å¤§å°\n",
        "        plt.rcParams['font.size'] = 10\n",
        "        plt.rcParams['axes.titlesize'] = 12\n",
        "        plt.rcParams['axes.labelsize'] = 10\n",
        "        plt.rcParams['xtick.labelsize'] = 9\n",
        "        plt.rcParams['ytick.labelsize'] = 9\n",
        "        plt.rcParams['legend.fontsize'] = 9\n",
        "\n",
        "        # è¨­å®šåœ–è¡¨å“è³ª\n",
        "        plt.rcParams['figure.dpi'] = 100\n",
        "        plt.rcParams['savefig.dpi'] = 150\n",
        "        plt.rcParams['savefig.bbox'] = 'tight'\n",
        "\n",
        "        if font_name and font_name != \"DejaVu Sans\":\n",
        "            print(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name} ({system})\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ä½¿ç”¨é è¨­å­—é«”: {font_name}\")\n",
        "            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"\n",
        "    æª¢æŸ¥åŸ·è¡Œç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶\n",
        "    \"\"\"\n",
        "    print(\"ğŸ” æª¢æŸ¥åŸ·è¡Œç’°å¢ƒ...\")\n",
        "    print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
        "    print(f\"ä½œæ¥­ç³»çµ±: {platform.system()} {platform.release()}\")\n",
        "    print(f\"ç•¶å‰æ™‚å€: {taipei_tz}\")\n",
        "\n",
        "    # æª¢æŸ¥é‡è¦å¥—ä»¶ç‰ˆæœ¬\n",
        "    required_packages = {\n",
        "        'pandas': pd.__version__,\n",
        "        'numpy': np.__version__,\n",
        "        'matplotlib': plt.matplotlib.__version__,\n",
        "        'requests': requests.__version__,\n",
        "        'yfinance': getattr(yf, '__version__', 'Unknown'),\n",
        "        'aiohttp': aiohttp.__version__,\n",
        "        'pytz': pytz.__version__\n",
        "    }\n",
        "\n",
        "    print(\"\\nğŸ“¦ å¥—ä»¶ç‰ˆæœ¬:\")\n",
        "    for package, version in required_packages.items():\n",
        "        print(f\"  {package}: {version}\")\n",
        "\n",
        "    # æª¢æŸ¥ç›®éŒ„æ¬Šé™\n",
        "    print(f\"\\nğŸ“ å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "    directories_status = {\n",
        "        'å¿«å–ç›®éŒ„': (CACHE_DIR, os.access(CACHE_DIR, os.W_OK)),\n",
        "        'çµæœç›®éŒ„': (RESULTS_DIR, os.access(RESULTS_DIR, os.W_OK)),\n",
        "        'åœ–è¡¨ç›®éŒ„': (CHARTS_DIR, os.access(CHARTS_DIR, os.W_OK))\n",
        "    }\n",
        "\n",
        "    for name, (path, writable) in directories_status.items():\n",
        "        status = 'âœ…' if writable else 'âŒ'\n",
        "        print(f\"{name}: {path} {status}\")\n",
        "\n",
        "    # æª¢æŸ¥ç¶²è·¯é€£ç·šï¼ˆç°¡å–®æ¸¬è©¦ï¼‰\n",
        "    try:\n",
        "        response = requests.get('https://httpbin.org/status/200', timeout=5)\n",
        "        network_status = 'âœ…' if response.status_code == 200 else 'âŒ'\n",
        "    except:\n",
        "        network_status = 'âŒ'\n",
        "\n",
        "    print(f\"ç¶²è·¯é€£ç·š: {network_status}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "def get_current_time():\n",
        "    \"\"\"\n",
        "    ç²å–ç•¶å‰å°åŒ—æ™‚é–“\n",
        "    \"\"\"\n",
        "    return datetime.now(taipei_tz)\n",
        "\n",
        "def format_timestamp(dt=None):\n",
        "    \"\"\"\n",
        "    æ ¼å¼åŒ–æ™‚é–“æˆ³è¨˜\n",
        "    \"\"\"\n",
        "    if dt is None:\n",
        "        dt = get_current_time()\n",
        "    return dt.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
        "\n",
        "# ==============================================================================\n",
        "# 12. ç¨‹å¼åˆå§‹åŒ–\n",
        "# ==============================================================================\n",
        "def initialize_application():\n",
        "    \"\"\"\n",
        "    æ‡‰ç”¨ç¨‹å¼åˆå§‹åŒ–\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· v2.1\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # æª¢æŸ¥ç’°å¢ƒ\n",
        "    check_environment()\n",
        "\n",
        "    # è¨­å®šä¸­æ–‡å­—é«”\n",
        "    set_chinese_font()\n",
        "\n",
        "    # è¨˜éŒ„å•Ÿå‹•æ™‚é–“\n",
        "    start_time = get_current_time()\n",
        "    logger.info(f\"æ‡‰ç”¨ç¨‹å¼å•Ÿå‹• - {format_timestamp(start_time)}\")\n",
        "    logger.info(f\"å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "\n",
        "    print(f\"âœ… åˆå§‹åŒ–å®Œæˆ - {format_timestamp(start_time)}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# StockAnalyzer é¡å®šç¾© (èˆ‡ä¹‹å‰ç›¸åŒï¼Œç„¡éœ€è®Šæ›´)\n",
        "# ==============================================================================\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.stocks_df = pd.DataFrame()\n",
        "\n",
        "    def standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "            return pd.DataFrame()\n",
        "        df = df.copy()\n",
        "        if df.index.name is not None and 'date' in df.index.name.lower():\n",
        "            df = df.reset_index()\n",
        "        column_mapping = {\n",
        "            'Date': 'Date', 'date': 'Date', 'æ—¥æœŸ': 'Date',\n",
        "            'Open': 'Open', 'open': 'Open', 'é–‹ç›¤åƒ¹': 'Open',\n",
        "            'High': 'High', 'high': 'High', 'æœ€é«˜åƒ¹': 'High',\n",
        "            'Low': 'Low', 'low': 'Low', 'æœ€ä½åƒ¹': 'Low',\n",
        "            'Close': 'Close', 'close': 'Close', 'æ”¶ç›¤åƒ¹': 'Close', 'Adj Close': 'Close',\n",
        "            'Volume': 'Volume', 'volume': 'Volume', 'æˆäº¤é‡': 'Volume',\n",
        "        }\n",
        "        rename_dict = {col: column_mapping.get(col, col) for col in df.columns}\n",
        "        df.rename(columns=rename_dict, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=False):\n",
        "        if not force_update and os.path.exists(STOCK_LIST_PATH):\n",
        "            if (time.time() - os.path.getmtime(STOCK_LIST_PATH)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(STOCK_LIST_PATH, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0]\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:]\n",
        "                df['market'] = market_name\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œç¨‹åºçµ‚æ­¢ã€‚\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "        df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "        df = df[df['stock_id'].str.match(r'^\\d{4}$')].copy()\n",
        "        exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "        df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)]\n",
        "        df['yahoo_symbol'] = df.apply(\n",
        "            lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "        final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "        final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "        final_df.to_csv(STOCK_LIST_PATH, index=False)\n",
        "        logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "        return final_df\n",
        "\n",
        "    async def fetch_yfinance_data_async(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3, backoff_factor: float = 0.5):\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "                        if df[col].isna().all():\n",
        "                            logger.warning(f\"[{stock_id}] {col} æ•¸æ“šå…¨ç‚º NaN\")\n",
        "                            return pd.DataFrame()\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = backoff_factor * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦æ™‚ç™¼ç”Ÿç•°å¸¸: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    await asyncio.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] å› ç•°å¸¸ï¼Œåœ¨ {retries} æ¬¡å˜—è©¦å¾Œç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    async def fetch_all_stocks(self, stocks_df):\n",
        "        tasks = [self.fetch_yfinance_data_async(row['yahoo_symbol']) for _, row in stocks_df.iterrows()]\n",
        "        results = await analyzer.fetch_all_stocks(stocks_df)\n",
        "        for stock, data_df in zip(stocks_df.itertuples(), results):\n",
        "            stock_id = stock.stock_id\n",
        "            if isinstance(data_df, pd.DataFrame) and not data_df.empty and len(data_df) >= 60:\n",
        "                data_df = analyzer.standardize_columns(data_df.reset_index())\n",
        "                # Proceed with volume checks and analysis\n",
        "            else:\n",
        "                logger.warning(f\"[{stock_id}] æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—ï¼Œè·³éã€‚\")\n",
        "                failed_stocks.append(stock_id)\n",
        "                continue\n",
        "        return await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    def fetch_yfinance_data_single_robust(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3, backoff_factor: float = 0.5, request_timeout: int = 30):\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True, timeout=request_timeout)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "                # Handle multi-level columns if present\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)  # Flatten to first level\n",
        "                # Ensure all required columns are numeric\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "                        if df[col].isna().all():\n",
        "                            logger.warning(f\"[{stock_id}] {col} æ•¸æ“šå…¨ç‚º NaN\")\n",
        "                            return pd.DataFrame()\n",
        "                # Drop rows with any NaN in required columns\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] æ•¸æ“šæ¸…ç†å¾Œç‚ºç©º\")\n",
        "                    return pd.DataFrame()\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = backoff_factor * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦æ™‚ç™¼ç”Ÿç•°å¸¸: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] å› ç•°å¸¸ï¼Œåœ¨ {retries} æ¬¡å˜—è©¦å¾Œç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "    def calculate_all_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if df.empty or 'Close' not in df.columns or len(df) < 20:\n",
        "            return df\n",
        "        df = df.copy()\n",
        "        for days in [5, 10, 20, 60]:\n",
        "            df[f'MA{days}'] = df['Close'].rolling(window=days, min_periods=1).mean()\n",
        "        delta = df['Close'].diff()\n",
        "        gain = delta.where(delta > 0, 0).rolling(window=14).mean()\n",
        "        loss = -delta.where(delta < 0, 0).rolling(window=14).mean()\n",
        "        rs = gain / (loss + 1e-9)\n",
        "        df['RSI'] = 100 - (100 / (1 + rs))\n",
        "        exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "        exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "        df['MACD'] = exp1 - exp2\n",
        "        df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "        df['Histogram'] = df['MACD'] - df['MACD_signal']\n",
        "        df = df.fillna(method='bfill').fillna(method='ffill')\n",
        "        return df\n",
        "\n",
        "    def analyze_stock(self, stock_info: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        try:\n",
        "            df = stock_info['data'].copy()\n",
        "            if len(df) < 60:\n",
        "                return {'success': False, 'message': f\"æ•¸æ“šé‡ä¸è¶³ ({len(df)} < 60)\"}\n",
        "\n",
        "            df_with_indicators = self.calculate_all_indicators(df)\n",
        "            if df_with_indicators.empty:\n",
        "                return {'success': False, 'message': \"æŒ‡æ¨™è¨ˆç®—å¾Œæ•¸æ“šç‚ºç©º\"}\n",
        "\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            momentum_analysis = self.analyze_momentum(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            pattern_analysis = self.analyze_patterns(df_with_indicators)\n",
        "\n",
        "            weights = {'trend': 0.3, 'momentum': 0.3, 'volume': 0.2, 'pattern': 0.2}\n",
        "            combined_score = (\n",
        "                trend_analysis.get('score', 50) * weights['trend'] +\n",
        "                momentum_analysis.get('score', 50) * weights['momentum'] +\n",
        "                volume_analysis.get('score', 50) * weights['volume'] +\n",
        "                pattern_analysis.get('score', 50) * weights['pattern']\n",
        "            )\n",
        "\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, momentum_analysis, volume_analysis, pattern_analysis)\n",
        "\n",
        "            return {\n",
        "                'success': True, 'stock_id': stock_info['stock_id'], 'stock_name': stock_info['stock_name'],\n",
        "                'industry': stock_info['industry'], 'data_df': df_with_indicators,\n",
        "                'combined_score': round(combined_score, 2), 'recommendation': recommendation,\n",
        "                'last_price': df_with_indicators['Close'].iloc[-1]\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_info.get('stock_id', 'N/A')} æ™‚ç™¼ç”Ÿé ‚å±¤éŒ¯èª¤: {e}\")\n",
        "            return {'success': False, 'message': str(e)}\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        try:\n",
        "            if len(df) < 60: return {'score': 50}\n",
        "            recent_close = float(df['Close'].iloc[-1])\n",
        "            recent_ma20 = float(df['MA20'].iloc[-1])\n",
        "            recent_ma60 = float(df['MA60'].iloc[-1])\n",
        "            score = 50\n",
        "            if recent_close > recent_ma20: score += 15\n",
        "            if recent_close > recent_ma60: score += 15\n",
        "            if recent_ma20 > recent_ma60: score += 10\n",
        "            return {'score': max(0, min(100, score))}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\"); return {'score': 50}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        try:\n",
        "            if len(df) < 20 or 'Volume' not in df.columns or df['Volume'].isna().all():\n",
        "                return {'score': 50}\n",
        "            # Convert to numeric\n",
        "            df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')\n",
        "            recent_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20 = float(df['Volume'].iloc[-20:].mean())\n",
        "            score = 50\n",
        "            if pd.isna(avg_volume_20) or avg_volume_20 == 0:\n",
        "                return {'score': 50}\n",
        "            volume_ratio = recent_volume / avg_volume_20\n",
        "            if volume_ratio > 1.5:\n",
        "                score += 20\n",
        "            if len(df) >= 2:\n",
        "                price_change = (float(df['Close'].iloc[-1]) - float(df['Close'].iloc[-2])) / float(df['Close'].iloc[-2])\n",
        "                if price_change > 0.02 and volume_ratio > 1.2:\n",
        "                    score += 20\n",
        "                elif price_change < -0.02 and volume_ratio > 1.2:\n",
        "                    score -= 20\n",
        "            return {'score': max(0, min(100, score))}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'score': 50}\n",
        "    def analyze_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        try:\n",
        "            if len(df) < 21: return {'score': 50, 'patterns': []}\n",
        "            patterns_found = []\n",
        "            score = 50\n",
        "            high_20 = float(df['High'].iloc[-21:-1].max())\n",
        "            latest_high = float(df['High'].iloc[-1])\n",
        "            if latest_high > high_20:\n",
        "                score += 25; patterns_found.append(\"çªç ´20æ—¥é«˜é»\")\n",
        "            return {'score': max(0, min(100, score)), 'patterns': patterns_found}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å½¢æ…‹åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\"); return {'score': 50, 'patterns': []}\n",
        "\n",
        "    def analyze_momentum(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        try:\n",
        "            if len(df) < 30 or 'RSI' not in df.columns or 'Histogram' not in df.columns:\n",
        "                return {'score': 50}\n",
        "            score = 50\n",
        "            recent_rsi = float(df['RSI'].iloc[-1])\n",
        "            recent_macd_hist = float(df['Histogram'].iloc[-1])\n",
        "            if recent_rsi < 30: score += 20\n",
        "            elif recent_rsi > 70: score -= 20\n",
        "            if recent_macd_hist > 0 and float(df['Histogram'].iloc[-2]) < 0:\n",
        "                score += 20  # MACD æŸ±ç‹€é«”ç”±è² è½‰æ­£\n",
        "            elif recent_macd_hist > 0:\n",
        "                score += 10\n",
        "            return {'score': max(0, min(100, score))}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å‹•èƒ½åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\"); return {'score': 50}\n",
        "\n",
        "    def generate_recommendation(self, combined_score, trend_analysis, momentum_analysis, volume_analysis, pattern_analysis):\n",
        "        buy_threshold = 65\n",
        "        sell_threshold = 35\n",
        "        action = \"è§€æœ›\"\n",
        "        if combined_score >= buy_threshold: action = \"è²·å…¥\"\n",
        "        elif combined_score <= sell_threshold: action = \"è³£å‡º\"\n",
        "\n",
        "        reasons = []\n",
        "        if trend_analysis.get('score', 50) > 70: reasons.append(\"è¶¨å‹¢å¼·å‹å‘ä¸Š\")\n",
        "        if momentum_analysis.get('score', 50) > 70: reasons.append(\"å‹•èƒ½å……æ²›\")\n",
        "        if volume_analysis.get('score', 50) > 70: reasons.append(\"åƒ¹é‡é…åˆè‰¯å¥½\")\n",
        "        if pattern_analysis.get('patterns'): reasons.extend(pattern_analysis['patterns'])\n",
        "        if not reasons: reasons.append(\"å¤šç©ºæŒ‡æ¨™å‡è¡¡\")\n",
        "\n",
        "        if combined_score > 50:\n",
        "            confidence = (combined_score - 50) / 50 * 100\n",
        "        else:\n",
        "            confidence = (50 - combined_score) / 50 * 100\n",
        "\n",
        "        return {'action': action, 'reasons': reasons, 'confidence': round(confidence, 2)}\n",
        "\n",
        "    def generate_detailed_analysis_report(self, stock_id: str, stock_name: str, stock_data: Dict, save_path: str):\n",
        "        df = stock_data.get('data_df')\n",
        "        if df is None or df.empty:\n",
        "            logger.error(f\"ç„¡æ³•ç‚º {stock_id} ç”Ÿæˆåœ–è¡¨ï¼Œç¼ºå°‘ data_dfã€‚\")\n",
        "            return None\n",
        "\n",
        "        df_chart = df.copy()\n",
        "\n",
        "        cols_to_convert = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "        for col in cols_to_convert:\n",
        "            if col in df_chart.columns:\n",
        "                df_chart[col] = pd.to_numeric(df_chart[col], errors='coerce')\n",
        "\n",
        "        df_chart.dropna(subset=cols_to_convert, inplace=True)\n",
        "\n",
        "        if not isinstance(df_chart.index, pd.DatetimeIndex):\n",
        "            if 'Date' in df_chart.columns:\n",
        "                df_chart['Date'] = pd.to_datetime(df_chart['Date'])\n",
        "                df_chart.set_index('Date', inplace=True)\n",
        "            else:\n",
        "                df_chart.index = pd.to_datetime(df_chart.index)\n",
        "\n",
        "        apds = [\n",
        "            mpf.make_addplot(df_chart['MA5'], color='orange', width=0.7),\n",
        "            mpf.make_addplot(df_chart['MA20'], color='blue', width=0.7),\n",
        "            mpf.make_addplot(df_chart['RSI'], panel=2, color='purple', ylabel='RSI'),\n",
        "            mpf.make_addplot(df_chart[['MACD', 'MACD_signal']], panel=3, ylabel='MACD'),\n",
        "            mpf.make_addplot(df_chart['Histogram'], type='bar', panel=3, color='gray', alpha=0.5)\n",
        "        ]\n",
        "        mc = mpf.make_marketcolors(up='r', down='g', inherit=True)\n",
        "        s = mpf.make_mpf_style(marketcolors=mc, gridstyle='--', facecolor='#F0F0F0', rc={'font.family': 'SimHei'})\n",
        "        title = f\"#{stock_id} {stock_name} - Score: {stock_data.get('combined_score', 0):.0f}\"\n",
        "\n",
        "        try:\n",
        "            mpf.plot(df_chart.tail(180), type='candle', style=s, title=title,\n",
        "                     volume=True, addplot=apds, figsize=(16, 9),\n",
        "                     panel_ratios=(3, 1, 1, 1), savefig=save_path)\n",
        "            logger.info(f\"æˆåŠŸç”Ÿæˆåœ–è¡¨: {save_path}\")\n",
        "            return save_path\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç‚º {stock_id} ç¹ªè£½åœ–è¡¨å¤±æ•—: {e}\")\n",
        "            return None\n",
        "\n",
        "    def print_advanced_filtered_stocks(self, results: Dict, top_n=20):\n",
        "        if not results:\n",
        "            logger.warning(\"æ²’æœ‰è‚¡ç¥¨é€šéæœ€çµ‚ç¯©é¸ã€‚\")\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"ğŸ¯ æœ€çµ‚ç¯©é¸å„ªè³ªè‚¡ç¥¨æ¸…å–® ğŸ¯\".center(80))\n",
        "            print(\"=\"*80)\n",
        "            print(\"ç„¡è‚¡ç¥¨é€šéç¯©é¸æ¢ä»¶ã€‚\")\n",
        "            print(\"=\"*80)\n",
        "            return\n",
        "\n",
        "        sorted_stocks = sorted(results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)[:top_n]\n",
        "\n",
        "        # Print summary table\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ¯ æœ€çµ‚ç¯©é¸å„ªè³ªè‚¡ç¥¨æ¸…å–® ğŸ¯\".center(80))\n",
        "        print(\"=\"*80)\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<7}{'åç¨±':<12}{'åˆ†æ•¸':<7}{'åƒ¹æ ¼':<10}{'å»ºè­°':<10}{'ç”¢æ¥­':<15}\")\n",
        "        print(\"-\" * 80)\n",
        "        for i, stock in enumerate(sorted_stocks, 1):\n",
        "            # å®‰å…¨è™•ç† industry æ¬„ä½ï¼Œç¢ºä¿æ˜¯å­—ä¸²é¡å‹\n",
        "            industry = stock.get('industry', '')\n",
        "            if pd.isna(industry) or not isinstance(industry, str):\n",
        "                industry = 'æœªåˆ†é¡'\n",
        "\n",
        "            print(\n",
        "            f\"{i:<4}\"\n",
        "            f\"{stock.get('stock_id', ''):<7}\"\n",
        "            f\"{stock.get('stock_name', '')[:10]:<12}\"\n",
        "            f\"{stock.get('combined_score', 0):<7.0f}\"\n",
        "            f\"{stock.get('last_price', 0):<10.2f}\"\n",
        "            f\"{stock.get('recommendation', {}).get('action', ''):<10}\"\n",
        "            f\"{industry[:12]:<15}\"\n",
        "            )\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # Print detailed report for each stock\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ“Š è©³ç´°åˆ†æå ±å‘Š ğŸ“Š\".center(80))\n",
        "        print(\"=\"*80)\n",
        "        for i, stock in enumerate(sorted_stocks, 1):\n",
        "            # åŒæ¨£å®‰å…¨è™•ç† industry æ¬„ä½\n",
        "            industry = stock.get('industry', '')\n",
        "            if pd.isna(industry) or not isinstance(industry, str):\n",
        "                industry = 'æœªåˆ†é¡'\n",
        "\n",
        "        print(f\"\\nå ±å‘Š #{i}: {stock.get('stock_id', 'N/A')} - {stock.get('stock_name', 'N/A')}\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"ç¶œåˆè©•åˆ†: {stock.get('combined_score', 0):.2f}\")\n",
        "        print(f\"æœ€æ–°æ”¶ç›¤åƒ¹: {stock.get('last_price', 0):.2f} å…ƒ\")\n",
        "        print(f\"ç”¢æ¥­é¡åˆ¥: {industry}\")\n",
        "        print(f\"æ¨è–¦è¡Œå‹•: {stock.get('recommendation', {}).get('action', 'N/A')}\")\n",
        "        print(f\"ä¿¡å¿ƒåº¦: {stock.get('recommendation', {}).get('confidence', 0):.2f}%\")\n",
        "        print(\"æ¨è–¦ç†ç”±:\")\n",
        "        reasons = stock.get('recommendation', {}).get('reasons', ['ç„¡ç‰¹å®šç†ç”±'])\n",
        "        for reason in reasons:\n",
        "            print(f\"  - {reason}\")\n",
        "        print(\"-\" * 50)\n",
        "    print(\"=\" * 80)\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸ - å¢å¼·ç‰ˆæœ¬\n",
        "# ==============================================================================\n",
        "# ä¿®æ”¹ send_notification å‡½æ•¸ï¼Œä½¿ session æˆç‚ºå¯é¸åƒæ•¸\n",
        "async def send_notification(message: str, files: List[str] = None, session: aiohttp.ClientSession = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾› sessionï¼Œå‰‡å‰µå»ºä¸€å€‹æ–°çš„\n",
        "    session_created = False\n",
        "    if session is None:\n",
        "        session = aiohttp.ClientSession()\n",
        "        session_created = True\n",
        "\n",
        "    try:\n",
        "        # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "        if not files:\n",
        "            chart_dir = \"/content/results/charts/\"\n",
        "            if os.path.exists(chart_dir):\n",
        "                # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "                files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                        if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "                if files:\n",
        "                    logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "                else:\n",
        "                    logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "        # Telegram\n",
        "        try:\n",
        "            # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "            for chat_id in TELEGRAM_CHAT_ID:\n",
        "                # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "                url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "                payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "                async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                    if response.status == 200:\n",
        "                        logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                    else:\n",
        "                        response_text = await response.text()\n",
        "                        logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "                if files:\n",
        "                    url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                    sent_count = 0\n",
        "                    for file_path in files:\n",
        "                        if os.path.exists(file_path):\n",
        "                            try:\n",
        "                                data = aiohttp.FormData()\n",
        "                                data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                                # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                                caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                                data.add_field('caption', caption)\n",
        "\n",
        "                                with open(file_path, 'rb') as f:\n",
        "                                    data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                    async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                        if response.status == 200:\n",
        "                                            sent_count += 1\n",
        "                                        else:\n",
        "                                            response_text = await response.text()\n",
        "                                            logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                                # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                                await asyncio.sleep(0.5)\n",
        "                            except Exception as file_error:\n",
        "                                logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                    logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "        # Discord\n",
        "        try:\n",
        "            # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "            message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "            for chunk in message_chunks:\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "            # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "            if files:\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(files), batch_size):\n",
        "                    batch_files = files[i:i+batch_size]\n",
        "                    webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                    for file_path in batch_files:\n",
        "                        if os.path.exists(file_path):\n",
        "                            try:\n",
        "                                with open(file_path, 'rb') as f:\n",
        "                                    webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                            except Exception as file_error:\n",
        "                                logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                    response = webhook.execute()\n",
        "                    if response and response.ok:\n",
        "                        logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                    else:\n",
        "                        status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                        content = response.content if response else \"æœªçŸ¥\"\n",
        "                        logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "    finally:\n",
        "        # å¦‚æœæˆ‘å€‘å‰µå»ºäº† sessionï¼Œå‰‡é—œé–‰å®ƒ\n",
        "        if session_created:\n",
        "            await session.close()\n",
        "async def send_chart_files(chart_path, caption=\"\"):\n",
        "    \"\"\"\n",
        "    ç™¼é€åœ–è¡¨æ–‡ä»¶åˆ° Telegram å’Œ Discord\n",
        "    \"\"\"\n",
        "    if not os.path.exists(chart_path):\n",
        "        logger.error(f\"åœ–è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {chart_path}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # ä½¿ç”¨ send_notification å‡½æ•¸ç™¼é€å–®å€‹æ–‡ä»¶\n",
        "        await send_notification(caption, files=[chart_path])\n",
        "        logger.info(f\"å·²ç™¼é€åœ–è¡¨: {os.path.basename(chart_path)}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€åœ–è¡¨æ™‚å‡ºéŒ¯: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "def format_notification_message(sorted_results):\n",
        "    \"\"\"\n",
        "    æ ¼å¼åŒ–é€šçŸ¥æ¶ˆæ¯\n",
        "    \"\"\"\n",
        "    if not sorted_results:\n",
        "        return \"âš ï¸ åˆ†æå®Œæˆï¼Œä½†æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ã€‚\"\n",
        "\n",
        "    # å–å‰ 10 å\n",
        "    top_n = min(10, len(sorted_results))\n",
        "    top_stocks = sorted_results[:top_n]\n",
        "\n",
        "    # è¨ˆç®—å‹•ä½œçµ±è¨ˆ\n",
        "    action_counts = {}\n",
        "    for stock in sorted_results:\n",
        "        action = stock.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "        action_counts[action] = action_counts.get(action, 0) + 1\n",
        "\n",
        "    # æ ¼å¼åŒ–æ¶ˆæ¯\n",
        "    message = f\"ğŸ“Š å°è‚¡æŠ€è¡“åˆ†æçµæœ ({datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M')})\\n\"\n",
        "    message += f\"å…±åˆ†æ {len(sorted_results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\\n\"\n",
        "    message += f\"è²·å…¥: {action_counts.get('è²·å…¥', 0)} | æŒæœ‰: {action_counts.get('æŒæœ‰', 0)} | è³£å‡º: {action_counts.get('è³£å‡º', 0)}\\n\\n\"\n",
        "\n",
        "    message += \"ğŸ† è©•åˆ†æœ€é«˜çš„è‚¡ç¥¨:\\n\"\n",
        "    for i, stock in enumerate(top_stocks, 1):\n",
        "        stock_id = stock['stock_id']\n",
        "        stock_name = stock['stock_name']\n",
        "        score = stock.get('combined_score', 0)\n",
        "        price = stock.get('last_price', 0)\n",
        "        action = stock.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "        confidence = stock.get('recommendation', {}).get('confidence', 0)\n",
        "\n",
        "        message += f\"{i}. {stock_name} ({stock_id}) - {price:.2f} å…ƒ\\n\"\n",
        "        message += f\"   è©•åˆ†: {score:.1f}/100 | å»ºè­°: {action} ({confidence:.0f}%)\\n\"\n",
        "\n",
        "    message += \"\\nğŸ“ˆ è©³ç´°åˆ†æåœ–è¡¨å·²ç”Ÿæˆï¼Œè«‹æŸ¥çœ‹é™„ä»¶ã€‚\"\n",
        "    return message\n",
        "\n",
        "\n",
        "async def generate_and_send_summary_chart(results, report_time):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆä¸¦ç™¼é€æ‘˜è¦åœ–è¡¨\n",
        "    \"\"\"\n",
        "    if not results:\n",
        "        logger.warning(\"æ²’æœ‰çµæœå¯ä¾›ç”Ÿæˆæ‘˜è¦åœ–è¡¨\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # å‰µå»ºæ‘˜è¦åœ–è¡¨\n",
        "        logger.info(\"ç”Ÿæˆæ‘˜è¦åœ–è¡¨...\")\n",
        "\n",
        "        # è¨­å®šåœ–è¡¨å¤§å° - 4K è§£æåº¦\n",
        "        plt.figure(figsize=(32, 18), dpi=150)  # 4K ç­‰æ•ˆ (4800x2700)\n",
        "\n",
        "        # è¨­å®šæ¨™é¡Œ\n",
        "        plt.suptitle(f'å°è‚¡æŠ€è¡“åˆ†ææ‘˜è¦ - {report_time}', fontsize=24, y=0.98)\n",
        "\n",
        "        # å–å‰ 20 åé€²è¡Œå±•ç¤º\n",
        "        top_n = min(20, len(results))\n",
        "        top_stocks = results[:top_n]\n",
        "\n",
        "        # æº–å‚™æ•¸æ“š\n",
        "        stock_ids = [f\"{r['stock_id']} {r['stock_name']}\" for r in top_stocks]\n",
        "        scores = [r.get('combined_score', 0) for r in top_stocks]\n",
        "        actions = [r.get('recommendation', {}).get('action', 'æŒæœ‰') for r in top_stocks]\n",
        "\n",
        "        # è¨­å®šé¡è‰²æ˜ å°„\n",
        "        colors = []\n",
        "        for action in actions:\n",
        "            if action == 'è²·å…¥':\n",
        "                colors.append('#FF5252')  # ç´…è‰²\n",
        "            elif action == 'è³£å‡º':\n",
        "                colors.append('#4CAF50')  # ç¶ è‰²\n",
        "            else:\n",
        "                colors.append('#FFC107')  # é»ƒè‰²\n",
        "\n",
        "        # ç¹ªè£½è©•åˆ†æ¢å½¢åœ–\n",
        "        ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
        "        bars = ax1.barh(stock_ids, scores, color=colors, alpha=0.8)\n",
        "        ax1.set_title('è‚¡ç¥¨ç¶œåˆè©•åˆ† (è¶Šé«˜è¶Šçœ‹å¥½)', fontsize=18)\n",
        "        ax1.set_xlim(0, 100)\n",
        "        ax1.axvline(x=50, color='gray', linestyle='--', alpha=0.5)\n",
        "        ax1.set_xlabel('è©•åˆ†', fontsize=14)\n",
        "        ax1.grid(axis='x', linestyle='--', alpha=0.3)\n",
        "\n",
        "        # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
        "        for bar, score in zip(bars, scores):\n",
        "            ax1.text(min(score + 2, 95), bar.get_y() + bar.get_height()/2,\n",
        "                    f'{score:.1f}', va='center', fontsize=12)\n",
        "\n",
        "        # ç¹ªè£½è©•åˆ†åˆ†ä½ˆç›´æ–¹åœ–\n",
        "        ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
        "        all_scores = [r.get('combined_score', 0) for r in results]\n",
        "        ax2.hist(all_scores, bins=20, range=(0, 100), color='skyblue', edgecolor='black', alpha=0.7)\n",
        "        ax2.set_title('æ‰€æœ‰è‚¡ç¥¨è©•åˆ†åˆ†ä½ˆ', fontsize=18)\n",
        "        ax2.set_xlabel('è©•åˆ†', fontsize=14)\n",
        "        ax2.set_ylabel('è‚¡ç¥¨æ•¸é‡', fontsize=14)\n",
        "        ax2.grid(linestyle='--', alpha=0.3)\n",
        "\n",
        "        # ç¹ªè£½å»ºè­°å‹•ä½œé¤…åœ–\n",
        "        ax3 = plt.subplot2grid((2, 2), (1, 1))\n",
        "        action_counts = {}\n",
        "        for r in results:\n",
        "            action = r.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "            action_counts[action] = action_counts.get(action, 0) + 1\n",
        "\n",
        "        labels = list(action_counts.keys())\n",
        "        sizes = list(action_counts.values())\n",
        "        colors_pie = ['#FF5252', '#FFC107', '#4CAF50']  # ç´…(è²·å…¥), é»ƒ(æŒæœ‰), ç¶ (è³£å‡º)\n",
        "        explode = [0.1 if label == 'è²·å…¥' else 0 for label in labels]  # çªå‡º\"è²·å…¥\"\n",
        "\n",
        "        ax3.pie(sizes, explode=explode, labels=labels, colors=colors_pie, autopct='%1.1f%%',\n",
        "               shadow=True, startangle=90, textprops={'fontsize': 14})\n",
        "        ax3.set_title('å»ºè­°å‹•ä½œåˆ†ä½ˆ', fontsize=18)\n",
        "\n",
        "        # æ·»åŠ åœ–ä¾‹\n",
        "        from matplotlib.lines import Line2D\n",
        "        legend_elements = [\n",
        "            Line2D([0], [0], color='#FF5252', lw=4, label='è²·å…¥'),\n",
        "            Line2D([0], [0], color='#FFC107', lw=4, label='æŒæœ‰'),\n",
        "            Line2D([0], [0], color='#4CAF50', lw=4, label='è³£å‡º')\n",
        "        ]\n",
        "        ax1.legend(handles=legend_elements, loc='lower right', fontsize=14)\n",
        "\n",
        "        # æ·»åŠ è¨»è…³\n",
        "        plt.figtext(0.5, 0.01,\n",
        "                   f'åˆ†ææ™‚é–“: {report_time} | å…±åˆ†æ {len(results)} æ”¯è‚¡ç¥¨ | ä½¿ç”¨æŒ‡æ¨™: è¶¨å‹¢ã€å‹•èƒ½ã€æˆäº¤é‡ã€å½¢æ…‹',\n",
        "                   ha='center', fontsize=12, bbox=dict(facecolor='#f0f0f0', alpha=0.5))\n",
        "\n",
        "        # èª¿æ•´ä½ˆå±€\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "        # ä¿å­˜åœ–è¡¨\n",
        "        summary_chart_path = os.path.join(CHARTS_DIR, f'summary_report_{datetime.now(taipei_tz).strftime(\"%Y%m%d_%H%M%S\")}.png')\n",
        "        plt.savefig(summary_chart_path, dpi=150, bbox_inches='tight')\n",
        "        logger.info(f\"æ‘˜è¦åœ–è¡¨å·²ä¿å­˜åˆ°: {summary_chart_path}\")\n",
        "\n",
        "        # é—œé–‰åœ–è¡¨ï¼Œé‡‹æ”¾è¨˜æ†¶é«”\n",
        "        plt.close()\n",
        "\n",
        "        return summary_chart_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”Ÿæˆæ‘˜è¦åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "        return None\n",
        "\n",
        "\n",
        "# å¦‚æœä½ é‚„éœ€è¦ä¸€å€‹ç´”çµ±è¨ˆåœ–è¡¨çš„ç‰ˆæœ¬ï¼Œå¯ä»¥é¡å¤–æ·»åŠ é€™å€‹å‡½æ•¸\n",
        "async def generate_and_send_statistics_chart(final_results: list, report_time: str):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆä¸¦ç™¼é€çµ±è¨ˆåˆ†æåœ–è¡¨ï¼ˆè¡Œæ¥­åˆ†å¸ƒ + è©•åˆ†åˆ†å¸ƒï¼‰\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not final_results:\n",
        "            logger.info(\"ç„¡çµæœæ•¸æ“šï¼Œè·³éçµ±è¨ˆåœ–è¡¨ç”Ÿæˆ\")\n",
        "            return\n",
        "\n",
        "        # å‰µå»ºåœ–è¡¨ - 1x2 å¸ƒå±€\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "        fig.suptitle(f'ğŸ“Š å°è‚¡åˆ†æçµ±è¨ˆåœ–è¡¨ - {report_time}', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # 1. è¡Œæ¥­åˆ†å¸ƒåœ“é¤…åœ–\n",
        "        industry_counts = {}\n",
        "        for stock in final_results:\n",
        "            industry = stock.get('industry', 'å…¶ä»–')\n",
        "            industry_counts[industry] = industry_counts.get(industry, 0) + 1\n",
        "\n",
        "        if industry_counts:\n",
        "            industries = list(industry_counts.keys())\n",
        "            counts = list(industry_counts.values())\n",
        "            colors = plt.cm.Set3(np.linspace(0, 1, len(industries)))\n",
        "\n",
        "            wedges, texts, autotexts = ax1.pie(counts, labels=industries, autopct='%1.0f%%',\n",
        "                                              colors=colors, startangle=90)\n",
        "            ax1.set_title('ğŸ­ è¡Œæ¥­åˆ†å¸ƒ', fontweight='bold', fontsize=14)\n",
        "\n",
        "            # èª¿æ•´æ–‡å­—å¤§å°\n",
        "            for text in texts:\n",
        "                text.set_fontsize(10)\n",
        "            for autotext in autotexts:\n",
        "                autotext.set_fontsize(9)\n",
        "                autotext.set_fontweight('bold')\n",
        "\n",
        "        # 2. è©•åˆ†åˆ†å¸ƒç›´æ–¹åœ–\n",
        "        all_scores = [s.get('combined_score', 0) for s in final_results]\n",
        "        n, bins, patches = ax2.hist(all_scores, bins=10, color='#4682B4', alpha=0.7, edgecolor='black')\n",
        "        ax2.set_xlabel('ç¶œåˆè©•åˆ†', fontsize=12)\n",
        "        ax2.set_ylabel('è‚¡ç¥¨æ•¸é‡', fontsize=12)\n",
        "        ax2.set_title('ğŸ“ˆ è©•åˆ†åˆ†å¸ƒ', fontweight='bold', fontsize=14)\n",
        "        ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "        # åœ¨ç›´æ–¹åœ–æŸ±å­ä¸Šé¡¯ç¤ºæ•¸é‡\n",
        "        for i, (count, patch) in enumerate(zip(n, patches)):\n",
        "            if count > 0:\n",
        "                ax2.text(patch.get_x() + patch.get_width()/2, patch.get_height() + 0.1,\n",
        "                        f'{int(count)}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆç·š\n",
        "        mean_score = np.mean(all_scores)\n",
        "        ax2.axvline(mean_score, color='red', linestyle='--', linewidth=2, label=f'å¹³å‡åˆ†: {mean_score:.1f}')\n",
        "        ax2.legend(fontsize=11)\n",
        "\n",
        "        # èª¿æ•´å¸ƒå±€\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # å„²å­˜åœ–è¡¨\n",
        "        stats_chart_path = os.path.join(CHARTS_DIR, f\"statistics_report_{datetime.now(taipei_tz).strftime('%Y%m%d_%H%M%S')}.png\")\n",
        "        plt.savefig(stats_chart_path, dpi=150, bbox_inches='tight',\n",
        "                   facecolor='white', edgecolor='none')\n",
        "        plt.close()\n",
        "\n",
        "        # ç™¼é€çµ±è¨ˆåœ–è¡¨\n",
        "        caption = f\"ğŸ“Š å°è‚¡åˆ†æçµ±è¨ˆåœ–è¡¨\\nâ° {report_time}\\nğŸ“ˆ å…± {len(final_results)} æ”¯ç¬¦åˆæ¢ä»¶\"\n",
        "        await send_chart_files(stats_chart_path, caption)\n",
        "\n",
        "        logger.info(f\"å·²ç”Ÿæˆä¸¦ç™¼é€çµ±è¨ˆåœ–è¡¨: {stats_chart_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”Ÿæˆçµ±è¨ˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "# ==============================================================================\n",
        "# ä¸»åŸ·è¡Œæµç¨‹ (main) - å¢å¼·ç‰ˆæœ¬\n",
        "# ==============================================================================\n",
        "async def main():\n",
        "    start_time = time.time()\n",
        "    report_time = format_timestamp()  # ä½¿ç”¨å°åŒ—æ™‚å€æ™‚é–“\n",
        "\n",
        "    logger.info(f\"==== ğŸ“ˆ é–‹å§‹åŸ·è¡Œå°è‚¡åˆ†æå·¥å…· (æ™‚é–“: {report_time}) ====\")\n",
        "\n",
        "    analyzer = StockAnalyzer()\n",
        "\n",
        "    # --- éšæ®µ 1: ç²å–è‚¡ç¥¨æ¸…å–® ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 1/5] ç²å–è‚¡ç¥¨æ¸…å–® ---\")\n",
        "    stocks_df = analyzer.get_taiwan_stocks()\n",
        "    if stocks_df.empty:\n",
        "        logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®ï¼Œç¨‹åºçµ‚æ­¢ã€‚\")\n",
        "        return\n",
        "    logger.info(f\"å…±ç²å– {len(stocks_df)} æ”¯è‚¡ç¥¨ã€‚\")\n",
        "\n",
        "    # --- éšæ®µ 2: é€ä¸€è™•ç†èˆ‡åˆ†æ ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 2/5] é€²è¡Œç¯©é¸ã€åˆ†æèˆ‡è©•åˆ† ---\")\n",
        "    all_results = []\n",
        "    failed_stocks = []\n",
        "    MIN_VOLUME = 1000 * 1000  # 1000å¼µ\n",
        "\n",
        "    for index, stock in stocks_df.iterrows():\n",
        "        stock_id = stock['stock_id']\n",
        "        yahoo_symbol = stock['yahoo_symbol']\n",
        "        logger.info(f\"--- è™•ç†ä¸­ ({index + 1}/{len(stocks_df)}): {stock_id} {stock['stock_name']} ---\")\n",
        "\n",
        "        try:\n",
        "            data_df = analyzer.fetch_yfinance_data_single_robust(yahoo_symbol, period='1y', interval='1d')\n",
        "            if data_df.empty or len(data_df) < 60:\n",
        "                logger.warning(f\"[{stock_id}] æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—ï¼Œè·³éã€‚\")\n",
        "                failed_stocks.append(stock_id)\n",
        "                continue\n",
        "\n",
        "            data_df = analyzer.standardize_columns(data_df.reset_index())\n",
        "\n",
        "            # Ensure Volume is numeric and handle missing/invalid data\n",
        "            if 'Volume' not in data_df.columns:\n",
        "                logger.info(f\"[{stock_id}] ç¼ºå°‘æˆäº¤é‡æ¬„ä½ï¼Œè·³éã€‚\")\n",
        "                failed_stocks.append(stock_id)\n",
        "                continue\n",
        "\n",
        "            # Convert Volume to numeric, coercing errors to NaN\n",
        "            data_df['Volume'] = pd.to_numeric(data_df['Volume'], errors='coerce')\n",
        "\n",
        "            # Check if recent volume data is sufficient and valid\n",
        "            recent_volume = data_df['Volume'].tail(15)\n",
        "            if recent_volume.empty or recent_volume.isna().all() or pd.isna(recent_volume.mean()) or recent_volume.mean() < MIN_VOLUME:\n",
        "                logger.info(f\"[{stock_id}] æœªé€šéæˆäº¤é‡ç¯©é¸ï¼Œè·³éã€‚\")\n",
        "                failed_stocks.append(stock_id)\n",
        "                continue\n",
        "\n",
        "            stock_info = {\n",
        "                'stock_id': stock_id, 'stock_name': stock['stock_name'],\n",
        "                'industry': stock['industry'], 'data': data_df\n",
        "            }\n",
        "            analysis_result = analyzer.analyze_stock(stock_info)\n",
        "\n",
        "            if analysis_result and analysis_result.get('success'):\n",
        "                all_results.append(analysis_result)\n",
        "                logger.info(f\"[{stock_id}] åˆ†æå®Œæˆï¼Œç¶œåˆè©•åˆ†: {analysis_result.get('combined_score')}\")\n",
        "            else:\n",
        "                logger.error(f\"å° {stock_id} çš„åˆ†æå¤±æ•—: {analysis_result.get('message', 'æœªçŸ¥éŒ¯èª¤')}\")\n",
        "                failed_stocks.append(stock_id)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç† {stock_id} æ™‚ç™¼ç”Ÿç•°å¸¸: {e}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            failed_stocks.append(stock_id)\n",
        "            continue\n",
        "\n",
        "   # --- éšæ®µ 3: é€²éšç¯©é¸èˆ‡å ±å‘Š ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 3/5] é€²è¡Œé€²éšç¯©é¸èˆ‡è¼¸å‡ºçµæœ ---\")\n",
        "    # é€™è£¡å®šç¾© final_results\n",
        "    final_results = [res for res in all_results if res.get('combined_score', 0) > 65 and res.get('recommendation', {}).get('action') == 'è²·å…¥']\n",
        "\n",
        "    # æŒ‰è©•åˆ†æ’åº - ç¢ºä¿å³ä½¿æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ï¼Œä¹Ÿæœ‰ä¸€å€‹ç©ºåˆ—è¡¨\n",
        "    sorted_results = sorted(final_results, key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "    final_results_dict = {res['stock_id']: res for res in final_results}\n",
        "    analyzer.print_advanced_filtered_stocks(final_results_dict, top_n=20)\n",
        "    # --- éšæ®µ 4: ç”Ÿæˆå€‹è‚¡åœ–è¡¨èˆ‡ç™¼é€é€šçŸ¥ ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 4/5] ç”Ÿæˆå€‹è‚¡åœ–è¡¨èˆ‡ç™¼é€é€šçŸ¥ ---\")\n",
        "    top_stocks_for_report = sorted_results[:5]  # å–å‰5å\n",
        "\n",
        "    if not top_stocks_for_report:\n",
        "        logger.warning(\"æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨å¯ä¾›å ±å‘Šã€‚\")\n",
        "        summary_message = f\"ğŸ“ˆ å°è‚¡åˆ†ææœ¬æ—¥ç²¾é¸ ğŸ“ˆ\\nâ° {report_time}\\n\\nä»Šæ—¥ç„¡ç‰¹åˆ¥äº®çœ¼æ¨™çš„ï¼Œå»ºè­°æŒçºŒè§€å¯Ÿå¸‚å ´ã€‚\"\n",
        "        await send_notification(summary_message)\n",
        "    else:\n",
        "        # ç™¼é€æ–‡å­—æ‘˜è¦\n",
        "        summary_lines = [f\"ğŸ“ˆ å°è‚¡åˆ†ææœ¬æ—¥ç²¾é¸ ğŸ“ˆ\", f\"â° {report_time}\", \"\"]\n",
        "        for i, stock in enumerate(top_stocks_for_report, 1):\n",
        "            rec = stock['recommendation']\n",
        "            summary_lines.append(\n",
        "                f\"{i}. *{stock['stock_id']} {stock['stock_name']}*\\n\"\n",
        "                f\"   è©•åˆ†: {stock['combined_score']:.0f} | \"\n",
        "                f\"å»ºè­°: *{rec['action']}* | \"\n",
        "                f\"ä¿¡å¿ƒåº¦: {rec.get('confidence', 0):.0f}%\"\n",
        "            )\n",
        "\n",
        "        summary_lines.append(f\"\\nğŸ“Š ç¸½è¨ˆ {len(final_results)} æ”¯ç¬¦åˆæ¢ä»¶è‚¡ç¥¨\")\n",
        "        summary_message = \"\\n\".join(summary_lines)\n",
        "\n",
        "        logger.info(\"æº–å‚™ç™¼é€æ‘˜è¦é€šçŸ¥...\")\n",
        "        await send_notification(summary_message)\n",
        "\n",
        "        # ç”Ÿæˆè©³ç´°å ±å‘Šæ–‡ä»¶\n",
        "        with open('stock_report.txt', 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"å°è‚¡åˆ†æè©³ç´°å ±å‘Š\\n\")\n",
        "            f.write(f\"å ±å‘Šæ™‚é–“: {report_time}\\n\")\n",
        "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "            original_stdout = sys.stdout\n",
        "            sys.stdout = f\n",
        "            analyzer.print_advanced_filtered_stocks(final_results_dict, top_n=10)\n",
        "            sys.stdout = original_stdout\n",
        "\n",
        "        # ç™¼é€å€‹è‚¡è©³ç´°åœ–è¡¨\n",
        "        logger.info(\"æº–å‚™ç™¼é€å€‹è‚¡è©³ç´°åœ–è¡¨...\")\n",
        "        for i, stock in enumerate(top_stocks_for_report, 1):\n",
        "            stock_id = stock['stock_id']\n",
        "            stock_name = stock['stock_name']\n",
        "            save_path = os.path.join(CHARTS_DIR, f\"{stock_id}_{stock_name}_report.png\")\n",
        "\n",
        "            chart_path = analyzer.generate_detailed_analysis_report(stock_id, stock_name, stock, save_path)\n",
        "\n",
        "            if chart_path:\n",
        "                caption = f\"ğŸ“Š {i}/5 - {stock_id} {stock_name}\\nè©•åˆ†: {stock['combined_score']:.0f}\"\n",
        "                await send_chart_files(chart_path, caption)\n",
        "                await asyncio.sleep(2)  # é¿å…ç™¼é€éå¿«\n",
        "\n",
        "   # --- éšæ®µ 5: ç”Ÿæˆä¸¦ç™¼é€æœ€çµ‚æ‘˜è¦åœ–è¡¨ ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 5/5] ç”Ÿæˆæœ€çµ‚æ‘˜è¦åœ–è¡¨ ---\")\n",
        "    if final_results:\n",
        "        summary_chart_path = await generate_and_send_summary_chart(final_results, report_time)\n",
        "        stats_chart_path = await generate_and_send_statistics_chart(final_results, report_time)\n",
        "\n",
        "        # æ”¶é›†æ‰€æœ‰åœ–è¡¨è·¯å¾‘\n",
        "        all_chart_paths = []\n",
        "        if summary_chart_path:\n",
        "            all_chart_paths.append(summary_chart_path)\n",
        "        if 'stats_chart_path' in locals() and stats_chart_path:\n",
        "            all_chart_paths.append(stats_chart_path)\n",
        "\n",
        "    # ç™¼é€åŸ·è¡Œå®Œæˆé€šçŸ¥\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    completion_time = format_timestamp()\n",
        "\n",
        "    # ä½¿ç”¨ sorted_results è€Œä¸æ˜¯ final_resultsï¼Œä¸¦ç¢ºä¿å®ƒå·²å®šç¾©\n",
        "    # é€™è£¡æ˜¯é—œéµä¿®å¾©éƒ¨åˆ†\n",
        "    if 'sorted_results' in locals() and sorted_results:\n",
        "        completion_message = format_notification_message(sorted_results)\n",
        "    else:\n",
        "        completion_message = f\"\"\"\n",
        "ğŸ‰ **åˆ†æå®Œæˆé€šçŸ¥** ğŸ‰\n",
        "\n",
        "â° é–‹å§‹æ™‚é–“: {report_time}\n",
        "â° å®Œæˆæ™‚é–“: {completion_time}\n",
        "âŒ› åŸ·è¡Œæ™‚é•·: {execution_time:.1f} ç§’\n",
        "\n",
        "ğŸ“Š **åŸ·è¡Œçµæœ:**\n",
        "â€¢ ç¸½è™•ç†è‚¡ç¥¨: {len(stocks_df)} æ”¯\n",
        "â€¢ æˆåŠŸåˆ†æ: {len(all_results)} æ”¯\n",
        "â€¢ ç¬¦åˆæ¢ä»¶: 0 æ”¯\n",
        "â€¢ å¤±æ•—è‚¡ç¥¨: {len(failed_stocks)} æ”¯\n",
        "\n",
        "âš ï¸ æ²’æœ‰ç¬¦åˆç¯©é¸æ¢ä»¶çš„è‚¡ç¥¨ã€‚\n",
        "\"\"\"\n",
        "\n",
        "    # ç™¼é€æœ€çµ‚é€šçŸ¥\n",
        "    await send_notification(completion_message)\n",
        "\n",
        "    logger.info(f\"\\nğŸ‰ğŸ‰ğŸ‰ å…¨éƒ¨æµç¨‹åŸ·è¡Œå®Œç•¢ï¼\")\n",
        "    logger.info(f\"ğŸ“Š è™•ç†çµ±è¨ˆ: ç¸½è¨ˆ {len(stocks_df)} æ”¯ï¼ŒæˆåŠŸ {len(all_results)} æ”¯ï¼Œç¬¦åˆæ¢ä»¶ {len(final_results)} æ”¯\")\n",
        "    logger.info(f\"âŒ› ç¸½è€—æ™‚: {execution_time:.2f} ç§’\")\n",
        "    logger.info(f\"â° å®Œæˆæ™‚é–“: {completion_time}\")\n",
        "# ==============================================================================\n",
        "# ä¸»ç¨‹å¼å…¥å£é»\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # æª¢æŸ¥æ˜¯å¦åœ¨ Jupyter ç’°å¢ƒä¸­\n",
        "        in_jupyter = 'ipykernel' in sys.modules\n",
        "\n",
        "        if in_jupyter:\n",
        "            # Jupyter ç’°å¢ƒè™•ç†\n",
        "            loop = asyncio.get_event_loop()\n",
        "            if loop.is_running():\n",
        "                # å¦‚æœäº‹ä»¶å¾ªç’°æ­£åœ¨é‹è¡Œï¼Œå‰µå»ºä»»å‹™\n",
        "                task = loop.create_task(main())\n",
        "                logger.info(\"åœ¨ Jupyter ç’°å¢ƒä¸­å‰µå»ºç•°æ­¥ä»»å‹™\")\n",
        "            else:\n",
        "                # å¦‚æœäº‹ä»¶å¾ªç’°æœªé‹è¡Œï¼Œç›´æ¥åŸ·è¡Œ\n",
        "                loop.run_until_complete(main())\n",
        "        else:\n",
        "            # ä¸€èˆ¬ Python ç’°å¢ƒ\n",
        "            asyncio.run(main())\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"ç”¨æˆ¶ä¸­æ–·ç¨‹å¼åŸ·è¡Œ\")\n",
        "    except Exception as e:\n",
        "        error_time = format_timestamp()\n",
        "        logger.critical(f\"ç¨‹å¼åŸ·è¡Œæ™‚ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤ ({error_time}): {e}\")\n",
        "        logger.critical(traceback.format_exc())\n",
        "\n",
        "        # ç™¼é€éŒ¯èª¤é€šçŸ¥ï¼ˆå¦‚æœé€šè¨ŠåŠŸèƒ½å¯ç”¨ï¼‰\n",
        "        if 'MESSAGING_AVAILABLE' in globals() and MESSAGING_AVAILABLE:\n",
        "            try:\n",
        "                error_message = f\"\"\"\n",
        "âŒ **ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤** âŒ\n",
        "\n",
        "â° éŒ¯èª¤æ™‚é–“: {error_time}\n",
        "ğŸ éŒ¯èª¤è¨Šæ¯: {str(e)}\n",
        "\n",
        "è«‹æª¢æŸ¥æ—¥èªŒæª”æ¡ˆä»¥ç²å–è©³ç´°è³‡è¨Šã€‚\n",
        "                \"\"\".strip()\n",
        "                asyncio.run(send_notification(error_message))\n",
        "            except:\n",
        "                pass  # é¿å…é€šçŸ¥ç™¼é€å¤±æ•—å°è‡´ç¨‹å¼å´©æ½°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb8sxRURqZ49"
      },
      "source": [
        "å¯å‚³è¨Šä½†çµ‚ç«¯æ²’æœ‰é¡¯ç¾å‡ºå ±å‘Šï¼Œå‚³è¨Šæœ‰åœ–ç‰‡ä½†æœƒå»¶é²å‡ºç¾ï¼Œè»Ÿé«”è¦è·‘å¾ˆä¹…ã€‚discordèˆ‡telegram éƒ½æˆåŠŸï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BqQdXWUVGzfD",
        "outputId": "c450822d-d933-4cf3-900c-838f3f668026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mplfinance ç‰ˆæœ¬: 0.12.10b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:[6589] æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—ï¼Œè·³éã€‚\n",
            "WARNING:__main__:[6909] æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—ï¼Œè·³éã€‚\n",
            "WARNING:__main__:[6918] æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—ï¼Œè·³éã€‚\n",
            "WARNING:__main__:[7749] æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—ï¼Œè·³éã€‚\n",
            "WARNING:__main__:[7740] æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—ï¼Œè·³éã€‚\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "                                 ğŸ¯ æœ€çµ‚ç¯©é¸å„ªè³ªè‚¡ç¥¨æ¸…å–® ğŸ¯                                 \n",
            "================================================================================\n",
            "æ’å  ä»£ç¢¼     åç¨±          åˆ†æ•¸     åƒ¹æ ¼        å»ºè­°        ç”¢æ¥­             \n",
            "--------------------------------------------------------------------------------\n",
            "1   1409   æ–°çº–          81     13.80     è²·å…¥        ç´¡ç¹”çº–ç¶­           \n",
            "2   3135   å‡Œèˆª          81     40.70     è²·å…¥        åŠå°é«”æ¥­           \n",
            "3   6213   è¯èŒ‚          81     103.50    è²·å…¥        é›»å­é›¶çµ„ä»¶æ¥­         \n",
            "4   1711   æ°¸å…‰          78     17.45     è²·å…¥        åŒ–å­¸å·¥æ¥­           \n",
            "5   8374   ç¾…æ˜‡          78     111.00    è²·å…¥        é›»æ©Ÿæ©Ÿæ¢°           \n",
            "6   3163   æ³¢è‹¥å¨         77     184.50    è²·å…¥        é€šä¿¡ç¶²è·¯æ¥­          \n",
            "7   8249   è±å…‰          76     57.60     è²·å…¥        é›»å­é›¶çµ„ä»¶æ¥­         \n",
            "8   3128   æ˜‡éŠ³          76     43.85     è²·å…¥        å…‰é›»æ¥­            \n",
            "9   3297   æ­ç‰¹          76     62.40     è²·å…¥        å…‰é›»æ¥­            \n",
            "10  5425   å°åŠ          76     49.75     è²·å…¥        åŠå°é«”æ¥­           \n",
            "11  2338   å…‰ç½©          75     35.65     è²·å…¥        åŠå°é«”æ¥­           \n",
            "12  4576   å¤§éŠ€å¾®ç³»çµ±       75     124.00    è²·å…¥        é›»æ©Ÿæ©Ÿæ¢°           \n",
            "13  3363   ä¸Šè©®          75     308.00    è²·å…¥        é€šä¿¡ç¶²è·¯æ¥­          \n",
            "14  4510   é«˜é‹’          75     51.90     è²·å…¥        é›»æ©Ÿæ©Ÿæ¢°           \n",
            "15  5314   ä¸–ç´€*         75     85.10     è²·å…¥        å…¶ä»–æ¥­            \n",
            "16  2359   æ‰€ç¾…é–€         74     146.00    è²·å…¥        å…¶ä»–é›»å­æ¥­          \n",
            "17  4540   å…¨çƒå‚³å‹•        74     42.05     è²·å…¥        é›»æ©Ÿæ©Ÿæ¢°           \n",
            "18  4927   æ³°é¼-KY       74     26.80     è²·å…¥        é›»å­é›¶çµ„ä»¶æ¥­         \n",
            "19  3709   é‘«è¯å¤§æŠ•æ§       74     40.10     è²·å…¥        é›»è…¦åŠé€±é‚Šè¨­å‚™æ¥­       \n",
            "20  3227   åŸç›¸          73     211.50    è²·å…¥        åŠå°é«”æ¥­           \n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "                                   ğŸ“Š è©³ç´°åˆ†æå ±å‘Š ğŸ“Š                                   \n",
            "================================================================================\n",
            "\n",
            "å ±å‘Š #20: 3227 - åŸç›¸\n",
            "--------------------------------------------------\n",
            "ç¶œåˆè©•åˆ†: 73.00\n",
            "æœ€æ–°æ”¶ç›¤åƒ¹: 211.50 å…ƒ\n",
            "ç”¢æ¥­é¡åˆ¥: åŠå°é«”æ¥­\n",
            "æ¨è–¦è¡Œå‹•: è²·å…¥\n",
            "ä¿¡å¿ƒåº¦: 46.00%\n",
            "æ¨è–¦ç†ç”±:\n",
            "  - è¶¨å‹¢å¼·å‹å‘ä¸Š\n",
            "  - åƒ¹é‡é…åˆè‰¯å¥½\n",
            "--------------------------------------------------\n",
            "========================================\n",
            "==== å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· ====\n",
            "========================================\n",
            "ğŸš€ é–‹å§‹è‡ªå‹•åˆ†ææ‰€æœ‰è‚¡ç¥¨...\n",
            "\n",
            "[éšæ®µ1/5] ç²å–æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬è³‡æ–™...\n",
            "âœ… å¾å¿«å–è¼‰å…¥ 1912 æ”¯è‚¡ç¥¨æ¸…å–®ã€‚\n",
            "\n",
            "[éšæ®µ2/5] æ‰¹æ¬¡ä¸‹è¼‰æ­·å²è³‡æ–™ (ä¸€å¹´æœŸ)...\n",
            "[1/1912] æ­£åœ¨ç²å–: 1101 å°æ³¥...\n",
            "[2/1912] æ­£åœ¨ç²å–: 1102 äºæ³¥...\n",
            "[3/1912] æ­£åœ¨ç²å–: 1103 å˜‰æ³¥...\n",
            "[4/1912] æ­£åœ¨ç²å–: 1104 ç’°æ³¥...\n",
            "[5/1912] æ­£åœ¨ç²å–: 1108 å¹¸ç¦...\n",
            "[6/1912] æ­£åœ¨ç²å–: 1109 ä¿¡å¤§...\n",
            "[7/1912] æ­£åœ¨ç²å–: 1110 æ±æ³¥...\n",
            "[8/1912] æ­£åœ¨ç²å–: 1201 å‘³å…¨...\n",
            "[9/1912] æ­£åœ¨ç²å–: 1203 å‘³ç‹...\n",
            "[10/1912] æ­£åœ¨ç²å–: 1210 å¤§æˆ...\n",
            "[11/1912] æ­£åœ¨ç²å–: 1213 å¤§é£²...\n",
            "[12/1912] æ­£åœ¨ç²å–: 1215 åœèœ‚...\n",
            "[13/1912] æ­£åœ¨ç²å–: 1216 çµ±ä¸€...\n",
            "[14/1912] æ­£åœ¨ç²å–: 1217 æ„›ä¹‹å‘³...\n",
            "[15/1912] æ­£åœ¨ç²å–: 1218 æ³°å±±...\n",
            "[16/1912] æ­£åœ¨ç²å–: 1219 ç¦å£½...\n",
            "[17/1912] æ­£åœ¨ç²å–: 1220 å°æ¦®...\n",
            "[18/1912] æ­£åœ¨ç²å–: 1225 ç¦æ‡‹æ²¹...\n",
            "[19/1912] æ­£åœ¨ç²å–: 1227 ä½³æ ¼...\n",
            "[20/1912] æ­£åœ¨ç²å–: 1229 è¯è¯...\n",
            "[21/1912] æ­£åœ¨ç²å–: 1231 è¯è¯é£Ÿ...\n",
            "[22/1912] æ­£åœ¨ç²å–: 1232 å¤§çµ±ç›Š...\n",
            "[23/1912] æ­£åœ¨ç²å–: 1233 å¤©ä»...\n",
            "[24/1912] æ­£åœ¨ç²å–: 1234 é»‘æ¾...\n",
            "[25/1912] æ­£åœ¨ç²å–: 1235 èˆˆæ³°...\n",
            "[26/1912] æ­£åœ¨ç²å–: 1236 å®äº...\n",
            "[27/1912] æ­£åœ¨ç²å–: 1256 é®®æ´»æœæ±-KY...\n",
            "[28/1912] æ­£åœ¨ç²å–: 1301 å°å¡‘...\n",
            "[29/1912] æ­£åœ¨ç²å–: 1303 å—äº...\n",
            "[30/1912] æ­£åœ¨ç²å–: 1304 å°èš...\n",
            "[31/1912] æ­£åœ¨ç²å–: 1305 è¯å¤...\n",
            "[32/1912] æ­£åœ¨ç²å–: 1307 ä¸‰èŠ³...\n",
            "[33/1912] æ­£åœ¨ç²å–: 1308 äºèš...\n",
            "[34/1912] æ­£åœ¨ç²å–: 1309 å°é”åŒ–...\n",
            "[35/1912] æ­£åœ¨ç²å–: 1310 å°è‹¯...\n",
            "[36/1912] æ­£åœ¨ç²å–: 1312 åœ‹å–¬...\n",
            "[37/1912] æ­£åœ¨ç²å–: 1313 è¯æˆ...\n",
            "[38/1912] æ­£åœ¨ç²å–: 1314 ä¸­çŸ³åŒ–...\n",
            "[39/1912] æ­£åœ¨ç²å–: 1315 é”æ–°...\n",
            "[40/1912] æ­£åœ¨ç²å–: 1316 ä¸Šæ›œ...\n",
            "[41/1912] æ­£åœ¨ç²å–: 1319 æ±é™½...\n",
            "[42/1912] æ­£åœ¨ç²å–: 1321 å¤§æ´‹...\n",
            "[43/1912] æ­£åœ¨ç²å–: 1323 æ°¸è£•...\n",
            "[44/1912] æ­£åœ¨ç²å–: 1324 åœ°çƒ...\n",
            "[45/1912] æ­£åœ¨ç²å–: 1325 æ†å¤§...\n",
            "[46/1912] æ­£åœ¨ç²å–: 1326 å°åŒ–...\n",
            "[47/1912] æ­£åœ¨ç²å–: 1337 å†ç”Ÿ-KY...\n",
            "[48/1912] æ­£åœ¨ç²å–: 1338 å»£è¯-KY...\n",
            "[49/1912] æ­£åœ¨ç²å–: 1339 æ˜­è¼...\n",
            "[50/1912] æ­£åœ¨ç²å–: 1340 å‹æ‚…-KY...\n",
            "[51/1912] æ­£åœ¨ç²å–: 1341 å¯Œæ—-KY...\n",
            "[52/1912] æ­£åœ¨ç²å–: 1342 å…«è²«...\n",
            "[53/1912] æ­£åœ¨ç²å–: 1402 é æ±æ–°...\n",
            "[54/1912] æ­£åœ¨ç²å–: 1409 æ–°çº–...\n",
            "[55/1912] æ­£åœ¨ç²å–: 1410 å—æŸ“...\n",
            "[56/1912] æ­£åœ¨ç²å–: 1413 å®æ´²...\n",
            "[57/1912] æ­£åœ¨ç²å–: 1414 æ±å’Œ...\n",
            "[58/1912] æ­£åœ¨ç²å–: 1416 å»£è±...\n",
            "[59/1912] æ­£åœ¨ç²å–: 1417 å˜‰è£•...\n",
            "[60/1912] æ­£åœ¨ç²å–: 1418 æ±è¯...\n",
            "[61/1912] æ­£åœ¨ç²å–: 1419 æ–°ç´¡...\n",
            "[62/1912] æ­£åœ¨ç²å–: 1423 åˆ©è¯...\n",
            "[63/1912] æ­£åœ¨ç²å–: 1432 å¤§é­¯é–£...\n",
            "[64/1912] æ­£åœ¨ç²å–: 1434 ç¦æ‡‹...\n",
            "[65/1912] æ­£åœ¨ç²å–: 1435 ä¸­ç¦...\n",
            "[66/1912] æ­£åœ¨ç²å–: 1436 è¯å‹è¯...\n",
            "[67/1912] æ­£åœ¨ç²å–: 1437 å‹¤ç›Šæ§...\n",
            "[68/1912] æ­£åœ¨ç²å–: 1438 ä¸‰åœ°é–‹ç™¼...\n",
            "[69/1912] æ­£åœ¨ç²å–: 1439 é›‹æš...\n",
            "[70/1912] æ­£åœ¨ç²å–: 1440 å—ç´¡...\n",
            "[71/1912] æ­£åœ¨ç²å–: 1441 å¤§æ±...\n",
            "[72/1912] æ­£åœ¨ç²å–: 1442 åè»’...\n",
            "[73/1912] æ­£åœ¨ç²å–: 1443 ç«‹ç›Šç‰©æµ...\n",
            "[74/1912] æ­£åœ¨ç²å–: 1444 åŠ›éº—...\n",
            "[75/1912] æ­£åœ¨ç²å–: 1445 å¤§å®‡...\n",
            "[76/1912] æ­£åœ¨ç²å–: 1446 å®å’Œ...\n",
            "[77/1912] æ­£åœ¨ç²å–: 1447 åŠ›éµ¬...\n",
            "[78/1912] æ­£åœ¨ç²å–: 1449 ä½³å’Œ...\n",
            "[79/1912] æ­£åœ¨ç²å–: 1451 å¹´èˆˆ...\n",
            "[80/1912] æ­£åœ¨ç²å–: 1452 å®ç›Š...\n",
            "[81/1912] æ­£åœ¨ç²å–: 1453 å¤§å°‡...\n",
            "[82/1912] æ­£åœ¨ç²å–: 1454 å°å¯Œ...\n",
            "[83/1912] æ­£åœ¨ç²å–: 1455 é›†ç››...\n",
            "[84/1912] æ­£åœ¨ç²å–: 1456 æ€¡è¯...\n",
            "[85/1912] æ­£åœ¨ç²å–: 1457 å®œé€²...\n",
            "[86/1912] æ­£åœ¨ç²å–: 1459 è¯ç™¼...\n",
            "[87/1912] æ­£åœ¨ç²å–: 1460 å®é ...\n",
            "[88/1912] æ­£åœ¨ç²å–: 1463 å¼·ç››æ–°...\n",
            "[89/1912] æ­£åœ¨ç²å–: 1464 å¾—åŠ›...\n",
            "[90/1912] æ­£åœ¨ç²å–: 1465 å‰å…¨...\n",
            "[91/1912] æ­£åœ¨ç²å–: 1466 èšéš†...\n",
            "[92/1912] æ­£åœ¨ç²å–: 1467 å—ç·¯...\n",
            "[93/1912] æ­£åœ¨ç²å–: 1468 æ˜¶å’Œ...\n",
            "[94/1912] æ­£åœ¨ç²å–: 1470 å¤§çµ±æ–°å‰µ...\n",
            "[95/1912] æ­£åœ¨ç²å–: 1471 é¦–åˆ©...\n",
            "[96/1912] æ­£åœ¨ç²å–: 1472 ä¸‰æ´‹å¯¦æ¥­...\n",
            "[97/1912] æ­£åœ¨ç²å–: 1473 å°å—...\n",
            "[98/1912] æ­£åœ¨ç²å–: 1474 å¼˜è£•...\n",
            "[99/1912] æ­£åœ¨ç²å–: 1475 æ¥­æ—º...\n",
            "[100/1912] æ­£åœ¨ç²å–: 1476 å„’é´»...\n",
            "[101/1912] æ­£åœ¨ç²å–: 1477 èšé™½...\n",
            "[102/1912] æ­£åœ¨ç²å–: 1503 å£«é›»...\n",
            "[103/1912] æ­£åœ¨ç²å–: 1504 æ±å…ƒ...\n",
            "[104/1912] æ­£åœ¨ç²å–: 1506 æ­£é“...\n",
            "[105/1912] æ­£åœ¨ç²å–: 1512 ç‘åˆ©...\n",
            "[106/1912] æ­£åœ¨ç²å–: 1513 ä¸­èˆˆé›»...\n",
            "[107/1912] æ­£åœ¨ç²å–: 1514 äºåŠ›...\n",
            "[108/1912] æ­£åœ¨ç²å–: 1515 åŠ›å±±...\n",
            "[109/1912] æ­£åœ¨ç²å–: 1516 å·é£›...\n",
            "[110/1912] æ­£åœ¨ç²å–: 1517 åˆ©å¥‡...\n",
            "[111/1912] æ­£åœ¨ç²å–: 1519 è¯åŸ...\n",
            "[112/1912] æ­£åœ¨ç²å–: 1521 å¤§å„„...\n",
            "[113/1912] æ­£åœ¨ç²å–: 1522 å ¤ç¶­è¥¿...\n",
            "[114/1912] æ­£åœ¨ç²å–: 1524 è€¿é¼...\n",
            "[115/1912] æ­£åœ¨ç²å–: 1525 æ±Ÿç”³...\n",
            "[116/1912] æ­£åœ¨ç²å–: 1526 æ—¥é¦³...\n",
            "[117/1912] æ­£åœ¨ç²å–: 1527 é‘½å…¨...\n",
            "[118/1912] æ­£åœ¨ç²å–: 1528 æ©å¾·...\n",
            "[119/1912] æ­£åœ¨ç²å–: 1529 æ¨‚äº‹ç¶ èƒ½...\n",
            "[120/1912] æ­£åœ¨ç²å–: 1530 äºå´´...\n",
            "[121/1912] æ­£åœ¨ç²å–: 1531 é«˜æ—è‚¡...\n",
            "[122/1912] æ­£åœ¨ç²å–: 1532 å‹¤ç¾...\n",
            "[123/1912] æ­£åœ¨ç²å–: 1533 è»Šç‹é›»...\n",
            "[124/1912] æ­£åœ¨ç²å–: 1535 ä¸­å®‡...\n",
            "[125/1912] æ­£åœ¨ç²å–: 1536 å’Œå¤§...\n",
            "[126/1912] æ­£åœ¨ç²å–: 1537 å»£éš†...\n",
            "[127/1912] æ­£åœ¨ç²å–: 1538 æ­£å³°...\n",
            "[128/1912] æ­£åœ¨ç²å–: 1539 å·¨åº­...\n",
            "[129/1912] æ­£åœ¨ç²å–: 1540 å–¬ç¦...\n",
            "[130/1912] æ­£åœ¨ç²å–: 1541 éŒ©æ³°...\n",
            "[131/1912] æ­£åœ¨ç²å–: 1558 ä¼¸èˆˆ...\n",
            "[132/1912] æ­£åœ¨ç²å–: 1560 ä¸­ç ‚...\n",
            "[133/1912] æ­£åœ¨ç²å–: 1563 å·§æ–°...\n",
            "[134/1912] æ­£åœ¨ç²å–: 1568 å€‰ä½‘...\n",
            "[135/1912] æ­£åœ¨ç²å–: 1582 ä¿¡éŒ¦...\n",
            "[136/1912] æ­£åœ¨ç²å–: 1583 ç¨‹æ³°...\n",
            "[137/1912] æ­£åœ¨ç²å–: 1587 å‰èŒ‚...\n",
            "[138/1912] æ­£åœ¨ç²å–: 1589 æ°¸å† -KY...\n",
            "[139/1912] æ­£åœ¨ç²å–: 1590 äºå¾·å®¢-KY...\n",
            "[140/1912] æ­£åœ¨ç²å–: 1597 ç›´å¾—...\n",
            "[141/1912] æ­£åœ¨ç²å–: 1598 å²±å®‡...\n",
            "[142/1912] æ­£åœ¨ç²å–: 1603 è¯é›»...\n",
            "[143/1912] æ­£åœ¨ç²å–: 1604 è²å¯¶...\n",
            "[144/1912] æ­£åœ¨ç²å–: 1605 è¯æ–°...\n",
            "[145/1912] æ­£åœ¨ç²å–: 1608 è¯æ¦®...\n",
            "[146/1912] æ­£åœ¨ç²å–: 1609 å¤§äº...\n",
            "[147/1912] æ­£åœ¨ç²å–: 1611 ä¸­é›»...\n",
            "[148/1912] æ­£åœ¨ç²å–: 1612 å®æ³°...\n",
            "[149/1912] æ­£åœ¨ç²å–: 1614 ä¸‰æ´‹é›»...\n",
            "[150/1912] æ­£åœ¨ç²å–: 1615 å¤§å±±...\n",
            "[151/1912] æ­£åœ¨ç²å–: 1616 å„„æ³°...\n",
            "[152/1912] æ­£åœ¨ç²å–: 1617 æ¦®æ˜Ÿ...\n",
            "[153/1912] æ­£åœ¨ç²å–: 1618 åˆæ©Ÿ...\n",
            "[154/1912] æ­£åœ¨ç²å–: 1626 è‰¾ç¾ç‰¹-KY...\n",
            "[155/1912] æ­£åœ¨ç²å–: 1702 å—åƒ‘...\n",
            "[156/1912] æ­£åœ¨ç²å–: 1707 è‘¡è„ç‹...\n",
            "[157/1912] æ­£åœ¨ç²å–: 1708 æ±é¹¼...\n",
            "[158/1912] æ­£åœ¨ç²å–: 1709 å’Œç›Š...\n",
            "[159/1912] æ­£åœ¨ç²å–: 1710 æ±è¯...\n",
            "[160/1912] æ­£åœ¨ç²å–: 1711 æ°¸å…‰...\n",
            "[161/1912] æ­£åœ¨ç²å–: 1712 èˆˆè¾²...\n",
            "[162/1912] æ­£åœ¨ç²å–: 1713 åœ‹åŒ–...\n",
            "[163/1912] æ­£åœ¨ç²å–: 1714 å’Œæ¡...\n",
            "[164/1912] æ­£åœ¨ç²å–: 1717 é•·èˆˆ...\n",
            "[165/1912] æ­£åœ¨ç²å–: 1718 ä¸­çº–...\n",
            "[166/1912] æ­£åœ¨ç²å–: 1720 ç”Ÿé”...\n",
            "[167/1912] æ­£åœ¨ç²å–: 1721 ä¸‰æ™ƒ...\n",
            "[168/1912] æ­£åœ¨ç²å–: 1722 å°è‚¥...\n",
            "[169/1912] æ­£åœ¨ç²å–: 1723 ä¸­ç¢³...\n",
            "[170/1912] æ­£åœ¨ç²å–: 1725 å…ƒç¦...\n",
            "[171/1912] æ­£åœ¨ç²å–: 1726 æ°¸è¨˜...\n",
            "[172/1912] æ­£åœ¨ç²å–: 1727 ä¸­è¯åŒ–...\n",
            "[173/1912] æ­£åœ¨ç²å–: 1730 èŠ±ä»™å­...\n",
            "[174/1912] æ­£åœ¨ç²å–: 1731 ç¾å¾è¯...\n",
            "[175/1912] æ­£åœ¨ç²å–: 1732 æ¯›å¯¶...\n",
            "[176/1912] æ­£åœ¨ç²å–: 1733 äº”é¼...\n",
            "[177/1912] æ­£åœ¨ç²å–: 1734 æè¼...\n",
            "[178/1912] æ­£åœ¨ç²å–: 1735 æ—¥å‹åŒ–...\n",
            "[179/1912] æ­£åœ¨ç²å–: 1736 å–¬å±±...\n",
            "[180/1912] æ­£åœ¨ç²å–: 1737 è‡ºé¹½...\n",
            "[181/1912] æ­£åœ¨ç²å–: 1752 å—å…‰...\n",
            "[182/1912] æ­£åœ¨ç²å–: 1760 å¯¶é½¡å¯ŒéŒ¦...\n",
            "[183/1912] æ­£åœ¨ç²å–: 1762 ä¸­åŒ–ç”Ÿ...\n",
            "[184/1912] æ­£åœ¨ç²å–: 1773 å‹ä¸€...\n",
            "[185/1912] æ­£åœ¨ç²å–: 1776 å±•å®‡...\n",
            "[186/1912] æ­£åœ¨ç²å–: 1783 å’Œåº·ç”Ÿ...\n",
            "[187/1912] æ­£åœ¨ç²å–: 1786 ç§‘å¦...\n",
            "[188/1912] æ­£åœ¨ç²å–: 1789 ç¥éš†...\n",
            "[189/1912] æ­£åœ¨ç²å–: 1795 ç¾æ™‚...\n",
            "[190/1912] æ­£åœ¨ç²å–: 1802 å°ç»...\n",
            "[191/1912] æ­£åœ¨ç²å–: 1805 å¯¶å¾ ...\n",
            "[192/1912] æ­£åœ¨ç²å–: 1806 å† è»...\n",
            "[193/1912] æ­£åœ¨ç²å–: 1808 æ½¤éš†...\n",
            "[194/1912] æ­£åœ¨ç²å–: 1809 ä¸­é‡‰...\n",
            "[195/1912] æ­£åœ¨ç²å–: 1810 å’Œæˆ...\n",
            "[196/1912] æ­£åœ¨ç²å–: 1817 å‡±æ’’è¡›...\n",
            "[197/1912] æ­£åœ¨ç²å–: 1903 å£«ç´™...\n",
            "[198/1912] æ­£åœ¨ç²å–: 1904 æ­£éš†...\n",
            "[199/1912] æ­£åœ¨ç²å–: 1905 è¯ç´™...\n",
            "[200/1912] æ­£åœ¨ç²å–: 1906 å¯¶éš†...\n",
            "[201/1912] æ­£åœ¨ç²å–: 1907 æ°¸è±é¤˜...\n",
            "[202/1912] æ­£åœ¨ç²å–: 1909 æ¦®æˆ...\n",
            "[203/1912] æ­£åœ¨ç²å–: 2002 ä¸­é‹¼...\n",
            "[204/1912] æ­£åœ¨ç²å–: 2006 æ±å’Œé‹¼éµ...\n",
            "[205/1912] æ­£åœ¨ç²å–: 2007 ç‡èˆˆ...\n",
            "[206/1912] æ­£åœ¨ç²å–: 2008 é«˜èˆˆæ˜Œ...\n",
            "[207/1912] æ­£åœ¨ç²å–: 2009 ç¬¬ä¸€éŠ…...\n",
            "[208/1912] æ­£åœ¨ç²å–: 2010 æ˜¥æº...\n",
            "[209/1912] æ­£åœ¨ç²å–: 2012 æ˜¥é›¨...\n",
            "[210/1912] æ­£åœ¨ç²å–: 2013 ä¸­é‹¼æ§‹...\n",
            "[211/1912] æ­£åœ¨ç²å–: 2014 ä¸­é´»...\n",
            "[212/1912] æ­£åœ¨ç²å–: 2015 è±èˆˆ...\n",
            "[213/1912] æ­£åœ¨ç²å–: 2017 å®˜ç”°é‹¼...\n",
            "[214/1912] æ­£åœ¨ç²å–: 2020 ç¾äº...\n",
            "[215/1912] æ­£åœ¨ç²å–: 2022 èšäº¨...\n",
            "[216/1912] æ­£åœ¨ç²å–: 2023 ç‡è¼...\n",
            "[217/1912] æ­£åœ¨ç²å–: 2024 å¿—è¯...\n",
            "[218/1912] æ­£åœ¨ç²å–: 2025 åƒèˆˆ...\n",
            "[219/1912] æ­£åœ¨ç²å–: 2027 å¤§æˆé‹¼...\n",
            "[220/1912] æ­£åœ¨ç²å–: 2028 å¨è‡´...\n",
            "[221/1912] æ­£åœ¨ç²å–: 2029 ç››é¤˜...\n",
            "[222/1912] æ­£åœ¨ç²å–: 2030 å½°æº...\n",
            "[223/1912] æ­£åœ¨ç²å–: 2031 æ–°å…‰é‹¼...\n",
            "[224/1912] æ­£åœ¨ç²å–: 2032 æ–°é‹¼...\n",
            "[225/1912] æ­£åœ¨ç²å–: 2033 ä½³å¤§...\n",
            "[226/1912] æ­£åœ¨ç²å–: 2034 å…å¼·...\n",
            "[227/1912] æ­£åœ¨ç²å–: 2038 æµ·å…‰...\n",
            "[228/1912] æ­£åœ¨ç²å–: 2049 ä¸ŠéŠ€...\n",
            "[229/1912] æ­£åœ¨ç²å–: 2059 å·æ¹–...\n",
            "[230/1912] æ­£åœ¨ç²å–: 2062 æ©‹æ¤¿...\n",
            "[231/1912] æ­£åœ¨ç²å–: 2069 é‹éŒ©...\n",
            "[232/1912] æ­£åœ¨ç²å–: 2101 å—æ¸¯...\n",
            "[233/1912] æ­£åœ¨ç²å–: 2102 æ³°è±...\n",
            "[234/1912] æ­£åœ¨ç²å–: 2103 å°æ©¡...\n",
            "[235/1912] æ­£åœ¨ç²å–: 2104 åœ‹éš›ä¸­æ©¡...\n",
            "[236/1912] æ­£åœ¨ç²å–: 2105 æ­£æ–°...\n",
            "[237/1912] æ­£åœ¨ç²å–: 2106 å»ºå¤§...\n",
            "[238/1912] æ­£åœ¨ç²å–: 2107 åšç”Ÿ...\n",
            "[239/1912] æ­£åœ¨ç²å–: 2108 å—å¸...\n",
            "[240/1912] æ­£åœ¨ç²å–: 2109 è¯è±...\n",
            "[241/1912] æ­£åœ¨ç²å–: 2114 é‘«æ°¸éŠ“...\n",
            "[242/1912] æ­£åœ¨ç²å–: 2115 å…­æš‰-KY...\n",
            "[243/1912] æ­£åœ¨ç²å–: 2201 è£•éš†...\n",
            "[244/1912] æ­£åœ¨ç²å–: 2204 ä¸­è¯...\n",
            "[245/1912] æ­£åœ¨ç²å–: 2206 ä¸‰é™½å·¥æ¥­...\n",
            "[246/1912] æ­£åœ¨ç²å–: 2207 å’Œæ³°è»Š...\n",
            "[247/1912] æ­£åœ¨ç²å–: 2208 å°èˆ¹...\n",
            "[248/1912] æ­£åœ¨ç²å–: 2211 é•·æ¦®é‹¼...\n",
            "[249/1912] æ­£åœ¨ç²å–: 2227 è£•æ—¥è»Š...\n",
            "[250/1912] æ­£åœ¨ç²å–: 2228 åŠéºŸ...\n",
            "[251/1912] æ­£åœ¨ç²å–: 2231 ç‚ºå‡...\n",
            "[252/1912] æ­£åœ¨ç²å–: 2233 å®‡éš†...\n",
            "[253/1912] æ­£åœ¨ç²å–: 2236 ç™¾é”-KY...\n",
            "[254/1912] æ­£åœ¨ç²å–: 2239 è‹±åˆ©-KY...\n",
            "[255/1912] æ­£åœ¨ç²å–: 2241 è‰¾å§†å‹’...\n",
            "[256/1912] æ­£åœ¨ç²å–: 2243 å®æ—­-KY...\n",
            "[257/1912] æ­£åœ¨ç²å–: 2247 æ±å¾·æ°¸æ¥­...\n",
            "[258/1912] æ­£åœ¨ç²å–: 2248 è¯å‹-KY...\n",
            "[259/1912] æ­£åœ¨ç²å–: 2250 IKKA-KY...\n",
            "[260/1912] æ­£åœ¨ç²å–: 2301 å…‰å¯¶ç§‘...\n",
            "[261/1912] æ­£åœ¨ç²å–: 2302 éº—æ­£...\n",
            "[262/1912] æ­£åœ¨ç²å–: 2303 è¯é›»...\n",
            "[263/1912] æ­£åœ¨ç²å–: 2305 å…¨å‹...\n",
            "[264/1912] æ­£åœ¨ç²å–: 2308 å°é”é›»...\n",
            "[265/1912] æ­£åœ¨ç²å–: 2312 é‡‘å¯¶...\n",
            "[266/1912] æ­£åœ¨ç²å–: 2313 è¯é€š...\n",
            "[267/1912] æ­£åœ¨ç²å–: 2314 å°æš...\n",
            "[268/1912] æ­£åœ¨ç²å–: 2316 æ¥ æ¢“é›»...\n",
            "[269/1912] æ­£åœ¨ç²å–: 2317 é´»æµ·...\n",
            "[270/1912] æ­£åœ¨ç²å–: 2321 æ±è¨Š...\n",
            "[271/1912] æ­£åœ¨ç²å–: 2323 ä¸­ç’°...\n",
            "[272/1912] æ­£åœ¨ç²å–: 2324 ä»å¯¶...\n",
            "[273/1912] æ­£åœ¨ç²å–: 2327 åœ‹å·¨...\n",
            "[274/1912] æ­£åœ¨ç²å–: 2328 å»£å®‡...\n",
            "[275/1912] æ­£åœ¨ç²å–: 2329 è¯æ³°...\n",
            "[276/1912] æ­£åœ¨ç²å–: 2330 å°ç©é›»...\n",
            "[277/1912] æ­£åœ¨ç²å–: 2331 ç²¾è‹±...\n",
            "[278/1912] æ­£åœ¨ç²å–: 2332 å‹è¨Š...\n",
            "[279/1912] æ­£åœ¨ç²å–: 2337 æ—ºå®...\n",
            "[280/1912] æ­£åœ¨ç²å–: 2338 å…‰ç½©...\n",
            "[281/1912] æ­£åœ¨ç²å–: 2340 å°äº...\n",
            "[282/1912] æ­£åœ¨ç²å–: 2342 èŒ‚çŸ½...\n",
            "[283/1912] æ­£åœ¨ç²å–: 2344 è¯é‚¦é›»...\n",
            "[284/1912] æ­£åœ¨ç²å–: 2345 æ™ºé‚¦...\n",
            "[285/1912] æ­£åœ¨ç²å–: 2347 è¯å¼·...\n",
            "[286/1912] æ­£åœ¨ç²å–: 2348 æµ·æ‚…...\n",
            "[287/1912] æ­£åœ¨ç²å–: 2349 éŒ¸å¾·...\n",
            "[288/1912] æ­£åœ¨ç²å–: 2351 é †å¾·...\n",
            "[289/1912] æ­£åœ¨ç²å–: 2352 ä½³ä¸–é”...\n",
            "[290/1912] æ­£åœ¨ç²å–: 2353 å®ï¿½ï¿½...\n",
            "[291/1912] æ­£åœ¨ç²å–: 2354 é´»æº–...\n",
            "[292/1912] æ­£åœ¨ç²å–: 2355 æ•¬éµ¬...\n",
            "[293/1912] æ­£åœ¨ç²å–: 2356 è‹±æ¥­é”...\n",
            "[294/1912] æ­£åœ¨ç²å–: 2357 è¯ç¢©...\n",
            "[295/1912] æ­£åœ¨ç²å–: 2359 æ‰€ç¾…é–€...\n",
            "[296/1912] æ­£åœ¨ç²å–: 2360 è‡´èŒ‚...\n",
            "[297/1912] æ­£åœ¨ç²å–: 2362 è—å¤©...\n",
            "[298/1912] æ­£åœ¨ç²å–: 2363 çŸ½çµ±...\n",
            "[299/1912] æ­£åœ¨ç²å–: 2364 å€«é£›...\n",
            "[300/1912] æ­£åœ¨ç²å–: 2365 æ˜†ç›ˆ...\n",
            "[301/1912] æ­£åœ¨ç²å–: 2367 ç‡¿è¯...\n",
            "[302/1912] æ­£åœ¨ç²å–: 2368 é‡‘åƒé›»...\n",
            "[303/1912] æ­£åœ¨ç²å–: 2369 è±ç”Ÿ...\n",
            "[304/1912] æ­£åœ¨ç²å–: 2371 å¤§åŒ...\n",
            "[305/1912] æ­£åœ¨ç²å–: 2373 éœ‡æ—¦è¡Œ...\n",
            "[306/1912] æ­£åœ¨ç²å–: 2374 ä½³èƒ½...\n",
            "[307/1912] æ­£åœ¨ç²å–: 2375 å‡±ç¾...\n",
            "[308/1912] æ­£åœ¨ç²å–: 2376 æŠ€å˜‰...\n",
            "[309/1912] æ­£åœ¨ç²å–: 2377 å¾®æ˜Ÿ...\n",
            "[310/1912] æ­£åœ¨ç²å–: 2379 ç‘æ˜±...\n",
            "[311/1912] æ­£åœ¨ç²å–: 2380 è™¹å…‰...\n",
            "[312/1912] æ­£åœ¨ç²å–: 2382 å»£é”...\n",
            "[313/1912] æ­£åœ¨ç²å–: 2383 å°å…‰é›»...\n",
            "[314/1912] æ­£åœ¨ç²å–: 2385 ç¾¤å…‰...\n",
            "[315/1912] æ­£åœ¨ç²å–: 2387 ç²¾å…ƒ...\n",
            "[316/1912] æ­£åœ¨ç²å–: 2388 å¨ç››...\n",
            "[317/1912] æ­£åœ¨ç²å–: 2390 äº‘è¾°...\n",
            "[318/1912] æ­£åœ¨ç²å–: 2392 æ­£å´´...\n",
            "[319/1912] æ­£åœ¨ç²å–: 2393 å„„å…‰...\n",
            "[320/1912] æ­£åœ¨ç²å–: 2395 ç ”è¯...\n",
            "[321/1912] æ­£åœ¨ç²å–: 2397 å‹é€š...\n",
            "[322/1912] æ­£åœ¨ç²å–: 2399 æ˜ æ³°...\n",
            "[323/1912] æ­£åœ¨ç²å–: 2401 å‡Œé™½...\n",
            "[324/1912] æ­£åœ¨ç²å–: 2402 æ¯…å˜‰...\n",
            "[325/1912] æ­£åœ¨ç²å–: 2404 æ¼¢å”...\n",
            "[326/1912] æ­£åœ¨ç²å–: 2405 è¼”ä¿¡...\n",
            "[327/1912] æ­£åœ¨ç²å–: 2406 åœ‹ç¢©...\n",
            "[328/1912] æ­£åœ¨ç²å–: 2408 å—äºç§‘...\n",
            "[329/1912] æ­£åœ¨ç²å–: 2409 å‹é”...\n",
            "[330/1912] æ­£åœ¨ç²å–: 2412 ä¸­è¯é›»...\n",
            "[331/1912] æ­£åœ¨ç²å–: 2413 ç’°ç§‘...\n",
            "[332/1912] æ­£åœ¨ç²å–: 2414 ç²¾æŠ€...\n",
            "[333/1912] æ­£åœ¨ç²å–: 2415 éŒ©æ–°...\n",
            "[334/1912] æ­£åœ¨ç²å–: 2417 åœ“å‰›...\n",
            "[335/1912] æ­£åœ¨ç²å–: 2419 ä»²ç¦...\n",
            "[336/1912] æ­£åœ¨ç²å–: 2420 æ–°å·¨...\n",
            "[337/1912] æ­£åœ¨ç²å–: 2421 å»ºæº–...\n",
            "[338/1912] æ­£åœ¨ç²å–: 2423 å›ºç·¯...\n",
            "[339/1912] æ­£åœ¨ç²å–: 2424 éš´è¯...\n",
            "[340/1912] æ­£åœ¨ç²å–: 2425 æ‰¿å•Ÿ...\n",
            "[341/1912] æ­£åœ¨ç²å–: 2426 é¼å…ƒ...\n",
            "[342/1912] æ­£åœ¨ç²å–: 2427 ä¸‰å•†é›»...\n",
            "[343/1912] æ­£åœ¨ç²å–: 2428 èˆˆå‹¤...\n",
            "[344/1912] æ­£åœ¨ç²å–: 2429 éŠ˜æ—ºç§‘...\n",
            "[345/1912] æ­£åœ¨ç²å–: 2430 ç‡¦å¤...\n",
            "[346/1912] æ­£åœ¨ç²å–: 2431 è¯æ˜Œ...\n",
            "[347/1912] æ­£åœ¨ç²å–: 2433 äº’ç››é›»...\n",
            "[348/1912] æ­£åœ¨ç²å–: 2434 çµ±æ‡‹...\n",
            "[349/1912] æ­£åœ¨ç²å–: 2436 å‰è©®é›»...\n",
            "[350/1912] æ­£åœ¨ç²å–: 2438 ç¿”è€€...\n",
            "[351/1912] æ­£åœ¨ç²å–: 2439 ç¾å¾‹...\n",
            "[352/1912] æ­£åœ¨ç²å–: 2440 å¤ªç©ºæ¢­...\n",
            "[353/1912] æ­£åœ¨ç²å–: 2441 è¶…è±...\n",
            "[354/1912] æ­£åœ¨ç²å–: 2442 æ–°ç¾é½Š...\n",
            "[355/1912] æ­£åœ¨ç²å–: 2444 å…†å‹...\n",
            "[356/1912] æ­£åœ¨ç²å–: 2449 äº¬å…ƒé›»å­...\n",
            "[357/1912] æ­£åœ¨ç²å–: 2450 ç¥è…¦...\n",
            "[358/1912] æ­£åœ¨ç²å–: 2451 å‰µè¦‹...\n",
            "[359/1912] æ­£åœ¨ç²å–: 2453 å‡Œç¾¤...\n",
            "[360/1912] æ­£åœ¨ç²å–: 2454 è¯ç™¼ç§‘...\n",
            "[361/1912] æ­£åœ¨ç²å–: 2455 å…¨æ–°...\n",
            "[362/1912] æ­£åœ¨ç²å–: 2457 é£›å®...\n",
            "[363/1912] æ­£åœ¨ç²å–: 2458 ç¾©éš†...\n",
            "[364/1912] æ­£åœ¨ç²å–: 2459 æ•¦å‰...\n",
            "[365/1912] æ­£åœ¨ç²å–: 2460 å»ºé€š...\n",
            "[366/1912] æ­£åœ¨ç²å–: 2461 å…‰ç¾¤é›·...\n",
            "[367/1912] æ­£åœ¨ç²å–: 2462 è‰¯å¾—é›»...\n",
            "[368/1912] æ­£åœ¨ç²å–: 2464 ç›Ÿç«‹...\n",
            "[369/1912] æ­£åœ¨ç²å–: 2465 éº—è‡º...\n",
            "[370/1912] æ­£åœ¨ç²å–: 2466 å† è¥¿é›»...\n",
            "[371/1912] æ­£åœ¨ç²å–: 2467 å¿—è–...\n",
            "[372/1912] æ­£åœ¨ç²å–: 2468 è¯ç¶“...\n",
            "[373/1912] æ­£åœ¨ç²å–: 2471 è³‡é€š...\n",
            "[374/1912] æ­£åœ¨ç²å–: 2472 ç«‹éš†é›»...\n",
            "[375/1912] æ­£åœ¨ç²å–: 2474 å¯æˆ...\n",
            "[376/1912] æ­£åœ¨ç²å–: 2476 é‰…ç¥¥...\n",
            "[377/1912] æ­£åœ¨ç²å–: 2477 ç¾éš†é›»...\n",
            "[378/1912] æ­£åœ¨ç²å–: 2478 å¤§æ¯…...\n",
            "[379/1912] æ­£åœ¨ç²å–: 2480 æ•¦é™½ç§‘...\n",
            "[380/1912] æ­£åœ¨ç²å–: 2481 å¼·èŒ‚...\n",
            "[381/1912] æ­£åœ¨ç²å–: 2482 é€£å®‡...\n",
            "[382/1912] æ­£åœ¨ç²å–: 2483 ç™¾å®¹...\n",
            "[383/1912] æ­£åœ¨ç²å–: 2484 å¸Œè¯...\n",
            "[384/1912] æ­£åœ¨ç²å–: 2485 å…†èµ«...\n",
            "[385/1912] æ­£åœ¨ç²å–: 2486 ä¸€è©®...\n",
            "[386/1912] æ­£åœ¨ç²å–: 2488 æ¼¢å¹³...\n",
            "[387/1912] æ­£åœ¨ç²å–: 2489 ç‘è»’...\n",
            "[388/1912] æ­£åœ¨ç²å–: 2491 å‰ç¥¥å…¨...\n",
            "[389/1912] æ­£åœ¨ç²å–: 2492 è¯æ–°ç§‘...\n",
            "[390/1912] æ­£åœ¨ç²å–: 2493 æšåš...\n",
            "[391/1912] æ­£åœ¨ç²å–: 2495 æ™®å®‰...\n",
            "[392/1912] æ­£åœ¨ç²å–: 2496 å“è¶Š...\n",
            "[393/1912] æ­£åœ¨ç²å–: 2497 æ€¡åˆ©é›»...\n",
            "[394/1912] æ­£åœ¨ç²å–: 2498 å®é”é›»...\n",
            "[395/1912] æ­£åœ¨ç²å–: 2501 åœ‹å»º...\n",
            "[396/1912] æ­£åœ¨ç²å–: 2504 åœ‹ç”¢...\n",
            "[397/1912] æ­£åœ¨ç²å–: 2505 åœ‹æš...\n",
            "[398/1912] æ­£åœ¨ç²å–: 2506 å¤ªè¨­...\n",
            "[399/1912] æ­£åœ¨ç²å–: 2509 å…¨å¤å»º...\n",
            "[400/1912] æ­£åœ¨ç²å–: 2511 å¤ªå­...\n",
            "[401/1912] æ­£åœ¨ç²å–: 2514 é¾é‚¦...\n",
            "[402/1912] æ­£åœ¨ç²å–: 2515 ä¸­å·¥...\n",
            "[403/1912] æ­£åœ¨ç²å–: 2516 æ–°å»º...\n",
            "[404/1912] æ­£åœ¨ç²å–: 2520 å† å¾·...\n",
            "[405/1912] æ­£åœ¨ç²å–: 2524 äº¬åŸ...\n",
            "[406/1912] æ­£åœ¨ç²å–: 2527 å®ç’Ÿ...\n",
            "[407/1912] æ­£åœ¨ç²å–: 2528 çš‡æ™®...\n",
            "[408/1912] æ­£åœ¨ç²å–: 2530 è¯å»º...\n",
            "[409/1912] æ­£åœ¨ç²å–: 2534 å®ç››...\n",
            "[410/1912] æ­£åœ¨ç²å–: 2535 é”æ¬£å·¥...\n",
            "[411/1912] æ­£åœ¨ç²å–: 2536 å®æ™®...\n",
            "[412/1912] æ­£åœ¨ç²å–: 2537 è¯ä¸Šç™¼...\n",
            "[413/1912] æ­£åœ¨ç²å–: 2538 åŸºæ³°...\n",
            "[414/1912] æ­£åœ¨ç²å–: 2539 æ«»èŠ±å»º...\n",
            "[415/1912] æ­£åœ¨ç²å–: 2540 æ„›å±±æ—...\n",
            "[416/1912] æ­£åœ¨ç²å–: 2542 èˆˆå¯Œç™¼...\n",
            "[417/1912] æ­£åœ¨ç²å–: 2543 çš‡æ˜Œ...\n",
            "[418/1912] æ­£åœ¨ç²å–: 2545 çš‡ç¿”...\n",
            "[419/1912] æ­£åœ¨ç²å–: 2546 æ ¹åŸº...\n",
            "[420/1912] æ­£åœ¨ç²å–: 2547 æ—¥å‹ç”Ÿ...\n",
            "[421/1912] æ­£åœ¨ç²å–: 2548 è¯å›º...\n",
            "[422/1912] æ­£åœ¨ç²å–: 2597 æ½¤å¼˜...\n",
            "[423/1912] æ­£åœ¨ç²å–: 2601 ç›Šèˆª...\n",
            "[424/1912] æ­£åœ¨ç²å–: 2603 é•·æ¦®...\n",
            "[425/1912] æ­£åœ¨ç²å–: 2605 æ–°èˆˆ...\n",
            "[426/1912] æ­£åœ¨ç²å–: 2606 è£•æ°‘...\n",
            "[427/1912] æ­£åœ¨ç²å–: 2607 æ¦®é‹...\n",
            "[428/1912] æ­£åœ¨ç²å–: 2608 å˜‰é‡Œå¤§æ¦®...\n",
            "[429/1912] æ­£åœ¨ç²å–: 2609 é™½æ˜...\n",
            "[430/1912] æ­£åœ¨ç²å–: 2610 è¯èˆª...\n",
            "[431/1912] æ­£åœ¨ç²å–: 2611 å¿—ä¿¡...\n",
            "[432/1912] æ­£åœ¨ç²å–: 2612 ä¸­èˆª...\n",
            "[433/1912] æ­£åœ¨ç²å–: 2613 ä¸­æ«ƒ...\n",
            "[434/1912] æ­£åœ¨ç²å–: 2614 æ±æ£®...\n",
            "[435/1912] æ­£åœ¨ç²å–: 2615 è¬æµ·...\n",
            "[436/1912] æ­£åœ¨ç²å–: 2616 å±±éš†...\n",
            "[437/1912] æ­£åœ¨ç²å–: 2617 å°èˆª...\n",
            "[438/1912] æ­£åœ¨ç²å–: 2618 é•·æ¦®èˆª...\n",
            "[439/1912] æ­£åœ¨ç²å–: 2630 äºèˆª...\n",
            "[440/1912] æ­£åœ¨ç²å–: 2633 å°ç£é«˜éµ...\n",
            "[441/1912] æ­£åœ¨ç²å–: 2634 æ¼¢ç¿”...\n",
            "[442/1912] æ­£åœ¨ç²å–: 2636 å°é©Šæ§è‚¡...\n",
            "[443/1912] æ­£åœ¨ç²å–: 2637 æ…§æ´‹-KY...\n",
            "[444/1912] æ­£åœ¨ç²å–: 2642 å®…é…é€š...\n",
            "[445/1912] æ­£åœ¨ç²å–: 2645 é•·æ¦®èˆªå¤ª...\n",
            "[446/1912] æ­£åœ¨ç²å–: 2646 æ˜Ÿå®‡èˆªç©º...\n",
            "[447/1912] æ­£åœ¨ç²å–: 2701 è¬ä¼...\n",
            "[448/1912] æ­£åœ¨ç²å–: 2702 è¯åœ’...\n",
            "[449/1912] æ­£åœ¨ç²å–: 2704 åœ‹è³“...\n",
            "[450/1912] æ­£åœ¨ç²å–: 2705 å…­ç¦...\n",
            "[451/1912] æ­£åœ¨ç²å–: 2706 ç¬¬ä¸€åº—...\n",
            "[452/1912] æ­£åœ¨ç²å–: 2707 æ™¶è¯...\n",
            "[453/1912] æ­£åœ¨ç²å–: 2712 é é›„ä¾†...\n",
            "[454/1912] æ­£åœ¨ç²å–: 2722 å¤éƒ½...\n",
            "[455/1912] æ­£åœ¨ç²å–: 2723 ç¾é£Ÿ-KY...\n",
            "[456/1912] æ­£åœ¨ç²å–: 2727 ç‹å“...\n",
            "[457/1912] æ­£åœ¨ç²å–: 2731 é›„ç…...\n",
            "[458/1912] æ­£åœ¨ç²å–: 2739 å¯’èˆ...\n",
            "[459/1912] æ­£åœ¨ç²å–: 2748 é›²å“...\n",
            "[460/1912] æ­£åœ¨ç²å–: 2753 å…«æ–¹é›²é›†...\n",
            "[461/1912] æ­£åœ¨ç²å–: 2762 ä¸–ç•Œå¥èº«-KY...\n",
            "[462/1912] æ­£åœ¨ç²å–: 2801 å½°éŠ€...\n",
            "[463/1912] æ­£åœ¨ç²å–: 2809 äº¬åŸéŠ€...\n",
            "[464/1912] æ­£åœ¨ç²å–: 2812 å°ä¸­éŠ€...\n",
            "[465/1912] æ­£åœ¨ç²å–: 2816 æ—ºæ—ºä¿...\n",
            "[466/1912] æ­£åœ¨ç²å–: 2820 è¯ç¥¨...\n",
            "[467/1912] æ­£åœ¨ç²å–: 2832 å°ç”¢...\n",
            "[468/1912] æ­£åœ¨ç²å–: 2834 è‡ºä¼éŠ€...\n",
            "[469/1912] æ­£åœ¨ç²å–: 2836 é«˜é›„éŠ€...\n",
            "[470/1912] æ­£åœ¨ç²å–: 2838 è¯é‚¦éŠ€...\n",
            "[471/1912] æ­£åœ¨ç²å–: 2845 é æ±éŠ€...\n",
            "[472/1912] æ­£åœ¨ç²å–: 2849 å®‰æ³°éŠ€...\n",
            "[473/1912] æ­£åœ¨ç²å–: 2850 æ–°ç”¢...\n",
            "[474/1912] æ­£åœ¨ç²å–: 2851 ä¸­å†ä¿...\n",
            "[475/1912] æ­£åœ¨ç²å–: 2852 ç¬¬ä¸€ä¿...\n",
            "[476/1912] æ­£åœ¨ç²å–: 2855 çµ±ä¸€è­‰...\n",
            "[477/1912] æ­£åœ¨ç²å–: 2867 ä¸‰å•†å£½...\n",
            "[478/1912] æ­£åœ¨ç²å–: 2880 è¯å—é‡‘...\n",
            "[479/1912] æ­£åœ¨ç²å–: 2881 å¯Œé‚¦é‡‘...\n",
            "[480/1912] æ­£åœ¨ç²å–: 2882 åœ‹æ³°é‡‘...\n",
            "[481/1912] æ­£åœ¨ç²å–: 2883 å‡±åŸºé‡‘...\n",
            "[482/1912] æ­£åœ¨ç²å–: 2884 ç‰å±±é‡‘...\n",
            "[483/1912] æ­£åœ¨ç²å–: 2885 å…ƒå¤§é‡‘...\n",
            "[484/1912] æ­£åœ¨ç²å–: 2886 å…†è±é‡‘...\n",
            "[485/1912] æ­£åœ¨ç²å–: 2887 å°æ–°é‡‘...\n",
            "[486/1912] æ­£åœ¨ç²å–: 2889 åœ‹ç¥¨é‡‘...\n",
            "[487/1912] æ­£åœ¨ç²å–: 2890 æ°¸è±é‡‘...\n",
            "[488/1912] æ­£åœ¨ç²å–: 2891 ä¸­ä¿¡é‡‘...\n",
            "[489/1912] æ­£åœ¨ç²å–: 2892 ç¬¬ä¸€é‡‘...\n",
            "[490/1912] æ­£åœ¨ç²å–: 2897 ç‹é“éŠ€è¡Œ...\n",
            "[491/1912] æ­£åœ¨ç²å–: 2901 æ¬£æ¬£...\n",
            "[492/1912] æ­£åœ¨ç²å–: 2903 é ç™¾...\n",
            "[493/1912] æ­£åœ¨ç²å–: 2904 åŒ¯åƒ‘...\n",
            "[494/1912] æ­£åœ¨ç²å–: 2905 ä¸‰å•†...\n",
            "[495/1912] æ­£åœ¨ç²å–: 2906 é«˜æ—...\n",
            "[496/1912] æ­£åœ¨ç²å–: 2908 ç‰¹åŠ›...\n",
            "[497/1912] æ­£åœ¨ç²å–: 2910 çµ±é ˜...\n",
            "[498/1912] æ­£åœ¨ç²å–: 2911 éº—å¬°æˆ¿...\n",
            "[499/1912] æ­£åœ¨ç²å–: 2912 çµ±ä¸€è¶…...\n",
            "[500/1912] æ­£åœ¨ç²å–: 2913 è¾²æ—...\n",
            "[501/1912] æ­£åœ¨ç²å–: 2915 æ½¤æ³°å…¨...\n",
            "[502/1912] æ­£åœ¨ç²å–: 2923 é¼å›º-KY...\n",
            "[503/1912] æ­£åœ¨ç²å–: 2929 æ·˜å¸-KY...\n",
            "[504/1912] æ­£åœ¨ç²å–: 2939 æ°¸é‚‘-KY...\n",
            "[505/1912] æ­£åœ¨ç²å–: 3002 æ­æ ¼...\n",
            "[506/1912] æ­£åœ¨ç²å–: 3003 å¥å’Œèˆˆ...\n",
            "[507/1912] æ­£åœ¨ç²å–: 3004 è±é”ç§‘...\n",
            "[508/1912] æ­£åœ¨ç²å–: 3005 ç¥åŸº...\n",
            "[509/1912] æ­£åœ¨ç²å–: 3006 æ™¶è±ªç§‘...\n",
            "[510/1912] æ­£åœ¨ç²å–: 3008 å¤§ç«‹å…‰...\n",
            "[511/1912] æ­£åœ¨ç²å–: 3010 è¯ç«‹...\n",
            "[512/1912] æ­£åœ¨ç²å–: 3011 ä»Šçš“...\n",
            "[513/1912] æ­£åœ¨ç²å–: 3013 æ™ŸéŠ˜é›»...\n",
            "[514/1912] æ­£åœ¨ç²å–: 3014 è¯é™½...\n",
            "[515/1912] æ­£åœ¨ç²å–: 3015 å…¨æ¼¢...\n",
            "[516/1912] æ­£åœ¨ç²å–: 3016 å˜‰æ™¶...\n",
            "[517/1912] æ­£åœ¨ç²å–: 3017 å¥‡é‹...\n",
            "[518/1912] æ­£åœ¨ç²å–: 3018 éš†éŠ˜ç¶ èƒ½...\n",
            "[519/1912] æ­£åœ¨ç²å–: 3019 äºå…‰...\n",
            "[520/1912] æ­£åœ¨ç²å–: 3021 é´»å...\n",
            "[521/1912] æ­£åœ¨ç²å–: 3022 å¨å¼·é›»...\n",
            "[522/1912] æ­£åœ¨ç²å–: 3023 ä¿¡é‚¦...\n",
            "[523/1912] æ­£åœ¨ç²å–: 3024 æ†¶è²...\n",
            "[524/1912] æ­£åœ¨ç²å–: 3025 æ˜Ÿé€š...\n",
            "[525/1912] æ­£åœ¨ç²å–: 3026 ç¦¾ä¼¸å ‚...\n",
            "[526/1912] æ­£åœ¨ç²å–: 3027 ç››é”...\n",
            "[527/1912] æ­£åœ¨ç²å–: 3028 å¢ä½ å¼·...\n",
            "[528/1912] æ­£åœ¨ç²å–: 3029 é›¶å£¹...\n",
            "[529/1912] æ­£åœ¨ç²å–: 3030 å¾·å¾‹...\n",
            "[530/1912] æ­£åœ¨ç²å–: 3031 ä½°é´»...\n",
            "[531/1912] æ­£åœ¨ç²å–: 3032 å‰è¨“...\n",
            "[532/1912] æ­£åœ¨ç²å–: 3033 å¨å¥...\n",
            "[533/1912] æ­£åœ¨ç²å–: 3034 è¯è© ...\n",
            "[534/1912] æ­£åœ¨ç²å–: 3035 æ™ºåŸ...\n",
            "[535/1912] æ­£åœ¨ç²å–: 3036 æ–‡æ›„...\n",
            "[536/1912] æ­£åœ¨ç²å–: 3037 æ¬£èˆˆ...\n",
            "[537/1912] æ­£åœ¨ç²å–: 3038 å…¨å°...\n",
            "[538/1912] æ­£åœ¨ç²å–: 3040 é è¦‹...\n",
            "[539/1912] æ­£åœ¨ç²å–: 3041 æšæ™º...\n",
            "[540/1912] æ­£åœ¨ç²å–: 3042 æ™¶æŠ€...\n",
            "[541/1912] æ­£åœ¨ç²å–: 3043 ç§‘é¢¨...\n",
            "[542/1912] æ­£åœ¨ç²å–: 3044 å¥é¼...\n",
            "[543/1912] æ­£åœ¨ç²å–: 3045 å°ç£å¤§...\n",
            "[544/1912] æ­£åœ¨ç²å–: 3046 å»ºï¿½ï¿½...\n",
            "[545/1912] æ­£åœ¨ç²å–: 3047 è¨ŠèˆŸ...\n",
            "[546/1912] æ­£åœ¨ç²å–: 3048 ç›Šç™»...\n",
            "[547/1912] æ­£åœ¨ç²å–: 3049 ç²¾é‡‘...\n",
            "[548/1912] æ­£åœ¨ç²å–: 3050 éˆºå¾·...\n",
            "[549/1912] æ­£åœ¨ç²å–: 3051 åŠ›ç‰¹...\n",
            "[550/1912] æ­£åœ¨ç²å–: 3052 å¤†å…¸...\n",
            "[551/1912] æ­£åœ¨ç²å–: 3054 ç«‹è¬åˆ©...\n",
            "[552/1912] æ­£åœ¨ç²å–: 3055 è”šè¯ç§‘...\n",
            "[553/1912] æ­£åœ¨ç²å–: 3056 å¯Œè¯æ–°...\n",
            "[554/1912] æ­£åœ¨ç²å–: 3057 å–¬é¼...\n",
            "[555/1912] æ­£åœ¨ç²å–: 3058 ç«‹å¾·...\n",
            "[556/1912] æ­£åœ¨ç²å–: 3059 è¯æ™¶ç§‘...\n",
            "[557/1912] æ­£åœ¨ç²å–: 3060 éŠ˜ç•°...\n",
            "[558/1912] æ­£åœ¨ç²å–: 3062 å»ºæ¼¢...\n",
            "[559/1912] æ­£åœ¨ç²å–: 3090 æ—¥é›»è²¿...\n",
            "[560/1912] æ­£åœ¨ç²å–: 3092 é´»ç¢©...\n",
            "[561/1912] æ­£åœ¨ç²å–: 3094 è¯å‚‘...\n",
            "[562/1912] æ­£åœ¨ç²å–: 3130 ä¸€é›¶å››...\n",
            "[563/1912] æ­£åœ¨ç²å–: 3135 å‡Œèˆª...\n",
            "[564/1912] æ­£åœ¨ç²å–: 3138 è€€ç™»...\n",
            "[565/1912] æ­£åœ¨ç²å–: 3149 æ­£é”...\n",
            "[566/1912] æ­£åœ¨ç²å–: 3164 æ™¯å²³...\n",
            "[567/1912] æ­£åœ¨ç²å–: 3167 å¤§é‡...\n",
            "[568/1912] æ­£åœ¨ç²å–: 3168 çœ¾ç¦ç§‘...\n",
            "[569/1912] æ­£åœ¨ç²å–: 3189 æ™¯ç¢©...\n",
            "[570/1912] æ­£åœ¨ç²å–: 3209 å…¨ç§‘...\n",
            "[571/1912] æ­£åœ¨ç²å–: 3229 æ™Ÿéˆ¦...\n",
            "[572/1912] æ­£åœ¨ç²å–: 3231 ç·¯å‰µ...\n",
            "[573/1912] æ­£åœ¨ç²å–: 3257 è™¹å† é›»...\n",
            "[574/1912] æ­£åœ¨ç²å–: 3266 æ˜‡é™½...\n",
            "[575/1912] æ­£åœ¨ç²å–: 3296 å‹å¾·...\n",
            "[576/1912] æ­£åœ¨ç²å–: 3305 æ˜‡è²¿...\n",
            "[577/1912] æ­£åœ¨ç²å–: 3308 è¯å¾·...\n",
            "[578/1912] æ­£åœ¨ç²å–: 3311 é–æš‰...\n",
            "[579/1912] æ­£åœ¨ç²å–: 3312 å¼˜æ†¶è‚¡...\n",
            "[580/1912] æ­£åœ¨ç²å–: 3321 åŒæ³°...\n",
            "[581/1912] æ­£åœ¨ç²å–: 3338 æ³°ç¢©...\n",
            "[582/1912] æ­£åœ¨ç²å–: 3346 éº—æ¸…...\n",
            "[583/1912] æ­£åœ¨ç²å–: 3356 å¥‡å¶...\n",
            "[584/1912] æ­£åœ¨ç²å–: 3376 æ–°æ—¥èˆˆ...\n",
            "[585/1912] æ­£åœ¨ç²å–: 3380 æ˜æ³°...\n",
            "[586/1912] æ­£åœ¨ç²å–: 3406 ç‰æ™¶å…‰...\n",
            "[587/1912] æ­£åœ¨ç²å–: 3413 äº¬é¼...\n",
            "[588/1912] æ­£åœ¨ç²å–: 3416 èç¨‹é›»...\n",
            "[589/1912] æ­£åœ¨ç²å–: 3419 è­è£•...\n",
            "[590/1912] æ­£åœ¨ç²å–: 3432 å°ç«¯...\n",
            "[591/1912] æ­£åœ¨ç²å–: 3437 æ¦®å‰µ...\n",
            "[592/1912] æ­£åœ¨ç²å–: 3443 å‰µæ„...\n",
            "[593/1912] æ­£åœ¨ç²å–: 3447 å±•é”...\n",
            "[594/1912] æ­£åœ¨ç²å–: 3450 è¯éˆ...\n",
            "[595/1912] æ­£åœ¨ç²å–: 3454 æ™¶ç¿...\n",
            "[596/1912] æ­£åœ¨ç²å–: 3481 ç¾¤å‰µ...\n",
            "[597/1912] æ­£åœ¨ç²å–: 3494 èª ç ”...\n",
            "[598/1912] æ­£åœ¨ç²å–: 3501 ç¶­ç†¹...\n",
            "[599/1912] æ­£åœ¨ç²å–: 3504 æšæ˜å…‰...\n",
            "[600/1912] æ­£åœ¨ç²å–: 3515 è¯æ“...\n",
            "[601/1912] æ­£åœ¨ç²å–: 3518 æŸé¨°...\n",
            "[602/1912] æ­£åœ¨ç²å–: 3528 å®‰é¦³...\n",
            "[603/1912] æ­£åœ¨ç²å–: 3530 æ™¶ç›¸å…‰...\n",
            "[604/1912] æ­£åœ¨ç²å–: 3532 å°å‹ç§‘...\n",
            "[605/1912] æ­£åœ¨ç²å–: 3533 å˜‰æ¾¤...\n",
            "[606/1912] æ­£åœ¨ç²å–: 3535 æ™¶å½©ç§‘...\n",
            "[607/1912] æ­£åœ¨ç²å–: 3543 å·å·§...\n",
            "[608/1912] æ­£åœ¨ç²å–: 3545 æ•¦æ³°...\n",
            "[609/1912] æ­£åœ¨ç²å–: 3550 è¯ç©...\n",
            "[610/1912] æ­£åœ¨ç²å–: 3557 å˜‰å¨...\n",
            "[611/1912] æ­£åœ¨ç²å–: 3563 ç‰§å¾·...\n",
            "[612/1912] æ­£åœ¨ç²å–: 3576 è¯åˆå†ç”Ÿ...\n",
            "[613/1912] æ­£åœ¨ç²å–: 3583 è¾›è€˜...\n",
            "[614/1912] æ­£åœ¨ç²å–: 3588 é€šå˜‰...\n",
            "[615/1912] æ­£åœ¨ç²å–: 3591 è‰¾ç¬›æ£®...\n",
            "[616/1912] æ­£åœ¨ç²å–: 3592 ç‘é¼...\n",
            "[617/1912] æ­£åœ¨ç²å–: 3593 åŠ›éŠ˜...\n",
            "[618/1912] æ­£åœ¨ç²å–: 3596 æ™ºæ˜“...\n",
            "[619/1912] æ­£åœ¨ç²å–: 3605 å®è‡´...\n",
            "[620/1912] æ­£åœ¨ç²å–: 3607 è°·å´§...\n",
            "[621/1912] æ­£åœ¨ç²å–: 3617 ç¢©å¤©...\n",
            "[622/1912] æ­£åœ¨ç²å–: 3622 æ´‹è¯...\n",
            "[623/1912] æ­£åœ¨ç²å–: 3645 é”é‚...\n",
            "[624/1912] æ­£åœ¨ç²å–: 3652 ç²¾è¯...\n",
            "[625/1912] æ­£åœ¨ç²å–: 3653 å¥ç­–...\n",
            "[626/1912] æ­£åœ¨ç²å–: 3661 ä¸–èŠ¯-KY...\n",
            "[627/1912] æ­£åœ¨ç²å–: 3665 è²¿è¯-KY...\n",
            "[628/1912] æ­£åœ¨ç²å–: 3669 åœ“å±•...\n",
            "[629/1912] æ­£åœ¨ç²å–: 3673 TPK-KY...\n",
            "[630/1912] æ­£åœ¨ç²å–: 3679 æ–°è‡³é™...\n",
            "[631/1912] æ­£åœ¨ç²å–: 3686 é”èƒ½...\n",
            "[632/1912] æ­£åœ¨ç²å–: 3694 æµ·è¯...\n",
            "[633/1912] æ­£åœ¨ç²å–: 3701 å¤§çœ¾æ§...\n",
            "[634/1912] æ­£åœ¨ç²å–: 3702 å¤§è¯å¤§...\n",
            "[635/1912] æ­£åœ¨ç²å–: 3703 æ¬£é™¸...\n",
            "[636/1912] æ­£åœ¨ç²å–: 3704 åˆå‹¤æ§...\n",
            "[637/1912] æ­£åœ¨ç²å–: 3705 æ°¸ä¿¡...\n",
            "[638/1912] æ­£åœ¨ç²å–: 3706 ç¥é”...\n",
            "[639/1912] æ­£åœ¨ç²å–: 3708 ä¸Šç·¯æŠ•æ§...\n",
            "[640/1912] æ­£åœ¨ç²å–: 3711 æ—¥æœˆå…‰æŠ•æ§...\n",
            "[641/1912] æ­£åœ¨ç²å–: 3712 æ°¸å´´æŠ•æ§...\n",
            "[642/1912] æ­£åœ¨ç²å–: 3714 å¯Œé‡‡...\n",
            "[643/1912] æ­£åœ¨ç²å–: 3715 å®šç©æŠ•æ§...\n",
            "[644/1912] æ­£åœ¨ç²å–: 3716 ä¸­åŒ–æ§è‚¡...\n",
            "[645/1912] æ­£åœ¨ç²å–: 4104 ä½³é†«...\n",
            "[646/1912] æ­£åœ¨ç²å–: 4106 é›ƒåš...\n",
            "[647/1912] æ­£åœ¨ç²å–: 4108 æ‡·ç‰¹...\n",
            "[648/1912] æ­£åœ¨ç²å–: 4119 æ—­å¯Œ...\n",
            "[649/1912] æ­£åœ¨ç²å–: 4133 äºè«¾æ³•...\n",
            "[650/1912] æ­£åœ¨ç²å–: 4137 éº—è±-KY...\n",
            "[651/1912] æ­£åœ¨ç²å–: 4142 åœ‹å…‰ç”Ÿ...\n",
            "[652/1912] æ­£åœ¨ç²å–: 4148 å…¨å®‡ç”ŸæŠ€-KY...\n",
            "[653/1912] æ­£åœ¨ç²å–: 4155 è¨Šæ˜ ...\n",
            "[654/1912] æ­£åœ¨ç²å–: 4164 æ‰¿æ¥­é†«...\n",
            "[655/1912] æ­£åœ¨ç²å–: 4190 ä½ç™»-KY...\n",
            "[656/1912] æ­£åœ¨ç²å–: 4306 ç‚æ´²...\n",
            "[657/1912] æ­£åœ¨ç²å–: 4414 å¦‚èˆˆ...\n",
            "[658/1912] æ­£åœ¨ç²å–: 4426 åˆ©å‹¤...\n",
            "[659/1912] æ­£åœ¨ç²å–: 4438 å»£è¶Š...\n",
            "[660/1912] æ­£åœ¨ç²å–: 4439 å† æ˜Ÿ-KY...\n",
            "[661/1912] æ­£åœ¨ç²å–: 4440 å®œæ–°å¯¦æ¥­...\n",
            "[662/1912] æ­£åœ¨ç²å–: 4526 æ±å°...\n",
            "[663/1912] æ­£åœ¨ç²å–: 4532 ç‘æ™º...\n",
            "[664/1912] æ­£åœ¨ç²å–: 4536 æ‹“å‡±...\n",
            "[665/1912] æ­£åœ¨ç²å–: 4540 å…¨çƒå‚³å‹•...\n",
            "[666/1912] æ­£åœ¨ç²å–: 4545 éŠ˜éˆº...\n",
            "[667/1912] æ­£åœ¨ç²å–: 4551 æ™ºä¼¸ç§‘...\n",
            "[668/1912] æ­£åœ¨ç²å–: 4552 åŠ›é”-KY...\n",
            "[669/1912] æ­£åœ¨ç²å–: 4555 æ°£ç«‹...\n",
            "[670/1912] æ­£åœ¨ç²å–: 4557 æ°¸æ–°-KY...\n",
            "[671/1912] æ­£åœ¨ç²å–: 4560 å¼·ä¿¡-KY...\n",
            "[672/1912] æ­£åœ¨ç²å–: 4562 ç©æ¼¢...\n",
            "[673/1912] æ­£åœ¨ç²å–: 4564 å…ƒç¿...\n",
            "[674/1912] æ­£åœ¨ç²å–: 4566 æ™‚ç¢©å·¥æ¥­...\n",
            "[675/1912] æ­£åœ¨ç²å–: 4569 å…­æ–¹ç§‘-KY...\n",
            "[676/1912] æ­£åœ¨ç²å–: 4571 éˆèˆˆ-KY...\n",
            "[677/1912] æ­£åœ¨ç²å–: 4572 é§é¾...\n",
            "[678/1912] æ­£åœ¨ç²å–: 4576 å¤§éŠ€å¾®ç³»çµ±...\n",
            "[679/1912] æ­£åœ¨ç²å–: 4581 å…‰éš†ç²¾å¯†-KY...\n",
            "[680/1912] æ­£åœ¨ç²å–: 4583 å°ç£ç²¾éŠ³...\n",
            "[681/1912] æ­£åœ¨ç²å–: 4588 ç–é¼é›»åŠ›...\n",
            "[682/1912] æ­£åœ¨ç²å–: 4720 å¾·æ·µ...\n",
            "[683/1912] æ­£åœ¨ç²å–: 4722 åœ‹ç²¾åŒ–...\n",
            "[684/1912] æ­£åœ¨ç²å–: 4736 æ³°åš...\n",
            "[685/1912] æ­£åœ¨ç²å–: 4737 è¯å»£...\n",
            "[686/1912] æ­£åœ¨ç²å–: 4739 åº·æ™®...\n",
            "[687/1912] æ­£åœ¨ç²å–: 4746 å°è€€...\n",
            "[688/1912] æ­£åœ¨ç²å–: 4755 ä¸‰ç¦åŒ–...\n",
            "[689/1912] æ­£åœ¨ç²å–: 4763 ææ–™*-KY...\n",
            "[690/1912] æ­£åœ¨ç²å–: 4764 é›™éµ...\n",
            "[691/1912] æ­£åœ¨ç²å–: 4766 å—å¯¶...\n",
            "[692/1912] æ­£åœ¨ç²å–: 4770 ä¸Šå“...\n",
            "[693/1912] æ­£åœ¨ç²å–: 4771 æœ›éš¼...\n",
            "[694/1912] æ­£åœ¨ç²å–: 4807 æ—¥æˆ-KY...\n",
            "[695/1912] æ­£åœ¨ç²å–: 4904 é å‚³...\n",
            "[696/1912] æ­£åœ¨ç²å–: 4906 æ­£æ–‡...\n",
            "[697/1912] æ­£åœ¨ç²å–: 4912 è¯å¾·æ§è‚¡-KY...\n",
            "[698/1912] æ­£åœ¨ç²å–: 4915 è‡´ä¼¸...\n",
            "[699/1912] æ­£åœ¨ç²å–: 4916 äº‹æ¬£ç§‘...\n",
            "[700/1912] æ­£åœ¨ç²å–: 4919 æ–°å”...\n",
            "[701/1912] æ­£åœ¨ç²å–: 4927 æ³°é¼-KY...\n",
            "[702/1912] æ­£åœ¨ç²å–: 4930 ç‡¦æ˜Ÿç¶²...\n",
            "[703/1912] æ­£åœ¨ç²å–: 4934 å¤ªæ¥µ...\n",
            "[704/1912] æ­£åœ¨ç²å–: 4935 èŒ‚æ—-KY...\n",
            "[705/1912] æ­£åœ¨ç²å–: 4938 å’Œç¢©...\n",
            "[706/1912] æ­£åœ¨ç²å–: 4942 å˜‰å½°...\n",
            "[707/1912] æ­£åœ¨ç²å–: 4943 åº·æ§-KY...\n",
            "[708/1912] æ­£åœ¨ç²å–: 4949 æœ‰æˆç²¾å¯†...\n",
            "[709/1912] æ­£åœ¨ç²å–: 4952 å‡Œé€š...\n",
            "[710/1912] æ­£åœ¨ç²å–: 4956 å…‰é‹...\n",
            "[711/1912] æ­£åœ¨ç²å–: 4958 è‡»é¼-KY...\n",
            "[712/1912] æ­£åœ¨ç²å–: 4960 èª ç¾æ...\n",
            "[713/1912] æ­£åœ¨ç²å–: 4961 å¤©éˆº...\n",
            "[714/1912] æ­£åœ¨ç²å–: 4967 åéŠ“...\n",
            "[715/1912] æ­£åœ¨ç²å–: 4968 ç«‹ç©...\n",
            "[716/1912] æ­£åœ¨ç²å–: 4976 ä½³å‡Œ...\n",
            "[717/1912] æ­£åœ¨ç²å–: 4977 çœ¾é”-KY...\n",
            "[718/1912] æ­£åœ¨ç²å–: 4989 æ¦®ç§‘...\n",
            "[719/1912] æ­£åœ¨ç²å–: 4994 å‚³å¥‡...\n",
            "[720/1912] æ­£åœ¨ç²å–: 4999 é‘«ç¦¾...\n",
            "[721/1912] æ­£åœ¨ç²å–: 5007 ä¸‰æ˜Ÿ...\n",
            "[722/1912] æ­£åœ¨ç²å–: 5203 è¨Šé€£...\n",
            "[723/1912] æ­£åœ¨ç²å–: 5215 ç§‘å˜‰-KY...\n",
            "[724/1912] æ­£åœ¨ç²å–: 5222 å…¨è¨Š...\n",
            "[725/1912] æ­£åœ¨ç²å–: 5225 æ±ç§‘-KY...\n",
            "[726/1912] æ­£åœ¨ç²å–: 5234 é”èˆˆææ–™...\n",
            "[727/1912] æ­£åœ¨ç²å–: 5243 ä¹™ç››-KY...\n",
            "[728/1912] æ­£åœ¨ç²å–: 5244 å¼˜å‡±...\n",
            "[729/1912] æ­£åœ¨ç²å–: 5258 è™¹å ¡...\n",
            "[730/1912] æ­£åœ¨ç²å–: 5269 ç¥¥ç¢©...\n",
            "[731/1912] æ­£åœ¨ç²å–: 5283 ç¦¾è¯ç¢©...\n",
            "[732/1912] æ­£åœ¨ç²å–: 5284 jpp-KY...\n",
            "[733/1912] æ­£åœ¨ç²å–: 5285 ç•Œéœ–...\n",
            "[734/1912] æ­£åœ¨ç²å–: 5288 è±ç¥¥-KY...\n",
            "[735/1912] æ­£åœ¨ç²å–: 5292 è¯æ‡‹...\n",
            "[736/1912] æ­£åœ¨ç²å–: 5306 æ¡‚ç›Ÿ...\n",
            "[737/1912] æ­£åœ¨ç²å–: 5388 ä¸­ç£Š...\n",
            "[738/1912] æ­£åœ¨ç²å–: 5434 å´‡è¶Š...\n",
            "[739/1912] æ­£åœ¨ç²å–: 5469 ç€šå®‡åš...\n",
            "[740/1912] æ­£åœ¨ç²å–: 5471 æ¾ç¿°...\n",
            "[741/1912] æ­£åœ¨ç²å–: 5484 æ…§å‹...\n",
            "[742/1912] æ­£åœ¨ç²å–: 5515 å»ºåœ‹...\n",
            "[743/1912] æ­£åœ¨ç²å–: 5519 éš†å¤§...\n",
            "[744/1912] æ­£åœ¨ç²å–: 5521 å·¥ä¿¡...\n",
            "[745/1912] æ­£åœ¨ç²å–: 5522 é é›„...\n",
            "[746/1912] æ­£åœ¨ç²å–: 5525 é †å¤©...\n",
            "[747/1912] æ­£åœ¨ç²å–: 5531 é„‰æ—...\n",
            "[748/1912] æ­£åœ¨ç²å–: 5533 çš‡é¼...\n",
            "[749/1912] æ­£åœ¨ç²å–: 5534 é•·è™¹...\n",
            "[750/1912] æ­£åœ¨ç²å–: 5538 æ±æ˜-KY...\n",
            "[751/1912] æ­£åœ¨ç²å–: 5546 æ°¸å›º-KY...\n",
            "[752/1912] æ­£åœ¨ç²å–: 5607 é é›„æ¸¯...\n",
            "[753/1912] æ­£åœ¨ç²å–: 5608 å››ç¶­èˆª...\n",
            "[754/1912] æ­£åœ¨ç²å–: 5706 é³³å‡°...\n",
            "[755/1912] æ­£åœ¨ç²å–: 5871 ä¸­ç§Ÿ-KY...\n",
            "[756/1912] æ­£åœ¨ç²å–: 5876 ä¸Šæµ·å•†éŠ€...\n",
            "[757/1912] æ­£åœ¨ç²å–: 5880 åˆåº«é‡‘...\n",
            "[758/1912] æ­£åœ¨ç²å–: 5906 å°å—-KY...\n",
            "[759/1912] æ­£åœ¨ç²å–: 5907 å¤§æ´‹-KY...\n",
            "[760/1912] æ­£åœ¨ç²å–: 6005 ç¾¤ç›Šè­‰...\n",
            "[761/1912] æ­£åœ¨ç²å–: 6024 ç¾¤ç›ŠæœŸ...\n",
            "[762/1912] æ­£åœ¨ç²å–: 6108 ç«¶åœ‹...\n",
            "[763/1912] æ­£åœ¨ç²å–: 6112 é‚é”ç‰¹...\n",
            "[764/1912] æ­£åœ¨ç²å–: 6115 é°å‹...\n",
            "[765/1912] æ­£åœ¨ç²å–: 6116 å½©æ™¶...\n",
            "[766/1912] æ­£åœ¨ç²å–: 6117 è¿å»£...\n",
            "[767/1912] æ­£åœ¨ç²å–: 6120 é”é‹...\n",
            "[768/1912] æ­£åœ¨ç²å–: 6128 ä¸Šç¦...\n",
            "[769/1912] æ­£åœ¨ç²å–: 6133 é‡‘æ©‹...\n",
            "[770/1912] æ­£åœ¨ç²å–: 6136 å¯Œçˆ¾ç‰¹...\n",
            "[771/1912] æ­£åœ¨ç²å–: 6139 äºç¿”...\n",
            "[772/1912] æ­£åœ¨ç²å–: 6141 æŸæ‰¿...\n",
            "[773/1912] æ­£åœ¨ç²å–: 6142 å‹å‹...\n",
            "[774/1912] æ­£åœ¨ç²å–: 6152 ç™¾ä¸€...\n",
            "[775/1912] æ­£åœ¨ç²å–: 6153 å˜‰è¯ç›Š...\n",
            "[776/1912] æ­£åœ¨ç²å–: 6155 éˆå¯¶...\n",
            "[777/1912] æ­£åœ¨ç²å–: 6164 è¯èˆˆ...\n",
            "[778/1912] æ­£åœ¨ç²å–: 6165 æµªå‡¡...\n",
            "[779/1912] æ­£åœ¨ç²å–: 6166 å‡Œè¯...\n",
            "[780/1912] æ­£åœ¨ç²å–: 6168 å®é½Š...\n",
            "[781/1912] æ­£åœ¨ç²å–: 6176 ç‘å„€...\n",
            "[782/1912] æ­£åœ¨ç²å–: 6177 é”éº—...\n",
            "[783/1912] æ­£åœ¨ç²å–: 6183 é—œè²¿...\n",
            "[784/1912] æ­£åœ¨ç²å–: 6184 å¤§è±é›»...\n",
            "[785/1912] æ­£åœ¨ç²å–: 6189 è±è—...\n",
            "[786/1912] æ­£åœ¨ç²å–: 6191 ç²¾æˆç§‘...\n",
            "[787/1912] æ­£åœ¨ç²å–: 6192 å·¨è·¯...\n",
            "[788/1912] æ­£åœ¨ç²å–: 6196 å¸†å®£...\n",
            "[789/1912] æ­£åœ¨ç²å–: 6197 ä½³å¿…çª...\n",
            "[790/1912] æ­£åœ¨ç²å–: 6201 äºå¼˜é›»...\n",
            "[791/1912] æ­£åœ¨ç²å–: 6202 ç››ç¾¤...\n",
            "[792/1912] æ­£åœ¨ç²å–: 6205 è©®æ¬£...\n",
            "[793/1912] æ­£åœ¨ç²å–: 6206 é£›æ·...\n",
            "[794/1912] æ­£åœ¨ç²å–: 6209 ä»Šåœ‹å…‰...\n",
            "[795/1912] æ­£åœ¨ç²å–: 6213 è¯èŒ‚...\n",
            "[796/1912] æ­£åœ¨ç²å–: 6214 ç²¾èª ...\n",
            "[797/1912] æ­£åœ¨ç²å–: 6215 å’Œæ¤¿...\n",
            "[798/1912] æ­£åœ¨ç²å–: 6216 å±…æ˜“...\n",
            "[799/1912] æ­£åœ¨ç²å–: 6224 èšé¼...\n",
            "[800/1912] æ­£åœ¨ç²å–: 6225 å¤©ç€š...\n",
            "[801/1912] æ­£åœ¨ç²å–: 6226 å…‰é¼...\n",
            "[802/1912] æ­£åœ¨ç²å–: 6230 å°¼å¾—ç§‘è¶…çœ¾...\n",
            "[803/1912] æ­£åœ¨ç²å–: 6235 è¯å­š...\n",
            "[804/1912] æ­£åœ¨ç²å–: 6239 åŠ›æˆ...\n",
            "[805/1912] æ­£åœ¨ç²å–: 6243 è¿…æ°...\n",
            "[806/1912] æ­£åœ¨ç²å–: 6257 çŸ½æ ¼...\n",
            "[807/1912] æ­£åœ¨ç²å–: 6269 å°éƒ¡...\n",
            "[808/1912] æ­£åœ¨ç²å–: 6271 åŒæ¬£é›»...\n",
            "[809/1912] æ­£åœ¨ç²å–: 6277 å®æ­£...\n",
            "[810/1912] æ­£åœ¨ç²å–: 6278 å°è¡¨ç§‘...\n",
            "[811/1912] æ­£åœ¨ç²å–: 6281 å…¨åœ‹é›»...\n",
            "[812/1912] æ­£åœ¨ç²å–: 6282 åº·èˆ’...\n",
            "[813/1912] æ­£åœ¨ç²å–: 6283 æ·³å®‰...\n",
            "[814/1912] æ­£åœ¨ç²å–: 6285 å•Ÿï¿½ï¿½...\n",
            "[815/1912] æ­£åœ¨ç²å–: 6288 è¯å˜‰...\n",
            "[816/1912] æ­£åœ¨ç²å–: 6405 æ‚…åŸ...\n",
            "[817/1912] æ­£åœ¨ç²å–: 6409 æ—­éš¼...\n",
            "[818/1912] æ­£åœ¨ç²å–: 6412 ç¾¤é›»...\n",
            "[819/1912] æ­£åœ¨ç²å–: 6414 æ¨ºæ¼¢...\n",
            "[820/1912] æ­£åœ¨ç²å–: 6415 çŸ½åŠ›*-KY...\n",
            "[821/1912] æ­£åœ¨ç²å–: 6416 ç‘ç¥ºé›»é€š...\n",
            "[822/1912] æ­£åœ¨ç²å–: 6426 çµ±æ–°...\n",
            "[823/1912] æ­£åœ¨ç²å–: 6431 å…‰éº—-KY...\n",
            "[824/1912] æ­£åœ¨ç²å–: 6438 è¿…å¾—...\n",
            "[825/1912] æ­£åœ¨ç²å–: 6442 å…‰è–...\n",
            "[826/1912] æ­£åœ¨ç²å–: 6443 å…ƒæ™¶...\n",
            "[827/1912] æ­£åœ¨ç²å–: 6446 è—¥è¯è—¥...\n",
            "[828/1912] æ­£åœ¨ç²å–: 6449 éˆºé‚¦...\n",
            "[829/1912] æ­£åœ¨ç²å–: 6451 è¨ŠèŠ¯-KY...\n",
            "[830/1912] æ­£åœ¨ç²å–: 6456 GIS-KY...\n",
            "[831/1912] æ­£åœ¨ç²å–: 6464 å°æ•¸ç§‘...\n",
            "[832/1912] æ­£åœ¨ç²å–: 6472 ä¿ç‘...\n",
            "[833/1912] æ­£åœ¨ç²å–: 6477 å®‰é›†...\n",
            "[834/1912] æ­£åœ¨ç²å–: 6491 æ™¶ç¢©...\n",
            "[835/1912] æ­£åœ¨ç²å–: 6504 å—å…­...\n",
            "[836/1912] æ­£åœ¨ç²å–: 6505 å°å¡‘åŒ–...\n",
            "[837/1912] æ­£åœ¨ç²å–: 6515 ç©å´´...\n",
            "[838/1912] æ­£åœ¨ç²å–: 6525 æ·æ•-KY...\n",
            "[839/1912] æ­£åœ¨ç²å–: 6526 é”ç™¼...\n",
            "[840/1912] æ­£åœ¨ç²å–: 6531 æ„›æ™®*...\n",
            "[841/1912] æ­£åœ¨ç²å–: 6533 æ™¶å¿ƒç§‘...\n",
            "[842/1912] æ­£åœ¨ç²å–: 6541 æ³°ç¦-KY...\n",
            "[843/1912] æ­£åœ¨ç²å–: 6550 åŒ—æ¥µæ˜Ÿè—¥æ¥­-KY...\n",
            "[844/1912] æ­£åœ¨ç²å–: 6552 æ˜“è¯é›»...\n",
            "[845/1912] æ­£åœ¨ç²å–: 6558 èˆˆèƒ½é«˜...\n",
            "[846/1912] æ­£åœ¨ç²å–: 6573 è™¹æš-KY...\n",
            "[847/1912] æ­£åœ¨ç²å–: 6579 ç ”æš...\n",
            "[848/1912] æ­£åœ¨ç²å–: 6581 é‹¼è¯...\n",
            "[849/1912] æ­£åœ¨ç²å–: 6582 ç”³è±...\n",
            "[850/1912] æ­£åœ¨ç²å–: 6585 é¼åŸº...\n",
            "[851/1912] æ­£åœ¨ç²å–: 6589 å°åº·ç”ŸæŠ€...\n",
            "[852/1912] æ­£åœ¨ç²å–: 6591 å‹•åŠ›-KY...\n",
            "[853/1912] æ­£åœ¨ç²å–: 6592 å’Œæ½¤ä¼æ¥­...\n",
            "[854/1912] æ­£åœ¨ç²å–: 6598 ABC-KY...\n",
            "[855/1912] æ­£åœ¨ç²å–: 6605 å¸å¯¶...\n",
            "[856/1912] æ­£åœ¨ç²å–: 6606 å»ºå¾·å·¥æ¥­...\n",
            "[857/1912] æ­£åœ¨ç²å–: 6625 å¿…æ‡‰...\n",
            "[858/1912] æ­£åœ¨ç²å–: 6641 åŸºå£«å¾·-KY...\n",
            "[859/1912] æ­£åœ¨ç²å–: 6655 ç§‘å®š...\n",
            "[860/1912] æ­£åœ¨ç²å–: 6657 è¯å®‰...\n",
            "[861/1912] æ­£åœ¨ç²å–: 6658 è¯ç­–...\n",
            "[862/1912] æ­£åœ¨ç²å–: 6666 ç¾…éº—èŠ¬-KY...\n",
            "[863/1912] æ­£åœ¨ç²å–: 6668 ä¸­æšå…‰...\n",
            "[864/1912] æ­£åœ¨ç²å–: 6669 ç·¯ç©...\n",
            "[865/1912] æ­£åœ¨ç²å–: 6670 å¾©ç››æ‡‰ç”¨...\n",
            "[866/1912] æ­£åœ¨ç²å–: 6671 ä¸‰èƒ½-KY...\n",
            "[867/1912] æ­£åœ¨ç²å–: 6672 é¨°è¼é›»å­-KY...\n",
            "[868/1912] æ­£åœ¨ç²å–: 6674 é‹å¯¶ç§‘æŠ€...\n",
            "[869/1912] æ­£åœ¨ç²å–: 6689 ä¼Šé›²è°·...\n",
            "[870/1912] æ­£åœ¨ç²å–: 6691 æ´‹åŸºå·¥ç¨‹...\n",
            "[871/1912] æ­£åœ¨ç²å–: 6695 èŠ¯é¼...\n",
            "[872/1912] æ­£åœ¨ç²å–: 6698 æ—­æš‰æ‡‰æ...\n",
            "[873/1912] æ­£åœ¨ç²å–: 6706 æƒ ç‰¹...\n",
            "[874/1912] æ­£åœ¨ç²å–: 6715 å˜‰åŸº...\n",
            "[875/1912] æ­£åœ¨ç²å–: 6719 åŠ›æ™º...\n",
            "[876/1912] æ­£åœ¨ç²å–: 6742 æ¾¤ç±³...\n",
            "[877/1912] æ­£åœ¨ç²å–: 6743 å®‰æ™®æ–°...\n",
            "[878/1912] æ­£åœ¨ç²å–: 6753 é¾å¾·é€ èˆ¹...\n",
            "[879/1912] æ­£åœ¨ç²å–: 6754 åŒ¯åƒ‘è¨­è¨ˆ...\n",
            "[880/1912] æ­£åœ¨ç²å–: 6756 å¨é‹’é›»å­...\n",
            "[881/1912] æ­£åœ¨ç²å–: 6757 å°ç£è™èˆª...\n",
            "[882/1912] æ­£åœ¨ç²å–: 6768 å¿—å¼·-KY...\n",
            "[883/1912] æ­£åœ¨ç²å–: 6770 åŠ›ç©é›»...\n",
            "[884/1912] æ­£åœ¨ç²å–: 6776 å±•ï¿½çœ¥ç¯•ï¿½...\n",
            "[885/1912] æ­£åœ¨ç²å–: 6781 AES-KY...\n",
            "[886/1912] æ­£åœ¨ç²å–: 6782 è¦–é™½...\n",
            "[887/1912] æ­£åœ¨ç²å–: 6789 é‡‡éˆº...\n",
            "[888/1912] æ­£åœ¨ç²å–: 6790 æ°¸è±å¯¦...\n",
            "[889/1912] æ­£åœ¨ç²å–: 6792 è© æ¥­...\n",
            "[890/1912] æ­£åœ¨ç²å–: 6796 æ™‰å¼˜...\n",
            "[891/1912] æ­£åœ¨ç²å–: 6799 ä¾†é ¡...\n",
            "[892/1912] æ­£åœ¨ç²å–: 6805 å¯Œä¸–é”...\n",
            "[893/1912] æ­£åœ¨ç²å–: 6806 æ£®å´´èƒ½æº...\n",
            "[894/1912] æ­£åœ¨ç²å–: 6807 å³°æº-KY...\n",
            "[895/1912] æ­£åœ¨ç²å–: 6830 æ±éŠ“...\n",
            "[896/1912] æ­£åœ¨ç²å–: 6834 å¤©äºŒç§‘æŠ€...\n",
            "[897/1912] æ­£åœ¨ç²å–: 6835 åœ“è£•...\n",
            "[898/1912] æ­£åœ¨ç²å–: 6838 å°æ–°è—¥...\n",
            "[899/1912] æ­£åœ¨ç²å–: 6861 ç¿ç”Ÿå…‰é›»...\n",
            "[900/1912] æ­£åœ¨ç²å–: 6862 ä¸‰é›†ç‘-KY...\n",
            "[901/1912] æ­£åœ¨ç²å–: 6863 æ°¸é“-KY...\n",
            "[902/1912] æ­£åœ¨ç²å–: 6869 é›²è±¹èƒ½æº...\n",
            "[903/1912] æ­£åœ¨ç²å–: 6873 æ³“å¾·èƒ½æº...\n",
            "[904/1912] æ­£åœ¨ç²å–: 6885 å…¨ç¦ç”ŸæŠ€...\n",
            "[905/1912] æ­£åœ¨ç²å–: 6887 å¯¶ç¶ ç‰¹-KY...\n",
            "[906/1912] æ­£åœ¨ç²å–: 6890 ä¾†å„„-KY...\n",
            "[907/1912] æ­£åœ¨ç²å–: 6901 é‘½çŸ³æŠ•è³‡...\n",
            "[908/1912] æ­£åœ¨ç²å–: 6902 GOGOLOOK...\n",
            "[909/1912] æ­£åœ¨ç²å–: 6906 ç¾è§€ç§‘...\n",
            "[910/1912] æ­£åœ¨ç²å–: 6909 å‰µæ§...\n",
            "[911/1912] æ­£åœ¨ç²å–: 6914 é˜œçˆ¾é‹é€š...\n",
            "[912/1912] æ­£åœ¨ç²å–: 6916 è¯å‡Œ...\n",
            "[913/1912] æ­£åœ¨ç²å–: 6918 æ„›æ´¾å¸...\n",
            "[914/1912] æ­£åœ¨ç²å–: 6919 åº·éœˆ*...\n",
            "[915/1912] æ­£åœ¨ç²å–: 6923 ä¸­å°...\n",
            "[916/1912] æ­£åœ¨ç²å–: 6928 æ”¸æ³°ç§‘æŠ€...\n",
            "[917/1912] æ­£åœ¨ç²å–: 6931 é’æ¾å¥åº·...\n",
            "[918/1912] æ­£åœ¨ç²å–: 6933 AMAX-KY...\n",
            "[919/1912] æ­£åœ¨ç²å–: 6936 æ°¸é´»ç”ŸæŠ€...\n",
            "[920/1912] æ­£åœ¨ç²å–: 6937 å¤©è™¹...\n",
            "[921/1912] æ­£åœ¨ç²å–: 6944 å…†è¯å¯¦æ¥­...\n",
            "[922/1912] æ­£åœ¨ç²å–: 6952 å¤§æ­¦å±±...\n",
            "[923/1912] æ­£åœ¨ç²å–: 6957 è£•æ…¶-KY...\n",
            "[924/1912] æ­£åœ¨ç²å–: 6958 æ—¥ç››å°é§¿...\n",
            "[925/1912] æ­£åœ¨ç²å–: 6962 å¥•åŠ›-KY...\n",
            "[926/1912] æ­£åœ¨ç²å–: 6965 ä¸­å‚‘-KY...\n",
            "[927/1912] æ­£åœ¨ç²å–: 6994 å¯Œå¨é›»åŠ›...\n",
            "[928/1912] æ­£åœ¨ç²å–: 7705 ä¸‰å•†é¤é£²...\n",
            "[929/1912] æ­£åœ¨ç²å–: 7721 å¾®ç¨‹å¼...\n",
            "[930/1912] æ­£åœ¨ç²å–: 7722 LINEPAY...\n",
            "[931/1912] æ­£åœ¨ç²å–: 7732 é‡‘èˆˆç²¾å¯†...\n",
            "[932/1912] æ­£åœ¨ç²å–: 7736 è™å±±...\n",
            "[933/1912] æ­£åœ¨ç²å–: 7749 æ„é¨°-KY...\n",
            "[934/1912] æ­£åœ¨ç²å–: 8011 å°é€š...\n",
            "[935/1912] æ­£åœ¨ç²å–: 8016 çŸ½å‰µ...\n",
            "[936/1912] æ­£åœ¨ç²å–: 8021 å°–é»...\n",
            "[937/1912] æ­£åœ¨ç²å–: 8028 æ˜‡é™½åŠå°é«”...\n",
            "[938/1912] æ­£åœ¨ç²å–: 8033 é›·è™...\n",
            "[939/1912] æ­£åœ¨ç²å–: 8039 å°è™¹...\n",
            "[940/1912] æ­£åœ¨ç²å–: 8045 é”é‹å…‰é›»...\n",
            "[941/1912] æ­£åœ¨ç²å–: 8046 å—é›»...\n",
            "[942/1912] æ­£åœ¨ç²å–: 8070 é•·è¯*...\n",
            "[943/1912] æ­£åœ¨ç²å–: 8072 é™æ³°...\n",
            "[944/1912] æ­£åœ¨ç²å–: 8081 è‡´æ–°...\n",
            "[945/1912] æ­£åœ¨ç²å–: 8101 è¯å† ...\n",
            "[946/1912] æ­£åœ¨ç²å–: 8103 ç€šèƒ...\n",
            "[947/1912] æ­£åœ¨ç²å–: 8104 éŒ¸å¯¶...\n",
            "[948/1912] æ­£åœ¨ç²å–: 8105 å‡Œå·¨...\n",
            "[949/1912] æ­£åœ¨ç²å–: 8110 è¯æ±...\n",
            "[950/1912] æ­£åœ¨ç²å–: 8112 è‡³ä¸Š...\n",
            "[951/1912] æ­£åœ¨ç²å–: 8114 æŒ¯æ¨ºé›»...\n",
            "[952/1912] æ­£åœ¨ç²å–: 8131 ç¦æ‡‹ç§‘...\n",
            "[953/1912] æ­£åœ¨ç²å–: 8150 å—èŒ‚...\n",
            "[954/1912] æ­£åœ¨ç²å–: 8163 é”æ–¹...\n",
            "[955/1912] æ­£åœ¨ç²å–: 8201 ç„¡æ•µ...\n",
            "[956/1912] æ­£åœ¨ç²å–: 8210 å‹¤èª ...\n",
            "[957/1912] æ­£åœ¨ç²å–: 8213 å¿—è¶…...\n",
            "[958/1912] æ­£åœ¨ç²å–: 8215 æ˜åŸºæ...\n",
            "[959/1912] æ­£åœ¨ç²å–: 8222 å¯¶ä¸€...\n",
            "[960/1912] æ­£åœ¨ç²å–: 8249 è±å…‰...\n",
            "[961/1912] æ­£åœ¨ç²å–: 8261 å¯Œé¼...\n",
            "[962/1912] æ­£åœ¨ç²å–: 8271 å®‡ç»...\n",
            "[963/1912] æ­£åœ¨ç²å–: 8341 æ—¥å‹...\n",
            "[964/1912] æ­£åœ¨ç²å–: 8367 å»ºæ–°åœ‹éš›...\n",
            "[965/1912] æ­£åœ¨ç²å–: 8374 ç¾…æ˜‡...\n",
            "[966/1912] æ­£åœ¨ç²å–: 8404 ç™¾å’Œèˆˆæ¥­-KY...\n",
            "[967/1912] æ­£åœ¨ç²å–: 8411 ç¦è²-KY...\n",
            "[968/1912] æ­£åœ¨ç²å–: 8422 å¯å¯§è¡›...\n",
            "[969/1912] æ­£åœ¨ç²å–: 8429 é‡‘éº—-KY...\n",
            "[970/1912] æ­£åœ¨ç²å–: 8438 æ˜¶æ˜•...\n",
            "[971/1912] æ­£åœ¨ç²å–: 8442 å¨å®-KY...\n",
            "[972/1912] æ­£åœ¨ç²å–: 8443 é˜¿ç˜¦...\n",
            "[973/1912] æ­£åœ¨ç²å–: 8454 å¯Œé‚¦åª’...\n",
            "[974/1912] æ­£åœ¨ç²å–: 8462 æŸæ–‡...\n",
            "[975/1912] æ­£åœ¨ç²å–: 8463 æ½¤æ³°æ...\n",
            "[976/1912] æ­£åœ¨ç²å–: 8464 å„„è±...\n",
            "[977/1912] æ­£åœ¨ç²å–: 8466 ç¾å‰å‰-KY...\n",
            "[978/1912] æ­£åœ¨ç²å–: 8467 æ³¢åŠ›-KY...\n",
            "[979/1912] æ­£åœ¨ç²å–: 8473 å±±æ—æ°´...\n",
            "[980/1912] æ­£åœ¨ç²å–: 8476 å°å¢ƒ*...\n",
            "[981/1912] æ­£åœ¨ç²å–: 8478 æ±å“¥éŠè‰‡...\n",
            "[982/1912] æ­£åœ¨ç²å–: 8481 æ”¿ä¼¸...\n",
            "[983/1912] æ­£åœ¨ç²å–: 8482 å•†å„„-KY...\n",
            "[984/1912] æ­£åœ¨ç²å–: 8488 å‰æº-KY...\n",
            "[985/1912] æ­£åœ¨ç²å–: 8499 é¼ç‚«-KY...\n",
            "[986/1912] æ­£åœ¨ç²å–: 8926 å°æ±½é›»...\n",
            "[987/1912] æ­£åœ¨ç²å–: 8940 æ–°å¤©åœ°...\n",
            "[988/1912] æ­£åœ¨ç²å–: 8996 é«˜åŠ›...\n",
            "[989/1912] æ­£åœ¨ç²å–: 9802 éˆºé½Š-KY...\n",
            "[990/1912] æ­£åœ¨ç²å–: 9902 å°ç«...\n",
            "[991/1912] æ­£åœ¨ç²å–: 9904 å¯¶æˆ...\n",
            "[992/1912] æ­£åœ¨ç²å–: 9905 å¤§è¯...\n",
            "[993/1912] æ­£åœ¨ç²å–: 9906 æ¬£å·´å·´...\n",
            "[994/1912] æ­£åœ¨ç²å–: 9907 çµ±ä¸€å¯¦...\n",
            "[995/1912] æ­£åœ¨ç²å–: 9908 å¤§å°åŒ—...\n",
            "[996/1912] æ­£åœ¨ç²å–: 9910 è±æ³°...\n",
            "[997/1912] æ­£åœ¨ç²å–: 9911 æ«»èŠ±...\n",
            "[998/1912] æ­£åœ¨ç²å–: 9912 å‰è¯...\n",
            "[999/1912] æ­£åœ¨ç²å–: 9914 ç¾åˆ©é”...\n",
            "[1000/1912] æ­£åœ¨ç²å–: 9917 ä¸­ä¿ç§‘...\n",
            "[1001/1912] æ­£åœ¨ç²å–: 9918 æ¬£å¤©ç„¶...\n",
            "[1002/1912] æ­£åœ¨ç²å–: 9919 åº·é‚£é¦™...\n",
            "[1003/1912] æ­£åœ¨ç²å–: 9921 å·¨å¤§...\n",
            "[1004/1912] æ­£åœ¨ç²å–: 9924 ç¦èˆˆ...\n",
            "[1005/1912] æ­£åœ¨ç²å–: 9925 æ–°ä¿...\n",
            "[1006/1912] æ­£åœ¨ç²å–: 9926 æ–°æµ·...\n",
            "[1007/1912] æ­£åœ¨ç²å–: 9927 æ³°éŠ˜...\n",
            "[1008/1912] æ­£åœ¨ç²å–: 9928 ä¸­è¦–...\n",
            "[1009/1912] æ­£åœ¨ç²å–: 9929 ç§‹é›¨...\n",
            "[1010/1912] æ­£åœ¨ç²å–: 9930 ä¸­è¯è³‡æº...\n",
            "[1011/1912] æ­£åœ¨ç²å–: 9931 æ¬£é«˜...\n",
            "[1012/1912] æ­£åœ¨ç²å–: 9933 ä¸­é¼...\n",
            "[1013/1912] æ­£åœ¨ç²å–: 9934 æˆéœ–...\n",
            "[1014/1912] æ­£åœ¨ç²å–: 9935 æ…¶è±å¯Œ...\n",
            "[1015/1912] æ­£åœ¨ç²å–: 9937 å…¨åœ‹...\n",
            "[1016/1912] æ­£åœ¨ç²å–: 9938 ç™¾å’Œ...\n",
            "[1017/1912] æ­£åœ¨ç²å–: 9939 å®å…¨...\n",
            "[1018/1912] æ­£åœ¨ç²å–: 9940 ä¿¡ç¾©...\n",
            "[1019/1912] æ­£åœ¨ç²å–: 9941 è£•è...\n",
            "[1020/1912] æ­£åœ¨ç²å–: 9942 èŒ‚é †...\n",
            "[1021/1912] æ­£åœ¨ç²å–: 9943 å¥½æ¨‚è¿ª...\n",
            "[1022/1912] æ­£åœ¨ç²å–: 9944 æ–°éº—...\n",
            "[1023/1912] æ­£åœ¨ç²å–: 9945 æ½¤æ³°æ–°...\n",
            "[1024/1912] æ­£åœ¨ç²å–: 9946 ä¸‰ç™¼åœ°ç”¢...\n",
            "[1025/1912] æ­£åœ¨ç²å–: 9955 ä½³é¾...\n",
            "[1026/1912] æ­£åœ¨ç²å–: 9958 ä¸–ç´€é‹¼...\n",
            "[1027/1912] æ­£åœ¨ç²å–: 2254 å·¨é§ç²¾å¯†-å‰µ...\n",
            "[1028/1912] æ­£åœ¨ç²å–: 2258 é´»è¯å…ˆé€²-å‰µ...\n",
            "[1029/1912] æ­£åœ¨ç²å–: 2432 å€šå¤©é…·ï¿½ï¿½-å‰µ...\n",
            "[1030/1912] æ­£åœ¨ç²å–: 3150 éˆºå¯¶-å‰µ...\n",
            "[1031/1912] æ­£åœ¨ç²å–: 6423 å„„è€Œå¾—-å‰µ...\n",
            "[1032/1912] æ­£åœ¨ç²å–: 6534 æ­£ç€š-å‰µ...\n",
            "[1033/1912] æ­£åœ¨ç²å–: 6645 é‡‘è¬æ—-å‰µ...\n",
            "[1034/1912] æ­£åœ¨ç²å–: 6771 å¹³å’Œç’°ä¿-å‰µ...\n",
            "[1035/1912] æ­£åœ¨ç²å–: 6794 å‘æ¦®ç”ŸæŠ€-å‰µ...\n",
            "[1036/1912] æ­£åœ¨ç²å–: 6854 éŒ¼å‰µç§‘æŠ€-KYå‰µ...\n",
            "[1037/1912] æ­£åœ¨ç²å–: 6924 æ¦®æƒ -KYå‰µ...\n",
            "[1038/1912] æ­£åœ¨ç²å–: 6949 æ²›çˆ¾ç”Ÿé†«-å‰µ...\n",
            "[1039/1912] æ­£åœ¨ç²å–: 6951 é’æ–°-å‰µ...\n",
            "[1040/1912] æ­£åœ¨ç²å–: 6955 é‚¦ç¿ç”ŸæŠ€-å‰µ...\n",
            "[1041/1912] æ­£åœ¨ç²å–: 6969 æˆä¿¡å¯¦æ¥­*-å‰µ...\n",
            "[1042/1912] æ­£åœ¨ç²å–: 6988 å¨åŠ›æš˜-å‰µ...\n",
            "[1043/1912] æ­£åœ¨ç²å–: 7631 èšè³¢ç ”ç™¼-å‰µ...\n",
            "[1044/1912] æ­£åœ¨ç²å–: 7740 ç†™ç‰¹çˆ¾-å‰µ...\n",
            "[1045/1912] æ­£åœ¨ç²å–: 8162 å¾®çŸ½é›»å­-å‰µ...\n",
            "[1046/1912] æ­£åœ¨ç²å–: 8487 æ„›çˆ¾é”-å‰µ...\n",
            "[1047/1912] æ­£åœ¨ç²å–: 0050 å…ƒå¤§å°ç£50...\n",
            "[1048/1912] æ­£åœ¨ç²å–: 0051 å…ƒå¤§ä¸­å‹100...\n",
            "[1049/1912] æ­£åœ¨ç²å–: 0052 å¯Œé‚¦ç§‘æŠ€...\n",
            "[1050/1912] æ­£åœ¨ç²å–: 0053 å…ƒå¤§é›»å­...\n",
            "[1051/1912] æ­£åœ¨ç²å–: 0055 å…ƒå¤§MSCIé‡‘è...\n",
            "[1052/1912] æ­£åœ¨ç²å–: 0056 å…ƒå¤§é«˜è‚¡æ¯...\n",
            "[1053/1912] æ­£åœ¨ç²å–: 0057 å¯Œé‚¦æ‘©å°...\n",
            "[1054/1912] æ­£åœ¨ç²å–: 0061 å…ƒå¤§å¯¶æ»¬æ·±...\n",
            "[1055/1912] æ­£åœ¨ç²å–: 9103 ç¾å¾·é†«ç™‚-DR...\n",
            "[1056/1912] æ­£åœ¨ç²å–: 9105 æ³°é‡‘å¯¶-DR...\n",
            "[1057/1912] æ­£åœ¨ç²å–: 9110 è¶Šå—æ§-DR...\n",
            "[1058/1912] æ­£åœ¨ç²å–: 9136 å·¨é¨°-DR...\n",
            "[1059/1912] æ­£åœ¨ç²å–: 1240 èŒ‚ç”Ÿè¾²ç¶“...\n",
            "[1060/1912] æ­£åœ¨ç²å–: 1259 å®‰å¿ƒ...\n",
            "[1061/1912] æ­£åœ¨ç²å–: 1264 å¾·éº¥...\n",
            "[1062/1912] æ­£åœ¨ç²å–: 1268 æ¼¢ä¾†ç¾é£Ÿ...\n",
            "[1063/1912] æ­£åœ¨ç²å–: 1294 æ¼¢ç”°ç”ŸæŠ€...\n",
            "[1064/1912] æ­£åœ¨ç²å–: 1295 ç”Ÿåˆ...\n",
            "[1065/1912] æ­£åœ¨ç²å–: 1336 å°ç¿°...\n",
            "[1066/1912] æ­£åœ¨ç²å–: 1565 ç²¾è¯...\n",
            "[1067/1912] æ­£åœ¨ç²å–: 1569 æ¿±å·...\n",
            "[1068/1912] æ­£åœ¨ç²å–: 1570 åŠ›è‚¯...\n",
            "[1069/1912] æ­£åœ¨ç²å–: 1580 æ–°éº¥...\n",
            "[1070/1912] æ­£åœ¨ç²å–: 1584 ç²¾å‰›...\n",
            "[1071/1912] æ­£åœ¨ç²å–: 1586 å’Œå‹¤...\n",
            "[1072/1912] æ­£åœ¨ç²å–: 1591 é§¿å‰-KY...\n",
            "[1073/1912] æ­£åœ¨ç²å–: 1593 ç¥ºé©Š...\n",
            "[1074/1912] æ­£åœ¨ç²å–: 1595 å·å¯¶...\n",
            "[1075/1912] æ­£åœ¨ç²å–: 1599 å®ä½³é¨°...\n",
            "[1076/1912] æ­£åœ¨ç²å–: 1742 å°è Ÿ...\n",
            "[1077/1912] æ­£åœ¨ç²å–: 1777 ç”Ÿæ³°...\n",
            "[1078/1912] æ­£åœ¨ç²å–: 1781 åˆä¸–...\n",
            "[1079/1912] æ­£åœ¨ç²å–: 1784 è¨Šè¯...\n",
            "[1080/1912] æ­£åœ¨ç²å–: 1785 å…‰æ´‹ç§‘...\n",
            "[1081/1912] æ­£åœ¨ç²å–: 1788 ææ˜Œ...\n",
            "[1082/1912] æ­£åœ¨ç²å–: 1796 é‡‘ç©ç”ŸæŠ€...\n",
            "[1083/1912] æ­£åœ¨ç²å–: 1799 æ˜“å¨...\n",
            "[1084/1912] æ­£åœ¨ç²å–: 1813 å¯¶åˆ©å¾ ...\n",
            "[1085/1912] æ­£åœ¨ç²å–: 1815 å¯Œå–¬...\n",
            "[1086/1912] æ­£åœ¨ç²å–: 2035 å”æ¦®...\n",
            "[1087/1912] æ­£åœ¨ç²å–: 2061 é¢¨é’...\n",
            "[1088/1912] æ­£åœ¨ç²å–: 2063 ä¸–é§...\n",
            "[1089/1912] æ­£åœ¨ç²å–: 2064 æ™‰æ¤¿...\n",
            "[1090/1912] æ­£åœ¨ç²å–: 2065 ä¸–è±...\n",
            "[1091/1912] æ­£åœ¨ç²å–: 2066 ä¸–å¾·...\n",
            "[1092/1912] æ­£åœ¨ç²å–: 2067 å˜‰é‹¼...\n",
            "[1093/1912] æ­£åœ¨ç²å–: 2070 ç²¾æ¹›...\n",
            "[1094/1912] æ­£åœ¨ç²å–: 2073 é›„é †...\n",
            "[1095/1912] æ­£åœ¨ç²å–: 2221 å¤§ç”²...\n",
            "[1096/1912] æ­£åœ¨ç²å–: 2230 æ³°èŒ‚...\n",
            "[1097/1912] æ­£åœ¨ç²å–: 2235 è¬šæº...\n",
            "[1098/1912] æ­£åœ¨ç²å–: 2596 ç¶ æ„...\n",
            "[1099/1912] æ­£åœ¨ç²å–: 2640 å¤§è»ŠéšŠ...\n",
            "[1100/1912] æ­£åœ¨ç²å–: 2641 æ­£å¾·...\n",
            "[1101/1912] æ­£åœ¨ç²å–: 2643 æ·è¿…...\n",
            "[1102/1912] æ­£åœ¨ç²å–: 2718 å…¨å¿ƒæŠ•æ§...\n",
            "[1103/1912] æ­£åœ¨ç²å–: 2719 ç‡¦æ˜Ÿæ—…...\n",
            "[1104/1912] æ­£åœ¨ç²å–: 2724 è—èˆ-KY...\n",
            "[1105/1912] æ­£åœ¨ç²å–: 2726 é›…èŒ—-KY...\n",
            "[1106/1912] æ­£åœ¨ç²å–: 2729 ç“¦åŸ...\n",
            "[1107/1912] æ­£åœ¨ç²å–: 2732 å…­è§’...\n",
            "[1108/1912] æ­£åœ¨ç²å–: 2734 æ˜“é£›ç¶²...\n",
            "[1109/1912] æ­£åœ¨ç²å–: 2736 å¯Œé‡...\n",
            "[1110/1912] æ­£åœ¨ç²å–: 2740 å¤©è”¥...\n",
            "[1111/1912] æ­£åœ¨ç²å–: 2743 å±±å¯Œ...\n",
            "[1112/1912] æ­£åœ¨ç²å–: 2745 äº”ç¦...\n",
            "[1113/1912] æ­£åœ¨ç²å–: 2751 ç‹åº§...\n",
            "[1114/1912] æ­£åœ¨ç²å–: 2752 è±†åºœ...\n",
            "[1115/1912] æ­£åœ¨ç²å–: 2754 äºæ´²è—å£½å¸...\n",
            "[1116/1912] æ­£åœ¨ç²å–: 2755 æšç§¦...\n",
            "[1117/1912] æ­£åœ¨ç²å–: 2756 è¯ç™¼åœ‹éš›...\n",
            "[1118/1912] æ­£åœ¨ç²å–: 2916 æ»¿å¿ƒ...\n",
            "[1119/1912] æ­£åœ¨ç²å–: 2924 å®å¤ª-KY...\n",
            "[1120/1912] æ­£åœ¨ç²å–: 2926 èª å“ç”Ÿæ´»...\n",
            "[1121/1912] æ­£åœ¨ç²å–: 2937 é›†é›…ç¤¾...\n",
            "[1122/1912] æ­£åœ¨ç²å–: 2941 ç±³æ–¯ç‰¹...\n",
            "[1123/1912] æ­£åœ¨ç²å–: 2947 æŒ¯å®‡äº”é‡‘...\n",
            "[1124/1912] æ­£åœ¨ç²å–: 2948 å¯¶é™...\n",
            "[1125/1912] æ­£åœ¨ç²å–: 2949 æ¬£æ–°ç¶²...\n",
            "[1126/1912] æ­£åœ¨ç²å–: 3064 æ³°å‰...\n",
            "[1127/1912] æ­£åœ¨ç²å–: 3066 ææ´²...\n",
            "[1128/1912] æ­£åœ¨ç²å–: 3067 å…¨åŸŸ...\n",
            "[1129/1912] æ­£åœ¨ç²å–: 3071 å”ç¦§...\n",
            "[1130/1912] æ­£åœ¨ç²å–: 3073 å¤©æ–¹èƒ½æº...\n",
            "[1131/1912] æ­£åœ¨ç²å–: 3078 åƒ‘å¨...\n",
            "[1132/1912] æ­£åœ¨ç²å–: 3081 è¯äº...\n",
            "[1133/1912] æ­£åœ¨ç²å–: 3083 ç¶²é¾...\n",
            "[1134/1912] æ­£åœ¨ç²å–: 3085 æ–°é›¶å”®...\n",
            "[1135/1912] æ­£åœ¨ç²å–: 3086 è¯ç¾©...\n",
            "[1136/1912] æ­£åœ¨ç²å–: 3088 è‰¾è¨Š...\n",
            "[1137/1912] æ­£åœ¨ç²å–: 3093 æ¸¯å»º*...\n",
            "[1138/1912] æ­£åœ¨ç²å–: 3095 åŠæˆ...\n",
            "[1139/1912] æ­£åœ¨ç²å–: 3105 ç©©æ‡‹...\n",
            "[1140/1912] æ­£åœ¨ç²å–: 3114 å¥½å¾·...\n",
            "[1141/1912] æ­£åœ¨ç²å–: 3115 å¯Œæ¦®ç¶±...\n",
            "[1142/1912] æ­£åœ¨ç²å–: 3118 é€²éš...\n",
            "[1143/1912] æ­£åœ¨ç²å–: 3122 ç¬™æ³‰...\n",
            "[1144/1912] æ­£åœ¨ç²å–: 3128 æ˜‡éŠ³...\n",
            "[1145/1912] æ­£åœ¨ç²å–: 3131 å¼˜å¡‘...\n",
            "[1146/1912] æ­£åœ¨ç²å–: 3141 æ™¶å®...\n",
            "[1147/1912] æ­£åœ¨ç²å–: 3147 å¤§ç¶œ...\n",
            "[1148/1912] æ­£åœ¨ç²å–: 3152 ç’Ÿå¾·...\n",
            "[1149/1912] æ­£åœ¨ç²å–: 3162 ç²¾ç¢º...\n",
            "[1150/1912] æ­£åœ¨ç²å–: 3163 æ³¢è‹¥å¨...\n",
            "[1151/1912] æ­£åœ¨ç²å–: 3169 äºä¿¡...\n",
            "[1152/1912] æ­£åœ¨ç²å–: 3171 ç‚æ´²æµé€š...\n",
            "[1153/1912] æ­£åœ¨ç²å–: 3176 åŸºäº...\n",
            "[1154/1912] æ­£åœ¨ç²å–: 3178 å…¬æº–...\n",
            "[1155/1912] æ­£åœ¨ç²å–: 3188 é‘«é¾é¨°...\n",
            "[1156/1912] æ­£åœ¨ç²å–: 3191 é›²å˜‰å—...\n",
            "[1157/1912] æ­£åœ¨ç²å–: 3205 ä½°ç ”...\n",
            "[1158/1912] æ­£åœ¨ç²å–: 3206 å¿—è±...\n",
            "[1159/1912] æ­£åœ¨ç²å–: 3207 è€€å‹...\n",
            "[1160/1912] æ­£åœ¨ç²å–: 3211 é †é”...\n",
            "[1161/1912] æ­£åœ¨ç²å–: 3213 èŒ‚è¨Š...\n",
            "[1162/1912] æ­£åœ¨ç²å–: 3217 å„ªç¾¤...\n",
            "[1163/1912] æ­£åœ¨ç²å–: 3218 å¤§å­¸å…‰...\n",
            "[1164/1912] æ­£åœ¨ç²å–: 3219 å€šå¼·ç§‘...\n",
            "[1165/1912] æ­£åœ¨ç²å–: 3221 å°å˜‰ç¢©...\n",
            "[1166/1912] æ­£åœ¨ç²å–: 3224 ä¸‰é¡§...\n",
            "[1167/1912] æ­£åœ¨ç²å–: 3226 é¾é‹’...\n",
            "[1168/1912] æ­£åœ¨ç²å–: 3227 åŸç›¸...\n",
            "[1169/1912] æ­£åœ¨ç²å–: 3228 é‡‘éº—ç§‘...\n",
            "[1170/1912] æ­£åœ¨ç²å–: 3230 éŒ¦æ˜...\n",
            "[1171/1912] æ­£åœ¨ç²å–: 3232 æ˜±æ·...\n",
            "[1172/1912] æ­£åœ¨ç²å–: 3234 å…‰ç’°...\n",
            "[1173/1912] æ­£åœ¨ç²å–: 3236 åƒå¦‚...\n",
            "[1174/1912] æ­£åœ¨ç²å–: 3252 æµ·ç£...\n",
            "[1175/1912] æ­£åœ¨ç²å–: 3259 é‘«å‰µ...\n",
            "[1176/1912] æ­£åœ¨ç²å–: 3260 å¨å‰›...\n",
            "[1177/1912] æ­£åœ¨ç²å–: 3264 æ¬£éŠ“...\n",
            "[1178/1912] æ­£åœ¨ç²å–: 3265 å°æ˜Ÿç§‘...\n",
            "[1179/1912] æ­£åœ¨ç²å–: 3268 æµ·å¾·å¨...\n",
            "[1180/1912] æ­£åœ¨ç²å–: 3272 æ±ç¢©...\n",
            "[1181/1912] æ­£åœ¨ç²å–: 3276 å®‡ç’°...\n",
            "[1182/1912] æ­£åœ¨ç²å–: 3284 å¤ªæ™®é«˜...\n",
            "[1183/1912] æ­£åœ¨ç²å–: 3285 å¾®ç«¯...\n",
            "[1184/1912] æ­£åœ¨ç²å–: 3287 å»£å¯°ç§‘...\n",
            "[1185/1912] æ­£åœ¨ç²å–: 3288 é»æ™¶...\n",
            "[1186/1912] æ­£åœ¨ç²å–: 3289 å®œç‰¹...\n",
            "[1187/1912] æ­£åœ¨ç²å–: 3290 æ±æµ¦...\n",
            "[1188/1912] æ­£åœ¨ç²å–: 3293 éˆŠè±¡...\n",
            "[1189/1912] æ­£åœ¨ç²å–: 3294 è‹±æ¿Ÿ...\n",
            "[1190/1912] æ­£åœ¨ç²å–: 3297 æ­ç‰¹...\n",
            "[1191/1912] æ­£åœ¨ç²å–: 3303 å²±ç¨œ...\n",
            "[1192/1912] æ­£åœ¨ç²å–: 3306 é¼å¤©...\n",
            "[1193/1912] æ­£åœ¨ç²å–: 3310 ä½³ç©...\n",
            "[1194/1912] æ­£åœ¨ç²å–: 3313 æ–æˆ...\n",
            "[1195/1912] æ­£åœ¨ç²å–: 3317 å°¼å…‹æ£®...\n",
            "[1196/1912] æ­£åœ¨ç²å–: 3322 å»ºèˆœé›»...\n",
            "[1197/1912] æ­£åœ¨ç²å–: 3323 åŠ ç™¾è£•...\n",
            "[1198/1912] æ­£åœ¨ç²å–: 3324 é›™é´»...\n",
            "[1199/1912] æ­£åœ¨ç²å–: 3325 æ—­å“...\n",
            "[1200/1912] æ­£åœ¨ç²å–: 3332 å¹¸åº·...\n",
            "[1201/1912] æ­£åœ¨ç²å–: 3339 æ³°è°·...\n",
            "[1202/1912] æ­£åœ¨ç²å–: 3349 å¯¶å¾·...\n",
            "[1203/1912] æ­£åœ¨ç²å–: 3354 å¾‹å‹...\n",
            "[1204/1912] æ­£åœ¨ç²å–: 3357 è‡ºæ…¶ç§‘...\n",
            "[1205/1912] æ­£åœ¨ç²å–: 3360 å°šç«‹...\n",
            "[1206/1912] æ­£åœ¨ç²å–: 3362 å…ˆé€²å…‰...\n",
            "[1207/1912] æ­£åœ¨ç²å–: 3363 ä¸Šè©®...\n",
            "[1208/1912] æ­£åœ¨ç²å–: 3372 å…¸ç¯„...\n",
            "[1209/1912] æ­£åœ¨ç²å–: 3373 ç†±æ˜ ...\n",
            "[1210/1912] æ­£åœ¨ç²å–: 3374 ç²¾æ...\n",
            "[1211/1912] æ­£åœ¨ç²å–: 3379 å½¬å°...\n",
            "[1212/1912] æ­£åœ¨ç²å–: 3388 å´‡è¶Šé›»...\n",
            "[1213/1912] æ­£åœ¨ç²å–: 3390 æ—­è»Ÿ...\n",
            "[1214/1912] æ­£åœ¨ç²å–: 3402 æ¼¢ç§‘...\n",
            "[1215/1912] æ­£åœ¨ç²å–: 3426 å°èˆˆ...\n",
            "[1216/1912] æ­£åœ¨ç²å–: 3430 å¥‡éˆ¦ç§‘...\n",
            "[1217/1912] æ­£åœ¨ç²å–: 3434 å“²å›º...\n",
            "[1218/1912] æ­£åœ¨ç²å–: 3438 é¡æ¯”ç§‘...\n",
            "[1219/1912] æ­£åœ¨ç²å–: 3441 è¯ä¸€å…‰...\n",
            "[1220/1912] æ­£åœ¨ç²å–: 3444 åˆ©æ©Ÿ...\n",
            "[1221/1912] æ­£åœ¨ç²å–: 3455 ç”±ç”°...\n",
            "[1222/1912] æ­£åœ¨ç²å–: 3465 é€²æ³°é›»å­...\n",
            "[1223/1912] æ­£åœ¨ç²å–: 3466 å¾·æ™‰...\n",
            "[1224/1912] æ­£åœ¨ç²å–: 3467 å°ç£ç²¾æ...\n",
            "[1225/1912] æ­£åœ¨ç²å–: 3479 å®‰å‹¤...\n",
            "[1226/1912] æ­£åœ¨ç²å–: 3483 åŠ›è‡´...\n",
            "[1227/1912] æ­£åœ¨ç²å–: 3484 å´§é¨°...\n",
            "[1228/1912] æ­£åœ¨ç²å–: 3489 æ£®å¯¶...\n",
            "[1229/1912] æ­£åœ¨ç²å–: 3490 å–®äº•...\n",
            "[1230/1912] æ­£åœ¨ç²å–: 3491 æ˜‡é”ç§‘...\n",
            "[1231/1912] æ­£åœ¨ç²å–: 3492 é•·ç››...\n",
            "[1232/1912] æ­£åœ¨ç²å–: 3498 é™½ç¨‹...\n",
            "[1233/1912] æ­£åœ¨ç²å–: 3499 ç’°å¤©ç§‘...\n",
            "[1234/1912] æ­£åœ¨ç²å–: 3508 ä½é€Ÿ...\n",
            "[1235/1912] æ­£åœ¨ç²å–: 3511 çŸ½ç‘ª...\n",
            "[1236/1912] æ­£åœ¨ç²å–: 3512 çš‡é¾...\n",
            "[1237/1912] æ­£åœ¨ç²å–: 3516 äºå¸æ­...\n",
            "[1238/1912] æ­£åœ¨ç²å–: 3520 è¯ç›ˆ...\n",
            "[1239/1912] æ­£åœ¨ç²å–: 3521 é´»ç¿Š...\n",
            "[1240/1912] æ­£åœ¨ç²å–: 3522 å¾¡åµ¿...\n",
            "[1241/1912] æ­£åœ¨ç²å–: 3523 è¿è¼...\n",
            "[1242/1912] æ­£åœ¨ç²å–: 3526 å‡¡ç”²...\n",
            "[1243/1912] æ­£åœ¨ç²å–: 3527 èšç©...\n",
            "[1244/1912] æ­£åœ¨ç²å–: 3529 åŠ›æ—º...\n",
            "[1245/1912] æ­£åœ¨ç²å–: 3531 å…ˆç›Š...\n",
            "[1246/1912] æ­£åœ¨ç²å–: 3537 å ¡é”...\n",
            "[1247/1912] æ­£åœ¨ç²å–: 3540 æ›œè¶Š...\n",
            "[1248/1912] æ­£åœ¨ç²å–: 3541 è¥¿æŸ...\n",
            "[1249/1912] æ­£åœ¨ç²å–: 3546 å®‡å³»...\n",
            "[1250/1912] æ­£åœ¨ç²å–: 3548 å…†åˆ©...\n",
            "[1251/1912] æ­£åœ¨ç²å–: 3551 ä¸–ç¦¾...\n",
            "[1252/1912] æ­£åœ¨ç²å–: 3552 åŒè‡´...\n",
            "[1253/1912] æ­£åœ¨ç²å–: 3555 åšå£«æ—º...\n",
            "[1254/1912] æ­£åœ¨ç²å–: 3556 ç¦¾ç‘äº...\n",
            "[1255/1912] æ­£åœ¨ç²å–: 3558 ç¥æº–...\n",
            "[1256/1912] æ­£åœ¨ç²å–: 3564 å…¶é™½...\n",
            "[1257/1912] æ­£åœ¨ç²å–: 3567 é€¸æ˜Œ...\n",
            "[1258/1912] æ­£åœ¨ç²å–: 3570 å¤§å¡š...\n",
            "[1259/1912] æ­£åœ¨ç²å–: 3577 æ³“æ ¼...\n",
            "[1260/1912] æ­£åœ¨ç²å–: 3580 å‹å¨ç§‘...\n",
            "[1261/1912] æ­£åœ¨ç²å–: 3581 åšç£Š...\n",
            "[1262/1912] æ­£åœ¨ç²å–: 3587 é–åº·...\n",
            "[1263/1912] æ­£åœ¨ç²å–: 3594 ç£å„€...\n",
            "[1264/1912] æ­£åœ¨ç²å–: 3597 æ˜ èˆˆ...\n",
            "[1265/1912] æ­£åœ¨ç²å–: 3609 ä¸‰ä¸€æ±æ—...\n",
            "[1266/1912] æ­£åœ¨ç²å–: 3611 é¼ç¿°...\n",
            "[1267/1912] æ­£åœ¨ç²å–: 3615 å®‰å¯...\n",
            "[1268/1912] æ­£åœ¨ç²å–: 3623 å¯Œæ™¶é€š...\n",
            "[1269/1912] æ­£åœ¨ç²å–: 3624 å…‰é ¡...\n",
            "[1270/1912] æ­£åœ¨ç²å–: 3625 è¥¿å‹...\n",
            "[1271/1912] æ­£åœ¨ç²å–: 3628 ç›ˆæ­£...\n",
            "[1272/1912] æ­£åœ¨ç²å–: 3629 åœ°å¿ƒå¼•åŠ›...\n",
            "[1273/1912] æ­£åœ¨ç²å–: 3630 æ–°é‰…ç§‘...\n",
            "[1274/1912] æ­£åœ¨ç²å–: 3631 æ™Ÿæ¥ ...\n",
            "[1275/1912] æ­£åœ¨ç²å–: 3632 ç ”å‹¤...\n",
            "[1276/1912] æ­£åœ¨ç²å–: 3646 è‰¾æ©ç‰¹...\n",
            "[1277/1912] æ­£åœ¨ç²å–: 3663 é‘«ç§‘...\n",
            "[1278/1912] æ­£åœ¨ç²å–: 3664 å®‰ç‘-KY...\n",
            "[1279/1912] æ­£åœ¨ç²å–: 3666 å…‰è€€...\n",
            "[1280/1912] æ­£åœ¨ç²å–: 3672 åº·è¯è¨Š...\n",
            "[1281/1912] æ­£åœ¨ç²å–: 3675 å¾·å¾®...\n",
            "[1282/1912] æ­£åœ¨ç²å–: 3680 å®¶ç™»...\n",
            "[1283/1912] æ­£åœ¨ç²å–: 3684 æ¦®æ˜Œ...\n",
            "[1284/1912] æ­£åœ¨ç²å–: 3685 å…ƒå‰µç²¾å¯†...\n",
            "[1285/1912] æ­£åœ¨ç²å–: 3687 æ­è²·å°¬...\n",
            "[1286/1912] æ­£åœ¨ç²å–: 3689 æ¹§å¾·...\n",
            "[1287/1912] æ­£åœ¨ç²å–: 3691 ç¢©ç¦¾...\n",
            "[1288/1912] æ­£åœ¨ç²å–: 3693 ç‡Ÿé‚¦...\n",
            "[1289/1912] æ­£åœ¨ç²å–: 3707 æ¼¢ç£Š...\n",
            "[1290/1912] æ­£åœ¨ç²å–: 3709 é‘«è¯å¤§æŠ•æ§...\n",
            "[1291/1912] æ­£åœ¨ç²å–: 3710 é€£å±•æŠ•æ§...\n",
            "[1292/1912] æ­£åœ¨ç²å–: 3713 æ–°æ™¶æŠ•æ§...\n",
            "[1293/1912] æ­£åœ¨ç²å–: 4102 æ°¸æ—¥...\n",
            "[1294/1912] æ­£åœ¨ç²å–: 4105 æ±æ´‹...\n",
            "[1295/1912] æ­£åœ¨ç²å–: 4107 é‚¦ç‰¹...\n",
            "[1296/1912] æ­£åœ¨ç²å–: 4109 åŠ æ·ç”Ÿé†«...\n",
            "[1297/1912] æ­£åœ¨ç²å–: 4111 æ¿Ÿç”Ÿ...\n",
            "[1298/1912] æ­£åœ¨ç²å–: 4113 è¯ä¸Š...\n",
            "[1299/1912] æ­£åœ¨ç²å–: 4114 å¥å–¬...\n",
            "[1300/1912] æ­£åœ¨ç²å–: 4116 æ˜åŸºé†«...\n",
            "[1301/1912] æ­£åœ¨ç²å–: 4120 å‹è¯...\n",
            "[1302/1912] æ­£åœ¨ç²å–: 4121 å„ªç››...\n",
            "[1303/1912] æ­£åœ¨ç²å–: 4123 æ™Ÿå¾·...\n",
            "[1304/1912] æ­£åœ¨ç²å–: 4126 å¤ªé†«...\n",
            "[1305/1912] æ­£åœ¨ç²å–: 4127 å¤©è‰¯...\n",
            "[1306/1912] æ­£åœ¨ç²å–: 4128 ä¸­å¤©...\n",
            "[1307/1912] æ­£åœ¨ç²å–: 4129 è¯åˆ...\n",
            "[1308/1912] æ­£åœ¨ç²å–: 4130 å¥äº...\n",
            "[1309/1912] æ­£åœ¨ç²å–: 4131 æµ©æ³°...\n",
            "[1310/1912] æ­£åœ¨ç²å–: 4138 æ›œäº...\n",
            "[1311/1912] æ­£åœ¨ç²å–: 4139 é¦¬å…‰-KY...\n",
            "[1312/1912] æ­£åœ¨ç²å–: 4147 ä¸­è£•...\n",
            "[1313/1912] æ­£åœ¨ç²å–: 4153 éˆºç·¯...\n",
            "[1314/1912] æ­£åœ¨ç²å–: 4154 æ¨‚å¨ç§‘-KY...\n",
            "[1315/1912] æ­£åœ¨ç²å–: 4157 å¤ªæ™¯*-KY...\n",
            "[1316/1912] æ­£åœ¨ç²å–: 4160 è¨Šè¯åŸºå› ...\n",
            "[1317/1912] æ­£åœ¨ç²å–: 4161 è¿æ–°ç§‘...\n",
            "[1318/1912] æ­£åœ¨ç²å–: 4162 æ™ºæ“...\n",
            "[1319/1912] æ­£åœ¨ç²å–: 4163 é¿éˆ¦...\n",
            "[1320/1912] æ­£åœ¨ç²å–: 4167 æ¾ç‘è—¥...\n",
            "[1321/1912] æ­£åœ¨ç²å–: 4168 é†£è¯...\n",
            "[1322/1912] æ­£åœ¨ç²å–: 4171 ç‘åŸº...\n",
            "[1323/1912] æ­£åœ¨ç²å–: 4173 ä¹…è£•...\n",
            "[1324/1912] æ­£åœ¨ç²å–: 4174 æµ©é¼...\n",
            "[1325/1912] æ­£åœ¨ç²å–: 4175 æä¸€...\n",
            "[1326/1912] æ­£åœ¨ç²å–: 4183 ç¦æ°¸ç”ŸæŠ€...\n",
            "[1327/1912] æ­£åœ¨ç²å–: 4188 å®‰å…‹...\n",
            "[1328/1912] æ­£åœ¨ç²å–: 4192 æåœ‹...\n",
            "[1329/1912] æ­£åœ¨ç²å–: 4198 æ¬£å¤§å¥åº·...\n",
            "[1330/1912] æ­£åœ¨ç²å–: 4205 ä¸­è¯é£Ÿ...\n",
            "[1331/1912] æ­£åœ¨ç²å–: 4207 ç’°æ³°...\n",
            "[1332/1912] æ­£åœ¨ç²å–: 4303 ä¿¡ç«‹...\n",
            "[1333/1912] æ­£åœ¨ç²å–: 4304 å‹æ˜±...\n",
            "[1334/1912] æ­£åœ¨ç²å–: 4305 ä¸–å¤...\n",
            "[1335/1912] æ­£åœ¨ç²å–: 4401 æ±éš†èˆˆ...\n",
            "[1336/1912] æ­£åœ¨ç²å–: 4402 éƒ¡éƒ½é–‹ç™¼...\n",
            "[1337/1912] æ­£åœ¨ç²å–: 4406 æ–°æ˜•çº–...\n",
            "[1338/1912] æ­£åœ¨ç²å–: 4413 é£›å¯¶ä¼æ¥­...\n",
            "[1339/1912] æ­£åœ¨ç²å–: 4416 ä¸‰åœ“...\n",
            "[1340/1912] æ­£åœ¨ç²å–: 4417 é‡‘æ´²...\n",
            "[1341/1912] æ­£åœ¨ç²å–: 4419 çš‡å®¶ç¾é£Ÿ...\n",
            "[1342/1912] æ­£åœ¨ç²å–: 4420 å…‰æ˜...\n",
            "[1343/1912] æ­£åœ¨ç²å–: 4430 è€€å„„...\n",
            "[1344/1912] æ­£åœ¨ç²å–: 4432 éŠ˜æ—ºå¯¦...\n",
            "[1345/1912] æ­£åœ¨ç²å–: 4433 èˆˆé‡‡...\n",
            "[1346/1912] æ­£åœ¨ç²å–: 4442 ç«£é‚¦-KY...\n",
            "[1347/1912] æ­£åœ¨ç²å–: 4502 å¥ä¿¡...\n",
            "[1348/1912] æ­£åœ¨ç²å–: 4503 é‡‘é›¨...\n",
            "[1349/1912] æ­£åœ¨ç²å–: 4506 å´‡å‹...\n",
            "[1350/1912] æ­£åœ¨ç²å–: 4510 é«˜é‹’...\n",
            "[1351/1912] æ­£åœ¨ç²å–: 4513 ç¦è£•...\n",
            "[1352/1912] æ­£åœ¨ç²å–: 4523 æ°¸å½°...\n",
            "[1353/1912] æ­£åœ¨ç²å–: 4527 æ–¹åœŸéœ–...\n",
            "[1354/1912] æ­£åœ¨ç²å–: 4528 æ±Ÿèˆˆé›...\n",
            "[1355/1912] æ­£åœ¨ç²å–: 4529 æ·³ç´³...\n",
            "[1356/1912] æ­£åœ¨ç²å–: 4530 å®æ˜“...\n",
            "[1357/1912] æ­£åœ¨ç²å–: 4533 å”æ˜“æ©Ÿ...\n",
            "[1358/1912] æ­£åœ¨ç²å–: 4534 æ…¶é¨°...\n",
            "[1359/1912] æ­£åœ¨ç²å–: 4535 è‡³èˆˆ...\n",
            "[1360/1912] æ­£åœ¨ç²å–: 4538 å¤§è© åŸ...\n",
            "[1361/1912] æ­£åœ¨ç²å–: 4541 æ™Ÿç”°...\n",
            "[1362/1912] æ­£åœ¨ç²å–: 4542 ç§‘å¶ ...\n",
            "[1363/1912] æ­£åœ¨ç²å–: 4543 è¬åœ¨...\n",
            "[1364/1912] æ­£åœ¨ç²å–: 4549 æ¡“é”...\n",
            "[1365/1912] æ­£åœ¨ç²å–: 4550 é•·ä½³...\n",
            "[1366/1912] æ­£åœ¨ç²å–: 4554 æ©™çš„...\n",
            "[1367/1912] æ­£åœ¨ç²å–: 4556 æ—­ç„¶...\n",
            "[1368/1912] æ­£åœ¨ç²å–: 4558 å¯¶ç·¯...\n",
            "[1369/1912] æ­£åœ¨ç²å–: 4561 å¥æ¤¿...\n",
            "[1370/1912] æ­£åœ¨ç²å–: 4563 ç™¾å¾·...\n",
            "[1371/1912] æ­£åœ¨ç²å–: 4568 ç§‘éš›ç²¾å¯†...\n",
            "[1372/1912] æ­£åœ¨ç²å–: 4577 é”èˆªç§‘æŠ€...\n",
            "[1373/1912] æ­£åœ¨ç²å–: 4580 æ·æµé–¥æ¥­...\n",
            "[1374/1912] æ­£åœ¨ç²å–: 4584 å›å¸†...\n",
            "[1375/1912] æ­£åœ¨ç²å–: 4609 å”é‹’...\n",
            "[1376/1912] æ­£åœ¨ç²å–: 4702 ä¸­ç¾å¯¦...\n",
            "[1377/1912] æ­£åœ¨ç²å–: 4706 å¤§æ­...\n",
            "[1378/1912] æ­£åœ¨ç²å–: 4707 ç£äº...\n",
            "[1379/1912] æ­£åœ¨ç²å–: 4711 æ°¸ç´”...\n",
            "[1380/1912] æ­£åœ¨ç²å–: 4714 æ°¸æ·...\n",
            "[1381/1912] æ­£åœ¨ç²å–: 4716 å¤§ç«‹...\n",
            "[1382/1912] æ­£åœ¨ç²å–: 4721 ç¾çªç‘ª...\n",
            "[1383/1912] æ­£åœ¨ç²å–: 4726 æ°¸æ˜•...\n",
            "[1384/1912] æ­£åœ¨ç²å–: 4728 é›™ç¾...\n",
            "[1385/1912] æ­£åœ¨ç²å–: 4729 ç†’èŒ‚...\n",
            "[1386/1912] æ­£åœ¨ç²å–: 4735 è±ªå±•...\n",
            "[1387/1912] æ­£åœ¨ç²å–: 4741 æ³“ç€š...\n",
            "[1388/1912] æ­£åœ¨ç²å–: 4743 åˆä¸€...\n",
            "[1389/1912] æ­£åœ¨ç²å–: 4744 çš‡å°‡...\n",
            "[1390/1912] æ­£åœ¨ç²å–: 4745 åˆå¯Œ-KY...\n",
            "[1391/1912] æ­£åœ¨ç²å–: 4747 å¼·ç”Ÿ...\n",
            "[1392/1912] æ­£åœ¨ç²å–: 4749 æ–°æ‡‰æ...\n",
            "[1393/1912] æ­£åœ¨ç²å–: 4754 åœ‹ç¢³ç§‘...\n",
            "[1394/1912] æ­£åœ¨ç²å–: 4760 å‹¤å‡±...\n",
            "[1395/1912] æ­£åœ¨ç²å–: 4767 èª æ³°ç§‘æŠ€...\n",
            "[1396/1912] æ­£åœ¨ç²å–: 4768 æ™¶å‘ˆç§‘æŠ€...\n",
            "[1397/1912] æ­£åœ¨ç²å–: 4772 å°ç‰¹åŒ–...\n",
            "[1398/1912] æ­£åœ¨ç²å–: 4804 å¤§ç•¥-KY...\n",
            "[1399/1912] æ­£åœ¨ç²å–: 4806 æ¡‚ç”°æ–‡å‰µ...\n",
            "[1400/1912] æ­£åœ¨ç²å–: 4903 è¯å…‰é€š...\n",
            "[1401/1912] æ­£åœ¨ç²å–: 4905 å°è¯é›»...\n",
            "[1402/1912] æ­£åœ¨ç²å–: 4907 å¯Œå®‡...\n",
            "[1403/1912] æ­£åœ¨ç²å–: 4908 å‰é¼...\n",
            "[1404/1912] æ­£åœ¨ç²å–: 4909 æ–°å¾©èˆˆ...\n",
            "[1405/1912] æ­£åœ¨ç²å–: 4911 å¾·è‹±...\n",
            "[1406/1912] æ­£åœ¨ç²å–: 4923 åŠ›å£«...\n",
            "[1407/1912] æ­£åœ¨ç²å–: 4924 æ¬£åš-KY...\n",
            "[1408/1912] æ­£åœ¨ç²å–: 4931 æ–°ç››åŠ›...\n",
            "[1409/1912] æ­£åœ¨ç²å–: 4933 å‹è¼...\n",
            "[1410/1912] æ­£åœ¨ç²å–: 4939 äºé›»...\n",
            "[1411/1912] æ­£åœ¨ç²å–: 4945 é™é”ç§‘æŠ€...\n",
            "[1412/1912] æ­£åœ¨ç²å–: 4946 è¾£æ¤’...\n",
            "[1413/1912] æ­£åœ¨ç²å–: 4950 é‡‘è€˜åœ‹éš›...\n",
            "[1414/1912] æ­£åœ¨ç²å–: 4951 ç²¾æ‹“ç§‘...\n",
            "[1415/1912] æ­£åœ¨ç²å–: 4953 ç·¯è»Ÿ...\n",
            "[1416/1912] æ­£åœ¨ç²å–: 4966 è­œç‘-KY...\n",
            "[1417/1912] æ­£åœ¨ç²å–: 4971 IET-KY...\n",
            "[1418/1912] æ­£åœ¨ç²å–: 4972 æ¹¯çŸ³ç…§æ˜...\n",
            "[1419/1912] æ­£åœ¨ç²å–: 4973 å»£ç©...\n",
            "[1420/1912] æ­£åœ¨ç²å–: 4974 äºæ³°...\n",
            "[1421/1912] æ­£åœ¨ç²å–: 4979 è¯æ˜Ÿå…‰...\n",
            "[1422/1912] æ­£åœ¨ç²å–: 4987 ç§‘èª ...\n",
            "[1423/1912] æ­£åœ¨ç²å–: 4991 ç’°å®‡-KY...\n",
            "[1424/1912] æ­£åœ¨ç²å–: 4995 æ™¶é”...\n",
            "[1425/1912] æ­£åœ¨ç²å–: 5009 æ¦®å‰›...\n",
            "[1426/1912] æ­£åœ¨ç²å–: 5011 ä¹…é™½...\n",
            "[1427/1912] æ­£åœ¨ç²å–: 5013 å¼·æ–°...\n",
            "[1428/1912] æ­£åœ¨ç²å–: 5014 å»ºéŒ©...\n",
            "[1429/1912] æ­£åœ¨ç²å–: 5015 è¯ç¥º...\n",
            "[1430/1912] æ­£åœ¨ç²å–: 5016 æ¾å’Œ...\n",
            "[1431/1912] æ­£åœ¨ç²å–: 5201 å‡±è¡›...\n",
            "[1432/1912] æ­£åœ¨ç²å–: 5202 åŠ›æ–°...\n",
            "[1433/1912] æ­£åœ¨ç²å–: 5205 ä¸­èŒ‚...\n",
            "[1434/1912] æ­£åœ¨ç²å–: 5206 å¤æ‚…...\n",
            "[1435/1912] æ­£åœ¨ç²å–: 5209 æ–°é¼...\n",
            "[1436/1912] æ­£åœ¨ç²å–: 5210 å¯¶ç¢©...\n",
            "[1437/1912] æ­£åœ¨ç²å–: 5211 è’™æ¬...\n",
            "[1438/1912] æ­£åœ¨ç²å–: 5212 å‡Œç¶²...\n",
            "[1439/1912] æ­£åœ¨ç²å–: 5213 äºæ˜•...\n",
            "[1440/1912] æ­£åœ¨ç²å–: 5220 è¬é”å…‰é›»...\n",
            "[1441/1912] æ­£åœ¨ç²å–: 5223 å®‰åŠ›-KY...\n",
            "[1442/1912] æ­£åœ¨ç²å–: 5227 ç«‹å‡±-KY...\n",
            "[1443/1912] æ­£åœ¨ç²å–: 5228 éˆºé§...\n",
            "[1444/1912] æ­£åœ¨ç²å–: 5230 é›·ç¬›å…‹å…‰å­¸...\n",
            "[1445/1912] æ­£åœ¨ç²å–: 5236 å‡Œé™½å‰µæ–°...\n",
            "[1446/1912] æ­£åœ¨ç²å–: 5245 æ™ºæ™¶...\n",
            "[1447/1912] æ­£åœ¨ç²å–: 5251 å¤©é‰é›»...\n",
            "[1448/1912] æ­£åœ¨ç²å–: 5263 æ™ºå´´...\n",
            "[1449/1912] æ­£åœ¨ç²å–: 5272 ç¬™ç§‘...\n",
            "[1450/1912] æ­£åœ¨ç²å–: 5274 ä¿¡é©Š...\n",
            "[1451/1912] æ­£åœ¨ç²å–: 5276 é”è¼-KY...\n",
            "[1452/1912] æ­£åœ¨ç²å–: 5278 å°šå‡¡*...\n",
            "[1453/1912] æ­£åœ¨ç²å–: 5287 æ•¸å­—...\n",
            "[1454/1912] æ­£åœ¨ç²å–: 5289 å®œé¼...\n",
            "[1455/1912] æ­£åœ¨ç²å–: 5291 é‚‘æ˜‡...\n",
            "[1456/1912] æ­£åœ¨ç²å–: 5299 æ°åŠ›...\n",
            "[1457/1912] æ­£åœ¨ç²å–: 5301 å¯¶å¾—åˆ©...\n",
            "[1458/1912] æ­£åœ¨ç²å–: 5302 å¤ªæ¬£...\n",
            "[1459/1912] æ­£åœ¨ç²å–: 5309 ç³»çµ±é›»...\n",
            "[1460/1912] æ­£åœ¨ç²å–: 5310 å¤©å‰›...\n",
            "[1461/1912] æ­£åœ¨ç²å–: 5312 å¯¶å³¶ç§‘...\n",
            "[1462/1912] æ­£åœ¨ç²å–: 5314 ä¸–ç´€*...\n",
            "[1463/1912] æ­£åœ¨ç²å–: 5315 å…‰è¯...\n",
            "[1464/1912] æ­£åœ¨ç²å–: 5321 ç¾è€Œå¿«...\n",
            "[1465/1912] æ­£åœ¨ç²å–: 5324 å£«é–‹...\n",
            "[1466/1912] æ­£åœ¨ç²å–: 5328 è¯å®¹...\n",
            "[1467/1912] æ­£åœ¨ç²å–: 5340 å»ºæ¦®...\n",
            "[1468/1912] æ­£åœ¨ç²å–: 5344 ç«‹è¡›...\n",
            "[1469/1912] æ­£åœ¨ç²å–: 5345 å¤©æš...\n",
            "[1470/1912] æ­£åœ¨ç²å–: 5347 ä¸–ç•Œ...\n",
            "[1471/1912] æ­£åœ¨ç²å–: 5348 æ­£èƒ½é‡æ™ºèƒ½...\n",
            "[1472/1912] æ­£åœ¨ç²å–: 5351 éˆºå‰µ...\n",
            "[1473/1912] æ­£åœ¨ç²å–: 5353 å°æ—...\n",
            "[1474/1912] æ­£åœ¨ç²å–: 5355 ä½³ç¸½...\n",
            "[1475/1912] æ­£åœ¨ç²å–: 5356 å”ç›Š...\n",
            "[1476/1912] æ­£åœ¨ç²å–: 5364 åŠ›éº—åº—...\n",
            "[1477/1912] æ­£åœ¨ç²å–: 5371 ä¸­å…‰é›»...\n",
            "[1478/1912] æ­£åœ¨ç²å–: 5381 åˆæ­£...\n",
            "[1479/1912] æ­£åœ¨ç²å–: 5386 é’é›²...\n",
            "[1480/1912] æ­£åœ¨ç²å–: 5392 èƒ½ç‡...\n",
            "[1481/1912] æ­£åœ¨ç²å–: 5398 æ…•åº·ç”Ÿé†«...\n",
            "[1482/1912] æ­£åœ¨ç²å–: 5403 ä¸­è²...\n",
            "[1483/1912] æ­£åœ¨ç²å–: 5410 åœ‹çœ¾...\n",
            "[1484/1912] æ­£åœ¨ç²å–: 5425 å°åŠ...\n",
            "[1485/1912] æ­£åœ¨ç²å–: 5426 æŒ¯ç™¼...\n",
            "[1486/1912] æ­£åœ¨ç²å–: 5432 æ–°é–€...\n",
            "[1487/1912] æ­£åœ¨ç²å–: 5438 æ±å‹...\n",
            "[1488/1912] æ­£åœ¨ç²å–: 5439 é«˜æŠ€...\n",
            "[1489/1912] æ­£åœ¨ç²å–: 5443 å‡è±ª...\n",
            "[1490/1912] æ­£åœ¨ç²å–: 5450 å—è‰¯...\n",
            "[1491/1912] æ­£åœ¨ç²å–: 5452 ä½¶å„ª...\n",
            "[1492/1912] æ­£åœ¨ç²å–: 5455 æ˜‡ç›Š...\n",
            "[1493/1912] æ­£åœ¨ç²å–: 5457 å®£å¾·...\n",
            "[1494/1912] æ­£åœ¨ç²å–: 5460 åŒå”...\n",
            "[1495/1912] æ­£åœ¨ç²å–: 5464 éœ–å®...\n",
            "[1496/1912] æ­£åœ¨ç²å–: 5465 å¯Œé©Š...\n",
            "[1497/1912] æ­£åœ¨ç²å–: 5468 å‡±éˆº...\n",
            "[1498/1912] æ­£åœ¨ç²å–: 5474 è°æ³°...\n",
            "[1499/1912] æ­£åœ¨ç²å–: 5475 å¾·å®...\n",
            "[1500/1912] æ­£åœ¨ç²å–: 5478 æ™ºå† ...\n",
            "[1501/1912] æ­£åœ¨ç²å–: 5481 æ–°è¯...\n",
            "[1502/1912] æ­£åœ¨ç²å–: 5483 ä¸­ç¾æ™¶...\n",
            "[1503/1912] æ­£åœ¨ç²å–: 5487 é€šæ³°...\n",
            "[1504/1912] æ­£åœ¨ç²å–: 5488 æ¾æ™®...\n",
            "[1505/1912] æ­£åœ¨ç²å–: 5489 å½©å¯Œ...\n",
            "[1506/1912] æ­£åœ¨ç²å–: 5490 åŒäº¨...\n",
            "[1507/1912] æ­£åœ¨ç²å–: 5493 ä¸‰è¯...\n",
            "[1508/1912] æ­£åœ¨ç²å–: 5498 å‡±å´´...\n",
            "[1509/1912] æ­£åœ¨ç²å–: 5508 æ°¸ä¿¡å»º...\n",
            "[1510/1912] æ­£åœ¨ç²å–: 5511 å¾·æ˜Œ...\n",
            "[1511/1912] æ­£åœ¨ç²å–: 5512 åŠ›éº’...\n",
            "[1512/1912] æ­£åœ¨ç²å–: 5514 ä¸‰è±...\n",
            "[1513/1912] æ­£åœ¨ç²å–: 5516 é›™å–œ...\n",
            "[1514/1912] æ­£åœ¨ç²å–: 5520 åŠ›æ³°...\n",
            "[1515/1912] æ­£åœ¨ç²å–: 5523 è±è¬™...\n",
            "[1516/1912] æ­£åœ¨ç²å–: 5529 é‰…é™...\n",
            "[1517/1912] æ­£åœ¨ç²å–: 5530 é¾å·–...\n",
            "[1518/1912] æ­£åœ¨ç²å–: 5536 è–æš‰*...\n",
            "[1519/1912] æ­£åœ¨ç²å–: 5543 æ¡“é¼-KY...\n",
            "[1520/1912] æ­£åœ¨ç²å–: 5548 å®‰å€‰...\n",
            "[1521/1912] æ­£åœ¨ç²å–: 5601 å°è¯æ«ƒ...\n",
            "[1522/1912] æ­£åœ¨ç²å–: 5603 é™¸æµ·...\n",
            "[1523/1912] æ­£åœ¨ç²å–: 5604 ä¸­é€£...\n",
            "[1524/1912] æ­£åœ¨ç²å–: 5609 ä¸­è²è¡Œ...\n",
            "[1525/1912] æ­£åœ¨ç²å–: 5701 åŠæ¹–å±±...\n",
            "[1526/1912] æ­£åœ¨ç²å–: 5703 äºéƒ½...\n",
            "[1527/1912] æ­£åœ¨ç²å–: 5704 è€çˆºçŸ¥...\n",
            "[1528/1912] æ­£åœ¨ç²å–: 5864 è‡´å’Œè­‰...\n",
            "[1529/1912] æ­£åœ¨ç²å–: 5878 å°å...\n",
            "[1530/1912] æ­£åœ¨ç²å–: 5902 å¾·è¨˜...\n",
            "[1531/1912] æ­£åœ¨ç²å–: 5903 å…¨å®¶...\n",
            "[1532/1912] æ­£åœ¨ç²å–: 5904 å¯¶é›…...\n",
            "[1533/1912] æ­£åœ¨ç²å–: 5905 å—ä»æ¹–...\n",
            "[1534/1912] æ­£åœ¨ç²å–: 6015 å®é è­‰...\n",
            "[1535/1912] æ­£åœ¨ç²å–: 6016 åº·å’Œè­‰...\n",
            "[1536/1912] æ­£åœ¨ç²å–: 6020 å¤§å±•è­‰...\n",
            "[1537/1912] æ­£åœ¨ç²å–: 6021 ç¾å¥½è­‰...\n",
            "[1538/1912] æ­£åœ¨ç²å–: 6023 å…ƒå¤§æœŸ...\n",
            "[1539/1912] æ­£åœ¨ç²å–: 6026 ç¦é‚¦è­‰...\n",
            "[1540/1912] æ­£åœ¨ç²å–: 6101 å¯¬é­šåœ‹éš›...\n",
            "[1541/1912] æ­£åœ¨ç²å–: 6103 åˆé‚¦...\n",
            "[1542/1912] æ­£åœ¨ç²å–: 6104 å‰µæƒŸ...\n",
            "[1543/1912] æ­£åœ¨ç²å–: 6109 äºå…ƒ...\n",
            "[1544/1912] æ­£åœ¨ç²å–: 6111 å¤§å®‡è³‡...\n",
            "[1545/1912] æ­£åœ¨ç²å–: 6113 äºçŸ½...\n",
            "[1546/1912] æ­£åœ¨ç²å–: 6114 ä¹…å¨...\n",
            "[1547/1912] æ­£åœ¨ç²å–: 6118 å»ºé”...\n",
            "[1548/1912] æ­£åœ¨ç²å–: 6121 æ–°æ™®...\n",
            "[1549/1912] æ­£åœ¨ç²å–: 6122 æ“é‚¦...\n",
            "[1550/1912] æ­£åœ¨ç²å–: 6123 ä¸Šå¥‡...\n",
            "[1551/1912] æ­£åœ¨ç²å–: 6124 æ¥­å¼·...\n",
            "[1552/1912] æ­£åœ¨ç²å–: 6125 å»£é‹...\n",
            "[1553/1912] æ­£åœ¨ç²å–: 6126 ä¿¡éŸ³...\n",
            "[1554/1912] æ­£åœ¨ç²å–: 6127 ä¹è±ª...\n",
            "[1555/1912] æ­£åœ¨ç²å–: 6129 æ™®èª ...\n",
            "[1556/1912] æ­£åœ¨ç²å–: 6130 ä¸Šäºç§‘æŠ€...\n",
            "[1557/1912] æ­£åœ¨ç²å–: 6134 è¬æ—­...\n",
            "[1558/1912] æ­£åœ¨ç²å–: 6138 èŒ‚é”...\n",
            "[1559/1912] æ­£åœ¨ç²å–: 6140 è¨Šé”...\n",
            "[1560/1912] æ­£åœ¨ç²å–: 6143 æŒ¯æ›œ...\n",
            "[1561/1912] æ­£åœ¨ç²å–: 6144 å¾—åˆ©å½±...\n",
            "[1562/1912] æ­£åœ¨ç²å–: 6146 è€•èˆˆ...\n",
            "[1563/1912] æ­£åœ¨ç²å–: 6147 é é‚¦...\n",
            "[1564/1912] æ­£åœ¨ç²å–: 6148 é©Šå®è³‡...\n",
            "[1565/1912] æ­£åœ¨ç²å–: 6150 æ’¼è¨Š...\n",
            "[1566/1912] æ­£åœ¨ç²å–: 6151 æ™‰å€«...\n",
            "[1567/1912] æ­£åœ¨ç²å–: 6154 é †ç™¼...\n",
            "[1568/1912] æ­£åœ¨ç²å–: 6156 æ¾ä¸Š...\n",
            "[1569/1912] æ­£åœ¨ç²å–: 6158 ç¦¾æ˜Œ...\n",
            "[1570/1912] æ­£åœ¨ç²å–: 6160 æ¬£æŠ€...\n",
            "[1571/1912] æ­£åœ¨ç²å–: 6161 æ·æ³¢...\n",
            "[1572/1912] æ­£åœ¨ç²å–: 6163 è¯é›»ç¶²...\n",
            "[1573/1912] æ­£åœ¨ç²å–: 6167 ä¹…æ­£...\n",
            "[1574/1912] æ­£åœ¨ç²å–: 6169 æ˜±æ³‰...\n",
            "[1575/1912] æ­£åœ¨ç²å–: 6170 çµ±æŒ¯...\n",
            "[1576/1912] æ­£åœ¨ç²å–: 6171 å¤§åŸåœ°ç”¢...\n",
            "[1577/1912] æ­£åœ¨ç²å–: 6173 ä¿¡æ˜Œé›»...\n",
            "[1578/1912] æ­£åœ¨ç²å–: 6174 å®‰ï¿½ï¿½...\n",
            "[1579/1912] æ­£åœ¨ç²å–: 6175 ç«‹æ•¦...\n",
            "[1580/1912] æ­£åœ¨ç²å–: 6179 äºé€š...\n",
            "[1581/1912] æ­£åœ¨ç²å–: 6180 æ©˜å­...\n",
            "[1582/1912] æ­£åœ¨ç²å–: 6182 åˆæ™¶...\n",
            "[1583/1912] æ­£åœ¨ç²å–: 6185 å¹ƒç¿”...\n",
            "[1584/1912] æ­£åœ¨ç²å–: 6186 æ–°æ½¤...\n",
            "[1585/1912] æ­£åœ¨ç²å–: 6187 è¬æ½¤...\n",
            "[1586/1912] æ­£åœ¨ç²å–: 6188 å»£æ˜...\n",
            "[1587/1912] æ­£åœ¨ç²å–: 6190 è¬æ³°ç§‘...\n",
            "[1588/1912] æ­£åœ¨ç²å–: 6194 è‚²å¯Œ...\n",
            "[1589/1912] æ­£åœ¨ç²å–: 6195 è©©è‚¯...\n",
            "[1590/1912] æ­£åœ¨ç²å–: 6198 ç‘ç¯‰...\n",
            "[1591/1912] æ­£åœ¨ç²å–: 6199 å¤©å“...\n",
            "[1592/1912] æ­£åœ¨ç²å–: 6203 æµ·éŸ»é›»...\n",
            "[1593/1912] æ­£åœ¨ç²å–: 6204 è‰¾è¯...\n",
            "[1594/1912] æ­£åœ¨ç²å–: 6207 é›·ç§‘...\n",
            "[1595/1912] æ­£åœ¨ç²å–: 6208 æ—¥æš...\n",
            "[1596/1912] æ­£åœ¨ç²å–: 6210 æ…¶ç”Ÿ...\n",
            "[1597/1912] æ­£åœ¨ç²å–: 6212 ç†éŠ˜...\n",
            "[1598/1912] æ­£åœ¨ç²å–: 6217 ä¸­æ¢é‡...\n",
            "[1599/1912] æ­£åœ¨ç²å–: 6218 è±ªå‹‰...\n",
            "[1600/1912] æ­£åœ¨ç²å–: 6219 å¯Œæ—º...\n",
            "[1601/1912] æ­£åœ¨ç²å–: 6220 å²³è±...\n",
            "[1602/1912] æ­£åœ¨ç²å–: 6221 æ™‰æ³°...\n",
            "[1603/1912] æ­£åœ¨ç²å–: 6222 ç«‹è»’...\n",
            "[1604/1912] æ­£åœ¨ç²å–: 6223 æ—ºçŸ½...\n",
            "[1605/1912] æ­£åœ¨ç²å–: 6227 èŒ‚ç¶¸...\n",
            "[1606/1912] æ­£åœ¨ç²å–: 6228 å…¨è­œ...\n",
            "[1607/1912] æ­£åœ¨ç²å–: 6229 ç ”é€š...\n",
            "[1608/1912] æ­£åœ¨ç²å–: 6231 ç³»å¾®...\n",
            "[1609/1912] æ­£åœ¨ç²å–: 6233 æ—ºç–...\n",
            "[1610/1912] æ­£åœ¨ç²å–: 6234 é«˜åƒ‘...\n",
            "[1611/1912] æ­£åœ¨ç²å–: 6236 ä¸­æ¹›...\n",
            "[1612/1912] æ­£åœ¨ç²å–: 6237 é©Šè¨Š...\n",
            "[1613/1912] æ­£åœ¨ç²å–: 6240 æ¾å´—...\n",
            "[1614/1912] æ­£åœ¨ç²å–: 6241 æ˜“é€šå±•...\n",
            "[1615/1912] æ­£åœ¨ç²å–: 6242 ç«‹åº·...\n",
            "[1616/1912] æ­£åœ¨ç²å–: 6244 èŒ‚è¿ª...\n",
            "[1617/1912] æ­£åœ¨ç²å–: 6245 ç«‹ç«¯...\n",
            "[1618/1912] æ­£åœ¨ç²å–: 6246 è‡ºé¾...\n",
            "[1619/1912] æ­£åœ¨ç²å–: 6248 æ²›æ³¢...\n",
            "[1620/1912] æ­£åœ¨ç²å–: 6259 ç™¾å¾½...\n",
            "[1621/1912] æ­£åœ¨ç²å–: 6261 ä¹…å…ƒ...\n",
            "[1622/1912] æ­£åœ¨ç²å–: 6263 æ™®èŠå¾·...\n",
            "[1623/1912] æ­£åœ¨ç²å–: 6264 å¯Œè£”...\n",
            "[1624/1912] æ­£åœ¨ç²å–: 6265 æ–¹åœŸæ˜¶...\n",
            "[1625/1912] æ­£åœ¨ç²å–: 6266 æ³°è© ...\n",
            "[1626/1912] æ­£åœ¨ç²å–: 6270 å€å¾®...\n",
            "[1627/1912] æ­£åœ¨ç²å–: 6274 å°ç‡¿...\n",
            "[1628/1912] æ­£åœ¨ç²å–: 6275 å…ƒå±±...\n",
            "[1629/1912] æ­£åœ¨ç²å–: 6276 å®‰éˆ¦å…‹...\n",
            "[1630/1912] æ­£åœ¨ç²å–: 6279 èƒ¡é€£...\n",
            "[1631/1912] æ­£åœ¨ç²å–: 6284 ä½³é‚¦...\n",
            "[1632/1912] æ­£åœ¨ç²å–: 6290 è‰¯ç¶­...\n",
            "[1633/1912] æ­£åœ¨ç²å–: 6291 æ²›äº¨...\n",
            "[1634/1912] æ­£åœ¨ç²å–: 6292 è¿…å¾·...\n",
            "[1635/1912] æ­£åœ¨ç²å–: 6294 æ™ºåŸº...\n",
            "[1636/1912] æ­£åœ¨ç²å–: 6411 æ™¶ç„±...\n",
            "[1637/1912] æ­£åœ¨ç²å–: 6417 éŸ‹åƒ‘...\n",
            "[1638/1912] æ­£åœ¨ç²å–: 6418 è© æ˜‡...\n",
            "[1639/1912] æ­£åœ¨ç²å–: 6419 äº¬æ™¨ç§‘...\n",
            "[1640/1912] æ­£åœ¨ç²å–: 6425 æ˜“ç™¼...\n",
            "[1641/1912] æ­£åœ¨ç²å–: 6432 ä»Šå±•ç§‘...\n",
            "[1642/1912] æ­£åœ¨ç²å–: 6435 å¤§ä¸­...\n",
            "[1643/1912] æ­£åœ¨ç²å–: 6441 å»£éŒ ...\n",
            "[1644/1912] æ­£åœ¨ç²å–: 6461 ç›Šå¾—...\n",
            "[1645/1912] æ­£åœ¨ç²å–: 6462 ç¥ç›¾...\n",
            "[1646/1912] æ­£åœ¨ç²å–: 6465 å¨æ½¤...\n",
            "[1647/1912] æ­£åœ¨ç²å–: 6469 å¤§æ¨¹...\n",
            "[1648/1912] æ­£åœ¨ç²å–: 6470 å®‡æ™º...\n",
            "[1649/1912] æ­£åœ¨ç²å–: 6482 å¼˜ç…œç§‘...\n",
            "[1650/1912] æ­£åœ¨ç²å–: 6485 é»åº...\n",
            "[1651/1912] æ­£åœ¨ç²å–: 6486 äº’å‹•...\n",
            "[1652/1912] æ­£åœ¨ç²å–: 6488 ç’°çƒæ™¶...\n",
            "[1653/1912] æ­£åœ¨ç²å–: 6492 ç”Ÿè¯ç§‘...\n",
            "[1654/1912] æ­£åœ¨ç²å–: 6494 ä¹é½Š...\n",
            "[1655/1912] æ­£åœ¨ç²å–: 6496 ç§‘æ‡‹...\n",
            "[1656/1912] æ­£åœ¨ç²å–: 6498 ä¹…ç¦¾å…‰...\n",
            "[1657/1912] æ­£åœ¨ç²å–: 6499 ç›Šå®‰...\n",
            "[1658/1912] æ­£åœ¨ç²å–: 6506 é›™é‚¦...\n",
            "[1659/1912] æ­£åœ¨ç²å–: 6508 æƒ å…‰...\n",
            "[1660/1912] æ­£åœ¨ç²å–: 6509 èšå’Œ...\n",
            "[1661/1912] æ­£åœ¨ç²å–: 6510 ç²¾æ¸¬...\n",
            "[1662/1912] æ­£åœ¨ç²å–: 6512 å•Ÿç™¼é›»...\n",
            "[1663/1912] æ­£åœ¨ç²å–: 6516 å‹¤å´´åœ‹éš›...\n",
            "[1664/1912] æ­£åœ¨ç²å–: 6517 ä¿å‹å…‰å­¸...\n",
            "[1665/1912] æ­£åœ¨ç²å–: 6523 é”çˆ¾è†š...\n",
            "[1666/1912] æ­£åœ¨ç²å–: 6527 æ˜é”é†«...\n",
            "[1667/1912] æ­£åœ¨ç²å–: 6530 å‰µå¨...\n",
            "[1668/1912] æ­£åœ¨ç²å–: 6532 ç‘è€˜...\n",
            "[1669/1912] æ­£åœ¨ç²å–: 6535 é †è—¥...\n",
            "[1670/1912] æ­£åœ¨ç²å–: 6538 å€‰å’Œ...\n",
            "[1671/1912] æ­£åœ¨ç²å–: 6542 éš†ä¸­...\n",
            "[1672/1912] æ­£åœ¨ç²å–: 6546 æ­£åŸº...\n",
            "[1673/1912] æ­£åœ¨ç²å–: 6547 é«˜ç«¯ç–«è‹—...\n",
            "[1674/1912] æ­£åœ¨ç²å–: 6548 é•·ç§‘*...\n",
            "[1675/1912] æ­£åœ¨ç²å–: 6556 å‹å“...\n",
            "[1676/1912] æ­£åœ¨ç²å–: 6560 æ¬£æ™®ç¾…...\n",
            "[1677/1912] æ­£åœ¨ç²å–: 6561 æ˜¯æ–¹...\n",
            "[1678/1912] æ­£åœ¨ç²å–: 6568 å®è§€...\n",
            "[1679/1912] æ­£åœ¨ç²å–: 6569 é†«æš...\n",
            "[1680/1912] æ­£åœ¨ç²å–: 6570 ç¶­ç”°...\n",
            "[1681/1912] æ­£åœ¨ç²å–: 6574 éœˆæ–¹...\n",
            "[1682/1912] æ­£åœ¨ç²å–: 6576 é€¸é”...\n",
            "[1683/1912] æ­£åœ¨ç²å–: 6577 å‹è±...\n",
            "[1684/1912] æ­£åœ¨ç²å–: 6578 é”é‚¦è›‹ç™½...\n",
            "[1685/1912] æ­£åœ¨ç²å–: 6584 å—ä¿Šåœ‹éš›...\n",
            "[1686/1912] æ­£åœ¨ç²å–: 6588 æ±å…¸å…‰é›»...\n",
            "[1687/1912] æ­£åœ¨ç²å–: 6590 æ™®é´»...\n",
            "[1688/1912] æ­£åœ¨ç²å–: 6593 å°ç£éŠ˜æ¿...\n",
            "[1689/1912] æ­£åœ¨ç²å–: 6596 å¯¬å®è—è¡“...\n",
            "[1690/1912] æ­£åœ¨ç²å–: 6597 ç«‹èª ...\n",
            "[1691/1912] æ­£åœ¨ç²å–: 6603 å¯Œå¼·é‘«...\n",
            "[1692/1912] æ­£åœ¨ç²å–: 6609 ç€§æ¾¤ç§‘...\n",
            "[1693/1912] æ­£åœ¨ç²å–: 6612 å¥ˆç±³é†«æ...\n",
            "[1694/1912] æ­£åœ¨ç²å–: 6613 æœ‹å„„*...\n",
            "[1695/1912] æ­£åœ¨ç²å–: 6615 æ…§æ™º...\n",
            "[1696/1912] æ­£åœ¨ç²å–: 6616 ç‰¹æ˜‡-KY...\n",
            "[1697/1912] æ­£åœ¨ç²å–: 6617 å…±ä¿¡-KY...\n",
            "[1698/1912] æ­£åœ¨ç²å–: 6624 è¬å¹´æ¸…...\n",
            "[1699/1912] æ­£åœ¨ç²å–: 6629 æ³°é‡‘-KY...\n",
            "[1700/1912] æ­£åœ¨ç²å–: 6637 é†«å½±...\n",
            "[1701/1912] æ­£åœ¨ç²å–: 6640 å‡è¯...\n",
            "[1702/1912] æ­£åœ¨ç²å–: 6642 å¯Œè‡´...\n",
            "[1703/1912] æ­£åœ¨ç²å–: 6643 M31...\n",
            "[1704/1912] æ­£åœ¨ç²å–: 6649 å°ç”Ÿæ...\n",
            "[1705/1912] æ­£åœ¨ç²å–: 6651 å…¨å®‡æ˜•...\n",
            "[1706/1912] æ­£åœ¨ç²å–: 6654 å¤©æ­£åœ‹éš›...\n",
            "[1707/1912] æ­£åœ¨ç²å–: 6661 å¨å¥ç”ŸæŠ€...\n",
            "[1708/1912] æ­£åœ¨ç²å–: 6662 æ¨‚æ–¯ç§‘...\n",
            "[1709/1912] æ­£åœ¨ç²å–: 6664 ç¾¤ç¿Š...\n",
            "[1710/1912] æ­£åœ¨ç²å–: 6667 ä¿¡ç´˜ç§‘...\n",
            "[1711/1912] æ­£åœ¨ç²å–: 6679 éˆºå¤ª...\n",
            "[1712/1912] æ­£åœ¨ç²å–: 6680 é‘«å‰µé›»å­...\n",
            "[1713/1912] æ­£åœ¨ç²å–: 6683 é›æ™ºç§‘æŠ€...\n",
            "[1714/1912] æ­£åœ¨ç²å–: 6684 å®‰æ ¼...\n",
            "[1715/1912] æ­£åœ¨ç²å–: 6690 å®‰ï¿½ç¡Œç©ˆT...\n",
            "[1716/1912] æ­£åœ¨ç²å–: 6692 é€²èƒ½æœ...\n",
            "[1717/1912] æ­£åœ¨ç²å–: 6693 å»£é–ç§‘...\n",
            "[1718/1912] æ­£åœ¨ç²å–: 6697 æ±æ·è³‡è¨Š...\n",
            "[1719/1912] æ­£åœ¨ç²å–: 6703 è»’éƒ...\n",
            "[1720/1912] æ­£åœ¨ç²å–: 6708 å¤©æ“...\n",
            "[1721/1912] æ­£åœ¨ç²å–: 6712 é•·è–...\n",
            "[1722/1912] æ­£åœ¨ç²å–: 6716 æ‡‰å»£...\n",
            "[1723/1912] æ­£åœ¨ç²å–: 6720 ä¹…æ˜Œ...\n",
            "[1724/1912] æ­£åœ¨ç²å–: 6721 ä¿¡å¯¦...\n",
            "[1725/1912] æ­£åœ¨ç²å–: 6727 äºæ³°é‡‘å±¬...\n",
            "[1726/1912] æ­£åœ¨ç²å–: 6728 ä¸Šæ´‹...\n",
            "[1727/1912] æ­£åœ¨ç²å–: 6732 æ˜‡ä½³é›»å­...\n",
            "[1728/1912] æ­£åœ¨ç²å–: 6733 åšæ™Ÿç”Ÿé†«...\n",
            "[1729/1912] æ­£åœ¨ç²å–: 6735 ç¾é”ç§‘æŠ€...\n",
            "[1730/1912] æ­£åœ¨ç²å–: 6739 ç«¹é™ç§‘æŠ€...\n",
            "[1731/1912] æ­£åœ¨ç²å–: 6741 91APP*-KY...\n",
            "[1732/1912] æ­£åœ¨ç²å–: 6747 äº¨æ³°å…‰...\n",
            "[1733/1912] æ­£åœ¨ç²å–: 6751 æ™ºè¯æœå‹™...\n",
            "[1734/1912] æ­£åœ¨ç²å–: 6752 å¡æš...\n",
            "[1735/1912] æ­£åœ¨ç²å–: 6761 ç©©å¾—...\n",
            "[1736/1912] æ­£åœ¨ç²å–: 6762 é”äº...\n",
            "[1737/1912] æ­£åœ¨ç²å–: 6763 ç¶ ç•Œç§‘æŠ€*...\n",
            "[1738/1912] æ­£åœ¨ç²å–: 6767 å°å¾®é†«...\n",
            "[1739/1912] æ­£åœ¨ç²å–: 6785 æ˜±å±•æ–°è—¥...\n",
            "[1740/1912] æ­£åœ¨ç²å–: 6788 è¯æ™¯é›»...\n",
            "[1741/1912] æ­£åœ¨ç²å–: 6791 è™é–€ç§‘æŠ€...\n",
            "[1742/1912] æ­£åœ¨ç²å–: 6803 å´‘é¼...\n",
            "[1743/1912] æ­£åœ¨ç²å–: 6804 æ˜ä¿‚...\n",
            "[1744/1912] æ­£åœ¨ç²å–: 6811 å®ï¿½ç¡Œç©ˆT...\n",
            "[1745/1912] æ­£åœ¨ç²å–: 6821 è¯å¯¶...\n",
            "[1746/1912] æ­£åœ¨ç²å–: 6823 æ¿¾èƒ½...\n",
            "[1747/1912] æ­£åœ¨ç²å–: 6829 åƒé™„ç²¾å¯†...\n",
            "[1748/1912] æ­£åœ¨ç²å–: 6840 æ±ç ”ä¿¡è¶…...\n",
            "[1749/1912] æ­£åœ¨ç²å–: 6841 é•·ä½³æ™ºèƒ½...\n",
            "[1750/1912] æ­£åœ¨ç²å–: 6843 é€²å…¸...\n",
            "[1751/1912] æ­£åœ¨ç²å–: 6844 è«¾è²å…’...\n",
            "[1752/1912] æ­£åœ¨ç²å–: 6846 ç¶ èŒµ...\n",
            "[1753/1912] æ­£åœ¨ç²å–: 6855 æ•¸æ³“ç§‘...\n",
            "[1754/1912] æ­£åœ¨ç²å–: 6856 é‘«å‚³...\n",
            "[1755/1912] æ­£åœ¨ç²å–: 6859 ä¼¯ç‰¹å…‰...\n",
            "[1756/1912] æ­£åœ¨ç²å–: 6865 å‰åº·ç§‘æŠ€...\n",
            "[1757/1912] æ­£åœ¨ç²å–: 6870 é¨°é›²...\n",
            "[1758/1912] æ­£åœ¨ç²å–: 6872 æµ©å®‡ç”Ÿé†«...\n",
            "[1759/1912] æ­£åœ¨ç²å–: 6874 å€åŠ›...\n",
            "[1760/1912] æ­£åœ¨ç²å–: 6875 åœ‹é‚‘*...\n",
            "[1761/1912] æ­£åœ¨ç²å–: 6877 éµå‹ç›Š...\n",
            "[1762/1912] æ­£åœ¨ç²å–: 6881 æ½¤å¾·...\n",
            "[1763/1912] æ­£åœ¨ç²å–: 6894 è¡›å¸ç‰¹...\n",
            "[1764/1912] æ­£åœ¨ç²å–: 6895 å®ç¢©ç³»çµ±...\n",
            "[1765/1912] æ­£åœ¨ç²å–: 6899 å‰µç‚ºç²¾å¯†...\n",
            "[1766/1912] æ­£åœ¨ç²å–: 6903 å·¨æ¼¢...\n",
            "[1767/1912] æ­£åœ¨ç²å–: 6904 ä¼¯é‘«...\n",
            "[1768/1912] æ­£åœ¨ç²å–: 6913 é´»å‘ˆ...\n",
            "[1769/1912] æ­£åœ¨ç²å–: 6922 å®¸æ›œ...\n",
            "[1770/1912] æ­£åœ¨ç²å–: 6925 æ„è—...\n",
            "[1771/1912] æ­£åœ¨ç²å–: 6929 ä½‘å…¨...\n",
            "[1772/1912] æ­£åœ¨ç²å–: 6953 å®¶ç¢©...\n",
            "[1773/1912] æ­£åœ¨ç²å–: 6967 æ±ç‘‹ææ–™...\n",
            "[1774/1912] æ­£åœ¨ç²å–: 6968 è¬é”å¯µç‰©...\n",
            "[1775/1912] æ­£åœ¨ç²å–: 6982 å¤§äº•æ³µæµ¦...\n",
            "[1776/1912] æ­£åœ¨ç²å–: 6996 åŠ›é ˜ç§‘æŠ€...\n",
            "[1777/1912] æ­£åœ¨ç²å–: 6997 åšå¼˜...\n",
            "[1778/1912] æ­£åœ¨ç²å–: 7402 é‚‘éŒ¡...\n",
            "[1779/1912] æ­£åœ¨ç²å–: 7547 ç¢©ç¶²...\n",
            "[1780/1912] æ­£åœ¨ç²å–: 7556 æ„å¾·å£«...\n",
            "[1781/1912] æ­£åœ¨ç²å–: 7584 æ¨‚æ„...\n",
            "[1782/1912] æ­£åœ¨ç²å–: 7642 æ˜¶ç‘æ©Ÿé›»...\n",
            "[1783/1912] æ­£åœ¨ç²å–: 7703 éŠ³æ¾¤...\n",
            "[1784/1912] æ­£åœ¨ç²å–: 7704 æ˜é ç²¾å¯†...\n",
            "[1785/1912] æ­£åœ¨ç²å–: 7708 å…¨å®¶é¤é£²...\n",
            "[1786/1912] æ­£åœ¨ç²å–: 7709 æ¦®ç”°...\n",
            "[1787/1912] æ­£åœ¨ç²å–: 7712 åšç››åŠå°é«”...\n",
            "[1788/1912] æ­£åœ¨ç²å–: 7713 å¨åŠ›å¾·ç”Ÿé†«...\n",
            "[1789/1912] æ­£åœ¨ç²å–: 7714 å‰µæ³“ç§‘æŠ€...\n",
            "[1790/1912] æ­£åœ¨ç²å–: 7715 è£•å±±...\n",
            "[1791/1912] æ­£åœ¨ç²å–: 7718 å‹é‹®...\n",
            "[1792/1912] æ­£åœ¨ç²å–: 7723 ç¯‰é–“...\n",
            "[1793/1912] æ­£åœ¨ç²å–: 7728 å…‰ç„±ç§‘æŠ€...\n",
            "[1794/1912] æ­£åœ¨ç²å–: 7734 å°èƒ½ç§‘æŠ€...\n",
            "[1795/1912] æ­£åœ¨ç²å–: 7743 é‡‘åˆ©é£Ÿå®‰...\n",
            "[1796/1912] æ­£åœ¨ç²å–: 7747 æ˜•å¥‡é›²ç«¯...\n",
            "[1797/1912] æ­£åœ¨ç²å–: 7753 æ˜Ÿäº...\n",
            "[1798/1912] æ­£åœ¨ç²å–: 8024 ä½‘è¯...\n",
            "[1799/1912] æ­£åœ¨ç²å–: 8027 éˆ¦æ˜‡...\n",
            "[1800/1912] æ­£åœ¨ç²å–: 8032 å…‰è±...\n",
            "[1801/1912] æ­£åœ¨ç²å–: 8034 æ¦®ç¾¤...\n",
            "[1802/1912] æ­£åœ¨ç²å–: 8038 é•·åœ’ç§‘...\n",
            "[1803/1912] æ­£åœ¨ç²å–: 8040 ä¹æš˜...\n",
            "[1804/1912] æ­£åœ¨ç²å–: 8042 é‡‘å±±é›»...\n",
            "[1805/1912] æ­£åœ¨ç²å–: 8043 èœœæœ›å¯¦...\n",
            "[1806/1912] æ­£åœ¨ç²å–: 8044 ç¶²å®¶...\n",
            "[1807/1912] æ­£åœ¨ç²å–: 8047 æ˜Ÿé›²...\n",
            "[1808/1912] æ­£åœ¨ç²å–: 8048 å¾·å‹...\n",
            "[1809/1912] æ­£åœ¨ç²å–: 8049 æ™¶é‡‡...\n",
            "[1810/1912] æ­£åœ¨ç²å–: 8050 å»£ç©...\n",
            "[1811/1912] æ­£åœ¨ç²å–: 8054 å®‰åœ‹...\n",
            "[1812/1912] æ­£åœ¨ç²å–: 8059 å‡±ç¢©...\n",
            "[1813/1912] æ­£åœ¨ç²å–: 8064 æ±æ·...\n",
            "[1814/1912] æ­£åœ¨ç²å–: 8066 ä¾†æ€é”...\n",
            "[1815/1912] æ­£åœ¨ç²å–: 8067 å¿—æ—­...\n",
            "[1816/1912] æ­£åœ¨ç²å–: 8068 å…¨é”...\n",
            "[1817/1912] æ­£åœ¨ç²å–: 8069 å…ƒå¤ª...\n",
            "[1818/1912] æ­£åœ¨ç²å–: 8071 èƒ½ç‡ç¶²é€š...\n",
            "[1819/1912] æ­£åœ¨ç²å–: 8074 é‰…æ©¡...\n",
            "[1820/1912] æ­£åœ¨ç²å–: 8076 ä¼è±...\n",
            "[1821/1912] æ­£åœ¨ç²å–: 8077 æ´›ï¿½ï¿½...\n",
            "[1822/1912] æ­£åœ¨ç²å–: 8080 æ³°éœ–...\n",
            "[1823/1912] æ­£åœ¨ç²å–: 8083 ç‘ç©...\n",
            "[1824/1912] æ­£åœ¨ç²å–: 8084 å·¨è™¹...\n",
            "[1825/1912] æ­£åœ¨ç²å–: 8085 ç¦è¯...\n",
            "[1826/1912] æ­£åœ¨ç²å–: 8086 å®æ·ç§‘...\n",
            "[1827/1912] æ­£åœ¨ç²å–: 8087 éº—å‡èƒ½æº...\n",
            "[1828/1912] æ­£åœ¨ç²å–: 8088 å“å®‰...\n",
            "[1829/1912] æ­£åœ¨ç²å–: 8089 åº·å…¨é›»è¨Š...\n",
            "[1830/1912] æ­£åœ¨ç²å–: 8091 ç¿”å...\n",
            "[1831/1912] æ­£åœ¨ç²å–: 8092 å»ºæš...\n",
            "[1832/1912] æ­£åœ¨ç²å–: 8093 ä¿éŠ³...\n",
            "[1833/1912] æ­£åœ¨ç²å–: 8096 æ“äº...\n",
            "[1834/1912] æ­£åœ¨ç²å–: 8097 å¸¸çµ...\n",
            "[1835/1912] æ­£åœ¨ç²å–: 8099 å¤§ä¸–ç§‘...\n",
            "[1836/1912] æ­£åœ¨ç²å–: 8107 å¤§å„„é‡‘èŒ‚...\n",
            "[1837/1912] æ­£åœ¨ç²å–: 8109 åšå¤§...\n",
            "[1838/1912] æ­£åœ¨ç²å–: 8111 ç«‹ï¿½ï¿½...\n",
            "[1839/1912] æ­£åœ¨ç²å–: 8121 è¶Šå³°...\n",
            "[1840/1912] æ­£åœ¨ç²å–: 8147 æ­£æ·©...\n",
            "[1841/1912] æ­£åœ¨ç²å–: 8155 åšæ™º...\n",
            "[1842/1912] æ­£åœ¨ç²å–: 8171 å¤©å®‡...\n",
            "[1843/1912] æ­£åœ¨ç²å–: 8176 æ™ºæ·...\n",
            "[1844/1912] æ­£åœ¨ç²å–: 8182 åŠ é«˜...\n",
            "[1845/1912] æ­£åœ¨ç²å–: 8183 ç²¾æ˜Ÿ...\n",
            "[1846/1912] æ­£åœ¨ç²å–: 8227 å·¨æœ‰ç§‘æŠ€...\n",
            "[1847/1912] æ­£åœ¨ç²å–: 8234 æ–°æ¼¢...\n",
            "[1848/1912] æ­£åœ¨ç²å–: 8240 è¯å®...\n",
            "[1849/1912] æ­£åœ¨ç²å–: 8255 æœ‹ç¨‹...\n",
            "[1850/1912] æ­£åœ¨ç²å–: 8272 å…¨æ™¯è»Ÿé«”...\n",
            "[1851/1912] æ­£åœ¨ç²å–: 8277 å•†ä¸...\n",
            "[1852/1912] æ­£åœ¨ç²å–: 8279 ç”Ÿå±•...\n",
            "[1853/1912] æ­£åœ¨ç²å–: 8284 ä¸‰ç«¹...\n",
            "[1854/1912] æ­£åœ¨ç²å–: 8289 æ³°è—...\n",
            "[1855/1912] æ­£åœ¨ç²å–: 8291 å°šèŒ‚...\n",
            "[1856/1912] æ­£åœ¨ç²å–: 8299 ç¾¤è¯...\n",
            "[1857/1912] æ­£åœ¨ç²å–: 8342 ç›Šå¼µ...\n",
            "[1858/1912] æ­£åœ¨ç²å–: 8349 ï¿½çŸ¬ï¿½...\n",
            "[1859/1912] æ­£åœ¨ç²å–: 8354 å† å¥½...\n",
            "[1860/1912] æ­£åœ¨ç²å–: 8358 é‡‘å±…...\n",
            "[1861/1912] æ­£åœ¨ç²å–: 8383 åƒé™„...\n",
            "[1862/1912] æ­£åœ¨ç²å–: 8390 é‡‘ç›Šé¼...\n",
            "[1863/1912] æ­£åœ¨ç²å–: 8401 ç™½ç´—ç§‘...\n",
            "[1864/1912] æ­£åœ¨ç²å–: 8403 ç››å¼˜...\n",
            "[1865/1912] æ­£åœ¨ç²å–: 8409 å•†ä¹‹å™¨...\n",
            "[1866/1912] æ­£åœ¨ç²å–: 8410 æ£®ç”°...\n",
            "[1867/1912] æ­£åœ¨ç²å–: 8415 å¤§åœ‹é‹¼...\n",
            "[1868/1912] æ­£åœ¨ç²å–: 8416 å¯¦å¨...\n",
            "[1869/1912] æ­£åœ¨ç²å–: 8421 æ—­æº...\n",
            "[1870/1912] æ­£åœ¨ç²å–: 8423 ä¿ç¶ -KY...\n",
            "[1871/1912] æ­£åœ¨ç²å–: 8424 æƒ æ™®...\n",
            "[1872/1912] æ­£åœ¨ç²å–: 8426 ç´…æœ¨-KY...\n",
            "[1873/1912] æ­£åœ¨ç²å–: 8431 åŒ¯é‘½ç§‘...\n",
            "[1874/1912] æ­£åœ¨ç²å–: 8432 æ±ç”Ÿè¯...\n",
            "[1875/1912] æ­£åœ¨ç²å–: 8433 å¼˜å¸†...\n",
            "[1876/1912] æ­£åœ¨ç²å–: 8435 é‰…é‚...\n",
            "[1877/1912] æ­£åœ¨ç²å–: 8436 å¤§æ±Ÿ...\n",
            "[1878/1912] æ­£åœ¨ç²å–: 8437 å¤§åœ°-KY...\n",
            "[1879/1912] æ­£åœ¨ç²å–: 8440 ç¶ é›»...\n",
            "[1880/1912] æ­£åœ¨ç²å–: 8444 ç¶ æ²³-KY...\n",
            "[1881/1912] æ­£åœ¨ç²å–: 8446 è¯ç ”...\n",
            "[1882/1912] æ­£åœ¨ç²å–: 8450 éœ¹é‚...\n",
            "[1883/1912] æ­£åœ¨ç²å–: 8455 å¤§æ‹“-KY...\n",
            "[1884/1912] æ­£åœ¨ç²å–: 8472 å¤ éº»å‰...\n",
            "[1885/1912] æ­£åœ¨ç²å–: 8477 å‰µæ¥­å®¶...\n",
            "[1886/1912] æ­£åœ¨ç²å–: 8489 ä¸‰è²å¾·...\n",
            "[1887/1912] æ­£åœ¨ç²å–: 8905 è£•åœ‹...\n",
            "[1888/1912] æ­£åœ¨ç²å–: 8906 èŠ±ç‹...\n",
            "[1889/1912] æ­£åœ¨ç²å–: 8908 æ¬£é›„...\n",
            "[1890/1912] æ­£åœ¨ç²å–: 8916 å…‰éš†...\n",
            "[1891/1912] æ­£åœ¨ç²å–: 8917 æ¬£æ³°...\n",
            "[1892/1912] æ­£åœ¨ç²å–: 8921 æ²ˆæ°...\n",
            "[1893/1912] æ­£åœ¨ç²å–: 8923 æ™‚å ±...\n",
            "[1894/1912] æ­£åœ¨ç²å–: 8924 å¤§ç”°...\n",
            "[1895/1912] æ­£åœ¨ç²å–: 8927 åŒ—åŸº...\n",
            "[1896/1912] æ­£åœ¨ç²å–: 8928 é‰…æ˜...\n",
            "[1897/1912] æ­£åœ¨ç²å–: 8929 å¯Œå ¡...\n",
            "[1898/1912] æ­£åœ¨ç²å–: 8930 é’é‹¼...\n",
            "[1899/1912] æ­£åœ¨ç²å–: 8931 å¤§æ±½é›»...\n",
            "[1900/1912] æ­£åœ¨ç²å–: 8932 æ™ºé€š*...\n",
            "[1901/1912] æ­£åœ¨ç²å–: 8933 æ„›åœ°é›…...\n",
            "[1902/1912] æ­£åœ¨ç²å–: 8935 é‚¦æ³°...\n",
            "[1903/1912] æ­£åœ¨ç²å–: 8936 åœ‹çµ±...\n",
            "[1904/1912] æ­£åœ¨ç²å–: 8937 åˆé¨...\n",
            "[1905/1912] æ­£åœ¨ç²å–: 8938 æ˜å®‰...\n",
            "[1906/1912] æ­£åœ¨ç²å–: 8941 é—œä¸­...\n",
            "[1907/1912] æ­£åœ¨ç²å–: 8942 æ£®é‰…...\n",
            "[1908/1912] æ­£åœ¨ç²å–: 9949 ç‰åœ’...\n",
            "[1909/1912] æ­£åœ¨ç²å–: 9950 è¬åœ‹é€š...\n",
            "[1910/1912] æ­£åœ¨ç²å–: 9951 çš‡ç”°...\n",
            "[1911/1912] æ­£åœ¨ç²å–: 9960 é‚é”åº·...\n",
            "[1912/1912] æ­£åœ¨ç²å–: 9962 æœ‰ç›Š...\n",
            "\n",
            "è™•ç†å®Œæˆï¼Œå…±ç²å– 1912/1912 æ”¯è‚¡ç¥¨çš„æ•¸æ“šã€‚\n",
            "\n",
            "[éšæ®µ3/5] éæ¿¾ä½æˆäº¤é‡è‚¡ç¥¨...\n",
            "\n",
            "é€²è¡Œæˆäº¤é‡éæ¿¾ (è¿‘22æ—¥æˆäº¤é‡ > 1,000 å¼µ)...\n",
            "æˆäº¤é‡éæ¿¾å¾Œï¼Œå‰©ä¸‹ 212 / 1912 æ”¯è‚¡ç¥¨ã€‚\n",
            "\n",
            "[éšæ®µ4/5] é€²è¡Œæ ¸å¿ƒåˆ†æèˆ‡ç¶œåˆè©•åˆ†...\n",
            "  åˆ†æä¸­ (1/212): 1101 å°æ³¥\n",
            "  åˆ†æä¸­ (2/212): 1102 äºæ³¥\n",
            "  åˆ†æä¸­ (3/212): 1210 å¤§æˆ\n",
            "  åˆ†æä¸­ (4/212): 1216 çµ±ä¸€\n",
            "  åˆ†æä¸­ (5/212): 1301 å°å¡‘\n",
            "  åˆ†æä¸­ (6/212): 1303 å—äº\n",
            "  åˆ†æä¸­ (7/212): 1312 åœ‹å–¬\n",
            "  åˆ†æä¸­ (8/212): 1313 è¯æˆ\n",
            "  åˆ†æä¸­ (9/212): 1314 ä¸­çŸ³åŒ–\n",
            "  åˆ†æä¸­ (10/212): 1326 å°åŒ–\n",
            "  åˆ†æä¸­ (11/212): 1402 é æ±æ–°\n",
            "  åˆ†æä¸­ (12/212): 1513 ä¸­èˆˆé›»\n",
            "  åˆ†æä¸­ (13/212): 1519 è¯åŸ\n",
            "  åˆ†æä¸­ (14/212): 1605 è¯æ–°\n",
            "  åˆ†æä¸­ (15/212): 1608 è¯æ¦®\n",
            "  åˆ†æä¸­ (16/212): 1609 å¤§äº\n",
            "  åˆ†æä¸­ (17/212): 1616 å„„æ³°\n",
            "  åˆ†æä¸­ (18/212): 1802 å°ç»\n",
            "  åˆ†æä¸­ (19/212): 2002 ä¸­é‹¼\n",
            "  åˆ†æä¸­ (20/212): 2014 ä¸­é´»\n",
            "  åˆ†æä¸­ (21/212): 2027 å¤§æˆé‹¼\n",
            "  åˆ†æä¸­ (22/212): 2105 æ­£æ–°\n",
            "  åˆ†æä¸­ (23/212): 2201 è£•éš†\n",
            "  åˆ†æä¸­ (24/212): 2301 å…‰å¯¶ç§‘\n",
            "  åˆ†æä¸­ (25/212): 2303 è¯é›»\n",
            "  åˆ†æä¸­ (26/212): 2308 å°é”é›»\n",
            "  åˆ†æä¸­ (27/212): 2312 é‡‘å¯¶\n",
            "  åˆ†æä¸­ (28/212): 2313 è¯é€š\n",
            "  åˆ†æä¸­ (29/212): 2316 æ¥ æ¢“é›»\n",
            "  åˆ†æä¸­ (30/212): 2324 ä»å¯¶\n",
            "  åˆ†æä¸­ (31/212): 2327 åœ‹å·¨\n",
            "  åˆ†æä¸­ (32/212): 2328 å»£å®‡\n",
            "  åˆ†æä¸­ (33/212): 2329 è¯æ³°\n",
            "  åˆ†æä¸­ (34/212): 2330 å°ç©é›»\n",
            "  åˆ†æä¸­ (35/212): 2332 å‹è¨Š\n",
            "  åˆ†æä¸­ (36/212): 2337 æ—ºå®\n",
            "  åˆ†æä¸­ (37/212): 2338 å…‰ç½©\n",
            "  åˆ†æä¸­ (38/212): 2344 è¯é‚¦é›»\n",
            "  åˆ†æä¸­ (39/212): 2345 æ™ºé‚¦\n",
            "  åˆ†æä¸­ (40/212): 2347 è¯å¼·\n",
            "  åˆ†æä¸­ (41/212): 2349 éŒ¸å¾·\n",
            "  åˆ†æä¸­ (42/212): 2352 ä½³ä¸–é”\n",
            "  åˆ†æä¸­ (43/212): 2353 å®ï¿½ï¿½\n",
            "  åˆ†æä¸­ (44/212): 2354 é´»æº–\n",
            "  åˆ†æä¸­ (45/212): 2356 è‹±æ¥­é”\n",
            "  åˆ†æä¸­ (46/212): 2357 è¯ç¢©\n",
            "  åˆ†æä¸­ (47/212): 2360 è‡´èŒ‚\n",
            "  åˆ†æä¸­ (48/212): 2363 çŸ½çµ±\n",
            "  åˆ†æä¸­ (49/212): 2367 ç‡¿è¯\n",
            "  åˆ†æä¸­ (50/212): 2368 é‡‘åƒé›»\n",
            "  åˆ†æä¸­ (51/212): 2371 å¤§åŒ\n",
            "  åˆ†æä¸­ (52/212): 2374 ä½³èƒ½\n",
            "  åˆ†æä¸­ (53/212): 2376 æŠ€å˜‰\n",
            "  åˆ†æä¸­ (54/212): 2377 å¾®æ˜Ÿ\n",
            "  åˆ†æä¸­ (55/212): 2382 å»£é”\n",
            "  åˆ†æä¸­ (56/212): 2383 å°å…‰é›»\n",
            "  åˆ†æä¸­ (57/212): 2385 ç¾¤å…‰\n",
            "  åˆ†æä¸­ (58/212): 2388 å¨ç››\n",
            "  åˆ†æä¸­ (59/212): 2392 æ­£å´´\n",
            "  åˆ†æä¸­ (60/212): 2404 æ¼¢å”\n",
            "  åˆ†æä¸­ (61/212): 2408 å—äºç§‘\n",
            "  åˆ†æä¸­ (62/212): 2409 å‹é”\n",
            "  åˆ†æä¸­ (63/212): 2412 ä¸­è¯é›»\n",
            "  åˆ†æä¸­ (64/212): 2421 å»ºæº–\n",
            "  åˆ†æä¸­ (65/212): 2449 äº¬å…ƒé›»å­\n",
            "  åˆ†æä¸­ (66/212): 2454 è¯ç™¼ç§‘\n",
            "  åˆ†æä¸­ (67/212): 2455 å…¨æ–°\n",
            "  åˆ†æä¸­ (68/212): 2486 ä¸€è©®\n",
            "  åˆ†æä¸­ (69/212): 2498 å®é”é›»\n",
            "  åˆ†æä¸­ (70/212): 2515 ä¸­å·¥\n",
            "  åˆ†æä¸­ (71/212): 2542 èˆˆå¯Œç™¼\n",
            "  åˆ†æä¸­ (72/212): 2603 é•·æ¦®\n",
            "  åˆ†æä¸­ (73/212): 2605 æ–°èˆˆ\n",
            "  åˆ†æä¸­ (74/212): 2606 è£•æ°‘\n",
            "  åˆ†æä¸­ (75/212): 2609 é™½æ˜\n",
            "  åˆ†æä¸­ (76/212): 2610 è¯èˆª\n",
            "  åˆ†æä¸­ (77/212): 2615 è¬æµ·\n",
            "  åˆ†æä¸­ (78/212): 2618 é•·æ¦®èˆª\n",
            "  åˆ†æä¸­ (79/212): 2634 æ¼¢ç¿”\n",
            "  åˆ†æä¸­ (80/212): 2637 æ…§æ´‹-KY\n",
            "  åˆ†æä¸­ (81/212): 2646 æ˜Ÿå®‡èˆªç©º\n",
            "  åˆ†æä¸­ (82/212): 2801 å½°éŠ€\n",
            "  åˆ†æä¸­ (83/212): 2812 å°ä¸­éŠ€\n",
            "  åˆ†æä¸­ (84/212): 2834 è‡ºä¼éŠ€\n",
            "  åˆ†æä¸­ (85/212): 2845 é æ±éŠ€\n",
            "  åˆ†æä¸­ (86/212): 2867 ä¸‰å•†å£½\n",
            "  åˆ†æä¸­ (87/212): 2880 è¯å—é‡‘\n",
            "  åˆ†æä¸­ (88/212): 2881 å¯Œé‚¦é‡‘\n",
            "  åˆ†æä¸­ (89/212): 2882 åœ‹æ³°é‡‘\n",
            "  åˆ†æä¸­ (90/212): 2883 å‡±åŸºé‡‘\n",
            "  åˆ†æä¸­ (91/212): 2884 ç‰å±±é‡‘\n",
            "  åˆ†æä¸­ (92/212): 2885 å…ƒå¤§é‡‘\n",
            "  åˆ†æä¸­ (93/212): 2886 å…†è±é‡‘\n",
            "  åˆ†æä¸­ (94/212): 2887 å°æ–°é‡‘\n",
            "  åˆ†æä¸­ (95/212): 2889 åœ‹ç¥¨é‡‘\n",
            "  åˆ†æä¸­ (96/212): 2890 æ°¸è±é‡‘\n",
            "  åˆ†æä¸­ (97/212): 2891 ä¸­ä¿¡é‡‘\n",
            "  åˆ†æä¸­ (98/212): 2892 ç¬¬ä¸€é‡‘\n",
            "  åˆ†æä¸­ (99/212): 3013 æ™ŸéŠ˜é›»\n",
            "  åˆ†æä¸­ (100/212): 3017 å¥‡é‹\n",
            "  åˆ†æä¸­ (101/212): 3019 äºå…‰\n",
            "  åˆ†æä¸­ (102/212): 3032 å‰è¨“\n",
            "  åˆ†æä¸­ (103/212): 3034 è¯è© \n",
            "  åˆ†æä¸­ (104/212): 3035 æ™ºåŸ\n",
            "  åˆ†æä¸­ (105/212): 3037 æ¬£èˆˆ\n",
            "  åˆ†æä¸­ (106/212): 3044 å¥é¼\n",
            "  åˆ†æä¸­ (107/212): 3045 å°ç£å¤§\n",
            "  åˆ†æä¸­ (108/212): 3056 å¯Œè¯æ–°\n",
            "  åˆ†æä¸­ (109/212): 3059 è¯æ™¶ç§‘\n",
            "  åˆ†æä¸­ (110/212): 3062 å»ºæ¼¢\n",
            "  åˆ†æä¸­ (111/212): 3167 å¤§é‡\n",
            "  åˆ†æä¸­ (112/212): 3189 æ™¯ç¢©\n",
            "  åˆ†æä¸­ (113/212): 3231 ç·¯å‰µ\n",
            "  åˆ†æä¸­ (114/212): 3376 æ–°æ—¥èˆˆ\n",
            "  åˆ†æä¸­ (115/212): 3450 è¯éˆ\n",
            "  åˆ†æä¸­ (116/212): 3481 ç¾¤å‰µ\n",
            "  åˆ†æä¸­ (117/212): 3535 æ™¶å½©ç§‘\n",
            "  åˆ†æä¸­ (118/212): 3543 å·å·§\n",
            "  åˆ†æä¸­ (119/212): 3576 è¯åˆå†ç”Ÿ\n",
            "  åˆ†æä¸­ (120/212): 3605 å®è‡´\n",
            "  åˆ†æä¸­ (121/212): 3645 é”é‚\n",
            "  åˆ†æä¸­ (122/212): 3661 ä¸–èŠ¯-KY\n",
            "  åˆ†æä¸­ (123/212): 3665 è²¿è¯-KY\n",
            "  åˆ†æä¸­ (124/212): 3702 å¤§è¯å¤§\n",
            "  åˆ†æä¸­ (125/212): 3706 ç¥é”\n",
            "  åˆ†æä¸­ (126/212): 3711 æ—¥æœˆå…‰æŠ•æ§\n",
            "  åˆ†æä¸­ (127/212): 3715 å®šç©æŠ•æ§\n",
            "  åˆ†æä¸­ (128/212): 4526 æ±å°\n",
            "  åˆ†æä¸­ (129/212): 4763 ææ–™*-KY\n",
            "  åˆ†æä¸­ (130/212): 4904 é å‚³\n",
            "  åˆ†æä¸­ (131/212): 4916 äº‹æ¬£ç§‘\n",
            "  åˆ†æä¸­ (132/212): 4938 å’Œç¢©\n",
            "  åˆ†æä¸­ (133/212): 4958 è‡»é¼-KY\n",
            "  åˆ†æä¸­ (134/212): 4977 çœ¾é”-KY\n",
            "  åˆ†æä¸­ (135/212): 5469 ç€šå®‡åš\n",
            "  åˆ†æä¸­ (136/212): 5871 ä¸­ç§Ÿ-KY\n",
            "  åˆ†æä¸­ (137/212): 5876 ä¸Šæµ·å•†éŠ€\n",
            "  åˆ†æä¸­ (138/212): 5880 åˆåº«é‡‘\n",
            "  åˆ†æä¸­ (139/212): 6005 ç¾¤ç›Šè­‰\n",
            "  åˆ†æä¸­ (140/212): 6112 é‚é”ç‰¹\n",
            "  åˆ†æä¸­ (141/212): 6116 å½©æ™¶\n",
            "  åˆ†æä¸­ (142/212): 6139 äºç¿”\n",
            "  åˆ†æä¸­ (143/212): 6153 å˜‰è¯ç›Š\n",
            "  åˆ†æä¸­ (144/212): 6191 ç²¾æˆç§‘\n",
            "  åˆ†æä¸­ (145/212): 6206 é£›æ·\n",
            "  åˆ†æä¸­ (146/212): 6213 è¯èŒ‚\n",
            "  åˆ†æä¸­ (147/212): 6215 å’Œæ¤¿\n",
            "  åˆ†æä¸­ (148/212): 6239 åŠ›æˆ\n",
            "  åˆ†æä¸­ (149/212): 6257 çŸ½æ ¼\n",
            "  åˆ†æä¸­ (150/212): 6269 å°éƒ¡\n",
            "  åˆ†æä¸­ (151/212): 6285 å•Ÿï¿½ï¿½\n",
            "  åˆ†æä¸­ (152/212): 6443 å…ƒæ™¶\n",
            "  åˆ†æä¸­ (153/212): 6505 å°å¡‘åŒ–\n",
            "  åˆ†æä¸­ (154/212): 6558 èˆˆèƒ½é«˜\n",
            "  åˆ†æä¸­ (155/212): 6770 åŠ›ç©é›»\n",
            "  åˆ†æä¸­ (156/212): 6805 å¯Œä¸–é”\n",
            "  åˆ†æä¸­ (157/212): 6919 åº·éœˆ*\n",
            "  åˆ†æä¸­ (158/212): 6962 å¥•åŠ›-KY\n",
            "  åˆ†æä¸­ (159/212): 8021 å°–é»\n",
            "  åˆ†æä¸­ (160/212): 8028 æ˜‡é™½åŠå°é«”\n",
            "  åˆ†æä¸­ (161/212): 8033 é›·è™\n",
            "  åˆ†æä¸­ (162/212): 8046 å—é›»\n",
            "  åˆ†æä¸­ (163/212): 8070 é•·è¯*\n",
            "  åˆ†æä¸­ (164/212): 9904 å¯¶æˆ\n",
            "  åˆ†æä¸­ (165/212): 9907 çµ±ä¸€å¯¦\n",
            "  åˆ†æä¸­ (166/212): 9933 ä¸­é¼\n",
            "  åˆ†æä¸­ (167/212): 9945 æ½¤æ³°æ–°\n",
            "  åˆ†æä¸­ (168/212): 9958 ä¸–ç´€é‹¼\n",
            "  åˆ†æä¸­ (169/212): 0050 å…ƒå¤§å°ç£50\n",
            "  åˆ†æä¸­ (170/212): 0056 å…ƒå¤§é«˜è‚¡æ¯\n",
            "  åˆ†æä¸­ (171/212): 9105 æ³°é‡‘å¯¶-DR\n",
            "  åˆ†æä¸­ (172/212): 1785 å…‰æ´‹ç§‘\n",
            "  åˆ†æä¸­ (173/212): 1815 å¯Œå–¬\n",
            "  åˆ†æä¸­ (174/212): 3078 åƒ‘å¨\n",
            "  åˆ†æä¸­ (175/212): 3105 ç©©æ‡‹\n",
            "  åˆ†æä¸­ (176/212): 3163 æ³¢è‹¥å¨\n",
            "  åˆ†æä¸­ (177/212): 3211 é †é”\n",
            "  åˆ†æä¸­ (178/212): 3260 å¨å‰›\n",
            "  åˆ†æä¸­ (179/212): 3264 æ¬£éŠ“\n",
            "  åˆ†æä¸­ (180/212): 3294 è‹±æ¿Ÿ\n",
            "  åˆ†æä¸­ (181/212): 3323 åŠ ç™¾è£•\n",
            "  åˆ†æä¸­ (182/212): 3324 é›™é´»\n",
            "  åˆ†æä¸­ (183/212): 3363 ä¸Šè©®\n",
            "  åˆ†æä¸­ (184/212): 3374 ç²¾æ\n",
            "  åˆ†æä¸­ (185/212): 3689 æ¹§å¾·\n",
            "  åˆ†æä¸­ (186/212): 4303 ä¿¡ç«‹\n",
            "  åˆ†æä¸­ (187/212): 4510 é«˜é‹’\n",
            "  åˆ†æä¸­ (188/212): 4714 æ°¸æ·\n",
            "  åˆ†æä¸­ (189/212): 4931 æ–°ç››åŠ›\n",
            "  åˆ†æä¸­ (190/212): 4971 IET-KY\n",
            "  åˆ†æä¸­ (191/212): 4979 è¯æ˜Ÿå…‰\n",
            "  åˆ†æä¸­ (192/212): 4991 ç’°å®‡-KY\n",
            "  åˆ†æä¸­ (193/212): 5309 ç³»çµ±é›»\n",
            "  åˆ†æä¸­ (194/212): 5347 ä¸–ç•Œ\n",
            "  åˆ†æä¸­ (195/212): 5371 ä¸­å…‰é›»\n",
            "  åˆ†æä¸­ (196/212): 5439 é«˜æŠ€\n",
            "  åˆ†æä¸­ (197/212): 5443 å‡è±ª\n",
            "  åˆ†æä¸­ (198/212): 5475 å¾·å®\n",
            "  åˆ†æä¸­ (199/212): 5483 ä¸­ç¾æ™¶\n",
            "  åˆ†æä¸­ (200/212): 5498 å‡±å´´\n",
            "  åˆ†æä¸­ (201/212): 6125 å»£é‹\n",
            "  åˆ†æä¸­ (202/212): 6190 è¬æ³°ç§‘\n",
            "  åˆ†æä¸­ (203/212): 6274 å°ç‡¿\n",
            "  åˆ†æä¸­ (204/212): 6290 è‰¯ç¶­\n",
            "  åˆ†æä¸­ (205/212): 6462 ç¥ç›¾\n",
            "  åˆ†æä¸­ (206/212): 6488 ç’°çƒæ™¶\n",
            "  åˆ†æä¸­ (207/212): 8054 å®‰åœ‹\n",
            "  åˆ†æä¸­ (208/212): 8069 å…ƒå¤ª\n",
            "  åˆ†æä¸­ (209/212): 8086 å®æ·ç§‘\n",
            "  åˆ†æä¸­ (210/212): 8111 ç«‹ï¿½ï¿½\n",
            "  åˆ†æä¸­ (211/212): 8358 é‡‘å±…\n",
            "  åˆ†æä¸­ (212/212): 8932 æ™ºé€š*\n",
            "\n",
            "[éšæ®µ5/5] ç¯©é¸é ‚å°–å€‹è‚¡ä¸¦ç”¢å‡ºå ±å‘Š...\n",
            "\n",
            "é€²è¡Œé ‚å°–ç¯©é¸ (åˆ†æ•¸éœ€ >= 91ï¼Œå³å‰ 2%)\n",
            "é ‚å°–ç¯©é¸å¾Œï¼Œå‰©ä¸‹ 10 / 212 æ”¯è‚¡ç¥¨ã€‚\n",
            "\n",
            "============================================================\n",
            "ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ† å‰ååç¸¾å„ªè‚¡åˆ—è¡¨ ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†\n",
            "============================================================\n",
            "æ’å  ä»£ç¢¼    åç¨±          åˆ†æ•¸    åƒ¹æ ¼      æœˆæ¼²å¹…(%)    å»ºè­°      \n",
            "------------------------------------------------------------\n",
            "1   1802  å°ç»          91    30      79        å¼·åŠ›è²·å…¥    \n",
            "2   2374  ä½³èƒ½          91    76      42        å¼·åŠ›è²·å…¥    \n",
            "3   2404  æ¼¢å”          91    1060    53        å¼·åŠ›è²·å…¥    \n",
            "4   2812  å°ä¸­éŠ€         91    22      6         å¼·åŠ›è²·å…¥    \n",
            "5   3019  äºå…‰          91    168     36        å¼·åŠ›è²·å…¥    \n",
            "6   3059  è¯æ™¶ç§‘         91    44      17        å¼·åŠ›è²·å…¥    \n",
            "7   4958  è‡»é¼-KY       91    160     47        å¼·åŠ›è²·å…¥    \n",
            "8   3323  åŠ ç™¾è£•         91    42      28        å¼·åŠ›è²·å…¥    \n",
            "9   5498  å‡±å´´          91    24      96        å¼·åŠ›è²·å…¥    \n",
            "10  6190  è¬æ³°ç§‘         91    50      31        å¼·åŠ›è²·å…¥    \n",
            "============================================================\n",
            "\n",
            "--- æ­£åœ¨ç‚ºé ‚å°–å€‹è‚¡ç”Ÿæˆè©³ç´°åœ–è¡¨å ±å‘Š ---\n",
            "\n",
            "ğŸ‰ å…¨éƒ¨æµç¨‹åŸ·è¡Œå®Œç•¢ï¼\n",
            "ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- åŸºç¤ Python æ¨™æº–åº« ---\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import platform\n",
        "import re\n",
        "from io import StringIO\n",
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "\n",
        "# --- æ•¸æ“šè™•ç†èˆ‡ç§‘å­¸è¨ˆç®— ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- ç¶²è·¯è«‹æ±‚ ---\n",
        "import requests\n",
        "import aiohttp # ç•°æ­¥è«‹æ±‚\n",
        "import asyncio # ç•°æ­¥æ¡†æ¶\n",
        "\n",
        "# --- é‡‘èæ•¸æ“šæº ---\n",
        "import yfinance as yf\n",
        "\n",
        "# --- æ•¸æ“šå¯è¦–åŒ– ---\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "import mplfinance as mpf\n",
        "# import chineseize_matplotlib # å»ºè­°ä½¿ç”¨ set_chinese_font() é€²è¡Œæ›´å¯æ§çš„è¨­å®š\n",
        "\n",
        "# --- é€šçŸ¥ç›¸é—œ ---\n",
        "import pytz\n",
        "from discord_webhook import DiscordWebhook\n",
        "\n",
        "# ==============================================\n",
        "# å…¨åŸŸè¨­å®šèˆ‡åˆå§‹åŒ–\n",
        "# ==============================================\n",
        "\n",
        "# --- ç›®éŒ„è¨­å®š ---\n",
        "CACHE_DIR = 'cache'\n",
        "RESULTS_DIR = 'results'\n",
        "CHARTS_DIR = os.path.join(RESULTS_DIR, 'charts')\n",
        "STOCK_LIST_PATH = os.path.join(CACHE_DIR, 'stock_list.csv')\n",
        "HISTORY_DATA_CACHE_DIR = os.path.join(CACHE_DIR, 'history_data')\n",
        "\n",
        "# --- åˆå§‹åŒ–ç›®éŒ„ ---\n",
        "for directory in [CACHE_DIR, RESULTS_DIR, CHARTS_DIR, HISTORY_DATA_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# --- é€šçŸ¥è¨­å®š (è«‹å¡«å…¥æ‚¨çš„é‡‘é‘°) ---\n",
        "# ==============================================================================\n",
        "# 9. é€šè¨Šèˆ‡é€šçŸ¥è¨­å®š\n",
        "# ==============================================================================\n",
        "# å»ºè­°å°‡ä¾†ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ– .env æª”æ¡ˆç®¡ç†å¯†é‘°ï¼Œä»¥ç­–å®‰å…¨\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]  # æ”¯æ´å¤šç”¨æˆ¶é€šçŸ¥\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "# --- æ—¥èªŒèˆ‡æ™‚å€è¨­å®š ---\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "try:\n",
        "    taipei_tz = pytz.timezone('Asia/Taipei')\n",
        "except pytz.UnknownTimeZoneError:\n",
        "    logger.error(\"æ™‚å€ 'Asia/Taipei' æ‰¾ä¸åˆ°ï¼Œè«‹ç¢ºä¿ pytz åº«å·²å®‰è£ä¸”æ•¸æ“šç‚ºæœ€æ–°ã€‚\")\n",
        "    taipei_tz = pytz.utc # é™ç´šä½¿ç”¨ UTC\n",
        "\n",
        "# ==============================================\n",
        "# è¼”åŠ©å‡½å¼èˆ‡ç’°å¢ƒè¨­å®š\n",
        "# ==============================================\n",
        "\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            font_name = 'Microsoft YaHei'\n",
        "        elif system == 'Darwin': # macOS\n",
        "            font_name = 'PingFang HK'\n",
        "        else: # Linux\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "            ]\n",
        "            found_font_path = next((path for path in font_paths if os.path.exists(path)), None)\n",
        "            if found_font_path:\n",
        "                font_manager.fontManager.addfont(found_font_path)\n",
        "                font_name = font_manager.FontProperties(fname=found_font_path).get_name()\n",
        "            else:\n",
        "                logger.warning(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                # ä½¿ç”¨ chineseize_matplotlib ä½œç‚ºå‚™æ´\n",
        "                import chineseize_matplotlib\n",
        "                logger.info(\"å•Ÿç”¨ chineseize_matplotlib ä½œç‚ºå‚™æ´å­—é«”æ–¹æ¡ˆã€‚\")\n",
        "                return\n",
        "\n",
        "        plt.rcParams['font.sans-serif'] = [font_name]\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "        if font_name:\n",
        "            logger.info(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# ==============================================\n",
        "# æ ¸å¿ƒåŠŸèƒ½å‡½å¼ (è³‡æ–™ç²å–ã€åˆ†æã€è©•åˆ†)\n",
        "# ==============================================\n",
        "\n",
        "def get_taiwan_stocks(cache_path=STOCK_LIST_PATH, force_update=False):\n",
        "    if not force_update and os.path.exists(cache_path) and (time.time() - os.path.getmtime(cache_path)) < 86400:\n",
        "        try:\n",
        "            df = pd.read_csv(cache_path, dtype={'stock_id': str})\n",
        "            if not df.empty and 'yahoo_symbol' in df.columns:\n",
        "                print(f\"âœ… å¾å¿«å–è¼‰å…¥ {len(df)} æ”¯è‚¡ç¥¨æ¸…å–®ã€‚\")\n",
        "                return df\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ è¼‰å…¥è‚¡ç¥¨æ¸…å–®å¿«å–å¤±æ•—: {e}ã€‚\")\n",
        "\n",
        "    print(\"ğŸŒ æ­£åœ¨ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–® (å¾è­‰äº¤æ‰€)...\")\n",
        "    try:\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        for market, url in urls.items():\n",
        "            response = requests.get(url, timeout=20)\n",
        "            df = pd.read_html(StringIO(response.text))[0]\n",
        "            df.columns = df.iloc[0]\n",
        "            df = df.iloc[1:].dropna(thresh=3, axis=0)\n",
        "            df['å¸‚å ´åˆ¥'] = market\n",
        "            all_stocks_df.append(df)\n",
        "\n",
        "        df_combined = pd.concat(all_stocks_df, ignore_index=True)\n",
        "        df_combined.columns = ['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±', 'åœ‹éš›è­‰åˆ¸è­˜åˆ¥ç¢¼', 'ä¸Šå¸‚æ—¥', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'CFI', 'å‚™è¨»']\n",
        "        df_combined[['stock_id', 'stock_name']] = df_combined['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', n=1, expand=True)\n",
        "        df_combined['stock_id'] = df_combined['stock_id'].str.strip()\n",
        "        df_combined['stock_name'] = df_combined['stock_name'].str.strip()\n",
        "        df_stocks = df_combined[df_combined['stock_id'].str.match(r'^\\d{4}$')].copy()\n",
        "        exclude_keywords = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š']\n",
        "        df_stocks = df_stocks[~df_stocks['stock_name'].str.contains('|'.join(exclude_keywords), na=False)]\n",
        "        df_stocks['yahoo_symbol'] = df_stocks.apply(\n",
        "            lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['å¸‚å ´åˆ¥'] else f\"{row['stock_id']}.TWO\",\n",
        "            axis=1\n",
        "        )\n",
        "        final_df = df_stocks[['stock_id', 'stock_name', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "        final_df.rename(columns={'å¸‚å ´åˆ¥': 'market', 'ç”¢æ¥­åˆ¥': 'industry'}, inplace=True)\n",
        "        final_df.to_csv(cache_path, index=False)\n",
        "        print(f\"âœ… æˆåŠŸå¾è­‰äº¤æ‰€ç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜ã€‚\")\n",
        "        return final_df\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å¾è­‰äº¤æ‰€ç²å–è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        if os.path.exists(cache_path):\n",
        "            print(\"â— é™ç´šä½¿ç”¨èˆŠçš„å¿«å–è‚¡ç¥¨æ¸…å–®ã€‚\")\n",
        "            return pd.read_csv(cache_path, dtype={'stock_id': str})\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def get_stock_basic_info(force_update=False):\n",
        "    stocks_df = get_taiwan_stocks(force_update=force_update)\n",
        "    if stocks_df.empty: return {}\n",
        "    return {str(row['stock_id']): row.to_dict() for _, row in stocks_df.iterrows()}\n",
        "\n",
        "# ***** é—œéµä¿®æ­£å‡½å¼ *****\n",
        "def fetch_stock_data(stock_id, yahoo_symbol, period='1y', force_update=False, retries=3, delay=2, cache_dir=HISTORY_DATA_CACHE_DIR):\n",
        "    \"\"\"ä¸‹è¼‰è‚¡åƒ¹æ•¸æ“šï¼Œå¢åŠ å° MultiIndex æ¬„ä½çš„è™•ç†ã€‚\"\"\"\n",
        "    formatted_id = str(stock_id)\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    cache_path = os.path.join(cache_dir, f\"{formatted_id}.json\")\n",
        "\n",
        "    if not force_update and os.path.exists(cache_path) and (time.time() - os.path.getmtime(cache_path)) < 86400:\n",
        "        try:\n",
        "            with open(cache_path, 'r', encoding='utf-8') as f:\n",
        "                return json.load(f)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            temp_df = yf.download(yahoo_symbol, period=period, progress=False, auto_adjust=True)\n",
        "\n",
        "            if temp_df.empty:\n",
        "                print(f\"âš ï¸ {yahoo_symbol} åœ¨æ­¤æœŸé–“ç„¡æ•¸æ“šã€‚\")\n",
        "                return None\n",
        "\n",
        "            # --- START OF THE FIX ---\n",
        "            # æª¢æŸ¥ä¸¦è™•ç† yfinance å¯èƒ½è¿”å›çš„å¤šé‡ç´¢å¼• (MultiIndex) åˆ—æ¨™é ­\n",
        "            if isinstance(temp_df.columns, pd.MultiIndex):\n",
        "                # å°‡å¤šé‡ç´¢å¼• 'flatten' ç‚ºå–®å±¤ç´¢å¼•\n",
        "                temp_df.columns = temp_df.columns.get_level_values(0)\n",
        "            # --- END OF THE FIX ---\n",
        "\n",
        "            df = temp_df.reset_index()\n",
        "            df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "            result = {\n",
        "                'data': df.to_dict('records'),\n",
        "                'stock_id': formatted_id,\n",
        "                'yahoo_symbol': yahoo_symbol,\n",
        "                'last_price': df['Close'].iloc[-1] if not df.empty else 0\n",
        "            }\n",
        "            with open(cache_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                # åœ¨æ­¤è™•å°å‡ºéŒ¯èª¤ï¼Œè®“ä¸»æµç¨‹çŸ¥é“ç™¼ç”Ÿäº†ä»€éº¼\n",
        "                print(f\"ä¸‹è¼‰ {yahoo_symbol} å¤±æ•—: {e}\")\n",
        "    return None\n",
        "\n",
        "def fetch_multiple_stocks_data(stocks_info, period='1y', force_update=False):\n",
        "    results = {}\n",
        "    stocks_list = list(stocks_info.values())\n",
        "    total_stocks = len(stocks_list)\n",
        "\n",
        "    for idx, stock in enumerate(stocks_list):\n",
        "        stock_id = str(stock.get('stock_id'))\n",
        "        stock_name = stock.get('stock_name', 'N/A')\n",
        "        yahoo_symbol = stock.get('yahoo_symbol')\n",
        "\n",
        "        if not yahoo_symbol:\n",
        "            print(f\"âš ï¸ è‚¡ç¥¨ {stock_id} {stock_name} ç¼ºå°‘ 'yahoo_symbol'ï¼Œè·³éã€‚\")\n",
        "            continue\n",
        "\n",
        "        print(f\"[{idx+1}/{total_stocks}] æ­£åœ¨ç²å–: {stock_id} {stock_name}...\")\n",
        "        stock_data = fetch_stock_data(\n",
        "            stock_id=stock_id,\n",
        "            yahoo_symbol=yahoo_symbol,\n",
        "            period=period,\n",
        "            force_update=force_update\n",
        "        )\n",
        "\n",
        "        if stock_data and 'data' in stock_data and stock_data['data']:\n",
        "            stock_data.update(stock) # å°‡è‚¡ç¥¨åŸºæœ¬è³‡æ–™åˆä½µé€²å»\n",
        "            results[stock_id] = stock_data\n",
        "\n",
        "    print(f\"\\nè™•ç†å®Œæˆï¼Œå…±ç²å– {len(results)}/{total_stocks} æ”¯è‚¡ç¥¨çš„æ•¸æ“šã€‚\")\n",
        "    return results\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# å‡è¨­æ‚¨çš„ç¨‹å¼ä¸­å·²ç¶“è¨­å®šäº† logger\n",
        "# å¦‚æœæ²’æœ‰ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢é€™è¡Œçš„è¨»è§£\n",
        "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def fetch_stock_history(stock_id, period='1y', retries=3, delay=5):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨ yfinance ç²å–æŒ‡å®šè‚¡ç¥¨çš„æ­·å²æ•¸æ“šï¼Œä¸¦è™•ç†å°ç£å¸‚å ´çš„è‚¡ç¥¨ä»£è™Ÿã€‚\n",
        "\n",
        "    åƒæ•¸:\n",
        "    stock_id (str): è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚ '2330')\n",
        "    period (str): æ•¸æ“šæœŸé–“ (ä¾‹å¦‚ '1y', '2y', 'max')\n",
        "    retries (int): ä¸‹è¼‰å¤±æ•—æ™‚çš„é‡è©¦æ¬¡æ•¸\n",
        "    delay (int): é‡è©¦å‰çš„å»¶é²ç§’æ•¸\n",
        "\n",
        "    è¿”å›:\n",
        "    pandas.DataFrame or None: åŒ…å« OHLCV æ•¸æ“šçš„ DataFrameï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› None\n",
        "    \"\"\"\n",
        "    # æ ¹æ“šè‚¡ç¥¨ä»£è™Ÿæ ¼å¼åˆ¤æ–·å¸‚å ´\n",
        "    # å°æ–¼æ•¸å­—ä»£è™Ÿï¼Œå„ªå…ˆå˜—è©¦ .TW (ä¸Šå¸‚)ï¼Œå¤±æ•—å‰‡å˜—è©¦ .TWO (ä¸Šæ«ƒ)\n",
        "    # å°æ–¼éæ•¸å­—ä»£è™Ÿ (å¦‚ ETF)ï¼Œç›´æ¥ä½¿ç”¨ .TW\n",
        "    ticker_symbol_tw = f\"{stock_id}.TW\"\n",
        "    ticker_symbol_two = f\"{stock_id}.TWO\"\n",
        "\n",
        "    # ç¢ºå®šè¦å˜—è©¦çš„è‚¡ç¥¨ä»£è™Ÿåˆ—è¡¨\n",
        "    symbols_to_try = [ticker_symbol_tw]\n",
        "    if stock_id.isdigit():\n",
        "        symbols_to_try.append(ticker_symbol_two)\n",
        "\n",
        "    for symbol in symbols_to_try:\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                stock = yf.Ticker(symbol)\n",
        "                data = stock.history(period=period, auto_adjust=False) # ä½¿ç”¨ auto_adjust=False ä¿ç•™åŸå§‹OHLC\n",
        "\n",
        "                if not data.empty:\n",
        "                    # è½‰æ›ç‚ºå°ç£æ™‚å€ä¸¦é‡è¨­ç´¢å¼•\n",
        "                    if data.index.tz is None:\n",
        "                        data = data.tz_localize('UTC').tz_convert('Asia/Taipei')\n",
        "                    else:\n",
        "                        data = data.tz_convert('Asia/Taipei')\n",
        "\n",
        "                    data = data.reset_index()\n",
        "\n",
        "                    # å°‡ 'Date' æˆ– 'Datetime' åˆ—çš„æ™‚å€è³‡è¨Šç§»é™¤ï¼Œä»¥æ–¹ä¾¿å¾ŒçºŒè™•ç†\n",
        "                    date_col = 'Date' if 'Date' in data.columns else 'Datetime'\n",
        "                    if date_col in data.columns:\n",
        "                        data[date_col] = data[date_col].dt.tz_localize(None)\n",
        "\n",
        "                    # æ›´æ”¹æ¬„ä½åç¨±ä»¥ç¬¦åˆç¿’æ…£\n",
        "                    data.rename(columns={\n",
        "                        date_col: 'date',\n",
        "                        'Open': 'open',\n",
        "                        'High': 'high',\n",
        "                        'Low': 'low',\n",
        "                        'Close': 'close',\n",
        "                        'Volume': 'volume'\n",
        "                    }, inplace=True)\n",
        "\n",
        "                    # ç§»é™¤ä¸éœ€è¦çš„æ¬„ä½\n",
        "                    cols_to_drop = ['Dividends', 'Stock Splits']\n",
        "                    data = data.drop(columns=[col for col in cols_to_drop if col in data.columns])\n",
        "\n",
        "                    logger.info(f\"âœ… æˆåŠŸç²å– {symbol} çš„æ­·å²æ•¸æ“šã€‚\")\n",
        "                    return data\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ä¸‹è¼‰ {symbol} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ (ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦): {e}\")\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(delay)\n",
        "                else:\n",
        "                    logger.error(f\"é‡è©¦ {retries} æ¬¡å¾Œï¼Œä»ç„¡æ³•ä¸‹è¼‰ {symbol} çš„æ•¸æ“šã€‚\")\n",
        "\n",
        "    logger.warning(f\"æœ€çµ‚ç„¡æ³•ç²å–è‚¡ç¥¨ {stock_id} çš„ä»»ä½•æ­·å²æ•¸æ“šã€‚\")\n",
        "    return None\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    if df.empty or 'Close' not in df.columns: return df\n",
        "    result = df.copy()\n",
        "    for days in [5, 10, 20, 60]: result[f'MA{days}'] = result['Close'].rolling(window=days).mean()\n",
        "    delta = result['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0); loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean(); avg_loss = loss.rolling(window=14).mean()\n",
        "    rs = avg_gain / (avg_loss + 1e-9); result['RSI'] = 100 - (100 / (1 + rs))\n",
        "    exp1 = result['Close'].ewm(span=12, adjust=False).mean(); exp2 = result['Close'].ewm(span=26, adjust=False).mean()\n",
        "    result['MACD'] = exp1 - exp2; result['Signal'] = result['MACD'].ewm(span=9, adjust=False).mean()\n",
        "    result['Histogram'] = result['MACD'] - result['Signal']\n",
        "    low_min = result['Low'].rolling(window=14).min(); high_max = result['High'].rolling(window=14).max()\n",
        "    result['K'] = 100 * ((result['Close'] - low_min) / (high_max - low_min + 1e-9))\n",
        "    result['D'] = result['K'].rolling(window=3).mean()\n",
        "    return result.fillna(0)\n",
        "\n",
        "def analyze_stock(stock_id, stock_data):\n",
        "    if not stock_data or not stock_data.get('data'):\n",
        "        return {'success': False, 'message': \"ç„¡æ•ˆæ•¸æ“š\"}\n",
        "    df = pd.DataFrame(stock_data['data'])\n",
        "    if len(df) < 60: return {'success': False, 'message': \"æ•¸æ“šä¸è¶³\"}\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df['Date']); df.set_index('Date', inplace=True)\n",
        "    df_with_indicators = add_technical_indicators(df)\n",
        "\n",
        "    price_change_1m = ((df['Close'].iloc[-1] / df['Close'].iloc[-22]) - 1) * 100 if len(df) > 21 else 0\n",
        "\n",
        "    return {\n",
        "        'stock_id': stock_id,\n",
        "        'stock_name': stock_data.get('stock_name', 'N/A'),\n",
        "        'last_price': stock_data.get('last_price', 0),\n",
        "        'price_change': {'1m': price_change_1m},\n",
        "        'data_df': df_with_indicators,\n",
        "        'success': True\n",
        "    }\n",
        "\n",
        "def calculate_comprehensive_score(analysis_result):\n",
        "    scores = {'trend_score': 50, 'momentum_score': 50, 'volume_score': 50}\n",
        "    df = analysis_result.get('data_df')\n",
        "    if df is None or df.empty or len(df) < 60: return scores, 50\n",
        "\n",
        "    if df['MA5'].iloc[-1] > df['MA10'].iloc[-1] > df['MA20'].iloc[-1] > df['MA60'].iloc[-1]:\n",
        "        scores['trend_score'] = 85\n",
        "    else: scores['trend_score'] = 20\n",
        "\n",
        "    momentum_points = 50\n",
        "    if df['RSI'].iloc[-1] > 60: momentum_points += 15\n",
        "    if df['MACD'].iloc[-1] > df['Signal'].iloc[-1]: momentum_points += 20\n",
        "    if df['K'].iloc[-1] > df['D'].iloc[-1]: momentum_points += 15\n",
        "    scores['momentum_score'] = max(0, min(100, momentum_points))\n",
        "\n",
        "    if df['Volume'].iloc[-1] > df['Volume'].rolling(window=20).mean().iloc[-1] * 1.5:\n",
        "        scores['volume_score'] = 80\n",
        "\n",
        "    final_score = scores['trend_score'] * 0.4 + scores['momentum_score'] * 0.45 + scores['volume_score'] * 0.15\n",
        "    return scores, final_score\n",
        "\n",
        "def generate_recommendation(score):\n",
        "    if score >= 75: return 'å¼·åŠ›è²·å…¥'\n",
        "    if score >= 60: return 'è²·å…¥'\n",
        "    if score >= 40: return 'æŒæœ‰'\n",
        "    if score >= 25: return 'è§€æœ›'\n",
        "    return 'è³£å‡º'\n",
        "\n",
        "\n",
        "\n",
        "import mplfinance as mpf\n",
        "print(f\"mplfinance ç‰ˆæœ¬: {mpf.__version__}\")\n",
        "\n",
        "def generate_detailed_analysis_report(stock_id, stock_name, stock_data, save_path=None):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆå–®ä¸€è‚¡ç¥¨çš„è©³ç´°åˆ†æåœ–è¡¨ (ä¿®æ­£ç‰ˆ)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. ç²å–åŒ…å«å®Œæ•´æŒ‡æ¨™çš„ DataFrame ä¸¦è¼¸å‡ºè©³ç´°è¨ºæ–·è³‡è¨Š\n",
        "        logger.info(f\"é–‹å§‹ç‚º {stock_id} {stock_name} ç”Ÿæˆåœ–è¡¨...\")\n",
        "\n",
        "        # æª¢æŸ¥ stock_data çš„çµæ§‹\n",
        "        if not isinstance(stock_data, dict):\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): stock_data ä¸æ˜¯å­—å…¸é¡å‹ï¼Œè€Œæ˜¯ {type(stock_data)}\")\n",
        "            return\n",
        "\n",
        "        # æª¢æŸ¥ data_df æ˜¯å¦å­˜åœ¨\n",
        "        if 'data_df' not in stock_data:\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): stock_data ä¸­ç¼ºå°‘ 'data_df' éµã€‚å¯ç”¨çš„éµ: {list(stock_data.keys())}\")\n",
        "            return\n",
        "\n",
        "        df_with_indicators = stock_data.get('data_df')\n",
        "\n",
        "        # æª¢æŸ¥ df_with_indicators æ˜¯å¦ç‚º DataFrame\n",
        "        if not isinstance(df_with_indicators, pd.DataFrame):\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): data_df ä¸æ˜¯ DataFrameï¼Œè€Œæ˜¯ {type(df_with_indicators)}\")\n",
        "            return\n",
        "\n",
        "        if df_with_indicators is None or df_with_indicators.empty:\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): data_df ç‚ºç©ºæˆ– None\")\n",
        "            return\n",
        "\n",
        "        # è¼¸å‡º DataFrame çš„åŸºæœ¬è³‡è¨Š\n",
        "        logger.info(f\"DataFrame è³‡è¨Š: è¡Œæ•¸={len(df_with_indicators)}, åˆ—æ•¸={len(df_with_indicators.columns)}\")\n",
        "        logger.info(f\"DataFrame åˆ—å: {list(df_with_indicators.columns)}\")\n",
        "\n",
        "        # æª¢æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨\n",
        "        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'MA5', 'MA20', 'MACD', 'Signal', 'Histogram', 'RSI']\n",
        "        missing_cols = [col for col in required_cols if col not in df_with_indicators.columns]\n",
        "        if missing_cols:\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}\")\n",
        "            return\n",
        "\n",
        "        # 2. æˆªå–æœ€è¿‘ 120 å¤©çš„æ•¸æ“šç”¨æ–¼ç¹ªåœ–ï¼Œä½¿ç”¨ .copy() é¿å…è­¦å‘Š\n",
        "        df_plot = df_with_indicators.tail(120).copy()\n",
        "        logger.info(f\"æˆªå–å¾Œçš„ DataFrame è¡Œæ•¸: {len(df_plot)}\")\n",
        "\n",
        "        if len(df_plot) < 20: # ç¢ºä¿æœ‰è¶³å¤ æ•¸æ“šç¹ªè£½æŒ‡æ¨™\n",
        "            logger.warning(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): æœ‰æ•ˆæ•¸æ“šä¸è¶³ (<20)ã€‚\")\n",
        "            return\n",
        "\n",
        "        # 3. æª¢æŸ¥æ˜¯å¦æœ‰ NaN å€¼\n",
        "        nan_counts = df_plot.isna().sum()\n",
        "        if nan_counts.sum() > 0:\n",
        "            logger.warning(f\"DataFrame ä¸­å­˜åœ¨ NaN å€¼: {nan_counts[nan_counts > 0]}\")\n",
        "            # å¡«å…… NaN å€¼ï¼Œé¿å…ç¹ªåœ–éŒ¯èª¤\n",
        "            df_plot = df_plot.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "        # 4. æª¢æŸ¥ DataFrame çš„ç´¢å¼•é¡å‹ - ç§»åˆ°é€™è£¡ï¼Œç¢ºä¿ df_plot å·²ç¶“å®šç¾©\n",
        "        if not isinstance(df_plot.index, pd.DatetimeIndex):\n",
        "            logger.warning(f\"DataFrame ç´¢å¼•ä¸æ˜¯ DatetimeIndexï¼Œå˜—è©¦è½‰æ›...\")\n",
        "            try:\n",
        "                # å¦‚æœ 'Date' æ˜¯åˆ—è€Œä¸æ˜¯ç´¢å¼•\n",
        "                if 'Date' in df_plot.columns:\n",
        "                    df_plot.set_index('Date', inplace=True)\n",
        "                # å˜—è©¦å°‡ç¾æœ‰ç´¢å¼•è½‰æ›ç‚º DatetimeIndex\n",
        "                df_plot.index = pd.to_datetime(df_plot.index)\n",
        "                logger.info(\"ç´¢å¼•è½‰æ›æˆåŠŸ\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"è½‰æ›ç´¢å¼•å¤±æ•—: {e}\")\n",
        "                # å¦‚æœè½‰æ›å¤±æ•—ï¼Œå˜—è©¦å‰µå»ºä¸€å€‹å‡çš„æ—¥æœŸç´¢å¼•\n",
        "                logger.info(\"å˜—è©¦å‰µå»ºå‡çš„æ—¥æœŸç´¢å¼•...\")\n",
        "                df_plot.index = pd.date_range(start='2023-01-01', periods=len(df_plot))\n",
        "                logger.info(\"å‰µå»ºå‡çš„æ—¥æœŸç´¢å¼•æˆåŠŸ\")\n",
        "\n",
        "        # 5. ä¿®æ­£æ¨£å¼è¨­å®šï¼šä½¿ç”¨ 'gridstyle' è€Œä¸æ˜¯ 'gridwidth'\n",
        "        mc = mpf.make_marketcolors(up='r', down='g', inherit=True)\n",
        "        s = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=mc, gridstyle='--')\n",
        "\n",
        "        # 6. å¾æˆªå–å¾Œçš„ df_plot å‰µå»ºé™„åŠ åœ–ï¼Œç¢ºä¿æ‰€æœ‰æ•¸æ“šé•·åº¦ä¸€è‡´\n",
        "        logger.info(\"é–‹å§‹å‰µå»ºé™„åŠ åœ–...\")\n",
        "        try:\n",
        "            apds = [\n",
        "                mpf.make_addplot(df_plot['MA5'], color='orange', width=0.7),\n",
        "                mpf.make_addplot(df_plot['MA20'], color='blue', width=0.7),\n",
        "                mpf.make_addplot(df_plot['Histogram'], type='bar', panel=1, color='grey', alpha=0.5),\n",
        "                mpf.make_addplot(df_plot[['MACD', 'Signal']], panel=1),\n",
        "                mpf.make_addplot(df_plot['RSI'], panel=2),\n",
        "            ]\n",
        "            logger.info(\"é™„åŠ åœ–å‰µå»ºæˆåŠŸ\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å‰µå»ºé™„åŠ åœ–æ™‚å‡ºéŒ¯: {e}\")\n",
        "            # å˜—è©¦ç°¡åŒ–é™„åŠ åœ–\n",
        "            try:\n",
        "                logger.info(\"å˜—è©¦ç°¡åŒ–é™„åŠ åœ–...\")\n",
        "                apds = [mpf.make_addplot(df_plot['MA5'], color='orange')]\n",
        "                logger.info(\"ç°¡åŒ–é™„åŠ åœ–å‰µå»ºæˆåŠŸ\")\n",
        "            except Exception as e2:\n",
        "                logger.error(f\"å‰µå»ºç°¡åŒ–é™„åŠ åœ–ä¹Ÿå¤±æ•—: {e2}\")\n",
        "                apds = []\n",
        "\n",
        "        # 7. è¨­å®šåœ–è¡¨æ¨™é¡Œèˆ‡å„²å­˜è·¯å¾‘\n",
        "        title = f\"{stock_id} {stock_name} (Score: {int(round(stock_data.get('combined_score', 0)))})\"\n",
        "        if not save_path:\n",
        "            save_path = os.path.join(CHARTS_DIR, f\"{stock_id}_report.png\")\n",
        "\n",
        "        logger.info(f\"æº–å‚™ç¹ªè£½åœ–è¡¨ï¼Œå„²å­˜è‡³: {save_path}\")\n",
        "\n",
        "        # 8. ç¹ªè£½åœ–è¡¨\n",
        "        try:\n",
        "            mpf.plot(\n",
        "                df_plot,\n",
        "                type='candle',\n",
        "                style=s,\n",
        "                title=title,\n",
        "                volume=True,\n",
        "                addplot=apds,\n",
        "                panel_ratios=(6, 2, 2), # (ä¸»åœ–, MACDé¢æ¿, RSIé¢æ¿)\n",
        "                figsize=(16, 9),\n",
        "                savefig=dict(fname=save_path, dpi=150)\n",
        "            )\n",
        "            logger.info(f\"âœ… åœ–è¡¨ç¹ªè£½æˆåŠŸä¸¦å„²å­˜è‡³: {save_path}\")\n",
        "        except Exception as plot_error:\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨æ™‚å‡ºéŒ¯: {plot_error}\")\n",
        "            # å˜—è©¦æœ€ç°¡å–®çš„ç¹ªåœ–æ–¹å¼\n",
        "            try:\n",
        "                logger.info(\"å˜—è©¦æœ€ç°¡å–®çš„ç¹ªåœ–æ–¹å¼...\")\n",
        "                plt.figure(figsize=(16, 9))\n",
        "                plt.title(title)\n",
        "                plt.plot(df_plot['Close'], label='Close')\n",
        "                plt.savefig(save_path, dpi=150)\n",
        "                logger.info(f\"âœ… ç°¡åŒ–åœ–è¡¨ç¹ªè£½æˆåŠŸä¸¦å„²å­˜è‡³: {save_path}\")\n",
        "            except Exception as simple_plot_error:\n",
        "                logger.error(f\"ç°¡åŒ–ç¹ªåœ–ä¹Ÿå¤±æ•—: {simple_plot_error}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç‚º {stock_id} ç¹ªè£½åœ–è¡¨æ™‚ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤: {e}\")\n",
        "        logger.error(traceback.format_exc())  # è¼¸å‡ºå®Œæ•´çš„å †ç–Šè¿½è¹¤\n",
        "    finally:\n",
        "        # 9. ç¢ºä¿é—œé–‰åœ–è¡¨ï¼Œé‡‹æ”¾è¨˜æ†¶é«”ï¼Œé¿å…åœ¨å¤§é‡è¿´åœˆä¸­è€—ç›¡è³‡æº\n",
        "        plt.close('all')\n",
        "\n",
        "# ==============================================\n",
        "# ä½¿ç”¨è€…ä»‹é¢ (UI) ç›¸é—œå‡½å¼\n",
        "# ==============================================\n",
        "\n",
        "def input_stock_ids():\n",
        "    while True:\n",
        "        user_input = input(\"\\nè«‹è¼¸å…¥æ¬²åˆ†æçš„4ä½å°è‚¡è‚¡ç¥¨ä»£ç¢¼ï¼ˆç”¨é€—è™Ÿæˆ–ç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚ 2330,2303 2603ï¼‰ï¼š\\n> \")\n",
        "        stock_ids = re.findall(r'\\b\\d{4}\\b', user_input)\n",
        "        if stock_ids:\n",
        "            print(f\"å·²è­˜åˆ¥è‚¡ç¥¨ä»£ç¢¼: {', '.join(stock_ids)}\")\n",
        "            return list(dict.fromkeys(stock_ids))\n",
        "        print(\"â— è¼¸å…¥æ ¼å¼éŒ¯èª¤æˆ–æœªåŒ…å«æœ‰æ•ˆçš„4ä½æ•¸ä»£ç¢¼ï¼Œè«‹é‡æ–°è¼¸å…¥ï¼\")\n",
        "\n",
        "def filter_by_volume(stock_data, min_volume_shares=1000000, days=22):\n",
        "    filtered = {}\n",
        "    print(f\"\\né€²è¡Œæˆäº¤é‡éæ¿¾ (è¿‘{days}æ—¥æˆäº¤é‡ > {min_volume_shares/1000:,.0f} å¼µ)...\")\n",
        "    for stock_id, data in stock_data.items():\n",
        "        if not data or 'data' not in data: continue\n",
        "        df = pd.DataFrame(data['data'])\n",
        "        if len(df) >= days and (df['Volume'].tail(days) >= min_volume_shares).all():\n",
        "            filtered[stock_id] = data\n",
        "    print(f\"æˆäº¤é‡éæ¿¾å¾Œï¼Œå‰©ä¸‹ {len(filtered)} / {len(stock_data)} æ”¯è‚¡ç¥¨ã€‚\")\n",
        "    return filtered\n",
        "\n",
        "def top_percentile_filter(results, score_key='combined_score', percentile=98):\n",
        "    if not results: return {}\n",
        "    all_scores = [r.get(score_key, 0) for r in results.values()]\n",
        "    if not all_scores: return {}\n",
        "    threshold = np.percentile(all_scores, percentile)\n",
        "    print(f\"\\né€²è¡Œé ‚å°–ç¯©é¸ (åˆ†æ•¸éœ€ >= {threshold:.0f}ï¼Œå³å‰ {100-percentile}%)\")\n",
        "    filtered = {sid: r for sid, r in results.items() if r.get(score_key, 0) >= threshold}\n",
        "    print(f\"é ‚å°–ç¯©é¸å¾Œï¼Œå‰©ä¸‹ {len(filtered)} / {len(results)} æ”¯è‚¡ç¥¨ã€‚\")\n",
        "    return filtered\n",
        "\n",
        "def print_top_stocks(results, top_n=10):\n",
        "    sorted_stocks = sorted(results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)[:top_n]\n",
        "    print(\"\\n\" + \"=\"*60); print(\"ğŸ†\" * 8 + \" å‰ååç¸¾å„ªè‚¡åˆ—è¡¨ \" + \"ğŸ†\" * 8); print(\"=\"*60)\n",
        "    print(f\"{'æ’å':<4}{'ä»£ç¢¼':<6}{'åç¨±':<12}{'åˆ†æ•¸':<6}{'åƒ¹æ ¼':<8}{'æœˆæ¼²å¹…(%)':<10}{'å»ºè­°':<8}\")\n",
        "    print(\"-\" * 60)\n",
        "    for i, stock in enumerate(sorted_stocks, 1):\n",
        "        print(f\"{i:<4}{stock.get('stock_id',''):<6}{stock.get('stock_name',''):<12}\"\n",
        "              f\"{int(round(stock.get('combined_score', 0))):<6}\"\n",
        "              f\"{int(round(stock.get('last_price', 0))):<8}\"\n",
        "              f\"{int(round(stock.get('price_change',{}).get('1m',0))):<10}\"\n",
        "              f\"{stock.get('recommendation',''):<8}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸\n",
        "# ==============================================================================\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "    if not files:\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        if os.path.exists(chart_dir):\n",
        "            # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "            files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                    if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            if files:\n",
        "                logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "            else:\n",
        "                logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                if response.status == 200:\n",
        "                    logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                else:\n",
        "                    response_text = await response.text()\n",
        "                    logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                sent_count = 0\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            data = aiohttp.FormData()\n",
        "                            data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                            # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                            caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                            data.add_field('caption', caption)\n",
        "\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                    if response.status == 200:\n",
        "                                        sent_count += 1\n",
        "                                    else:\n",
        "                                        response_text = await response.text()\n",
        "                                        logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                            # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                            await asyncio.sleep(0.5)\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "        message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "        for chunk in message_chunks:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response and response.ok:\n",
        "                logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                content = response.content if response else \"æœªçŸ¥\"\n",
        "                logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "        # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "        if files:\n",
        "            batch_size = 10\n",
        "            for i in range(0, len(files), batch_size):\n",
        "                batch_files = files[i:i+batch_size]\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                for file_path in batch_files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        # ç²å–åœ–è¡¨æª”æ¡ˆæ•¸é‡\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        chart_count = 0\n",
        "        if os.path.exists(chart_dir):\n",
        "            chart_files = [f for f in os.listdir(chart_dir) if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            chart_count = len(chart_files)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ“Š ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ“ˆ TOP {min(5, len(filtered_results))} æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            # ç²å–æ›´å¤šæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\n",
        "            macd = tech.get('macd_value', 0)\n",
        "            signal = tech.get('signal_value', 0)\n",
        "            macd_status = \"å¤šé ­\" if macd > signal else \"ç©ºé ­\" if macd < signal else \"ä¸­æ€§\"\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_status', 'ä¸­æ€§')})\n",
        "   ğŸ“‰ MACD: {macd_status}\n",
        "\"\"\"\n",
        "\n",
        "        # æ·»åŠ åœ–è¡¨è³‡è¨Š\n",
        "        if chart_count > 0:\n",
        "            message += f\"\"\"\n",
        "ğŸ“Š è©³ç´°åˆ†æåœ–è¡¨:\n",
        "â€¢ å·²ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "â€¢ åœ–è¡¨åŒ…å«Kç·šã€å‡ç·šã€æˆäº¤é‡ã€MACDåŠRSIæŒ‡æ¨™\n",
        "â€¢ åœ–è¡¨å°‡åœ¨æ­¤è¨Šæ¯å¾Œç™¼é€\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "#=======================================\n",
        "# ä¸»ç¨‹å¼åŸ·è¡Œæµç¨‹\n",
        "# ==============================================\n",
        "\n",
        "async def main_menu():\n",
        "    print(\"=\"*40)\n",
        "    print(\"==== å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· ====\")\n",
        "    print(\"=\"*40)\n",
        "    print(\"ğŸš€ é–‹å§‹è‡ªå‹•åˆ†ææ‰€æœ‰è‚¡ç¥¨...\")\n",
        "\n",
        "    print(\"\\n[éšæ®µ1/5] ç²å–æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬è³‡æ–™...\")\n",
        "    stocks_info = get_stock_basic_info()\n",
        "    stock_ids = list(stocks_info.keys())\n",
        "\n",
        "    print(\"\\n[éšæ®µ2/5] æ‰¹æ¬¡ä¸‹è¼‰æ­·å²è³‡æ–™ (ä¸€å¹´æœŸ)...\")\n",
        "    all_stocks_data = fetch_multiple_stocks_data(stocks_info, period='1y')\n",
        "    if not all_stocks_data:\n",
        "        print(\"âŒ ç„¡æ³•å–å¾—ä»»ä½•è‚¡ç¥¨æ­·å²è³‡æ–™ï¼Œæµç¨‹ä¸­æ­¢ã€‚\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n[éšæ®µ3/5] éæ¿¾ä½æˆäº¤é‡è‚¡ç¥¨...\")\n",
        "    filtered_data = filter_by_volume(all_stocks_data, min_volume_shares=1000 * 1000)\n",
        "    if not filtered_data:\n",
        "        print(\"âŒ æ²’æœ‰ä»»ä½•å€‹è‚¡ç¬¦åˆæˆäº¤é‡æ¨™æº– (è¿‘ä¸€å€‹æœˆæ¯æ—¥æˆäº¤é‡ > 1000å¼µ)ã€‚\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n[éšæ®µ4/5] é€²è¡Œæ ¸å¿ƒåˆ†æèˆ‡ç¶œåˆè©•åˆ†...\")\n",
        "    all_analysis_results = {}\n",
        "    for i, (stock_id, stock_data) in enumerate(filtered_data.items()):\n",
        "        print(f\"  åˆ†æä¸­ ({i+1}/{len(filtered_data)}): {stock_id} {stock_data.get('stock_name', '')}\")\n",
        "        analysis_result = analyze_stock(stock_id, stock_data)\n",
        "        if analysis_result.get('success'):\n",
        "            scores, final_score = calculate_comprehensive_score(analysis_result)\n",
        "            analysis_result['scores'] = {k: int(round(v)) for k, v in scores.items()}\n",
        "            analysis_result['combined_score'] = int(round(final_score))\n",
        "            analysis_result['recommendation'] = generate_recommendation(final_score)\n",
        "            all_analysis_results[stock_id] = analysis_result\n",
        "\n",
        "    if not all_analysis_results: # <- ä¿®æ­£äº†è®Šæ•¸åç¨±ä¸¦è£œä¸Šå†’è™Ÿ\n",
        "        print(\"âŒ æ ¸å¿ƒåˆ†æå¾Œï¼Œæ²’æœ‰ä»»ä½•è‚¡ç¥¨ç¬¦åˆæ¨™æº–ã€‚\")\n",
        "        # ç™¼é€ç©ºçµæœé€šçŸ¥\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            empty_message = format_notification_message({})\n",
        "            await send_notification(session, empty_message)\n",
        "        print(\"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\")\n",
        "        return # çµæŸå‡½å¼\n",
        "\n",
        "    print(\"\\n[éšæ®µ5/5] ç¯©é¸é ‚å°–å€‹è‚¡ä¸¦ç”¢å‡ºå ±å‘Š...\")\n",
        "    elite_results = top_percentile_filter(all_analysis_results, percentile=98)\n",
        "    results_to_show = elite_results if elite_results else all_analysis_results\n",
        "\n",
        "    if not results_to_show:\n",
        "        print(\"ğŸ¤· æ‰¾ä¸åˆ°ä»»ä½•å¯é¡¯ç¤ºçš„çµæœã€‚\")\n",
        "        return\n",
        "\n",
        "    if not elite_results:\n",
        "        print(\"ğŸ¤· æ²’æœ‰å€‹è‚¡åˆ†æ•¸é”åˆ°å‰2%çš„é–€æª»ã€‚å°‡é¡¯ç¤ºåŸå§‹æ¸…å–®ä¸­åˆ†æ•¸æœ€é«˜çš„è‚¡ç¥¨ã€‚\")\n",
        "\n",
        "    print_top_stocks(results_to_show, top_n=10)\n",
        "\n",
        "    print(\"\\n--- æ­£åœ¨ç‚ºé ‚å°–å€‹è‚¡ç”Ÿæˆè©³ç´°åœ–è¡¨å ±å‘Š ---\")\n",
        "    top_stocks_to_report = sorted(results_to_show.values(), key=lambda x: x.get('combined_score', 0), reverse=True)[:10]\n",
        "    for stock in top_stocks_to_report:\n",
        "        generate_detailed_analysis_report(\n",
        "            stock_id=stock['stock_id'],\n",
        "            stock_name=stock['stock_name'],\n",
        "            stock_data=stock\n",
        "        )\n",
        "    print(\"\\nğŸ‰ å…¨éƒ¨æµç¨‹åŸ·è¡Œå®Œç•¢ï¼\")\n",
        "    # å³ä½¿æ²’æœ‰çµæœä¹Ÿç™¼é€é€šçŸ¥            try:\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            message = format_notification_message({})\n",
        "            await send_notification(session, message)\n",
        "            print(\"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ç©ºçµæœé€šçŸ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "if __name__ == \"__main__\":\n",
        "    set_chinese_font()\n",
        "    asyncio.run(main_menu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG0sUErIIRDT",
        "outputId": "a67e0297-35c2-4a7c-cddd-6f8fb7d65095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å·²è¼‰å…¥ chineseize_matplotlib ä¸­æ–‡å­—é«”æ”¯æ´\n",
            "ğŸ” æª¢æŸ¥åŸ·è¡Œç’°å¢ƒ...\n",
            "Python ç‰ˆæœ¬: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "ä½œæ¥­ç³»çµ±: Linux 6.1.123+\n",
            "\n",
            "ğŸ“¦ å¥—ä»¶ç‰ˆæœ¬:\n",
            "  pandas: 2.2.2\n",
            "  numpy: 2.0.2\n",
            "  matplotlib: 3.10.0\n",
            "  requests: 2.32.3\n",
            "  yfinance: 0.2.65\n",
            "\n",
            "ğŸ“ å·¥ä½œç›®éŒ„: /content\n",
            "å¿«å–ç›®éŒ„: cache âœ…\n",
            "çµæœç›®éŒ„: results âœ…\n",
            "==================================================\n",
            "âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\n",
            "========================================\n",
            "==== å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· ====\n",
            "========================================\n",
            "ğŸš€ é–‹å§‹è‡ªå‹•åˆ†ææ‰€æœ‰è‚¡ç¥¨...\n",
            "\n",
            "[éšæ®µ1/7] ç²å–æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬è³‡æ–™...\n",
            "âœ… å¾å¿«å–è¼‰å…¥ 1912 æ”¯è‚¡ç¥¨æ¸…å–®ã€‚\n",
            "âœ… æˆåŠŸç²å– 1912 æ”¯è‚¡ç¥¨è³‡æ–™\n",
            "\n",
            "[éšæ®µ2/7] æ‰¹æ¬¡ä¸‹è¼‰æ­·å²è³‡æ–™...\n",
            "[1/1912] æ­£åœ¨è™•ç†: 1101 å°æ³¥\n",
            "[2/1912] æ­£åœ¨è™•ç†: 1102 äºæ³¥\n",
            "[3/1912] æ­£åœ¨è™•ç†: 1103 å˜‰æ³¥\n",
            "[4/1912] æ­£åœ¨è™•ç†: 1104 ç’°æ³¥\n",
            "[5/1912] æ­£åœ¨è™•ç†: 1108 å¹¸ç¦\n",
            "[6/1912] æ­£åœ¨è™•ç†: 1109 ä¿¡å¤§\n",
            "[7/1912] æ­£åœ¨è™•ç†: 1110 æ±æ³¥\n",
            "[8/1912] æ­£åœ¨è™•ç†: 1201 å‘³å…¨\n",
            "[9/1912] æ­£åœ¨è™•ç†: 1203 å‘³ç‹\n",
            "[10/1912] æ­£åœ¨è™•ç†: 1210 å¤§æˆ\n",
            "[11/1912] æ­£åœ¨è™•ç†: 1213 å¤§é£²\n",
            "[12/1912] æ­£åœ¨è™•ç†: 1215 åœèœ‚\n",
            "[13/1912] æ­£åœ¨è™•ç†: 1216 çµ±ä¸€\n",
            "[14/1912] æ­£åœ¨è™•ç†: 1217 æ„›ä¹‹å‘³\n",
            "[15/1912] æ­£åœ¨è™•ç†: 1218 æ³°å±±\n",
            "[16/1912] æ­£åœ¨è™•ç†: 1219 ç¦å£½\n",
            "[17/1912] æ­£åœ¨è™•ç†: 1220 å°æ¦®\n",
            "[18/1912] æ­£åœ¨è™•ç†: 1225 ç¦æ‡‹æ²¹\n",
            "[19/1912] æ­£åœ¨è™•ç†: 1227 ä½³æ ¼\n",
            "[20/1912] æ­£åœ¨è™•ç†: 1229 è¯è¯\n",
            "[21/1912] æ­£åœ¨è™•ç†: 1231 è¯è¯é£Ÿ\n",
            "[22/1912] æ­£åœ¨è™•ç†: 1232 å¤§çµ±ç›Š\n",
            "[23/1912] æ­£åœ¨è™•ç†: 1233 å¤©ä»\n",
            "[24/1912] æ­£åœ¨è™•ç†: 1234 é»‘æ¾\n",
            "[25/1912] æ­£åœ¨è™•ç†: 1235 èˆˆæ³°\n",
            "[26/1912] æ­£åœ¨è™•ç†: 1236 å®äº\n",
            "[27/1912] æ­£åœ¨è™•ç†: 1256 é®®æ´»æœæ±-KY\n",
            "[28/1912] æ­£åœ¨è™•ç†: 1301 å°å¡‘\n",
            "[29/1912] æ­£åœ¨è™•ç†: 1303 å—äº\n",
            "[30/1912] æ­£åœ¨è™•ç†: 1304 å°èš\n",
            "[31/1912] æ­£åœ¨è™•ç†: 1305 è¯å¤\n",
            "[32/1912] æ­£åœ¨è™•ç†: 1307 ä¸‰èŠ³\n",
            "[33/1912] æ­£åœ¨è™•ç†: 1308 äºèš\n",
            "[34/1912] æ­£åœ¨è™•ç†: 1309 å°é”åŒ–\n",
            "[35/1912] æ­£åœ¨è™•ç†: 1310 å°è‹¯\n",
            "[36/1912] æ­£åœ¨è™•ç†: 1312 åœ‹å–¬\n",
            "[37/1912] æ­£åœ¨è™•ç†: 1313 è¯æˆ\n",
            "[38/1912] æ­£åœ¨è™•ç†: 1314 ä¸­çŸ³åŒ–\n",
            "[39/1912] æ­£åœ¨è™•ç†: 1315 é”æ–°\n",
            "[40/1912] æ­£åœ¨è™•ç†: 1316 ä¸Šæ›œ\n",
            "[41/1912] æ­£åœ¨è™•ç†: 1319 æ±é™½\n",
            "[42/1912] æ­£åœ¨è™•ç†: 1321 å¤§æ´‹\n",
            "[43/1912] æ­£åœ¨è™•ç†: 1323 æ°¸è£•\n",
            "[44/1912] æ­£åœ¨è™•ç†: 1324 åœ°çƒ\n",
            "[45/1912] æ­£åœ¨è™•ç†: 1325 æ†å¤§\n",
            "[46/1912] æ­£åœ¨è™•ç†: 1326 å°åŒ–\n",
            "[47/1912] æ­£åœ¨è™•ç†: 1337 å†ç”Ÿ-KY\n",
            "[48/1912] æ­£åœ¨è™•ç†: 1338 å»£è¯-KY\n",
            "[49/1912] æ­£åœ¨è™•ç†: 1339 æ˜­è¼\n",
            "[50/1912] æ­£åœ¨è™•ç†: 1340 å‹æ‚…-KY\n",
            "[51/1912] æ­£åœ¨è™•ç†: 1341 å¯Œæ—-KY\n",
            "[52/1912] æ­£åœ¨è™•ç†: 1342 å…«è²«\n",
            "[53/1912] æ­£åœ¨è™•ç†: 1402 é æ±æ–°\n",
            "[54/1912] æ­£åœ¨è™•ç†: 1409 æ–°çº–\n",
            "[55/1912] æ­£åœ¨è™•ç†: 1410 å—æŸ“\n",
            "[56/1912] æ­£åœ¨è™•ç†: 1413 å®æ´²\n",
            "[57/1912] æ­£åœ¨è™•ç†: 1414 æ±å’Œ\n",
            "[58/1912] æ­£åœ¨è™•ç†: 1416 å»£è±\n",
            "[59/1912] æ­£åœ¨è™•ç†: 1417 å˜‰è£•\n",
            "[60/1912] æ­£åœ¨è™•ç†: 1418 æ±è¯\n",
            "[61/1912] æ­£åœ¨è™•ç†: 1419 æ–°ç´¡\n",
            "[62/1912] æ­£åœ¨è™•ç†: 1423 åˆ©è¯\n",
            "[63/1912] æ­£åœ¨è™•ç†: 1432 å¤§é­¯é–£\n",
            "[64/1912] æ­£åœ¨è™•ç†: 1434 ç¦æ‡‹\n",
            "[65/1912] æ­£åœ¨è™•ç†: 1435 ä¸­ç¦\n",
            "[66/1912] æ­£åœ¨è™•ç†: 1436 è¯å‹è¯\n",
            "[67/1912] æ­£åœ¨è™•ç†: 1437 å‹¤ç›Šæ§\n",
            "[68/1912] æ­£åœ¨è™•ç†: 1438 ä¸‰åœ°é–‹ç™¼\n",
            "[69/1912] æ­£åœ¨è™•ç†: 1439 é›‹æš\n",
            "[70/1912] æ­£åœ¨è™•ç†: 1440 å—ç´¡\n",
            "[71/1912] æ­£åœ¨è™•ç†: 1441 å¤§æ±\n",
            "[72/1912] æ­£åœ¨è™•ç†: 1442 åè»’\n",
            "[73/1912] æ­£åœ¨è™•ç†: 1443 ç«‹ç›Šç‰©æµ\n",
            "[74/1912] æ­£åœ¨è™•ç†: 1444 åŠ›éº—\n",
            "[75/1912] æ­£åœ¨è™•ç†: 1445 å¤§å®‡\n",
            "[76/1912] æ­£åœ¨è™•ç†: 1446 å®å’Œ\n",
            "[77/1912] æ­£åœ¨è™•ç†: 1447 åŠ›éµ¬\n",
            "[78/1912] æ­£åœ¨è™•ç†: 1449 ä½³å’Œ\n",
            "[79/1912] æ­£åœ¨è™•ç†: 1451 å¹´èˆˆ\n",
            "[80/1912] æ­£åœ¨è™•ç†: 1452 å®ç›Š\n",
            "[81/1912] æ­£åœ¨è™•ç†: 1453 å¤§å°‡\n",
            "[82/1912] æ­£åœ¨è™•ç†: 1454 å°å¯Œ\n",
            "[83/1912] æ­£åœ¨è™•ç†: 1455 é›†ç››\n",
            "[84/1912] æ­£åœ¨è™•ç†: 1456 æ€¡è¯\n",
            "[85/1912] æ­£åœ¨è™•ç†: 1457 å®œé€²\n",
            "[86/1912] æ­£åœ¨è™•ç†: 1459 è¯ç™¼\n",
            "[87/1912] æ­£åœ¨è™•ç†: 1460 å®é \n",
            "[88/1912] æ­£åœ¨è™•ç†: 1463 å¼·ç››æ–°\n",
            "[89/1912] æ­£åœ¨è™•ç†: 1464 å¾—åŠ›\n",
            "[90/1912] æ­£åœ¨è™•ç†: 1465 å‰å…¨\n",
            "[91/1912] æ­£åœ¨è™•ç†: 1466 èšéš†\n",
            "[92/1912] æ­£åœ¨è™•ç†: 1467 å—ç·¯\n",
            "[93/1912] æ­£åœ¨è™•ç†: 1468 æ˜¶å’Œ\n",
            "[94/1912] æ­£åœ¨è™•ç†: 1470 å¤§çµ±æ–°å‰µ\n",
            "[95/1912] æ­£åœ¨è™•ç†: 1471 é¦–åˆ©\n",
            "[96/1912] æ­£åœ¨è™•ç†: 1472 ä¸‰æ´‹å¯¦æ¥­\n",
            "[97/1912] æ­£åœ¨è™•ç†: 1473 å°å—\n",
            "[98/1912] æ­£åœ¨è™•ç†: 1474 å¼˜è£•\n",
            "[99/1912] æ­£åœ¨è™•ç†: 1475 æ¥­æ—º\n",
            "[100/1912] æ­£åœ¨è™•ç†: 1476 å„’é´»\n",
            "[101/1912] æ­£åœ¨è™•ç†: 1477 èšé™½\n",
            "[102/1912] æ­£åœ¨è™•ç†: 1503 å£«é›»\n",
            "[103/1912] æ­£åœ¨è™•ç†: 1504 æ±å…ƒ\n",
            "[104/1912] æ­£åœ¨è™•ç†: 1506 æ­£é“\n",
            "[105/1912] æ­£åœ¨è™•ç†: 1512 ç‘åˆ©\n",
            "[106/1912] æ­£åœ¨è™•ç†: 1513 ä¸­èˆˆé›»\n",
            "[107/1912] æ­£åœ¨è™•ç†: 1514 äºåŠ›\n",
            "[108/1912] æ­£åœ¨è™•ç†: 1515 åŠ›å±±\n",
            "[109/1912] æ­£åœ¨è™•ç†: 1516 å·é£›\n",
            "[110/1912] æ­£åœ¨è™•ç†: 1517 åˆ©å¥‡\n",
            "[111/1912] æ­£åœ¨è™•ç†: 1519 è¯åŸ\n",
            "[112/1912] æ­£åœ¨è™•ç†: 1521 å¤§å„„\n",
            "[113/1912] æ­£åœ¨è™•ç†: 1522 å ¤ç¶­è¥¿\n",
            "[114/1912] æ­£åœ¨è™•ç†: 1524 è€¿é¼\n",
            "[115/1912] æ­£åœ¨è™•ç†: 1525 æ±Ÿç”³\n",
            "[116/1912] æ­£åœ¨è™•ç†: 1526 æ—¥é¦³\n",
            "[117/1912] æ­£åœ¨è™•ç†: 1527 é‘½å…¨\n",
            "[118/1912] æ­£åœ¨è™•ç†: 1528 æ©å¾·\n",
            "[119/1912] æ­£åœ¨è™•ç†: 1529 æ¨‚äº‹ç¶ èƒ½\n",
            "[120/1912] æ­£åœ¨è™•ç†: 1530 äºå´´\n",
            "[121/1912] æ­£åœ¨è™•ç†: 1531 é«˜æ—è‚¡\n",
            "[122/1912] æ­£åœ¨è™•ç†: 1532 å‹¤ç¾\n",
            "[123/1912] æ­£åœ¨è™•ç†: 1533 è»Šç‹é›»\n",
            "[124/1912] æ­£åœ¨è™•ç†: 1535 ä¸­å®‡\n",
            "[125/1912] æ­£åœ¨è™•ç†: 1536 å’Œå¤§\n",
            "[126/1912] æ­£åœ¨è™•ç†: 1537 å»£éš†\n",
            "[127/1912] æ­£åœ¨è™•ç†: 1538 æ­£å³°\n",
            "[128/1912] æ­£åœ¨è™•ç†: 1539 å·¨åº­\n",
            "[129/1912] æ­£åœ¨è™•ç†: 1540 å–¬ç¦\n",
            "[130/1912] æ­£åœ¨è™•ç†: 1541 éŒ©æ³°\n",
            "[131/1912] æ­£åœ¨è™•ç†: 1558 ä¼¸èˆˆ\n",
            "[132/1912] æ­£åœ¨è™•ç†: 1560 ä¸­ç ‚\n",
            "[133/1912] æ­£åœ¨è™•ç†: 1563 å·§æ–°\n",
            "[134/1912] æ­£åœ¨è™•ç†: 1568 å€‰ä½‘\n",
            "[135/1912] æ­£åœ¨è™•ç†: 1582 ä¿¡éŒ¦\n",
            "[136/1912] æ­£åœ¨è™•ç†: 1583 ç¨‹æ³°\n",
            "[137/1912] æ­£åœ¨è™•ç†: 1587 å‰èŒ‚\n",
            "[138/1912] æ­£åœ¨è™•ç†: 1589 æ°¸å† -KY\n",
            "[139/1912] æ­£åœ¨è™•ç†: 1590 äºå¾·å®¢-KY\n",
            "[140/1912] æ­£åœ¨è™•ç†: 1597 ç›´å¾—\n",
            "[141/1912] æ­£åœ¨è™•ç†: 1598 å²±å®‡\n",
            "[142/1912] æ­£åœ¨è™•ç†: 1603 è¯é›»\n",
            "[143/1912] æ­£åœ¨è™•ç†: 1604 è²å¯¶\n",
            "[144/1912] æ­£åœ¨è™•ç†: 1605 è¯æ–°\n",
            "[145/1912] æ­£åœ¨è™•ç†: 1608 è¯æ¦®\n",
            "[146/1912] æ­£åœ¨è™•ç†: 1609 å¤§äº\n",
            "[147/1912] æ­£åœ¨è™•ç†: 1611 ä¸­é›»\n",
            "[148/1912] æ­£åœ¨è™•ç†: 1612 å®æ³°\n",
            "[149/1912] æ­£åœ¨è™•ç†: 1614 ä¸‰æ´‹é›»\n",
            "[150/1912] æ­£åœ¨è™•ç†: 1615 å¤§å±±\n",
            "[151/1912] æ­£åœ¨è™•ç†: 1616 å„„æ³°\n",
            "[152/1912] æ­£åœ¨è™•ç†: 1617 æ¦®æ˜Ÿ\n",
            "[153/1912] æ­£åœ¨è™•ç†: 1618 åˆæ©Ÿ\n",
            "[154/1912] æ­£åœ¨è™•ç†: 1626 è‰¾ç¾ç‰¹-KY\n",
            "[155/1912] æ­£åœ¨è™•ç†: 1702 å—åƒ‘\n",
            "[156/1912] æ­£åœ¨è™•ç†: 1707 è‘¡è„ç‹\n",
            "[157/1912] æ­£åœ¨è™•ç†: 1708 æ±é¹¼\n",
            "[158/1912] æ­£åœ¨è™•ç†: 1709 å’Œç›Š\n",
            "[159/1912] æ­£åœ¨è™•ç†: 1710 æ±è¯\n",
            "[160/1912] æ­£åœ¨è™•ç†: 1711 æ°¸å…‰\n",
            "[161/1912] æ­£åœ¨è™•ç†: 1712 èˆˆè¾²\n",
            "[162/1912] æ­£åœ¨è™•ç†: 1713 åœ‹åŒ–\n",
            "[163/1912] æ­£åœ¨è™•ç†: 1714 å’Œæ¡\n",
            "[164/1912] æ­£åœ¨è™•ç†: 1717 é•·èˆˆ\n",
            "[165/1912] æ­£åœ¨è™•ç†: 1718 ä¸­çº–\n",
            "[166/1912] æ­£åœ¨è™•ç†: 1720 ç”Ÿé”\n",
            "[167/1912] æ­£åœ¨è™•ç†: 1721 ä¸‰æ™ƒ\n",
            "[168/1912] æ­£åœ¨è™•ç†: 1722 å°è‚¥\n",
            "[169/1912] æ­£åœ¨è™•ç†: 1723 ä¸­ç¢³\n",
            "[170/1912] æ­£åœ¨è™•ç†: 1725 å…ƒç¦\n",
            "[171/1912] æ­£åœ¨è™•ç†: 1726 æ°¸è¨˜\n",
            "[172/1912] æ­£åœ¨è™•ç†: 1727 ä¸­è¯åŒ–\n",
            "[173/1912] æ­£åœ¨è™•ç†: 1730 èŠ±ä»™å­\n",
            "[174/1912] æ­£åœ¨è™•ç†: 1731 ç¾å¾è¯\n",
            "[175/1912] æ­£åœ¨è™•ç†: 1732 æ¯›å¯¶\n",
            "[176/1912] æ­£åœ¨è™•ç†: 1733 äº”é¼\n",
            "[177/1912] æ­£åœ¨è™•ç†: 1734 æè¼\n",
            "[178/1912] æ­£åœ¨è™•ç†: 1735 æ—¥å‹åŒ–\n",
            "[179/1912] æ­£åœ¨è™•ç†: 1736 å–¬å±±\n",
            "[180/1912] æ­£åœ¨è™•ç†: 1737 è‡ºé¹½\n",
            "[181/1912] æ­£åœ¨è™•ç†: 1752 å—å…‰\n",
            "[182/1912] æ­£åœ¨è™•ç†: 1760 å¯¶é½¡å¯ŒéŒ¦\n",
            "[183/1912] æ­£åœ¨è™•ç†: 1762 ä¸­åŒ–ç”Ÿ\n",
            "[184/1912] æ­£åœ¨è™•ç†: 1773 å‹ä¸€\n",
            "[185/1912] æ­£åœ¨è™•ç†: 1776 å±•å®‡\n",
            "[186/1912] æ­£åœ¨è™•ç†: 1783 å’Œåº·ç”Ÿ\n",
            "[187/1912] æ­£åœ¨è™•ç†: 1786 ç§‘å¦\n",
            "[188/1912] æ­£åœ¨è™•ç†: 1789 ç¥éš†\n",
            "[189/1912] æ­£åœ¨è™•ç†: 1795 ç¾æ™‚\n",
            "[190/1912] æ­£åœ¨è™•ç†: 1802 å°ç»\n",
            "[191/1912] æ­£åœ¨è™•ç†: 1805 å¯¶å¾ \n",
            "[192/1912] æ­£åœ¨è™•ç†: 1806 å† è»\n",
            "[193/1912] æ­£åœ¨è™•ç†: 1808 æ½¤éš†\n",
            "[194/1912] æ­£åœ¨è™•ç†: 1809 ä¸­é‡‰\n",
            "[195/1912] æ­£åœ¨è™•ç†: 1810 å’Œæˆ\n",
            "[196/1912] æ­£åœ¨è™•ç†: 1817 å‡±æ’’è¡›\n",
            "[197/1912] æ­£åœ¨è™•ç†: 1903 å£«ç´™\n",
            "[198/1912] æ­£åœ¨è™•ç†: 1904 æ­£éš†\n",
            "[199/1912] æ­£åœ¨è™•ç†: 1905 è¯ç´™\n",
            "[200/1912] æ­£åœ¨è™•ç†: 1906 å¯¶éš†\n",
            "[201/1912] æ­£åœ¨è™•ç†: 1907 æ°¸è±é¤˜\n",
            "[202/1912] æ­£åœ¨è™•ç†: 1909 æ¦®æˆ\n",
            "[203/1912] æ­£åœ¨è™•ç†: 2002 ä¸­é‹¼\n",
            "[204/1912] æ­£åœ¨è™•ç†: 2006 æ±å’Œé‹¼éµ\n",
            "[205/1912] æ­£åœ¨è™•ç†: 2007 ç‡èˆˆ\n",
            "[206/1912] æ­£åœ¨è™•ç†: 2008 é«˜èˆˆæ˜Œ\n",
            "[207/1912] æ­£åœ¨è™•ç†: 2009 ç¬¬ä¸€éŠ…\n",
            "[208/1912] æ­£åœ¨è™•ç†: 2010 æ˜¥æº\n",
            "[209/1912] æ­£åœ¨è™•ç†: 2012 æ˜¥é›¨\n",
            "[210/1912] æ­£åœ¨è™•ç†: 2013 ä¸­é‹¼æ§‹\n",
            "[211/1912] æ­£åœ¨è™•ç†: 2014 ä¸­é´»\n",
            "[212/1912] æ­£åœ¨è™•ç†: 2015 è±èˆˆ\n",
            "[213/1912] æ­£åœ¨è™•ç†: 2017 å®˜ç”°é‹¼\n",
            "[214/1912] æ­£åœ¨è™•ç†: 2020 ç¾äº\n",
            "[215/1912] æ­£åœ¨è™•ç†: 2022 èšäº¨\n",
            "[216/1912] æ­£åœ¨è™•ç†: 2023 ç‡è¼\n",
            "[217/1912] æ­£åœ¨è™•ç†: 2024 å¿—è¯\n",
            "[218/1912] æ­£åœ¨è™•ç†: 2025 åƒèˆˆ\n",
            "[219/1912] æ­£åœ¨è™•ç†: 2027 å¤§æˆé‹¼\n",
            "[220/1912] æ­£åœ¨è™•ç†: 2028 å¨è‡´\n",
            "[221/1912] æ­£åœ¨è™•ç†: 2029 ç››é¤˜\n",
            "[222/1912] æ­£åœ¨è™•ç†: 2030 å½°æº\n",
            "[223/1912] æ­£åœ¨è™•ç†: 2031 æ–°å…‰é‹¼\n",
            "[224/1912] æ­£åœ¨è™•ç†: 2032 æ–°é‹¼\n",
            "[225/1912] æ­£åœ¨è™•ç†: 2033 ä½³å¤§\n",
            "[226/1912] æ­£åœ¨è™•ç†: 2034 å…å¼·\n",
            "[227/1912] æ­£åœ¨è™•ç†: 2038 æµ·å…‰\n",
            "[228/1912] æ­£åœ¨è™•ç†: 2049 ä¸ŠéŠ€\n",
            "[229/1912] æ­£åœ¨è™•ç†: 2059 å·æ¹–\n",
            "[230/1912] æ­£åœ¨è™•ç†: 2062 æ©‹æ¤¿\n",
            "[231/1912] æ­£åœ¨è™•ç†: 2069 é‹éŒ©\n",
            "[232/1912] æ­£åœ¨è™•ç†: 2101 å—æ¸¯\n",
            "[233/1912] æ­£åœ¨è™•ç†: 2102 æ³°è±\n",
            "[234/1912] æ­£åœ¨è™•ç†: 2103 å°æ©¡\n",
            "[235/1912] æ­£åœ¨è™•ç†: 2104 åœ‹éš›ä¸­æ©¡\n",
            "[236/1912] æ­£åœ¨è™•ç†: 2105 æ­£æ–°\n",
            "[237/1912] æ­£åœ¨è™•ç†: 2106 å»ºå¤§\n",
            "[238/1912] æ­£åœ¨è™•ç†: 2107 åšç”Ÿ\n",
            "[239/1912] æ­£åœ¨è™•ç†: 2108 å—å¸\n",
            "[240/1912] æ­£åœ¨è™•ç†: 2109 è¯è±\n",
            "[241/1912] æ­£åœ¨è™•ç†: 2114 é‘«æ°¸éŠ“\n",
            "[242/1912] æ­£åœ¨è™•ç†: 2115 å…­æš‰-KY\n",
            "[243/1912] æ­£åœ¨è™•ç†: 2201 è£•éš†\n",
            "[244/1912] æ­£åœ¨è™•ç†: 2204 ä¸­è¯\n",
            "[245/1912] æ­£åœ¨è™•ç†: 2206 ä¸‰é™½å·¥æ¥­\n",
            "[246/1912] æ­£åœ¨è™•ç†: 2207 å’Œæ³°è»Š\n",
            "[247/1912] æ­£åœ¨è™•ç†: 2208 å°èˆ¹\n",
            "[248/1912] æ­£åœ¨è™•ç†: 2211 é•·æ¦®é‹¼\n",
            "[249/1912] æ­£åœ¨è™•ç†: 2227 è£•æ—¥è»Š\n",
            "[250/1912] æ­£åœ¨è™•ç†: 2228 åŠéºŸ\n",
            "[251/1912] æ­£åœ¨è™•ç†: 2231 ç‚ºå‡\n",
            "[252/1912] æ­£åœ¨è™•ç†: 2233 å®‡éš†\n",
            "[253/1912] æ­£åœ¨è™•ç†: 2236 ç™¾é”-KY\n",
            "[254/1912] æ­£åœ¨è™•ç†: 2239 è‹±åˆ©-KY\n",
            "[255/1912] æ­£åœ¨è™•ç†: 2241 è‰¾å§†å‹’\n",
            "[256/1912] æ­£åœ¨è™•ç†: 2243 å®æ—­-KY\n",
            "[257/1912] æ­£åœ¨è™•ç†: 2247 æ±å¾·æ°¸æ¥­\n",
            "[258/1912] æ­£åœ¨è™•ç†: 2248 è¯å‹-KY\n",
            "[259/1912] æ­£åœ¨è™•ç†: 2250 IKKA-KY\n",
            "[260/1912] æ­£åœ¨è™•ç†: 2301 å…‰å¯¶ç§‘\n",
            "[261/1912] æ­£åœ¨è™•ç†: 2302 éº—æ­£\n",
            "[262/1912] æ­£åœ¨è™•ç†: 2303 è¯é›»\n",
            "[263/1912] æ­£åœ¨è™•ç†: 2305 å…¨å‹\n",
            "[264/1912] æ­£åœ¨è™•ç†: 2308 å°é”é›»\n",
            "[265/1912] æ­£åœ¨è™•ç†: 2312 é‡‘å¯¶\n",
            "[266/1912] æ­£åœ¨è™•ç†: 2313 è¯é€š\n",
            "[267/1912] æ­£åœ¨è™•ç†: 2314 å°æš\n",
            "[268/1912] æ­£åœ¨è™•ç†: 2316 æ¥ æ¢“é›»\n",
            "[269/1912] æ­£åœ¨è™•ç†: 2317 é´»æµ·\n",
            "[270/1912] æ­£åœ¨è™•ç†: 2321 æ±è¨Š\n",
            "[271/1912] æ­£åœ¨è™•ç†: 2323 ä¸­ç’°\n",
            "[272/1912] æ­£åœ¨è™•ç†: 2324 ä»å¯¶\n",
            "[273/1912] æ­£åœ¨è™•ç†: 2327 åœ‹å·¨\n",
            "[274/1912] æ­£åœ¨è™•ç†: 2328 å»£å®‡\n",
            "[275/1912] æ­£åœ¨è™•ç†: 2329 è¯æ³°\n",
            "[276/1912] æ­£åœ¨è™•ç†: 2330 å°ç©é›»\n",
            "[277/1912] æ­£åœ¨è™•ç†: 2331 ç²¾è‹±\n",
            "[278/1912] æ­£åœ¨è™•ç†: 2332 å‹è¨Š\n",
            "[279/1912] æ­£åœ¨è™•ç†: 2337 æ—ºå®\n",
            "[280/1912] æ­£åœ¨è™•ç†: 2338 å…‰ç½©\n",
            "[281/1912] æ­£åœ¨è™•ç†: 2340 å°äº\n",
            "[282/1912] æ­£åœ¨è™•ç†: 2342 èŒ‚çŸ½\n",
            "[283/1912] æ­£åœ¨è™•ç†: 2344 è¯é‚¦é›»\n",
            "[284/1912] æ­£åœ¨è™•ç†: 2345 æ™ºé‚¦\n",
            "[285/1912] æ­£åœ¨è™•ç†: 2347 è¯å¼·\n",
            "[286/1912] æ­£åœ¨è™•ç†: 2348 æµ·æ‚…\n",
            "[287/1912] æ­£åœ¨è™•ç†: 2349 éŒ¸å¾·\n",
            "[288/1912] æ­£åœ¨è™•ç†: 2351 é †å¾·\n",
            "[289/1912] æ­£åœ¨è™•ç†: 2352 ä½³ä¸–é”\n",
            "[290/1912] æ­£åœ¨è™•ç†: 2353 å®ï¿½ï¿½\n",
            "[291/1912] æ­£åœ¨è™•ç†: 2354 é´»æº–\n",
            "[292/1912] æ­£åœ¨è™•ç†: 2355 æ•¬éµ¬\n",
            "[293/1912] æ­£åœ¨è™•ç†: 2356 è‹±æ¥­é”\n",
            "[294/1912] æ­£åœ¨è™•ç†: 2357 è¯ç¢©\n",
            "[295/1912] æ­£åœ¨è™•ç†: 2359 æ‰€ç¾…é–€\n",
            "[296/1912] æ­£åœ¨è™•ç†: 2360 è‡´èŒ‚\n",
            "[297/1912] æ­£åœ¨è™•ç†: 2362 è—å¤©\n",
            "[298/1912] æ­£åœ¨è™•ç†: 2363 çŸ½çµ±\n",
            "[299/1912] æ­£åœ¨è™•ç†: 2364 å€«é£›\n",
            "[300/1912] æ­£åœ¨è™•ç†: 2365 æ˜†ç›ˆ\n",
            "[301/1912] æ­£åœ¨è™•ç†: 2367 ç‡¿è¯\n",
            "[302/1912] æ­£åœ¨è™•ç†: 2368 é‡‘åƒé›»\n",
            "[303/1912] æ­£åœ¨è™•ç†: 2369 è±ç”Ÿ\n",
            "[304/1912] æ­£åœ¨è™•ç†: 2371 å¤§åŒ\n",
            "[305/1912] æ­£åœ¨è™•ç†: 2373 éœ‡æ—¦è¡Œ\n",
            "[306/1912] æ­£åœ¨è™•ç†: 2374 ä½³èƒ½\n",
            "[307/1912] æ­£åœ¨è™•ç†: 2375 å‡±ç¾\n",
            "[308/1912] æ­£åœ¨è™•ç†: 2376 æŠ€å˜‰\n",
            "[309/1912] æ­£åœ¨è™•ç†: 2377 å¾®æ˜Ÿ\n",
            "[310/1912] æ­£åœ¨è™•ç†: 2379 ç‘æ˜±\n",
            "[311/1912] æ­£åœ¨è™•ç†: 2380 è™¹å…‰\n",
            "[312/1912] æ­£åœ¨è™•ç†: 2382 å»£é”\n",
            "[313/1912] æ­£åœ¨è™•ç†: 2383 å°å…‰é›»\n",
            "[314/1912] æ­£åœ¨è™•ç†: 2385 ç¾¤å…‰\n",
            "[315/1912] æ­£åœ¨è™•ç†: 2387 ç²¾å…ƒ\n",
            "[316/1912] æ­£åœ¨è™•ç†: 2388 å¨ç››\n",
            "[317/1912] æ­£åœ¨è™•ç†: 2390 äº‘è¾°\n",
            "[318/1912] æ­£åœ¨è™•ç†: 2392 æ­£å´´\n",
            "[319/1912] æ­£åœ¨è™•ç†: 2393 å„„å…‰\n",
            "[320/1912] æ­£åœ¨è™•ç†: 2395 ç ”è¯\n",
            "[321/1912] æ­£åœ¨è™•ç†: 2397 å‹é€š\n",
            "[322/1912] æ­£åœ¨è™•ç†: 2399 æ˜ æ³°\n",
            "[323/1912] æ­£åœ¨è™•ç†: 2401 å‡Œé™½\n",
            "[324/1912] æ­£åœ¨è™•ç†: 2402 æ¯…å˜‰\n",
            "[325/1912] æ­£åœ¨è™•ç†: 2404 æ¼¢å”\n",
            "[326/1912] æ­£åœ¨è™•ç†: 2405 è¼”ä¿¡\n",
            "[327/1912] æ­£åœ¨è™•ç†: 2406 åœ‹ç¢©\n",
            "[328/1912] æ­£åœ¨è™•ç†: 2408 å—äºç§‘\n",
            "[329/1912] æ­£åœ¨è™•ç†: 2409 å‹é”\n",
            "[330/1912] æ­£åœ¨è™•ç†: 2412 ä¸­è¯é›»\n",
            "[331/1912] æ­£åœ¨è™•ç†: 2413 ç’°ç§‘\n",
            "[332/1912] æ­£åœ¨è™•ç†: 2414 ç²¾æŠ€\n",
            "[333/1912] æ­£åœ¨è™•ç†: 2415 éŒ©æ–°\n",
            "[334/1912] æ­£åœ¨è™•ç†: 2417 åœ“å‰›\n",
            "[335/1912] æ­£åœ¨è™•ç†: 2419 ä»²ç¦\n",
            "[336/1912] æ­£åœ¨è™•ç†: 2420 æ–°å·¨\n",
            "[337/1912] æ­£åœ¨è™•ç†: 2421 å»ºæº–\n",
            "[338/1912] æ­£åœ¨è™•ç†: 2423 å›ºç·¯\n",
            "[339/1912] æ­£åœ¨è™•ç†: 2424 éš´è¯\n",
            "[340/1912] æ­£åœ¨è™•ç†: 2425 æ‰¿å•Ÿ\n",
            "[341/1912] æ­£åœ¨è™•ç†: 2426 é¼å…ƒ\n",
            "[342/1912] æ­£åœ¨è™•ç†: 2427 ä¸‰å•†é›»\n",
            "[343/1912] æ­£åœ¨è™•ç†: 2428 èˆˆå‹¤\n",
            "[344/1912] æ­£åœ¨è™•ç†: 2429 éŠ˜æ—ºç§‘\n",
            "[345/1912] æ­£åœ¨è™•ç†: 2430 ç‡¦å¤\n",
            "[346/1912] æ­£åœ¨è™•ç†: 2431 è¯æ˜Œ\n",
            "[347/1912] æ­£åœ¨è™•ç†: 2433 äº’ç››é›»\n",
            "[348/1912] æ­£åœ¨è™•ç†: 2434 çµ±æ‡‹\n",
            "[349/1912] æ­£åœ¨è™•ç†: 2436 å‰è©®é›»\n",
            "[350/1912] æ­£åœ¨è™•ç†: 2438 ç¿”è€€\n",
            "[351/1912] æ­£åœ¨è™•ç†: 2439 ç¾å¾‹\n",
            "[352/1912] æ­£åœ¨è™•ç†: 2440 å¤ªç©ºæ¢­\n",
            "[353/1912] æ­£åœ¨è™•ç†: 2441 è¶…è±\n",
            "[354/1912] æ­£åœ¨è™•ç†: 2442 æ–°ç¾é½Š\n",
            "[355/1912] æ­£åœ¨è™•ç†: 2444 å…†å‹\n",
            "[356/1912] æ­£åœ¨è™•ç†: 2449 äº¬å…ƒé›»å­\n",
            "[357/1912] æ­£åœ¨è™•ç†: 2450 ç¥è…¦\n",
            "[358/1912] æ­£åœ¨è™•ç†: 2451 å‰µè¦‹\n",
            "[359/1912] æ­£åœ¨è™•ç†: 2453 å‡Œç¾¤\n",
            "[360/1912] æ­£åœ¨è™•ç†: 2454 è¯ç™¼ç§‘\n",
            "[361/1912] æ­£åœ¨è™•ç†: 2455 å…¨æ–°\n",
            "[362/1912] æ­£åœ¨è™•ç†: 2457 é£›å®\n",
            "[363/1912] æ­£åœ¨è™•ç†: 2458 ç¾©éš†\n",
            "[364/1912] æ­£åœ¨è™•ç†: 2459 æ•¦å‰\n",
            "[365/1912] æ­£åœ¨è™•ç†: 2460 å»ºé€š\n",
            "[366/1912] æ­£åœ¨è™•ç†: 2461 å…‰ç¾¤é›·\n",
            "[367/1912] æ­£åœ¨è™•ç†: 2462 è‰¯å¾—é›»\n",
            "[368/1912] æ­£åœ¨è™•ç†: 2464 ç›Ÿç«‹\n",
            "[369/1912] æ­£åœ¨è™•ç†: 2465 éº—è‡º\n",
            "[370/1912] æ­£åœ¨è™•ç†: 2466 å† è¥¿é›»\n",
            "[371/1912] æ­£åœ¨è™•ç†: 2467 å¿—è–\n",
            "[372/1912] æ­£åœ¨è™•ç†: 2468 è¯ç¶“\n",
            "[373/1912] æ­£åœ¨è™•ç†: 2471 è³‡é€š\n",
            "[374/1912] æ­£åœ¨è™•ç†: 2472 ç«‹éš†é›»\n",
            "[375/1912] æ­£åœ¨è™•ç†: 2474 å¯æˆ\n",
            "[376/1912] æ­£åœ¨è™•ç†: 2476 é‰…ç¥¥\n",
            "[377/1912] æ­£åœ¨è™•ç†: 2477 ç¾éš†é›»\n",
            "[378/1912] æ­£åœ¨è™•ç†: 2478 å¤§æ¯…\n",
            "[379/1912] æ­£åœ¨è™•ç†: 2480 æ•¦é™½ç§‘\n",
            "[380/1912] æ­£åœ¨è™•ç†: 2481 å¼·èŒ‚\n",
            "[381/1912] æ­£åœ¨è™•ç†: 2482 é€£å®‡\n",
            "[382/1912] æ­£åœ¨è™•ç†: 2483 ç™¾å®¹\n",
            "[383/1912] æ­£åœ¨è™•ç†: 2484 å¸Œè¯\n",
            "[384/1912] æ­£åœ¨è™•ç†: 2485 å…†èµ«\n",
            "[385/1912] æ­£åœ¨è™•ç†: 2486 ä¸€è©®\n",
            "[386/1912] æ­£åœ¨è™•ç†: 2488 æ¼¢å¹³\n",
            "[387/1912] æ­£åœ¨è™•ç†: 2489 ç‘è»’\n",
            "[388/1912] æ­£åœ¨è™•ç†: 2491 å‰ç¥¥å…¨\n",
            "[389/1912] æ­£åœ¨è™•ç†: 2492 è¯æ–°ç§‘\n",
            "[390/1912] æ­£åœ¨è™•ç†: 2493 æšåš\n",
            "[391/1912] æ­£åœ¨è™•ç†: 2495 æ™®å®‰\n",
            "[392/1912] æ­£åœ¨è™•ç†: 2496 å“è¶Š\n",
            "[393/1912] æ­£åœ¨è™•ç†: 2497 æ€¡åˆ©é›»\n",
            "[394/1912] æ­£åœ¨è™•ç†: 2498 å®é”é›»\n",
            "[395/1912] æ­£åœ¨è™•ç†: 2501 åœ‹å»º\n",
            "[396/1912] æ­£åœ¨è™•ç†: 2504 åœ‹ç”¢\n",
            "[397/1912] æ­£åœ¨è™•ç†: 2505 åœ‹æš\n",
            "[398/1912] æ­£åœ¨è™•ç†: 2506 å¤ªè¨­\n",
            "[399/1912] æ­£åœ¨è™•ç†: 2509 å…¨å¤å»º\n",
            "[400/1912] æ­£åœ¨è™•ç†: 2511 å¤ªå­\n",
            "[401/1912] æ­£åœ¨è™•ç†: 2514 é¾é‚¦\n",
            "[402/1912] æ­£åœ¨è™•ç†: 2515 ä¸­å·¥\n",
            "[403/1912] æ­£åœ¨è™•ç†: 2516 æ–°å»º\n",
            "[404/1912] æ­£åœ¨è™•ç†: 2520 å† å¾·\n",
            "[405/1912] æ­£åœ¨è™•ç†: 2524 äº¬åŸ\n",
            "[406/1912] æ­£åœ¨è™•ç†: 2527 å®ç’Ÿ\n",
            "[407/1912] æ­£åœ¨è™•ç†: 2528 çš‡æ™®\n",
            "[408/1912] æ­£åœ¨è™•ç†: 2530 è¯å»º\n",
            "[409/1912] æ­£åœ¨è™•ç†: 2534 å®ç››\n",
            "[410/1912] æ­£åœ¨è™•ç†: 2535 é”æ¬£å·¥\n",
            "[411/1912] æ­£åœ¨è™•ç†: 2536 å®æ™®\n",
            "[412/1912] æ­£åœ¨è™•ç†: 2537 è¯ä¸Šç™¼\n",
            "[413/1912] æ­£åœ¨è™•ç†: 2538 åŸºæ³°\n",
            "[414/1912] æ­£åœ¨è™•ç†: 2539 æ«»èŠ±å»º\n",
            "[415/1912] æ­£åœ¨è™•ç†: 2540 æ„›å±±æ—\n",
            "[416/1912] æ­£åœ¨è™•ç†: 2542 èˆˆå¯Œç™¼\n",
            "[417/1912] æ­£åœ¨è™•ç†: 2543 çš‡æ˜Œ\n",
            "[418/1912] æ­£åœ¨è™•ç†: 2545 çš‡ç¿”\n",
            "[419/1912] æ­£åœ¨è™•ç†: 2546 æ ¹åŸº\n",
            "[420/1912] æ­£åœ¨è™•ç†: 2547 æ—¥å‹ç”Ÿ\n",
            "[421/1912] æ­£åœ¨è™•ç†: 2548 è¯å›º\n",
            "[422/1912] æ­£åœ¨è™•ç†: 2597 æ½¤å¼˜\n",
            "[423/1912] æ­£åœ¨è™•ç†: 2601 ç›Šèˆª\n",
            "[424/1912] æ­£åœ¨è™•ç†: 2603 é•·æ¦®\n",
            "[425/1912] æ­£åœ¨è™•ç†: 2605 æ–°èˆˆ\n",
            "[426/1912] æ­£åœ¨è™•ç†: 2606 è£•æ°‘\n",
            "[427/1912] æ­£åœ¨è™•ç†: 2607 æ¦®é‹\n",
            "[428/1912] æ­£åœ¨è™•ç†: 2608 å˜‰é‡Œå¤§æ¦®\n",
            "[429/1912] æ­£åœ¨è™•ç†: 2609 é™½æ˜\n",
            "[430/1912] æ­£åœ¨è™•ç†: 2610 è¯èˆª\n",
            "[431/1912] æ­£åœ¨è™•ç†: 2611 å¿—ä¿¡\n",
            "[432/1912] æ­£åœ¨è™•ç†: 2612 ä¸­èˆª\n",
            "[433/1912] æ­£åœ¨è™•ç†: 2613 ä¸­æ«ƒ\n",
            "[434/1912] æ­£åœ¨è™•ç†: 2614 æ±æ£®\n",
            "[435/1912] æ­£åœ¨è™•ç†: 2615 è¬æµ·\n",
            "[436/1912] æ­£åœ¨è™•ç†: 2616 å±±éš†\n",
            "[437/1912] æ­£åœ¨è™•ç†: 2617 å°èˆª\n",
            "[438/1912] æ­£åœ¨è™•ç†: 2618 é•·æ¦®èˆª\n",
            "[439/1912] æ­£åœ¨è™•ç†: 2630 äºèˆª\n",
            "[440/1912] æ­£åœ¨è™•ç†: 2633 å°ç£é«˜éµ\n",
            "[441/1912] æ­£åœ¨è™•ç†: 2634 æ¼¢ç¿”\n",
            "[442/1912] æ­£åœ¨è™•ç†: 2636 å°é©Šæ§è‚¡\n",
            "[443/1912] æ­£åœ¨è™•ç†: 2637 æ…§æ´‹-KY\n",
            "[444/1912] æ­£åœ¨è™•ç†: 2642 å®…é…é€š\n",
            "[445/1912] æ­£åœ¨è™•ç†: 2645 é•·æ¦®èˆªå¤ª\n",
            "[446/1912] æ­£åœ¨è™•ç†: 2646 æ˜Ÿå®‡èˆªç©º\n",
            "[447/1912] æ­£åœ¨è™•ç†: 2701 è¬ä¼\n",
            "[448/1912] æ­£åœ¨è™•ç†: 2702 è¯åœ’\n",
            "[449/1912] æ­£åœ¨è™•ç†: 2704 åœ‹è³“\n",
            "[450/1912] æ­£åœ¨è™•ç†: 2705 å…­ç¦\n",
            "[451/1912] æ­£åœ¨è™•ç†: 2706 ç¬¬ä¸€åº—\n",
            "[452/1912] æ­£åœ¨è™•ç†: 2707 æ™¶è¯\n",
            "[453/1912] æ­£åœ¨è™•ç†: 2712 é é›„ä¾†\n",
            "[454/1912] æ­£åœ¨è™•ç†: 2722 å¤éƒ½\n",
            "[455/1912] æ­£åœ¨è™•ç†: 2723 ç¾é£Ÿ-KY\n",
            "[456/1912] æ­£åœ¨è™•ç†: 2727 ç‹å“\n",
            "[457/1912] æ­£åœ¨è™•ç†: 2731 é›„ç…\n",
            "[458/1912] æ­£åœ¨è™•ç†: 2739 å¯’èˆ\n",
            "[459/1912] æ­£åœ¨è™•ç†: 2748 é›²å“\n",
            "[460/1912] æ­£åœ¨è™•ç†: 2753 å…«æ–¹é›²é›†\n",
            "[461/1912] æ­£åœ¨è™•ç†: 2762 ä¸–ç•Œå¥èº«-KY\n",
            "[462/1912] æ­£åœ¨è™•ç†: 2801 å½°éŠ€\n",
            "[463/1912] æ­£åœ¨è™•ç†: 2809 äº¬åŸéŠ€\n",
            "[464/1912] æ­£åœ¨è™•ç†: 2812 å°ä¸­éŠ€\n",
            "[465/1912] æ­£åœ¨è™•ç†: 2816 æ—ºæ—ºä¿\n",
            "[466/1912] æ­£åœ¨è™•ç†: 2820 è¯ç¥¨\n",
            "[467/1912] æ­£åœ¨è™•ç†: 2832 å°ç”¢\n",
            "[468/1912] æ­£åœ¨è™•ç†: 2834 è‡ºä¼éŠ€\n",
            "[469/1912] æ­£åœ¨è™•ç†: 2836 é«˜é›„éŠ€\n",
            "[470/1912] æ­£åœ¨è™•ç†: 2838 è¯é‚¦éŠ€\n",
            "[471/1912] æ­£åœ¨è™•ç†: 2845 é æ±éŠ€\n",
            "[472/1912] æ­£åœ¨è™•ç†: 2849 å®‰æ³°éŠ€\n",
            "[473/1912] æ­£åœ¨è™•ç†: 2850 æ–°ç”¢\n",
            "[474/1912] æ­£åœ¨è™•ç†: 2851 ä¸­å†ä¿\n",
            "[475/1912] æ­£åœ¨è™•ç†: 2852 ç¬¬ä¸€ä¿\n",
            "[476/1912] æ­£åœ¨è™•ç†: 2855 çµ±ä¸€è­‰\n",
            "[477/1912] æ­£åœ¨è™•ç†: 2867 ä¸‰å•†å£½\n",
            "[478/1912] æ­£åœ¨è™•ç†: 2880 è¯å—é‡‘\n",
            "[479/1912] æ­£åœ¨è™•ç†: 2881 å¯Œé‚¦é‡‘\n",
            "[480/1912] æ­£åœ¨è™•ç†: 2882 åœ‹æ³°é‡‘\n",
            "[481/1912] æ­£åœ¨è™•ç†: 2883 å‡±åŸºé‡‘\n",
            "[482/1912] æ­£åœ¨è™•ç†: 2884 ç‰å±±é‡‘\n",
            "[483/1912] æ­£åœ¨è™•ç†: 2885 å…ƒå¤§é‡‘\n",
            "[484/1912] æ­£åœ¨è™•ç†: 2886 å…†è±é‡‘\n",
            "[485/1912] æ­£åœ¨è™•ç†: 2887 å°æ–°é‡‘\n",
            "[486/1912] æ­£åœ¨è™•ç†: 2889 åœ‹ç¥¨é‡‘\n",
            "[487/1912] æ­£åœ¨è™•ç†: 2890 æ°¸è±é‡‘\n",
            "[488/1912] æ­£åœ¨è™•ç†: 2891 ä¸­ä¿¡é‡‘\n",
            "[489/1912] æ­£åœ¨è™•ç†: 2892 ç¬¬ä¸€é‡‘\n",
            "[490/1912] æ­£åœ¨è™•ç†: 2897 ç‹é“éŠ€è¡Œ\n",
            "[491/1912] æ­£åœ¨è™•ç†: 2901 æ¬£æ¬£\n",
            "[492/1912] æ­£åœ¨è™•ç†: 2903 é ç™¾\n",
            "[493/1912] æ­£åœ¨è™•ç†: 2904 åŒ¯åƒ‘\n",
            "[494/1912] æ­£åœ¨è™•ç†: 2905 ä¸‰å•†\n",
            "[495/1912] æ­£åœ¨è™•ç†: 2906 é«˜æ—\n",
            "[496/1912] æ­£åœ¨è™•ç†: 2908 ç‰¹åŠ›\n",
            "[497/1912] æ­£åœ¨è™•ç†: 2910 çµ±é ˜\n",
            "[498/1912] æ­£åœ¨è™•ç†: 2911 éº—å¬°æˆ¿\n",
            "[499/1912] æ­£åœ¨è™•ç†: 2912 çµ±ä¸€è¶…\n",
            "[500/1912] æ­£åœ¨è™•ç†: 2913 è¾²æ—\n",
            "[501/1912] æ­£åœ¨è™•ç†: 2915 æ½¤æ³°å…¨\n",
            "[502/1912] æ­£åœ¨è™•ç†: 2923 é¼å›º-KY\n",
            "[503/1912] æ­£åœ¨è™•ç†: 2929 æ·˜å¸-KY\n",
            "[504/1912] æ­£åœ¨è™•ç†: 2939 æ°¸é‚‘-KY\n",
            "[505/1912] æ­£åœ¨è™•ç†: 3002 æ­æ ¼\n",
            "[506/1912] æ­£åœ¨è™•ç†: 3003 å¥å’Œèˆˆ\n",
            "[507/1912] æ­£åœ¨è™•ç†: 3004 è±é”ç§‘\n",
            "[508/1912] æ­£åœ¨è™•ç†: 3005 ç¥åŸº\n",
            "[509/1912] æ­£åœ¨è™•ç†: 3006 æ™¶è±ªç§‘\n",
            "[510/1912] æ­£åœ¨è™•ç†: 3008 å¤§ç«‹å…‰\n",
            "[511/1912] æ­£åœ¨è™•ç†: 3010 è¯ç«‹\n",
            "[512/1912] æ­£åœ¨è™•ç†: 3011 ä»Šçš“\n",
            "[513/1912] æ­£åœ¨è™•ç†: 3013 æ™ŸéŠ˜é›»\n",
            "[514/1912] æ­£åœ¨è™•ç†: 3014 è¯é™½\n",
            "[515/1912] æ­£åœ¨è™•ç†: 3015 å…¨æ¼¢\n",
            "[516/1912] æ­£åœ¨è™•ç†: 3016 å˜‰æ™¶\n",
            "[517/1912] æ­£åœ¨è™•ç†: 3017 å¥‡é‹\n",
            "[518/1912] æ­£åœ¨è™•ç†: 3018 éš†éŠ˜ç¶ èƒ½\n",
            "[519/1912] æ­£åœ¨è™•ç†: 3019 äºå…‰\n",
            "[520/1912] æ­£åœ¨è™•ç†: 3021 é´»å\n",
            "[521/1912] æ­£åœ¨è™•ç†: 3022 å¨å¼·é›»\n",
            "[522/1912] æ­£åœ¨è™•ç†: 3023 ä¿¡é‚¦\n",
            "[523/1912] æ­£åœ¨è™•ç†: 3024 æ†¶è²\n",
            "[524/1912] æ­£åœ¨è™•ç†: 3025 æ˜Ÿé€š\n",
            "[525/1912] æ­£åœ¨è™•ç†: 3026 ç¦¾ä¼¸å ‚\n",
            "[526/1912] æ­£åœ¨è™•ç†: 3027 ç››é”\n",
            "[527/1912] æ­£åœ¨è™•ç†: 3028 å¢ä½ å¼·\n",
            "[528/1912] æ­£åœ¨è™•ç†: 3029 é›¶å£¹\n",
            "[529/1912] æ­£åœ¨è™•ç†: 3030 å¾·å¾‹\n",
            "[530/1912] æ­£åœ¨è™•ç†: 3031 ä½°é´»\n",
            "[531/1912] æ­£åœ¨è™•ç†: 3032 å‰è¨“\n",
            "[532/1912] æ­£åœ¨è™•ç†: 3033 å¨å¥\n",
            "[533/1912] æ­£åœ¨è™•ç†: 3034 è¯è© \n",
            "[534/1912] æ­£åœ¨è™•ç†: 3035 æ™ºåŸ\n",
            "[535/1912] æ­£åœ¨è™•ç†: 3036 æ–‡æ›„\n",
            "[536/1912] æ­£åœ¨è™•ç†: 3037 æ¬£èˆˆ\n",
            "[537/1912] æ­£åœ¨è™•ç†: 3038 å…¨å°\n",
            "[538/1912] æ­£åœ¨è™•ç†: 3040 é è¦‹\n",
            "[539/1912] æ­£åœ¨è™•ç†: 3041 æšæ™º\n",
            "[540/1912] æ­£åœ¨è™•ç†: 3042 æ™¶æŠ€\n",
            "[541/1912] æ­£åœ¨è™•ç†: 3043 ç§‘é¢¨\n",
            "[542/1912] æ­£åœ¨è™•ç†: 3044 å¥é¼\n",
            "[543/1912] æ­£åœ¨è™•ç†: 3045 å°ç£å¤§\n",
            "[544/1912] æ­£åœ¨è™•ç†: 3046 å»ºï¿½ï¿½\n",
            "[545/1912] æ­£åœ¨è™•ç†: 3047 è¨ŠèˆŸ\n",
            "[546/1912] æ­£åœ¨è™•ç†: 3048 ç›Šç™»\n",
            "[547/1912] æ­£åœ¨è™•ç†: 3049 ç²¾é‡‘\n",
            "[548/1912] æ­£åœ¨è™•ç†: 3050 éˆºå¾·\n",
            "[549/1912] æ­£åœ¨è™•ç†: 3051 åŠ›ç‰¹\n",
            "[550/1912] æ­£åœ¨è™•ç†: 3052 å¤†å…¸\n",
            "[551/1912] æ­£åœ¨è™•ç†: 3054 ç«‹è¬åˆ©\n",
            "[552/1912] æ­£åœ¨è™•ç†: 3055 è”šè¯ç§‘\n",
            "[553/1912] æ­£åœ¨è™•ç†: 3056 å¯Œè¯æ–°\n",
            "[554/1912] æ­£åœ¨è™•ç†: 3057 å–¬é¼\n",
            "[555/1912] æ­£åœ¨è™•ç†: 3058 ç«‹å¾·\n",
            "[556/1912] æ­£åœ¨è™•ç†: 3059 è¯æ™¶ç§‘\n",
            "[557/1912] æ­£åœ¨è™•ç†: 3060 éŠ˜ç•°\n",
            "[558/1912] æ­£åœ¨è™•ç†: 3062 å»ºæ¼¢\n",
            "[559/1912] æ­£åœ¨è™•ç†: 3090 æ—¥é›»è²¿\n",
            "[560/1912] æ­£åœ¨è™•ç†: 3092 é´»ç¢©\n",
            "[561/1912] æ­£åœ¨è™•ç†: 3094 è¯å‚‘\n",
            "[562/1912] æ­£åœ¨è™•ç†: 3130 ä¸€é›¶å››\n",
            "[563/1912] æ­£åœ¨è™•ç†: 3135 å‡Œèˆª\n",
            "[564/1912] æ­£åœ¨è™•ç†: 3138 è€€ç™»\n",
            "[565/1912] æ­£åœ¨è™•ç†: 3149 æ­£é”\n",
            "[566/1912] æ­£åœ¨è™•ç†: 3164 æ™¯å²³\n",
            "[567/1912] æ­£åœ¨è™•ç†: 3167 å¤§é‡\n",
            "[568/1912] æ­£åœ¨è™•ç†: 3168 çœ¾ç¦ç§‘\n",
            "[569/1912] æ­£åœ¨è™•ç†: 3189 æ™¯ç¢©\n",
            "[570/1912] æ­£åœ¨è™•ç†: 3209 å…¨ç§‘\n",
            "[571/1912] æ­£åœ¨è™•ç†: 3229 æ™Ÿéˆ¦\n",
            "[572/1912] æ­£åœ¨è™•ç†: 3231 ç·¯å‰µ\n",
            "[573/1912] æ­£åœ¨è™•ç†: 3257 è™¹å† é›»\n",
            "[574/1912] æ­£åœ¨è™•ç†: 3266 æ˜‡é™½\n",
            "[575/1912] æ­£åœ¨è™•ç†: 3296 å‹å¾·\n",
            "[576/1912] æ­£åœ¨è™•ç†: 3305 æ˜‡è²¿\n",
            "[577/1912] æ­£åœ¨è™•ç†: 3308 è¯å¾·\n",
            "[578/1912] æ­£åœ¨è™•ç†: 3311 é–æš‰\n",
            "[579/1912] æ­£åœ¨è™•ç†: 3312 å¼˜æ†¶è‚¡\n",
            "[580/1912] æ­£åœ¨è™•ç†: 3321 åŒæ³°\n",
            "[581/1912] æ­£åœ¨è™•ç†: 3338 æ³°ç¢©\n",
            "[582/1912] æ­£åœ¨è™•ç†: 3346 éº—æ¸…\n",
            "[583/1912] æ­£åœ¨è™•ç†: 3356 å¥‡å¶\n",
            "[584/1912] æ­£åœ¨è™•ç†: 3376 æ–°æ—¥èˆˆ\n",
            "[585/1912] æ­£åœ¨è™•ç†: 3380 æ˜æ³°\n",
            "[586/1912] æ­£åœ¨è™•ç†: 3406 ç‰æ™¶å…‰\n",
            "[587/1912] æ­£åœ¨è™•ç†: 3413 äº¬é¼\n",
            "[588/1912] æ­£åœ¨è™•ç†: 3416 èç¨‹é›»\n",
            "[589/1912] æ­£åœ¨è™•ç†: 3419 è­è£•\n",
            "[590/1912] æ­£åœ¨è™•ç†: 3432 å°ç«¯\n",
            "[591/1912] æ­£åœ¨è™•ç†: 3437 æ¦®å‰µ\n",
            "[592/1912] æ­£åœ¨è™•ç†: 3443 å‰µæ„\n",
            "[593/1912] æ­£åœ¨è™•ç†: 3447 å±•é”\n",
            "[594/1912] æ­£åœ¨è™•ç†: 3450 è¯éˆ\n",
            "[595/1912] æ­£åœ¨è™•ç†: 3454 æ™¶ç¿\n",
            "[596/1912] æ­£åœ¨è™•ç†: 3481 ç¾¤å‰µ\n",
            "[597/1912] æ­£åœ¨è™•ç†: 3494 èª ç ”\n",
            "[598/1912] æ­£åœ¨è™•ç†: 3501 ç¶­ç†¹\n",
            "[599/1912] æ­£åœ¨è™•ç†: 3504 æšæ˜å…‰\n",
            "[600/1912] æ­£åœ¨è™•ç†: 3515 è¯æ“\n",
            "[601/1912] æ­£åœ¨è™•ç†: 3518 æŸé¨°\n",
            "[602/1912] æ­£åœ¨è™•ç†: 3528 å®‰é¦³\n",
            "[603/1912] æ­£åœ¨è™•ç†: 3530 æ™¶ç›¸å…‰\n",
            "[604/1912] æ­£åœ¨è™•ç†: 3532 å°å‹ç§‘\n",
            "[605/1912] æ­£åœ¨è™•ç†: 3533 å˜‰æ¾¤\n",
            "[606/1912] æ­£åœ¨è™•ç†: 3535 æ™¶å½©ç§‘\n",
            "[607/1912] æ­£åœ¨è™•ç†: 3543 å·å·§\n",
            "[608/1912] æ­£åœ¨è™•ç†: 3545 æ•¦æ³°\n",
            "[609/1912] æ­£åœ¨è™•ç†: 3550 è¯ç©\n",
            "[610/1912] æ­£åœ¨è™•ç†: 3557 å˜‰å¨\n",
            "[611/1912] æ­£åœ¨è™•ç†: 3563 ç‰§å¾·\n",
            "[612/1912] æ­£åœ¨è™•ç†: 3576 è¯åˆå†ç”Ÿ\n",
            "[613/1912] æ­£åœ¨è™•ç†: 3583 è¾›è€˜\n",
            "[614/1912] æ­£åœ¨è™•ç†: 3588 é€šå˜‰\n",
            "[615/1912] æ­£åœ¨è™•ç†: 3591 è‰¾ç¬›æ£®\n",
            "[616/1912] æ­£åœ¨è™•ç†: 3592 ç‘é¼\n",
            "[617/1912] æ­£åœ¨è™•ç†: 3593 åŠ›éŠ˜\n",
            "[618/1912] æ­£åœ¨è™•ç†: 3596 æ™ºæ˜“\n",
            "[619/1912] æ­£åœ¨è™•ç†: 3605 å®è‡´\n",
            "[620/1912] æ­£åœ¨è™•ç†: 3607 è°·å´§\n",
            "[621/1912] æ­£åœ¨è™•ç†: 3617 ç¢©å¤©\n",
            "[622/1912] æ­£åœ¨è™•ç†: 3622 æ´‹è¯\n",
            "[623/1912] æ­£åœ¨è™•ç†: 3645 é”é‚\n",
            "[624/1912] æ­£åœ¨è™•ç†: 3652 ç²¾è¯\n",
            "[625/1912] æ­£åœ¨è™•ç†: 3653 å¥ç­–\n",
            "[626/1912] æ­£åœ¨è™•ç†: 3661 ä¸–èŠ¯-KY\n",
            "[627/1912] æ­£åœ¨è™•ç†: 3665 è²¿è¯-KY\n",
            "[628/1912] æ­£åœ¨è™•ç†: 3669 åœ“å±•\n",
            "[629/1912] æ­£åœ¨è™•ç†: 3673 TPK-KY\n",
            "[630/1912] æ­£åœ¨è™•ç†: 3679 æ–°è‡³é™\n",
            "[631/1912] æ­£åœ¨è™•ç†: 3686 é”èƒ½\n",
            "[632/1912] æ­£åœ¨è™•ç†: 3694 æµ·è¯\n",
            "[633/1912] æ­£åœ¨è™•ç†: 3701 å¤§çœ¾æ§\n",
            "[634/1912] æ­£åœ¨è™•ç†: 3702 å¤§è¯å¤§\n",
            "[635/1912] æ­£åœ¨è™•ç†: 3703 æ¬£é™¸\n",
            "[636/1912] æ­£åœ¨è™•ç†: 3704 åˆå‹¤æ§\n",
            "[637/1912] æ­£åœ¨è™•ç†: 3705 æ°¸ä¿¡\n",
            "[638/1912] æ­£åœ¨è™•ç†: 3706 ç¥é”\n",
            "[639/1912] æ­£åœ¨è™•ç†: 3708 ä¸Šç·¯æŠ•æ§\n",
            "[640/1912] æ­£åœ¨è™•ç†: 3711 æ—¥æœˆå…‰æŠ•æ§\n",
            "[641/1912] æ­£åœ¨è™•ç†: 3712 æ°¸å´´æŠ•æ§\n",
            "[642/1912] æ­£åœ¨è™•ç†: 3714 å¯Œé‡‡\n",
            "[643/1912] æ­£åœ¨è™•ç†: 3715 å®šç©æŠ•æ§\n",
            "[644/1912] æ­£åœ¨è™•ç†: 3716 ä¸­åŒ–æ§è‚¡\n",
            "[645/1912] æ­£åœ¨è™•ç†: 4104 ä½³é†«\n",
            "[646/1912] æ­£åœ¨è™•ç†: 4106 é›ƒåš\n",
            "[647/1912] æ­£åœ¨è™•ç†: 4108 æ‡·ç‰¹\n",
            "[648/1912] æ­£åœ¨è™•ç†: 4119 æ—­å¯Œ\n",
            "[649/1912] æ­£åœ¨è™•ç†: 4133 äºè«¾æ³•\n",
            "[650/1912] æ­£åœ¨è™•ç†: 4137 éº—è±-KY\n",
            "[651/1912] æ­£åœ¨è™•ç†: 4142 åœ‹å…‰ç”Ÿ\n",
            "[652/1912] æ­£åœ¨è™•ç†: 4148 å…¨å®‡ç”ŸæŠ€-KY\n",
            "[653/1912] æ­£åœ¨è™•ç†: 4155 è¨Šæ˜ \n",
            "[654/1912] æ­£åœ¨è™•ç†: 4164 æ‰¿æ¥­é†«\n",
            "[655/1912] æ­£åœ¨è™•ç†: 4190 ä½ç™»-KY\n",
            "[656/1912] æ­£åœ¨è™•ç†: 4306 ç‚æ´²\n",
            "[657/1912] æ­£åœ¨è™•ç†: 4414 å¦‚èˆˆ\n",
            "[658/1912] æ­£åœ¨è™•ç†: 4426 åˆ©å‹¤\n",
            "[659/1912] æ­£åœ¨è™•ç†: 4438 å»£è¶Š\n",
            "[660/1912] æ­£åœ¨è™•ç†: 4439 å† æ˜Ÿ-KY\n",
            "[661/1912] æ­£åœ¨è™•ç†: 4440 å®œæ–°å¯¦æ¥­\n",
            "[662/1912] æ­£åœ¨è™•ç†: 4526 æ±å°\n",
            "[663/1912] æ­£åœ¨è™•ç†: 4532 ç‘æ™º\n",
            "[664/1912] æ­£åœ¨è™•ç†: 4536 æ‹“å‡±\n",
            "[665/1912] æ­£åœ¨è™•ç†: 4540 å…¨çƒå‚³å‹•\n",
            "[666/1912] æ­£åœ¨è™•ç†: 4545 éŠ˜éˆº\n",
            "[667/1912] æ­£åœ¨è™•ç†: 4551 æ™ºä¼¸ç§‘\n",
            "[668/1912] æ­£åœ¨è™•ç†: 4552 åŠ›é”-KY\n",
            "[669/1912] æ­£åœ¨è™•ç†: 4555 æ°£ç«‹\n",
            "[670/1912] æ­£åœ¨è™•ç†: 4557 æ°¸æ–°-KY\n",
            "[671/1912] æ­£åœ¨è™•ç†: 4560 å¼·ä¿¡-KY\n",
            "[672/1912] æ­£åœ¨è™•ç†: 4562 ç©æ¼¢\n",
            "[673/1912] æ­£åœ¨è™•ç†: 4564 å…ƒç¿\n",
            "[674/1912] æ­£åœ¨è™•ç†: 4566 æ™‚ç¢©å·¥æ¥­\n",
            "[675/1912] æ­£åœ¨è™•ç†: 4569 å…­æ–¹ç§‘-KY\n",
            "[676/1912] æ­£åœ¨è™•ç†: 4571 éˆèˆˆ-KY\n",
            "[677/1912] æ­£åœ¨è™•ç†: 4572 é§é¾\n",
            "[678/1912] æ­£åœ¨è™•ç†: 4576 å¤§éŠ€å¾®ç³»çµ±\n",
            "[679/1912] æ­£åœ¨è™•ç†: 4581 å…‰éš†ç²¾å¯†-KY\n",
            "[680/1912] æ­£åœ¨è™•ç†: 4583 å°ç£ç²¾éŠ³\n",
            "[681/1912] æ­£åœ¨è™•ç†: 4588 ç–é¼é›»åŠ›\n",
            "[682/1912] æ­£åœ¨è™•ç†: 4720 å¾·æ·µ\n",
            "[683/1912] æ­£åœ¨è™•ç†: 4722 åœ‹ç²¾åŒ–\n",
            "[684/1912] æ­£åœ¨è™•ç†: 4736 æ³°åš\n",
            "[685/1912] æ­£åœ¨è™•ç†: 4737 è¯å»£\n",
            "[686/1912] æ­£åœ¨è™•ç†: 4739 åº·æ™®\n",
            "[687/1912] æ­£åœ¨è™•ç†: 4746 å°è€€\n",
            "[688/1912] æ­£åœ¨è™•ç†: 4755 ä¸‰ç¦åŒ–\n",
            "[689/1912] æ­£åœ¨è™•ç†: 4763 ææ–™*-KY\n",
            "[690/1912] æ­£åœ¨è™•ç†: 4764 é›™éµ\n",
            "[691/1912] æ­£åœ¨è™•ç†: 4766 å—å¯¶\n",
            "[692/1912] æ­£åœ¨è™•ç†: 4770 ä¸Šå“\n",
            "[693/1912] æ­£åœ¨è™•ç†: 4771 æœ›éš¼\n",
            "[694/1912] æ­£åœ¨è™•ç†: 4807 æ—¥æˆ-KY\n",
            "[695/1912] æ­£åœ¨è™•ç†: 4904 é å‚³\n",
            "[696/1912] æ­£åœ¨è™•ç†: 4906 æ­£æ–‡\n",
            "[697/1912] æ­£åœ¨è™•ç†: 4912 è¯å¾·æ§è‚¡-KY\n",
            "[698/1912] æ­£åœ¨è™•ç†: 4915 è‡´ä¼¸\n",
            "[699/1912] æ­£åœ¨è™•ç†: 4916 äº‹æ¬£ç§‘\n",
            "[700/1912] æ­£åœ¨è™•ç†: 4919 æ–°å”\n",
            "[701/1912] æ­£åœ¨è™•ç†: 4927 æ³°é¼-KY\n",
            "[702/1912] æ­£åœ¨è™•ç†: 4930 ç‡¦æ˜Ÿç¶²\n",
            "[703/1912] æ­£åœ¨è™•ç†: 4934 å¤ªæ¥µ\n",
            "[704/1912] æ­£åœ¨è™•ç†: 4935 èŒ‚æ—-KY\n",
            "[705/1912] æ­£åœ¨è™•ç†: 4938 å’Œç¢©\n",
            "[706/1912] æ­£åœ¨è™•ç†: 4942 å˜‰å½°\n",
            "[707/1912] æ­£åœ¨è™•ç†: 4943 åº·æ§-KY\n",
            "[708/1912] æ­£åœ¨è™•ç†: 4949 æœ‰æˆç²¾å¯†\n",
            "[709/1912] æ­£åœ¨è™•ç†: 4952 å‡Œé€š\n",
            "[710/1912] æ­£åœ¨è™•ç†: 4956 å…‰é‹\n",
            "[711/1912] æ­£åœ¨è™•ç†: 4958 è‡»é¼-KY\n",
            "[712/1912] æ­£åœ¨è™•ç†: 4960 èª ç¾æ\n",
            "[713/1912] æ­£åœ¨è™•ç†: 4961 å¤©éˆº\n",
            "[714/1912] æ­£åœ¨è™•ç†: 4967 åéŠ“\n",
            "[715/1912] æ­£åœ¨è™•ç†: 4968 ç«‹ç©\n",
            "[716/1912] æ­£åœ¨è™•ç†: 4976 ä½³å‡Œ\n",
            "[717/1912] æ­£åœ¨è™•ç†: 4977 çœ¾é”-KY\n",
            "[718/1912] æ­£åœ¨è™•ç†: 4989 æ¦®ç§‘\n",
            "[719/1912] æ­£åœ¨è™•ç†: 4994 å‚³å¥‡\n",
            "[720/1912] æ­£åœ¨è™•ç†: 4999 é‘«ç¦¾\n",
            "[721/1912] æ­£åœ¨è™•ç†: 5007 ä¸‰æ˜Ÿ\n",
            "[722/1912] æ­£åœ¨è™•ç†: 5203 è¨Šé€£\n",
            "[723/1912] æ­£åœ¨è™•ç†: 5215 ç§‘å˜‰-KY\n",
            "[724/1912] æ­£åœ¨è™•ç†: 5222 å…¨è¨Š\n",
            "[725/1912] æ­£åœ¨è™•ç†: 5225 æ±ç§‘-KY\n",
            "[726/1912] æ­£åœ¨è™•ç†: 5234 é”èˆˆææ–™\n",
            "[727/1912] æ­£åœ¨è™•ç†: 5243 ä¹™ç››-KY\n",
            "[728/1912] æ­£åœ¨è™•ç†: 5244 å¼˜å‡±\n",
            "[729/1912] æ­£åœ¨è™•ç†: 5258 è™¹å ¡\n",
            "[730/1912] æ­£åœ¨è™•ç†: 5269 ç¥¥ç¢©\n",
            "[731/1912] æ­£åœ¨è™•ç†: 5283 ç¦¾è¯ç¢©\n",
            "[732/1912] æ­£åœ¨è™•ç†: 5284 jpp-KY\n",
            "[733/1912] æ­£åœ¨è™•ç†: 5285 ç•Œéœ–\n",
            "[734/1912] æ­£åœ¨è™•ç†: 5288 è±ç¥¥-KY\n",
            "[735/1912] æ­£åœ¨è™•ç†: 5292 è¯æ‡‹\n",
            "[736/1912] æ­£åœ¨è™•ç†: 5306 æ¡‚ç›Ÿ\n",
            "[737/1912] æ­£åœ¨è™•ç†: 5388 ä¸­ç£Š\n",
            "[738/1912] æ­£åœ¨è™•ç†: 5434 å´‡è¶Š\n",
            "[739/1912] æ­£åœ¨è™•ç†: 5469 ç€šå®‡åš\n",
            "[740/1912] æ­£åœ¨è™•ç†: 5471 æ¾ç¿°\n",
            "[741/1912] æ­£åœ¨è™•ç†: 5484 æ…§å‹\n",
            "[742/1912] æ­£åœ¨è™•ç†: 5515 å»ºåœ‹\n",
            "[743/1912] æ­£åœ¨è™•ç†: 5519 éš†å¤§\n",
            "[744/1912] æ­£åœ¨è™•ç†: 5521 å·¥ä¿¡\n",
            "[745/1912] æ­£åœ¨è™•ç†: 5522 é é›„\n",
            "[746/1912] æ­£åœ¨è™•ç†: 5525 é †å¤©\n",
            "[747/1912] æ­£åœ¨è™•ç†: 5531 é„‰æ—\n",
            "[748/1912] æ­£åœ¨è™•ç†: 5533 çš‡é¼\n",
            "[749/1912] æ­£åœ¨è™•ç†: 5534 é•·è™¹\n",
            "[750/1912] æ­£åœ¨è™•ç†: 5538 æ±æ˜-KY\n",
            "[751/1912] æ­£åœ¨è™•ç†: 5546 æ°¸å›º-KY\n",
            "[752/1912] æ­£åœ¨è™•ç†: 5607 é é›„æ¸¯\n",
            "[753/1912] æ­£åœ¨è™•ç†: 5608 å››ç¶­èˆª\n",
            "[754/1912] æ­£åœ¨è™•ç†: 5706 é³³å‡°\n",
            "[755/1912] æ­£åœ¨è™•ç†: 5871 ä¸­ç§Ÿ-KY\n",
            "[756/1912] æ­£åœ¨è™•ç†: 5876 ä¸Šæµ·å•†éŠ€\n",
            "[757/1912] æ­£åœ¨è™•ç†: 5880 åˆåº«é‡‘\n",
            "[758/1912] æ­£åœ¨è™•ç†: 5906 å°å—-KY\n",
            "[759/1912] æ­£åœ¨è™•ç†: 5907 å¤§æ´‹-KY\n",
            "[760/1912] æ­£åœ¨è™•ç†: 6005 ç¾¤ç›Šè­‰\n",
            "[761/1912] æ­£åœ¨è™•ç†: 6024 ç¾¤ç›ŠæœŸ\n",
            "[762/1912] æ­£åœ¨è™•ç†: 6108 ç«¶åœ‹\n",
            "[763/1912] æ­£åœ¨è™•ç†: 6112 é‚é”ç‰¹\n",
            "[764/1912] æ­£åœ¨è™•ç†: 6115 é°å‹\n",
            "[765/1912] æ­£åœ¨è™•ç†: 6116 å½©æ™¶\n",
            "[766/1912] æ­£åœ¨è™•ç†: 6117 è¿å»£\n",
            "[767/1912] æ­£åœ¨è™•ç†: 6120 é”é‹\n",
            "[768/1912] æ­£åœ¨è™•ç†: 6128 ä¸Šç¦\n",
            "[769/1912] æ­£åœ¨è™•ç†: 6133 é‡‘æ©‹\n",
            "[770/1912] æ­£åœ¨è™•ç†: 6136 å¯Œçˆ¾ç‰¹\n",
            "[771/1912] æ­£åœ¨è™•ç†: 6139 äºç¿”\n",
            "[772/1912] æ­£åœ¨è™•ç†: 6141 æŸæ‰¿\n",
            "[773/1912] æ­£åœ¨è™•ç†: 6142 å‹å‹\n",
            "[774/1912] æ­£åœ¨è™•ç†: 6152 ç™¾ä¸€\n",
            "[775/1912] æ­£åœ¨è™•ç†: 6153 å˜‰è¯ç›Š\n",
            "[776/1912] æ­£åœ¨è™•ç†: 6155 éˆå¯¶\n",
            "[777/1912] æ­£åœ¨è™•ç†: 6164 è¯èˆˆ\n",
            "[778/1912] æ­£åœ¨è™•ç†: 6165 æµªå‡¡\n",
            "[779/1912] æ­£åœ¨è™•ç†: 6166 å‡Œè¯\n",
            "[780/1912] æ­£åœ¨è™•ç†: 6168 å®é½Š\n",
            "[781/1912] æ­£åœ¨è™•ç†: 6176 ç‘å„€\n",
            "[782/1912] æ­£åœ¨è™•ç†: 6177 é”éº—\n",
            "[783/1912] æ­£åœ¨è™•ç†: 6183 é—œè²¿\n",
            "[784/1912] æ­£åœ¨è™•ç†: 6184 å¤§è±é›»\n",
            "[785/1912] æ­£åœ¨è™•ç†: 6189 è±è—\n",
            "[786/1912] æ­£åœ¨è™•ç†: 6191 ç²¾æˆç§‘\n",
            "[787/1912] æ­£åœ¨è™•ç†: 6192 å·¨è·¯\n",
            "[788/1912] æ­£åœ¨è™•ç†: 6196 å¸†å®£\n",
            "[789/1912] æ­£åœ¨è™•ç†: 6197 ä½³å¿…çª\n",
            "[790/1912] æ­£åœ¨è™•ç†: 6201 äºå¼˜é›»\n",
            "[791/1912] æ­£åœ¨è™•ç†: 6202 ç››ç¾¤\n",
            "[792/1912] æ­£åœ¨è™•ç†: 6205 è©®æ¬£\n",
            "[793/1912] æ­£åœ¨è™•ç†: 6206 é£›æ·\n",
            "[794/1912] æ­£åœ¨è™•ç†: 6209 ä»Šåœ‹å…‰\n",
            "[795/1912] æ­£åœ¨è™•ç†: 6213 è¯èŒ‚\n",
            "[796/1912] æ­£åœ¨è™•ç†: 6214 ç²¾èª \n",
            "[797/1912] æ­£åœ¨è™•ç†: 6215 å’Œæ¤¿\n",
            "[798/1912] æ­£åœ¨è™•ç†: 6216 å±…æ˜“\n",
            "[799/1912] æ­£åœ¨è™•ç†: 6224 èšé¼\n",
            "[800/1912] æ­£åœ¨è™•ç†: 6225 å¤©ç€š\n",
            "[801/1912] æ­£åœ¨è™•ç†: 6226 å…‰é¼\n",
            "[802/1912] æ­£åœ¨è™•ç†: 6230 å°¼å¾—ç§‘è¶…çœ¾\n",
            "[803/1912] æ­£åœ¨è™•ç†: 6235 è¯å­š\n",
            "[804/1912] æ­£åœ¨è™•ç†: 6239 åŠ›æˆ\n",
            "[805/1912] æ­£åœ¨è™•ç†: 6243 è¿…æ°\n",
            "[806/1912] æ­£åœ¨è™•ç†: 6257 çŸ½æ ¼\n",
            "[807/1912] æ­£åœ¨è™•ç†: 6269 å°éƒ¡\n",
            "[808/1912] æ­£åœ¨è™•ç†: 6271 åŒæ¬£é›»\n",
            "[809/1912] æ­£åœ¨è™•ç†: 6277 å®æ­£\n",
            "[810/1912] æ­£åœ¨è™•ç†: 6278 å°è¡¨ç§‘\n",
            "[811/1912] æ­£åœ¨è™•ç†: 6281 å…¨åœ‹é›»\n",
            "[812/1912] æ­£åœ¨è™•ç†: 6282 åº·èˆ’\n",
            "[813/1912] æ­£åœ¨è™•ç†: 6283 æ·³å®‰\n",
            "[814/1912] æ­£åœ¨è™•ç†: 6285 å•Ÿï¿½ï¿½\n",
            "[815/1912] æ­£åœ¨è™•ç†: 6288 è¯å˜‰\n",
            "[816/1912] æ­£åœ¨è™•ç†: 6405 æ‚…åŸ\n",
            "[817/1912] æ­£åœ¨è™•ç†: 6409 æ—­éš¼\n",
            "[818/1912] æ­£åœ¨è™•ç†: 6412 ç¾¤é›»\n",
            "[819/1912] æ­£åœ¨è™•ç†: 6414 æ¨ºæ¼¢\n",
            "[820/1912] æ­£åœ¨è™•ç†: 6415 çŸ½åŠ›*-KY\n",
            "[821/1912] æ­£åœ¨è™•ç†: 6416 ç‘ç¥ºé›»é€š\n",
            "[822/1912] æ­£åœ¨è™•ç†: 6426 çµ±æ–°\n",
            "[823/1912] æ­£åœ¨è™•ç†: 6431 å…‰éº—-KY\n",
            "[824/1912] æ­£åœ¨è™•ç†: 6438 è¿…å¾—\n",
            "[825/1912] æ­£åœ¨è™•ç†: 6442 å…‰è–\n",
            "[826/1912] æ­£åœ¨è™•ç†: 6443 å…ƒæ™¶\n",
            "[827/1912] æ­£åœ¨è™•ç†: 6446 è—¥è¯è—¥\n",
            "[828/1912] æ­£åœ¨è™•ç†: 6449 éˆºé‚¦\n",
            "[829/1912] æ­£åœ¨è™•ç†: 6451 è¨ŠèŠ¯-KY\n",
            "[830/1912] æ­£åœ¨è™•ç†: 6456 GIS-KY\n",
            "[831/1912] æ­£åœ¨è™•ç†: 6464 å°æ•¸ç§‘\n",
            "[832/1912] æ­£åœ¨è™•ç†: 6472 ä¿ç‘\n",
            "[833/1912] æ­£åœ¨è™•ç†: 6477 å®‰é›†\n",
            "[834/1912] æ­£åœ¨è™•ç†: 6491 æ™¶ç¢©\n",
            "[835/1912] æ­£åœ¨è™•ç†: 6504 å—å…­\n",
            "[836/1912] æ­£åœ¨è™•ç†: 6505 å°å¡‘åŒ–\n",
            "[837/1912] æ­£åœ¨è™•ç†: 6515 ç©å´´\n",
            "[838/1912] æ­£åœ¨è™•ç†: 6525 æ·æ•-KY\n",
            "[839/1912] æ­£åœ¨è™•ç†: 6526 é”ç™¼\n",
            "[840/1912] æ­£åœ¨è™•ç†: 6531 æ„›æ™®*\n",
            "[841/1912] æ­£åœ¨è™•ç†: 6533 æ™¶å¿ƒç§‘\n",
            "[842/1912] æ­£åœ¨è™•ç†: 6541 æ³°ç¦-KY\n",
            "[843/1912] æ­£åœ¨è™•ç†: 6550 åŒ—æ¥µæ˜Ÿè—¥æ¥­-KY\n",
            "[844/1912] æ­£åœ¨è™•ç†: 6552 æ˜“è¯é›»\n",
            "[845/1912] æ­£åœ¨è™•ç†: 6558 èˆˆèƒ½é«˜\n",
            "[846/1912] æ­£åœ¨è™•ç†: 6573 è™¹æš-KY\n",
            "[847/1912] æ­£åœ¨è™•ç†: 6579 ç ”æš\n",
            "[848/1912] æ­£åœ¨è™•ç†: 6581 é‹¼è¯\n",
            "[849/1912] æ­£åœ¨è™•ç†: 6582 ç”³è±\n",
            "[850/1912] æ­£åœ¨è™•ç†: 6585 é¼åŸº\n",
            "[851/1912] æ­£åœ¨è™•ç†: 6589 å°åº·ç”ŸæŠ€\n",
            "[852/1912] æ­£åœ¨è™•ç†: 6591 å‹•åŠ›-KY\n",
            "[853/1912] æ­£åœ¨è™•ç†: 6592 å’Œæ½¤ä¼æ¥­\n",
            "[854/1912] æ­£åœ¨è™•ç†: 6598 ABC-KY\n",
            "[855/1912] æ­£åœ¨è™•ç†: 6605 å¸å¯¶\n",
            "[856/1912] æ­£åœ¨è™•ç†: 6606 å»ºå¾·å·¥æ¥­\n",
            "[857/1912] æ­£åœ¨è™•ç†: 6625 å¿…æ‡‰\n",
            "[858/1912] æ­£åœ¨è™•ç†: 6641 åŸºå£«å¾·-KY\n",
            "[859/1912] æ­£åœ¨è™•ç†: 6655 ç§‘å®š\n",
            "[860/1912] æ­£åœ¨è™•ç†: 6657 è¯å®‰\n",
            "[861/1912] æ­£åœ¨è™•ç†: 6658 è¯ç­–\n",
            "[862/1912] æ­£åœ¨è™•ç†: 6666 ç¾…éº—èŠ¬-KY\n",
            "[863/1912] æ­£åœ¨è™•ç†: 6668 ä¸­æšå…‰\n",
            "[864/1912] æ­£åœ¨è™•ç†: 6669 ç·¯ç©\n",
            "[865/1912] æ­£åœ¨è™•ç†: 6670 å¾©ç››æ‡‰ç”¨\n",
            "[866/1912] æ­£åœ¨è™•ç†: 6671 ä¸‰èƒ½-KY\n",
            "[867/1912] æ­£åœ¨è™•ç†: 6672 é¨°è¼é›»å­-KY\n",
            "[868/1912] æ­£åœ¨è™•ç†: 6674 é‹å¯¶ç§‘æŠ€\n",
            "[869/1912] æ­£åœ¨è™•ç†: 6689 ä¼Šé›²è°·\n",
            "[870/1912] æ­£åœ¨è™•ç†: 6691 æ´‹åŸºå·¥ç¨‹\n",
            "[871/1912] æ­£åœ¨è™•ç†: 6695 èŠ¯é¼\n",
            "[872/1912] æ­£åœ¨è™•ç†: 6698 æ—­æš‰æ‡‰æ\n",
            "[873/1912] æ­£åœ¨è™•ç†: 6706 æƒ ç‰¹\n",
            "[874/1912] æ­£åœ¨è™•ç†: 6715 å˜‰åŸº\n",
            "[875/1912] æ­£åœ¨è™•ç†: 6719 åŠ›æ™º\n",
            "[876/1912] æ­£åœ¨è™•ç†: 6742 æ¾¤ç±³\n",
            "[877/1912] æ­£åœ¨è™•ç†: 6743 å®‰æ™®æ–°\n",
            "[878/1912] æ­£åœ¨è™•ç†: 6753 é¾å¾·é€ èˆ¹\n",
            "[879/1912] æ­£åœ¨è™•ç†: 6754 åŒ¯åƒ‘è¨­è¨ˆ\n",
            "[880/1912] æ­£åœ¨è™•ç†: 6756 å¨é‹’é›»å­\n",
            "[881/1912] æ­£åœ¨è™•ç†: 6757 å°ç£è™èˆª\n",
            "[882/1912] æ­£åœ¨è™•ç†: 6768 å¿—å¼·-KY\n",
            "[883/1912] æ­£åœ¨è™•ç†: 6770 åŠ›ç©é›»\n",
            "[884/1912] æ­£åœ¨è™•ç†: 6776 å±•ï¿½çœ¥ç¯•ï¿½\n",
            "[885/1912] æ­£åœ¨è™•ç†: 6781 AES-KY\n",
            "[886/1912] æ­£åœ¨è™•ç†: 6782 è¦–é™½\n",
            "[887/1912] æ­£åœ¨è™•ç†: 6789 é‡‡éˆº\n",
            "[888/1912] æ­£åœ¨è™•ç†: 6790 æ°¸è±å¯¦\n",
            "[889/1912] æ­£åœ¨è™•ç†: 6792 è© æ¥­\n",
            "[890/1912] æ­£åœ¨è™•ç†: 6796 æ™‰å¼˜\n",
            "[891/1912] æ­£åœ¨è™•ç†: 6799 ä¾†é ¡\n",
            "[892/1912] æ­£åœ¨è™•ç†: 6805 å¯Œä¸–é”\n",
            "[893/1912] æ­£åœ¨è™•ç†: 6806 æ£®å´´èƒ½æº\n",
            "[894/1912] æ­£åœ¨è™•ç†: 6807 å³°æº-KY\n",
            "[895/1912] æ­£åœ¨è™•ç†: 6830 æ±éŠ“\n",
            "[896/1912] æ­£åœ¨è™•ç†: 6834 å¤©äºŒç§‘æŠ€\n",
            "[897/1912] æ­£åœ¨è™•ç†: 6835 åœ“è£•\n",
            "[898/1912] æ­£åœ¨è™•ç†: 6838 å°æ–°è—¥\n",
            "[899/1912] æ­£åœ¨è™•ç†: 6861 ç¿ç”Ÿå…‰é›»\n",
            "[900/1912] æ­£åœ¨è™•ç†: 6862 ä¸‰é›†ç‘-KY\n",
            "[901/1912] æ­£åœ¨è™•ç†: 6863 æ°¸é“-KY\n",
            "[902/1912] æ­£åœ¨è™•ç†: 6869 é›²è±¹èƒ½æº\n",
            "[903/1912] æ­£åœ¨è™•ç†: 6873 æ³“å¾·èƒ½æº\n",
            "[904/1912] æ­£åœ¨è™•ç†: 6885 å…¨ç¦ç”ŸæŠ€\n",
            "[905/1912] æ­£åœ¨è™•ç†: 6887 å¯¶ç¶ ç‰¹-KY\n",
            "[906/1912] æ­£åœ¨è™•ç†: 6890 ä¾†å„„-KY\n",
            "[907/1912] æ­£åœ¨è™•ç†: 6901 é‘½çŸ³æŠ•è³‡\n",
            "[908/1912] æ­£åœ¨è™•ç†: 6902 GOGOLOOK\n",
            "[909/1912] æ­£åœ¨è™•ç†: 6906 ç¾è§€ç§‘\n",
            "[910/1912] æ­£åœ¨è™•ç†: 6909 å‰µæ§\n",
            "[911/1912] æ­£åœ¨è™•ç†: 6914 é˜œçˆ¾é‹é€š\n",
            "[912/1912] æ­£åœ¨è™•ç†: 6916 è¯å‡Œ\n",
            "[913/1912] æ­£åœ¨è™•ç†: 6918 æ„›æ´¾å¸\n",
            "[914/1912] æ­£åœ¨è™•ç†: 6919 åº·éœˆ*\n",
            "[915/1912] æ­£åœ¨è™•ç†: 6923 ä¸­å°\n",
            "[916/1912] æ­£åœ¨è™•ç†: 6928 æ”¸æ³°ç§‘æŠ€\n",
            "[917/1912] æ­£åœ¨è™•ç†: 6931 é’æ¾å¥åº·\n",
            "[918/1912] æ­£åœ¨è™•ç†: 6933 AMAX-KY\n",
            "[919/1912] æ­£åœ¨è™•ç†: 6936 æ°¸é´»ç”ŸæŠ€\n",
            "[920/1912] æ­£åœ¨è™•ç†: 6937 å¤©è™¹\n",
            "[921/1912] æ­£åœ¨è™•ç†: 6944 å…†è¯å¯¦æ¥­\n",
            "[922/1912] æ­£åœ¨è™•ç†: 6952 å¤§æ­¦å±±\n",
            "[923/1912] æ­£åœ¨è™•ç†: 6957 è£•æ…¶-KY\n",
            "[924/1912] æ­£åœ¨è™•ç†: 6958 æ—¥ç››å°é§¿\n",
            "[925/1912] æ­£åœ¨è™•ç†: 6962 å¥•åŠ›-KY\n",
            "[926/1912] æ­£åœ¨è™•ç†: 6965 ä¸­å‚‘-KY\n",
            "[927/1912] æ­£åœ¨è™•ç†: 6994 å¯Œå¨é›»åŠ›\n",
            "[928/1912] æ­£åœ¨è™•ç†: 7705 ä¸‰å•†é¤é£²\n",
            "[929/1912] æ­£åœ¨è™•ç†: 7721 å¾®ç¨‹å¼\n",
            "[930/1912] æ­£åœ¨è™•ç†: 7722 LINEPAY\n",
            "[931/1912] æ­£åœ¨è™•ç†: 7732 é‡‘èˆˆç²¾å¯†\n",
            "[932/1912] æ­£åœ¨è™•ç†: 7736 è™å±±\n",
            "[933/1912] æ­£åœ¨è™•ç†: 7749 æ„é¨°-KY\n",
            "[934/1912] æ­£åœ¨è™•ç†: 8011 å°é€š\n",
            "[935/1912] æ­£åœ¨è™•ç†: 8016 çŸ½å‰µ\n",
            "[936/1912] æ­£åœ¨è™•ç†: 8021 å°–é»\n",
            "[937/1912] æ­£åœ¨è™•ç†: 8028 æ˜‡é™½åŠå°é«”\n",
            "[938/1912] æ­£åœ¨è™•ç†: 8033 é›·è™\n",
            "[939/1912] æ­£åœ¨è™•ç†: 8039 å°è™¹\n",
            "[940/1912] æ­£åœ¨è™•ç†: 8045 é”é‹å…‰é›»\n",
            "[941/1912] æ­£åœ¨è™•ç†: 8046 å—é›»\n",
            "[942/1912] æ­£åœ¨è™•ç†: 8070 é•·è¯*\n",
            "[943/1912] æ­£åœ¨è™•ç†: 8072 é™æ³°\n",
            "[944/1912] æ­£åœ¨è™•ç†: 8081 è‡´æ–°\n",
            "[945/1912] æ­£åœ¨è™•ç†: 8101 è¯å† \n",
            "[946/1912] æ­£åœ¨è™•ç†: 8103 ç€šèƒ\n",
            "[947/1912] æ­£åœ¨è™•ç†: 8104 éŒ¸å¯¶\n",
            "[948/1912] æ­£åœ¨è™•ç†: 8105 å‡Œå·¨\n",
            "[949/1912] æ­£åœ¨è™•ç†: 8110 è¯æ±\n",
            "[950/1912] æ­£åœ¨è™•ç†: 8112 è‡³ä¸Š\n",
            "[951/1912] æ­£åœ¨è™•ç†: 8114 æŒ¯æ¨ºé›»\n",
            "[952/1912] æ­£åœ¨è™•ç†: 8131 ç¦æ‡‹ç§‘\n",
            "[953/1912] æ­£åœ¨è™•ç†: 8150 å—èŒ‚\n",
            "[954/1912] æ­£åœ¨è™•ç†: 8163 é”æ–¹\n",
            "[955/1912] æ­£åœ¨è™•ç†: 8201 ç„¡æ•µ\n",
            "[956/1912] æ­£åœ¨è™•ç†: 8210 å‹¤èª \n",
            "[957/1912] æ­£åœ¨è™•ç†: 8213 å¿—è¶…\n",
            "[958/1912] æ­£åœ¨è™•ç†: 8215 æ˜åŸºæ\n",
            "[959/1912] æ­£åœ¨è™•ç†: 8222 å¯¶ä¸€\n",
            "[960/1912] æ­£åœ¨è™•ç†: 8249 è±å…‰\n",
            "[961/1912] æ­£åœ¨è™•ç†: 8261 å¯Œé¼\n",
            "[962/1912] æ­£åœ¨è™•ç†: 8271 å®‡ç»\n",
            "[963/1912] æ­£åœ¨è™•ç†: 8341 æ—¥å‹\n",
            "[964/1912] æ­£åœ¨è™•ç†: 8367 å»ºæ–°åœ‹éš›\n",
            "[965/1912] æ­£åœ¨è™•ç†: 8374 ç¾…æ˜‡\n",
            "[966/1912] æ­£åœ¨è™•ç†: 8404 ç™¾å’Œèˆˆæ¥­-KY\n",
            "[967/1912] æ­£åœ¨è™•ç†: 8411 ç¦è²-KY\n",
            "[968/1912] æ­£åœ¨è™•ç†: 8422 å¯å¯§è¡›\n",
            "[969/1912] æ­£åœ¨è™•ç†: 8429 é‡‘éº—-KY\n",
            "[970/1912] æ­£åœ¨è™•ç†: 8438 æ˜¶æ˜•\n",
            "[971/1912] æ­£åœ¨è™•ç†: 8442 å¨å®-KY\n",
            "[972/1912] æ­£åœ¨è™•ç†: 8443 é˜¿ç˜¦\n",
            "[973/1912] æ­£åœ¨è™•ç†: 8454 å¯Œé‚¦åª’\n",
            "[974/1912] æ­£åœ¨è™•ç†: 8462 æŸæ–‡\n",
            "[975/1912] æ­£åœ¨è™•ç†: 8463 æ½¤æ³°æ\n",
            "[976/1912] æ­£åœ¨è™•ç†: 8464 å„„è±\n",
            "[977/1912] æ­£åœ¨è™•ç†: 8466 ç¾å‰å‰-KY\n",
            "[978/1912] æ­£åœ¨è™•ç†: 8467 æ³¢åŠ›-KY\n",
            "[979/1912] æ­£åœ¨è™•ç†: 8473 å±±æ—æ°´\n",
            "[980/1912] æ­£åœ¨è™•ç†: 8476 å°å¢ƒ*\n",
            "[981/1912] æ­£åœ¨è™•ç†: 8478 æ±å“¥éŠè‰‡\n",
            "[982/1912] æ­£åœ¨è™•ç†: 8481 æ”¿ä¼¸\n",
            "[983/1912] æ­£åœ¨è™•ç†: 8482 å•†å„„-KY\n",
            "[984/1912] æ­£åœ¨è™•ç†: 8488 å‰æº-KY\n",
            "[985/1912] æ­£åœ¨è™•ç†: 8499 é¼ç‚«-KY\n",
            "[986/1912] æ­£åœ¨è™•ç†: 8926 å°æ±½é›»\n",
            "[987/1912] æ­£åœ¨è™•ç†: 8940 æ–°å¤©åœ°\n",
            "[988/1912] æ­£åœ¨è™•ç†: 8996 é«˜åŠ›\n",
            "[989/1912] æ­£åœ¨è™•ç†: 9802 éˆºé½Š-KY\n",
            "[990/1912] æ­£åœ¨è™•ç†: 9902 å°ç«\n",
            "[991/1912] æ­£åœ¨è™•ç†: 9904 å¯¶æˆ\n",
            "[992/1912] æ­£åœ¨è™•ç†: 9905 å¤§è¯\n",
            "[993/1912] æ­£åœ¨è™•ç†: 9906 æ¬£å·´å·´\n",
            "[994/1912] æ­£åœ¨è™•ç†: 9907 çµ±ä¸€å¯¦\n",
            "[995/1912] æ­£åœ¨è™•ç†: 9908 å¤§å°åŒ—\n",
            "[996/1912] æ­£åœ¨è™•ç†: 9910 è±æ³°\n",
            "[997/1912] æ­£åœ¨è™•ç†: 9911 æ«»èŠ±\n",
            "[998/1912] æ­£åœ¨è™•ç†: 9912 å‰è¯\n",
            "[999/1912] æ­£åœ¨è™•ç†: 9914 ç¾åˆ©é”\n",
            "[1000/1912] æ­£åœ¨è™•ç†: 9917 ä¸­ä¿ç§‘\n",
            "[1001/1912] æ­£åœ¨è™•ç†: 9918 æ¬£å¤©ç„¶\n",
            "[1002/1912] æ­£åœ¨è™•ç†: 9919 åº·é‚£é¦™\n",
            "[1003/1912] æ­£åœ¨è™•ç†: 9921 å·¨å¤§\n",
            "[1004/1912] æ­£åœ¨è™•ç†: 9924 ç¦èˆˆ\n",
            "[1005/1912] æ­£åœ¨è™•ç†: 9925 æ–°ä¿\n",
            "[1006/1912] æ­£åœ¨è™•ç†: 9926 æ–°æµ·\n",
            "[1007/1912] æ­£åœ¨è™•ç†: 9927 æ³°éŠ˜\n",
            "[1008/1912] æ­£åœ¨è™•ç†: 9928 ä¸­è¦–\n",
            "[1009/1912] æ­£åœ¨è™•ç†: 9929 ç§‹é›¨\n",
            "[1010/1912] æ­£åœ¨è™•ç†: 9930 ä¸­è¯è³‡æº\n",
            "[1011/1912] æ­£åœ¨è™•ç†: 9931 æ¬£é«˜\n",
            "[1012/1912] æ­£åœ¨è™•ç†: 9933 ä¸­é¼\n",
            "[1013/1912] æ­£åœ¨è™•ç†: 9934 æˆéœ–\n",
            "[1014/1912] æ­£åœ¨è™•ç†: 9935 æ…¶è±å¯Œ\n",
            "[1015/1912] æ­£åœ¨è™•ç†: 9937 å…¨åœ‹\n",
            "[1016/1912] æ­£åœ¨è™•ç†: 9938 ç™¾å’Œ\n",
            "[1017/1912] æ­£åœ¨è™•ç†: 9939 å®å…¨\n",
            "[1018/1912] æ­£åœ¨è™•ç†: 9940 ä¿¡ç¾©\n",
            "[1019/1912] æ­£åœ¨è™•ç†: 9941 è£•è\n",
            "[1020/1912] æ­£åœ¨è™•ç†: 9942 èŒ‚é †\n",
            "[1021/1912] æ­£åœ¨è™•ç†: 9943 å¥½æ¨‚è¿ª\n",
            "[1022/1912] æ­£åœ¨è™•ç†: 9944 æ–°éº—\n",
            "[1023/1912] æ­£åœ¨è™•ç†: 9945 æ½¤æ³°æ–°\n",
            "[1024/1912] æ­£åœ¨è™•ç†: 9946 ä¸‰ç™¼åœ°ç”¢\n",
            "[1025/1912] æ­£åœ¨è™•ç†: 9955 ä½³é¾\n",
            "[1026/1912] æ­£åœ¨è™•ç†: 9958 ä¸–ç´€é‹¼\n",
            "[1027/1912] æ­£åœ¨è™•ç†: 2254 å·¨é§ç²¾å¯†-å‰µ\n",
            "[1028/1912] æ­£åœ¨è™•ç†: 2258 é´»è¯å…ˆé€²-å‰µ\n",
            "[1029/1912] æ­£åœ¨è™•ç†: 2432 å€šå¤©é…·ï¿½ï¿½-å‰µ\n",
            "[1030/1912] æ­£åœ¨è™•ç†: 3150 éˆºå¯¶-å‰µ\n",
            "[1031/1912] æ­£åœ¨è™•ç†: 6423 å„„è€Œå¾—-å‰µ\n",
            "[1032/1912] æ­£åœ¨è™•ç†: 6534 æ­£ç€š-å‰µ\n",
            "[1033/1912] æ­£åœ¨è™•ç†: 6645 é‡‘è¬æ—-å‰µ\n",
            "[1034/1912] æ­£åœ¨è™•ç†: 6771 å¹³å’Œç’°ä¿-å‰µ\n",
            "[1035/1912] æ­£åœ¨è™•ç†: 6794 å‘æ¦®ç”ŸæŠ€-å‰µ\n",
            "[1036/1912] æ­£åœ¨è™•ç†: 6854 éŒ¼å‰µç§‘æŠ€-KYå‰µ\n",
            "[1037/1912] æ­£åœ¨è™•ç†: 6924 æ¦®æƒ -KYå‰µ\n",
            "[1038/1912] æ­£åœ¨è™•ç†: 6949 æ²›çˆ¾ç”Ÿé†«-å‰µ\n",
            "[1039/1912] æ­£åœ¨è™•ç†: 6951 é’æ–°-å‰µ\n",
            "[1040/1912] æ­£åœ¨è™•ç†: 6955 é‚¦ç¿ç”ŸæŠ€-å‰µ\n",
            "[1041/1912] æ­£åœ¨è™•ç†: 6969 æˆä¿¡å¯¦æ¥­*-å‰µ\n",
            "[1042/1912] æ­£åœ¨è™•ç†: 6988 å¨åŠ›æš˜-å‰µ\n",
            "[1043/1912] æ­£åœ¨è™•ç†: 7631 èšè³¢ç ”ç™¼-å‰µ\n",
            "[1044/1912] æ­£åœ¨è™•ç†: 7740 ç†™ç‰¹çˆ¾-å‰µ\n",
            "[1045/1912] æ­£åœ¨è™•ç†: 8162 å¾®çŸ½é›»å­-å‰µ\n",
            "[1046/1912] æ­£åœ¨è™•ç†: 8487 æ„›çˆ¾é”-å‰µ\n",
            "[1047/1912] æ­£åœ¨è™•ç†: 0050 å…ƒå¤§å°ç£50\n",
            "[1048/1912] æ­£åœ¨è™•ç†: 0051 å…ƒå¤§ä¸­å‹100\n",
            "[1049/1912] æ­£åœ¨è™•ç†: 0052 å¯Œé‚¦ç§‘æŠ€\n",
            "[1050/1912] æ­£åœ¨è™•ç†: 0053 å…ƒå¤§é›»å­\n",
            "[1051/1912] æ­£åœ¨è™•ç†: 0055 å…ƒå¤§MSCIé‡‘è\n",
            "[1052/1912] æ­£åœ¨è™•ç†: 0056 å…ƒå¤§é«˜è‚¡æ¯\n",
            "[1053/1912] æ­£åœ¨è™•ç†: 0057 å¯Œé‚¦æ‘©å°\n",
            "[1054/1912] æ­£åœ¨è™•ç†: 0061 å…ƒå¤§å¯¶æ»¬æ·±\n",
            "[1055/1912] æ­£åœ¨è™•ç†: 9103 ç¾å¾·é†«ç™‚-DR\n",
            "[1056/1912] æ­£åœ¨è™•ç†: 9105 æ³°é‡‘å¯¶-DR\n",
            "[1057/1912] æ­£åœ¨è™•ç†: 9110 è¶Šå—æ§-DR\n",
            "[1058/1912] æ­£åœ¨è™•ç†: 9136 å·¨é¨°-DR\n",
            "[1059/1912] æ­£åœ¨è™•ç†: 1240 èŒ‚ç”Ÿè¾²ç¶“\n",
            "[1060/1912] æ­£åœ¨è™•ç†: 1259 å®‰å¿ƒ\n",
            "[1061/1912] æ­£åœ¨è™•ç†: 1264 å¾·éº¥\n",
            "[1062/1912] æ­£åœ¨è™•ç†: 1268 æ¼¢ä¾†ç¾é£Ÿ\n",
            "[1063/1912] æ­£åœ¨è™•ç†: 1294 æ¼¢ç”°ç”ŸæŠ€\n",
            "[1064/1912] æ­£åœ¨è™•ç†: 1295 ç”Ÿåˆ\n",
            "[1065/1912] æ­£åœ¨è™•ç†: 1336 å°ç¿°\n",
            "[1066/1912] æ­£åœ¨è™•ç†: 1565 ç²¾è¯\n",
            "[1067/1912] æ­£åœ¨è™•ç†: 1569 æ¿±å·\n",
            "[1068/1912] æ­£åœ¨è™•ç†: 1570 åŠ›è‚¯\n",
            "[1069/1912] æ­£åœ¨è™•ç†: 1580 æ–°éº¥\n",
            "[1070/1912] æ­£åœ¨è™•ç†: 1584 ç²¾å‰›\n",
            "[1071/1912] æ­£åœ¨è™•ç†: 1586 å’Œå‹¤\n",
            "[1072/1912] æ­£åœ¨è™•ç†: 1591 é§¿å‰-KY\n",
            "[1073/1912] æ­£åœ¨è™•ç†: 1593 ç¥ºé©Š\n",
            "[1074/1912] æ­£åœ¨è™•ç†: 1595 å·å¯¶\n",
            "[1075/1912] æ­£åœ¨è™•ç†: 1599 å®ä½³é¨°\n",
            "[1076/1912] æ­£åœ¨è™•ç†: 1742 å°è Ÿ\n",
            "[1077/1912] æ­£åœ¨è™•ç†: 1777 ç”Ÿæ³°\n",
            "[1078/1912] æ­£åœ¨è™•ç†: 1781 åˆä¸–\n",
            "[1079/1912] æ­£åœ¨è™•ç†: 1784 è¨Šè¯\n",
            "[1080/1912] æ­£åœ¨è™•ç†: 1785 å…‰æ´‹ç§‘\n",
            "[1081/1912] æ­£åœ¨è™•ç†: 1788 ææ˜Œ\n",
            "[1082/1912] æ­£åœ¨è™•ç†: 1796 é‡‘ç©ç”ŸæŠ€\n",
            "[1083/1912] æ­£åœ¨è™•ç†: 1799 æ˜“å¨\n",
            "[1084/1912] æ­£åœ¨è™•ç†: 1813 å¯¶åˆ©å¾ \n",
            "[1085/1912] æ­£åœ¨è™•ç†: 1815 å¯Œå–¬\n",
            "[1086/1912] æ­£åœ¨è™•ç†: 2035 å”æ¦®\n",
            "[1087/1912] æ­£åœ¨è™•ç†: 2061 é¢¨é’\n",
            "[1088/1912] æ­£åœ¨è™•ç†: 2063 ä¸–é§\n",
            "[1089/1912] æ­£åœ¨è™•ç†: 2064 æ™‰æ¤¿\n",
            "[1090/1912] æ­£åœ¨è™•ç†: 2065 ä¸–è±\n",
            "[1091/1912] æ­£åœ¨è™•ç†: 2066 ä¸–å¾·\n",
            "[1092/1912] æ­£åœ¨è™•ç†: 2067 å˜‰é‹¼\n",
            "[1093/1912] æ­£åœ¨è™•ç†: 2070 ç²¾æ¹›\n",
            "[1094/1912] æ­£åœ¨è™•ç†: 2073 é›„é †\n",
            "[1095/1912] æ­£åœ¨è™•ç†: 2221 å¤§ç”²\n",
            "[1096/1912] æ­£åœ¨è™•ç†: 2230 æ³°èŒ‚\n",
            "[1097/1912] æ­£åœ¨è™•ç†: 2235 è¬šæº\n",
            "[1098/1912] æ­£åœ¨è™•ç†: 2596 ç¶ æ„\n",
            "[1099/1912] æ­£åœ¨è™•ç†: 2640 å¤§è»ŠéšŠ\n",
            "[1100/1912] æ­£åœ¨è™•ç†: 2641 æ­£å¾·\n",
            "[1101/1912] æ­£åœ¨è™•ç†: 2643 æ·è¿…\n",
            "[1102/1912] æ­£åœ¨è™•ç†: 2718 å…¨å¿ƒæŠ•æ§\n",
            "[1103/1912] æ­£åœ¨è™•ç†: 2719 ç‡¦æ˜Ÿæ—…\n",
            "[1104/1912] æ­£åœ¨è™•ç†: 2724 è—èˆ-KY\n",
            "[1105/1912] æ­£åœ¨è™•ç†: 2726 é›…èŒ—-KY\n",
            "[1106/1912] æ­£åœ¨è™•ç†: 2729 ç“¦åŸ\n",
            "[1107/1912] æ­£åœ¨è™•ç†: 2732 å…­è§’\n",
            "[1108/1912] æ­£åœ¨è™•ç†: 2734 æ˜“é£›ç¶²\n",
            "[1109/1912] æ­£åœ¨è™•ç†: 2736 å¯Œé‡\n",
            "[1110/1912] æ­£åœ¨è™•ç†: 2740 å¤©è”¥\n",
            "[1111/1912] æ­£åœ¨è™•ç†: 2743 å±±å¯Œ\n",
            "[1112/1912] æ­£åœ¨è™•ç†: 2745 äº”ç¦\n",
            "[1113/1912] æ­£åœ¨è™•ç†: 2751 ç‹åº§\n",
            "[1114/1912] æ­£åœ¨è™•ç†: 2752 è±†åºœ\n",
            "[1115/1912] æ­£åœ¨è™•ç†: 2754 äºæ´²è—å£½å¸\n",
            "[1116/1912] æ­£åœ¨è™•ç†: 2755 æšç§¦\n",
            "[1117/1912] æ­£åœ¨è™•ç†: 2756 è¯ç™¼åœ‹éš›\n",
            "[1118/1912] æ­£åœ¨è™•ç†: 2916 æ»¿å¿ƒ\n",
            "[1119/1912] æ­£åœ¨è™•ç†: 2924 å®å¤ª-KY\n",
            "[1120/1912] æ­£åœ¨è™•ç†: 2926 èª å“ç”Ÿæ´»\n",
            "[1121/1912] æ­£åœ¨è™•ç†: 2937 é›†é›…ç¤¾\n",
            "[1122/1912] æ­£åœ¨è™•ç†: 2941 ç±³æ–¯ç‰¹\n",
            "[1123/1912] æ­£åœ¨è™•ç†: 2947 æŒ¯å®‡äº”é‡‘\n",
            "[1124/1912] æ­£åœ¨è™•ç†: 2948 å¯¶é™\n",
            "[1125/1912] æ­£åœ¨è™•ç†: 2949 æ¬£æ–°ç¶²\n",
            "[1126/1912] æ­£åœ¨è™•ç†: 3064 æ³°å‰\n",
            "[1127/1912] æ­£åœ¨è™•ç†: 3066 ææ´²\n",
            "[1128/1912] æ­£åœ¨è™•ç†: 3067 å…¨åŸŸ\n",
            "[1129/1912] æ­£åœ¨è™•ç†: 3071 å”ç¦§\n",
            "[1130/1912] æ­£åœ¨è™•ç†: 3073 å¤©æ–¹èƒ½æº\n",
            "[1131/1912] æ­£åœ¨è™•ç†: 3078 åƒ‘å¨\n",
            "[1132/1912] æ­£åœ¨è™•ç†: 3081 è¯äº\n",
            "[1133/1912] æ­£åœ¨è™•ç†: 3083 ç¶²é¾\n",
            "[1134/1912] æ­£åœ¨è™•ç†: 3085 æ–°é›¶å”®\n",
            "[1135/1912] æ­£åœ¨è™•ç†: 3086 è¯ç¾©\n",
            "[1136/1912] æ­£åœ¨è™•ç†: 3088 è‰¾è¨Š\n",
            "[1137/1912] æ­£åœ¨è™•ç†: 3093 æ¸¯å»º*\n",
            "[1138/1912] æ­£åœ¨è™•ç†: 3095 åŠæˆ\n",
            "[1139/1912] æ­£åœ¨è™•ç†: 3105 ç©©æ‡‹\n",
            "[1140/1912] æ­£åœ¨è™•ç†: 3114 å¥½å¾·\n",
            "[1141/1912] æ­£åœ¨è™•ç†: 3115 å¯Œæ¦®ç¶±\n",
            "[1142/1912] æ­£åœ¨è™•ç†: 3118 é€²éš\n",
            "[1143/1912] æ­£åœ¨è™•ç†: 3122 ç¬™æ³‰\n",
            "[1144/1912] æ­£åœ¨è™•ç†: 3128 æ˜‡éŠ³\n",
            "[1145/1912] æ­£åœ¨è™•ç†: 3131 å¼˜å¡‘\n",
            "[1146/1912] æ­£åœ¨è™•ç†: 3141 æ™¶å®\n",
            "[1147/1912] æ­£åœ¨è™•ç†: 3147 å¤§ç¶œ\n",
            "[1148/1912] æ­£åœ¨è™•ç†: 3152 ç’Ÿå¾·\n",
            "[1149/1912] æ­£åœ¨è™•ç†: 3162 ç²¾ç¢º\n",
            "[1150/1912] æ­£åœ¨è™•ç†: 3163 æ³¢è‹¥å¨\n",
            "[1151/1912] æ­£åœ¨è™•ç†: 3169 äºä¿¡\n",
            "[1152/1912] æ­£åœ¨è™•ç†: 3171 ç‚æ´²æµé€š\n",
            "[1153/1912] æ­£åœ¨è™•ç†: 3176 åŸºäº\n",
            "[1154/1912] æ­£åœ¨è™•ç†: 3178 å…¬æº–\n",
            "[1155/1912] æ­£åœ¨è™•ç†: 3188 é‘«é¾é¨°\n",
            "[1156/1912] æ­£åœ¨è™•ç†: 3191 é›²å˜‰å—\n",
            "[1157/1912] æ­£åœ¨è™•ç†: 3205 ä½°ç ”\n",
            "[1158/1912] æ­£åœ¨è™•ç†: 3206 å¿—è±\n",
            "[1159/1912] æ­£åœ¨è™•ç†: 3207 è€€å‹\n",
            "[1160/1912] æ­£åœ¨è™•ç†: 3211 é †é”\n",
            "[1161/1912] æ­£åœ¨è™•ç†: 3213 èŒ‚è¨Š\n",
            "[1162/1912] æ­£åœ¨è™•ç†: 3217 å„ªç¾¤\n",
            "[1163/1912] æ­£åœ¨è™•ç†: 3218 å¤§å­¸å…‰\n",
            "[1164/1912] æ­£åœ¨è™•ç†: 3219 å€šå¼·ç§‘\n",
            "[1165/1912] æ­£åœ¨è™•ç†: 3221 å°å˜‰ç¢©\n",
            "[1166/1912] æ­£åœ¨è™•ç†: 3224 ä¸‰é¡§\n",
            "[1167/1912] æ­£åœ¨è™•ç†: 3226 é¾é‹’\n",
            "[1168/1912] æ­£åœ¨è™•ç†: 3227 åŸç›¸\n",
            "[1169/1912] æ­£åœ¨è™•ç†: 3228 é‡‘éº—ç§‘\n",
            "[1170/1912] æ­£åœ¨è™•ç†: 3230 éŒ¦æ˜\n",
            "[1171/1912] æ­£åœ¨è™•ç†: 3232 æ˜±æ·\n",
            "[1172/1912] æ­£åœ¨è™•ç†: 3234 å…‰ç’°\n",
            "[1173/1912] æ­£åœ¨è™•ç†: 3236 åƒå¦‚\n",
            "[1174/1912] æ­£åœ¨è™•ç†: 3252 æµ·ç£\n",
            "[1175/1912] æ­£åœ¨è™•ç†: 3259 é‘«å‰µ\n",
            "[1176/1912] æ­£åœ¨è™•ç†: 3260 å¨å‰›\n",
            "[1177/1912] æ­£åœ¨è™•ç†: 3264 æ¬£éŠ“\n",
            "[1178/1912] æ­£åœ¨è™•ç†: 3265 å°æ˜Ÿç§‘\n",
            "[1179/1912] æ­£åœ¨è™•ç†: 3268 æµ·å¾·å¨\n",
            "[1180/1912] æ­£åœ¨è™•ç†: 3272 æ±ç¢©\n",
            "[1181/1912] æ­£åœ¨è™•ç†: 3276 å®‡ç’°\n",
            "[1182/1912] æ­£åœ¨è™•ç†: 3284 å¤ªæ™®é«˜\n",
            "[1183/1912] æ­£åœ¨è™•ç†: 3285 å¾®ç«¯\n",
            "[1184/1912] æ­£åœ¨è™•ç†: 3287 å»£å¯°ç§‘\n",
            "[1185/1912] æ­£åœ¨è™•ç†: 3288 é»æ™¶\n",
            "[1186/1912] æ­£åœ¨è™•ç†: 3289 å®œç‰¹\n",
            "[1187/1912] æ­£åœ¨è™•ç†: 3290 æ±æµ¦\n",
            "[1188/1912] æ­£åœ¨è™•ç†: 3293 éˆŠè±¡\n",
            "[1189/1912] æ­£åœ¨è™•ç†: 3294 è‹±æ¿Ÿ\n",
            "[1190/1912] æ­£åœ¨è™•ç†: 3297 æ­ç‰¹\n",
            "[1191/1912] æ­£åœ¨è™•ç†: 3303 å²±ç¨œ\n",
            "[1192/1912] æ­£åœ¨è™•ç†: 3306 é¼å¤©\n",
            "[1193/1912] æ­£åœ¨è™•ç†: 3310 ä½³ç©\n",
            "[1194/1912] æ­£åœ¨è™•ç†: 3313 æ–æˆ\n",
            "[1195/1912] æ­£åœ¨è™•ç†: 3317 å°¼å…‹æ£®\n",
            "[1196/1912] æ­£åœ¨è™•ç†: 3322 å»ºèˆœé›»\n",
            "[1197/1912] æ­£åœ¨è™•ç†: 3323 åŠ ç™¾è£•\n",
            "[1198/1912] æ­£åœ¨è™•ç†: 3324 é›™é´»\n",
            "[1199/1912] æ­£åœ¨è™•ç†: 3325 æ—­å“\n",
            "[1200/1912] æ­£åœ¨è™•ç†: 3332 å¹¸åº·\n",
            "[1201/1912] æ­£åœ¨è™•ç†: 3339 æ³°è°·\n",
            "[1202/1912] æ­£åœ¨è™•ç†: 3349 å¯¶å¾·\n",
            "[1203/1912] æ­£åœ¨è™•ç†: 3354 å¾‹å‹\n",
            "[1204/1912] æ­£åœ¨è™•ç†: 3357 è‡ºæ…¶ç§‘\n",
            "[1205/1912] æ­£åœ¨è™•ç†: 3360 å°šç«‹\n",
            "[1206/1912] æ­£åœ¨è™•ç†: 3362 å…ˆé€²å…‰\n",
            "[1207/1912] æ­£åœ¨è™•ç†: 3363 ä¸Šè©®\n",
            "[1208/1912] æ­£åœ¨è™•ç†: 3372 å…¸ç¯„\n",
            "[1209/1912] æ­£åœ¨è™•ç†: 3373 ç†±æ˜ \n",
            "[1210/1912] æ­£åœ¨è™•ç†: 3374 ç²¾æ\n",
            "[1211/1912] æ­£åœ¨è™•ç†: 3379 å½¬å°\n",
            "[1212/1912] æ­£åœ¨è™•ç†: 3388 å´‡è¶Šé›»\n",
            "[1213/1912] æ­£åœ¨è™•ç†: 3390 æ—­è»Ÿ\n",
            "[1214/1912] æ­£åœ¨è™•ç†: 3402 æ¼¢ç§‘\n",
            "[1215/1912] æ­£åœ¨è™•ç†: 3426 å°èˆˆ\n",
            "[1216/1912] æ­£åœ¨è™•ç†: 3430 å¥‡éˆ¦ç§‘\n",
            "[1217/1912] æ­£åœ¨è™•ç†: 3434 å“²å›º\n",
            "[1218/1912] æ­£åœ¨è™•ç†: 3438 é¡æ¯”ç§‘\n",
            "[1219/1912] æ­£åœ¨è™•ç†: 3441 è¯ä¸€å…‰\n",
            "[1220/1912] æ­£åœ¨è™•ç†: 3444 åˆ©æ©Ÿ\n",
            "[1221/1912] æ­£åœ¨è™•ç†: 3455 ç”±ç”°\n",
            "[1222/1912] æ­£åœ¨è™•ç†: 3465 é€²æ³°é›»å­\n",
            "[1223/1912] æ­£åœ¨è™•ç†: 3466 å¾·æ™‰\n",
            "[1224/1912] æ­£åœ¨è™•ç†: 3467 å°ç£ç²¾æ\n",
            "[1225/1912] æ­£åœ¨è™•ç†: 3479 å®‰å‹¤\n",
            "[1226/1912] æ­£åœ¨è™•ç†: 3483 åŠ›è‡´\n",
            "[1227/1912] æ­£åœ¨è™•ç†: 3484 å´§é¨°\n",
            "[1228/1912] æ­£åœ¨è™•ç†: 3489 æ£®å¯¶\n",
            "[1229/1912] æ­£åœ¨è™•ç†: 3490 å–®äº•\n",
            "[1230/1912] æ­£åœ¨è™•ç†: 3491 æ˜‡é”ç§‘\n",
            "[1231/1912] æ­£åœ¨è™•ç†: 3492 é•·ç››\n",
            "[1232/1912] æ­£åœ¨è™•ç†: 3498 é™½ç¨‹\n",
            "[1233/1912] æ­£åœ¨è™•ç†: 3499 ç’°å¤©ç§‘\n",
            "[1234/1912] æ­£åœ¨è™•ç†: 3508 ä½é€Ÿ\n",
            "[1235/1912] æ­£åœ¨è™•ç†: 3511 çŸ½ç‘ª\n",
            "[1236/1912] æ­£åœ¨è™•ç†: 3512 çš‡é¾\n",
            "[1237/1912] æ­£åœ¨è™•ç†: 3516 äºå¸æ­\n",
            "[1238/1912] æ­£åœ¨è™•ç†: 3520 è¯ç›ˆ\n",
            "[1239/1912] æ­£åœ¨è™•ç†: 3521 é´»ç¿Š\n",
            "[1240/1912] æ­£åœ¨è™•ç†: 3522 å¾¡åµ¿\n",
            "[1241/1912] æ­£åœ¨è™•ç†: 3523 è¿è¼\n",
            "[1242/1912] æ­£åœ¨è™•ç†: 3526 å‡¡ç”²\n",
            "[1243/1912] æ­£åœ¨è™•ç†: 3527 èšç©\n",
            "[1244/1912] æ­£åœ¨è™•ç†: 3529 åŠ›æ—º\n",
            "[1245/1912] æ­£åœ¨è™•ç†: 3531 å…ˆç›Š\n",
            "[1246/1912] æ­£åœ¨è™•ç†: 3537 å ¡é”\n",
            "[1247/1912] æ­£åœ¨è™•ç†: 3540 æ›œè¶Š\n",
            "[1248/1912] æ­£åœ¨è™•ç†: 3541 è¥¿æŸ\n",
            "[1249/1912] æ­£åœ¨è™•ç†: 3546 å®‡å³»\n",
            "[1250/1912] æ­£åœ¨è™•ç†: 3548 å…†åˆ©\n",
            "[1251/1912] æ­£åœ¨è™•ç†: 3551 ä¸–ç¦¾\n",
            "[1252/1912] æ­£åœ¨è™•ç†: 3552 åŒè‡´\n",
            "[1253/1912] æ­£åœ¨è™•ç†: 3555 åšå£«æ—º\n",
            "[1254/1912] æ­£åœ¨è™•ç†: 3556 ç¦¾ç‘äº\n",
            "[1255/1912] æ­£åœ¨è™•ç†: 3558 ç¥æº–\n",
            "[1256/1912] æ­£åœ¨è™•ç†: 3564 å…¶é™½\n",
            "[1257/1912] æ­£åœ¨è™•ç†: 3567 é€¸æ˜Œ\n",
            "[1258/1912] æ­£åœ¨è™•ç†: 3570 å¤§å¡š\n",
            "[1259/1912] æ­£åœ¨è™•ç†: 3577 æ³“æ ¼\n",
            "[1260/1912] æ­£åœ¨è™•ç†: 3580 å‹å¨ç§‘\n",
            "[1261/1912] æ­£åœ¨è™•ç†: 3581 åšç£Š\n",
            "[1262/1912] æ­£åœ¨è™•ç†: 3587 é–åº·\n",
            "[1263/1912] æ­£åœ¨è™•ç†: 3594 ç£å„€\n",
            "[1264/1912] æ­£åœ¨è™•ç†: 3597 æ˜ èˆˆ\n",
            "[1265/1912] æ­£åœ¨è™•ç†: 3609 ä¸‰ä¸€æ±æ—\n",
            "[1266/1912] æ­£åœ¨è™•ç†: 3611 é¼ç¿°\n",
            "[1267/1912] æ­£åœ¨è™•ç†: 3615 å®‰å¯\n",
            "[1268/1912] æ­£åœ¨è™•ç†: 3623 å¯Œæ™¶é€š\n",
            "[1269/1912] æ­£åœ¨è™•ç†: 3624 å…‰é ¡\n",
            "[1270/1912] æ­£åœ¨è™•ç†: 3625 è¥¿å‹\n",
            "[1271/1912] æ­£åœ¨è™•ç†: 3628 ç›ˆæ­£\n",
            "[1272/1912] æ­£åœ¨è™•ç†: 3629 åœ°å¿ƒå¼•åŠ›\n",
            "[1273/1912] æ­£åœ¨è™•ç†: 3630 æ–°é‰…ç§‘\n",
            "[1274/1912] æ­£åœ¨è™•ç†: 3631 æ™Ÿæ¥ \n",
            "[1275/1912] æ­£åœ¨è™•ç†: 3632 ç ”å‹¤\n",
            "[1276/1912] æ­£åœ¨è™•ç†: 3646 è‰¾æ©ç‰¹\n",
            "[1277/1912] æ­£åœ¨è™•ç†: 3663 é‘«ç§‘\n",
            "[1278/1912] æ­£åœ¨è™•ç†: 3664 å®‰ç‘-KY\n",
            "[1279/1912] æ­£åœ¨è™•ç†: 3666 å…‰è€€\n",
            "[1280/1912] æ­£åœ¨è™•ç†: 3672 åº·è¯è¨Š\n",
            "[1281/1912] æ­£åœ¨è™•ç†: 3675 å¾·å¾®\n",
            "[1282/1912] æ­£åœ¨è™•ç†: 3680 å®¶ç™»\n",
            "[1283/1912] æ­£åœ¨è™•ç†: 3684 æ¦®æ˜Œ\n",
            "[1284/1912] æ­£åœ¨è™•ç†: 3685 å…ƒå‰µç²¾å¯†\n",
            "[1285/1912] æ­£åœ¨è™•ç†: 3687 æ­è²·å°¬\n",
            "[1286/1912] æ­£åœ¨è™•ç†: 3689 æ¹§å¾·\n",
            "[1287/1912] æ­£åœ¨è™•ç†: 3691 ç¢©ç¦¾\n",
            "[1288/1912] æ­£åœ¨è™•ç†: 3693 ç‡Ÿé‚¦\n",
            "[1289/1912] æ­£åœ¨è™•ç†: 3707 æ¼¢ç£Š\n",
            "[1290/1912] æ­£åœ¨è™•ç†: 3709 é‘«è¯å¤§æŠ•æ§\n",
            "[1291/1912] æ­£åœ¨è™•ç†: 3710 é€£å±•æŠ•æ§\n",
            "[1292/1912] æ­£åœ¨è™•ç†: 3713 æ–°æ™¶æŠ•æ§\n",
            "[1293/1912] æ­£åœ¨è™•ç†: 4102 æ°¸æ—¥\n",
            "[1294/1912] æ­£åœ¨è™•ç†: 4105 æ±æ´‹\n",
            "[1295/1912] æ­£åœ¨è™•ç†: 4107 é‚¦ç‰¹\n",
            "[1296/1912] æ­£åœ¨è™•ç†: 4109 åŠ æ·ç”Ÿé†«\n",
            "[1297/1912] æ­£åœ¨è™•ç†: 4111 æ¿Ÿç”Ÿ\n",
            "[1298/1912] æ­£åœ¨è™•ç†: 4113 è¯ä¸Š\n",
            "[1299/1912] æ­£åœ¨è™•ç†: 4114 å¥å–¬\n",
            "[1300/1912] æ­£åœ¨è™•ç†: 4116 æ˜åŸºé†«\n",
            "[1301/1912] æ­£åœ¨è™•ç†: 4120 å‹è¯\n",
            "[1302/1912] æ­£åœ¨è™•ç†: 4121 å„ªç››\n",
            "[1303/1912] æ­£åœ¨è™•ç†: 4123 æ™Ÿå¾·\n",
            "[1304/1912] æ­£åœ¨è™•ç†: 4126 å¤ªé†«\n",
            "[1305/1912] æ­£åœ¨è™•ç†: 4127 å¤©è‰¯\n",
            "[1306/1912] æ­£åœ¨è™•ç†: 4128 ä¸­å¤©\n",
            "[1307/1912] æ­£åœ¨è™•ç†: 4129 è¯åˆ\n",
            "[1308/1912] æ­£åœ¨è™•ç†: 4130 å¥äº\n",
            "[1309/1912] æ­£åœ¨è™•ç†: 4131 æµ©æ³°\n",
            "[1310/1912] æ­£åœ¨è™•ç†: 4138 æ›œäº\n",
            "[1311/1912] æ­£åœ¨è™•ç†: 4139 é¦¬å…‰-KY\n",
            "[1312/1912] æ­£åœ¨è™•ç†: 4147 ä¸­è£•\n",
            "[1313/1912] æ­£åœ¨è™•ç†: 4153 éˆºç·¯\n",
            "[1314/1912] æ­£åœ¨è™•ç†: 4154 æ¨‚å¨ç§‘-KY\n",
            "[1315/1912] æ­£åœ¨è™•ç†: 4157 å¤ªæ™¯*-KY\n",
            "[1316/1912] æ­£åœ¨è™•ç†: 4160 è¨Šè¯åŸºå› \n",
            "[1317/1912] æ­£åœ¨è™•ç†: 4161 è¿æ–°ç§‘\n",
            "[1318/1912] æ­£åœ¨è™•ç†: 4162 æ™ºæ“\n",
            "[1319/1912] æ­£åœ¨è™•ç†: 4163 é¿éˆ¦\n",
            "[1320/1912] æ­£åœ¨è™•ç†: 4167 æ¾ç‘è—¥\n",
            "[1321/1912] æ­£åœ¨è™•ç†: 4168 é†£è¯\n",
            "[1322/1912] æ­£åœ¨è™•ç†: 4171 ç‘åŸº\n",
            "[1323/1912] æ­£åœ¨è™•ç†: 4173 ä¹…è£•\n",
            "[1324/1912] æ­£åœ¨è™•ç†: 4174 æµ©é¼\n",
            "[1325/1912] æ­£åœ¨è™•ç†: 4175 æä¸€\n",
            "[1326/1912] æ­£åœ¨è™•ç†: 4183 ç¦æ°¸ç”ŸæŠ€\n",
            "[1327/1912] æ­£åœ¨è™•ç†: 4188 å®‰å…‹\n",
            "[1328/1912] æ­£åœ¨è™•ç†: 4192 æåœ‹\n",
            "[1329/1912] æ­£åœ¨è™•ç†: 4198 æ¬£å¤§å¥åº·\n",
            "[1330/1912] æ­£åœ¨è™•ç†: 4205 ä¸­è¯é£Ÿ\n",
            "[1331/1912] æ­£åœ¨è™•ç†: 4207 ç’°æ³°\n",
            "[1332/1912] æ­£åœ¨è™•ç†: 4303 ä¿¡ç«‹\n",
            "[1333/1912] æ­£åœ¨è™•ç†: 4304 å‹æ˜±\n",
            "[1334/1912] æ­£åœ¨è™•ç†: 4305 ä¸–å¤\n",
            "[1335/1912] æ­£åœ¨è™•ç†: 4401 æ±éš†èˆˆ\n",
            "[1336/1912] æ­£åœ¨è™•ç†: 4402 éƒ¡éƒ½é–‹ç™¼\n",
            "[1337/1912] æ­£åœ¨è™•ç†: 4406 æ–°æ˜•çº–\n",
            "[1338/1912] æ­£åœ¨è™•ç†: 4413 é£›å¯¶ä¼æ¥­\n",
            "[1339/1912] æ­£åœ¨è™•ç†: 4416 ä¸‰åœ“\n",
            "[1340/1912] æ­£åœ¨è™•ç†: 4417 é‡‘æ´²\n",
            "[1341/1912] æ­£åœ¨è™•ç†: 4419 çš‡å®¶ç¾é£Ÿ\n",
            "[1342/1912] æ­£åœ¨è™•ç†: 4420 å…‰æ˜\n",
            "[1343/1912] æ­£åœ¨è™•ç†: 4430 è€€å„„\n",
            "[1344/1912] æ­£åœ¨è™•ç†: 4432 éŠ˜æ—ºå¯¦\n",
            "[1345/1912] æ­£åœ¨è™•ç†: 4433 èˆˆé‡‡\n",
            "[1346/1912] æ­£åœ¨è™•ç†: 4442 ç«£é‚¦-KY\n",
            "[1347/1912] æ­£åœ¨è™•ç†: 4502 å¥ä¿¡\n",
            "[1348/1912] æ­£åœ¨è™•ç†: 4503 é‡‘é›¨\n",
            "[1349/1912] æ­£åœ¨è™•ç†: 4506 å´‡å‹\n",
            "[1350/1912] æ­£åœ¨è™•ç†: 4510 é«˜é‹’\n",
            "[1351/1912] æ­£åœ¨è™•ç†: 4513 ç¦è£•\n",
            "[1352/1912] æ­£åœ¨è™•ç†: 4523 æ°¸å½°\n",
            "[1353/1912] æ­£åœ¨è™•ç†: 4527 æ–¹åœŸéœ–\n",
            "[1354/1912] æ­£åœ¨è™•ç†: 4528 æ±Ÿèˆˆé›\n",
            "[1355/1912] æ­£åœ¨è™•ç†: 4529 æ·³ç´³\n",
            "[1356/1912] æ­£åœ¨è™•ç†: 4530 å®æ˜“\n",
            "[1357/1912] æ­£åœ¨è™•ç†: 4533 å”æ˜“æ©Ÿ\n",
            "[1358/1912] æ­£åœ¨è™•ç†: 4534 æ…¶é¨°\n",
            "[1359/1912] æ­£åœ¨è™•ç†: 4535 è‡³èˆˆ\n",
            "[1360/1912] æ­£åœ¨è™•ç†: 4538 å¤§è© åŸ\n",
            "[1361/1912] æ­£åœ¨è™•ç†: 4541 æ™Ÿç”°\n",
            "[1362/1912] æ­£åœ¨è™•ç†: 4542 ç§‘å¶ \n",
            "[1363/1912] æ­£åœ¨è™•ç†: 4543 è¬åœ¨\n",
            "[1364/1912] æ­£åœ¨è™•ç†: 4549 æ¡“é”\n",
            "[1365/1912] æ­£åœ¨è™•ç†: 4550 é•·ä½³\n",
            "[1366/1912] æ­£åœ¨è™•ç†: 4554 æ©™çš„\n",
            "[1367/1912] æ­£åœ¨è™•ç†: 4556 æ—­ç„¶\n",
            "[1368/1912] æ­£åœ¨è™•ç†: 4558 å¯¶ç·¯\n",
            "[1369/1912] æ­£åœ¨è™•ç†: 4561 å¥æ¤¿\n",
            "[1370/1912] æ­£åœ¨è™•ç†: 4563 ç™¾å¾·\n",
            "[1371/1912] æ­£åœ¨è™•ç†: 4568 ç§‘éš›ç²¾å¯†\n",
            "[1372/1912] æ­£åœ¨è™•ç†: 4577 é”èˆªç§‘æŠ€\n",
            "[1373/1912] æ­£åœ¨è™•ç†: 4580 æ·æµé–¥æ¥­\n",
            "[1374/1912] æ­£åœ¨è™•ç†: 4584 å›å¸†\n",
            "[1375/1912] æ­£åœ¨è™•ç†: 4609 å”é‹’\n",
            "[1376/1912] æ­£åœ¨è™•ç†: 4702 ä¸­ç¾å¯¦\n",
            "[1377/1912] æ­£åœ¨è™•ç†: 4706 å¤§æ­\n",
            "[1378/1912] æ­£åœ¨è™•ç†: 4707 ç£äº\n",
            "[1379/1912] æ­£åœ¨è™•ç†: 4711 æ°¸ç´”\n",
            "[1380/1912] æ­£åœ¨è™•ç†: 4714 æ°¸æ·\n",
            "[1381/1912] æ­£åœ¨è™•ç†: 4716 å¤§ç«‹\n",
            "[1382/1912] æ­£åœ¨è™•ç†: 4721 ç¾çªç‘ª\n",
            "[1383/1912] æ­£åœ¨è™•ç†: 4726 æ°¸æ˜•\n",
            "[1384/1912] æ­£åœ¨è™•ç†: 4728 é›™ç¾\n",
            "[1385/1912] æ­£åœ¨è™•ç†: 4729 ç†’èŒ‚\n",
            "[1386/1912] æ­£åœ¨è™•ç†: 4735 è±ªå±•\n",
            "[1387/1912] æ­£åœ¨è™•ç†: 4741 æ³“ç€š\n",
            "[1388/1912] æ­£åœ¨è™•ç†: 4743 åˆä¸€\n",
            "[1389/1912] æ­£åœ¨è™•ç†: 4744 çš‡å°‡\n",
            "[1390/1912] æ­£åœ¨è™•ç†: 4745 åˆå¯Œ-KY\n",
            "[1391/1912] æ­£åœ¨è™•ç†: 4747 å¼·ç”Ÿ\n",
            "[1392/1912] æ­£åœ¨è™•ç†: 4749 æ–°æ‡‰æ\n",
            "[1393/1912] æ­£åœ¨è™•ç†: 4754 åœ‹ç¢³ç§‘\n",
            "[1394/1912] æ­£åœ¨è™•ç†: 4760 å‹¤å‡±\n",
            "[1395/1912] æ­£åœ¨è™•ç†: 4767 èª æ³°ç§‘æŠ€\n",
            "[1396/1912] æ­£åœ¨è™•ç†: 4768 æ™¶å‘ˆç§‘æŠ€\n",
            "[1397/1912] æ­£åœ¨è™•ç†: 4772 å°ç‰¹åŒ–\n",
            "[1398/1912] æ­£åœ¨è™•ç†: 4804 å¤§ç•¥-KY\n",
            "[1399/1912] æ­£åœ¨è™•ç†: 4806 æ¡‚ç”°æ–‡å‰µ\n",
            "[1400/1912] æ­£åœ¨è™•ç†: 4903 è¯å…‰é€š\n",
            "[1401/1912] æ­£åœ¨è™•ç†: 4905 å°è¯é›»\n",
            "[1402/1912] æ­£åœ¨è™•ç†: 4907 å¯Œå®‡\n",
            "[1403/1912] æ­£åœ¨è™•ç†: 4908 å‰é¼\n",
            "[1404/1912] æ­£åœ¨è™•ç†: 4909 æ–°å¾©èˆˆ\n",
            "[1405/1912] æ­£åœ¨è™•ç†: 4911 å¾·è‹±\n",
            "[1406/1912] æ­£åœ¨è™•ç†: 4923 åŠ›å£«\n",
            "[1407/1912] æ­£åœ¨è™•ç†: 4924 æ¬£åš-KY\n",
            "[1408/1912] æ­£åœ¨è™•ç†: 4931 æ–°ç››åŠ›\n",
            "[1409/1912] æ­£åœ¨è™•ç†: 4933 å‹è¼\n",
            "[1410/1912] æ­£åœ¨è™•ç†: 4939 äºé›»\n",
            "[1411/1912] æ­£åœ¨è™•ç†: 4945 é™é”ç§‘æŠ€\n",
            "[1412/1912] æ­£åœ¨è™•ç†: 4946 è¾£æ¤’\n",
            "[1413/1912] æ­£åœ¨è™•ç†: 4950 é‡‘è€˜åœ‹éš›\n",
            "[1414/1912] æ­£åœ¨è™•ç†: 4951 ç²¾æ‹“ç§‘\n",
            "[1415/1912] æ­£åœ¨è™•ç†: 4953 ç·¯è»Ÿ\n",
            "[1416/1912] æ­£åœ¨è™•ç†: 4966 è­œç‘-KY\n",
            "[1417/1912] æ­£åœ¨è™•ç†: 4971 IET-KY\n",
            "[1418/1912] æ­£åœ¨è™•ç†: 4972 æ¹¯çŸ³ç…§æ˜\n",
            "[1419/1912] æ­£åœ¨è™•ç†: 4973 å»£ç©\n",
            "[1420/1912] æ­£åœ¨è™•ç†: 4974 äºæ³°\n",
            "[1421/1912] æ­£åœ¨è™•ç†: 4979 è¯æ˜Ÿå…‰\n",
            "[1422/1912] æ­£åœ¨è™•ç†: 4987 ç§‘èª \n",
            "[1423/1912] æ­£åœ¨è™•ç†: 4991 ç’°å®‡-KY\n",
            "[1424/1912] æ­£åœ¨è™•ç†: 4995 æ™¶é”\n",
            "[1425/1912] æ­£åœ¨è™•ç†: 5009 æ¦®å‰›\n",
            "[1426/1912] æ­£åœ¨è™•ç†: 5011 ä¹…é™½\n",
            "[1427/1912] æ­£åœ¨è™•ç†: 5013 å¼·æ–°\n",
            "[1428/1912] æ­£åœ¨è™•ç†: 5014 å»ºéŒ©\n",
            "[1429/1912] æ­£åœ¨è™•ç†: 5015 è¯ç¥º\n",
            "[1430/1912] æ­£åœ¨è™•ç†: 5016 æ¾å’Œ\n",
            "[1431/1912] æ­£åœ¨è™•ç†: 5201 å‡±è¡›\n",
            "[1432/1912] æ­£åœ¨è™•ç†: 5202 åŠ›æ–°\n",
            "[1433/1912] æ­£åœ¨è™•ç†: 5205 ä¸­èŒ‚\n",
            "[1434/1912] æ­£åœ¨è™•ç†: 5206 å¤æ‚…\n",
            "[1435/1912] æ­£åœ¨è™•ç†: 5209 æ–°é¼\n",
            "[1436/1912] æ­£åœ¨è™•ç†: 5210 å¯¶ç¢©\n",
            "[1437/1912] æ­£åœ¨è™•ç†: 5211 è’™æ¬\n",
            "[1438/1912] æ­£åœ¨è™•ç†: 5212 å‡Œç¶²\n",
            "[1439/1912] æ­£åœ¨è™•ç†: 5213 äºæ˜•\n",
            "[1440/1912] æ­£åœ¨è™•ç†: 5220 è¬é”å…‰é›»\n",
            "[1441/1912] æ­£åœ¨è™•ç†: 5223 å®‰åŠ›-KY\n",
            "[1442/1912] æ­£åœ¨è™•ç†: 5227 ç«‹å‡±-KY\n",
            "[1443/1912] æ­£åœ¨è™•ç†: 5228 éˆºé§\n",
            "[1444/1912] æ­£åœ¨è™•ç†: 5230 é›·ç¬›å…‹å…‰å­¸\n",
            "[1445/1912] æ­£åœ¨è™•ç†: 5236 å‡Œé™½å‰µæ–°\n",
            "[1446/1912] æ­£åœ¨è™•ç†: 5245 æ™ºæ™¶\n",
            "[1447/1912] æ­£åœ¨è™•ç†: 5251 å¤©é‰é›»\n",
            "[1448/1912] æ­£åœ¨è™•ç†: 5263 æ™ºå´´\n",
            "[1449/1912] æ­£åœ¨è™•ç†: 5272 ç¬™ç§‘\n",
            "[1450/1912] æ­£åœ¨è™•ç†: 5274 ä¿¡é©Š\n",
            "[1451/1912] æ­£åœ¨è™•ç†: 5276 é”è¼-KY\n",
            "[1452/1912] æ­£åœ¨è™•ç†: 5278 å°šå‡¡*\n",
            "[1453/1912] æ­£åœ¨è™•ç†: 5287 æ•¸å­—\n",
            "[1454/1912] æ­£åœ¨è™•ç†: 5289 å®œé¼\n",
            "[1455/1912] æ­£åœ¨è™•ç†: 5291 é‚‘æ˜‡\n",
            "[1456/1912] æ­£åœ¨è™•ç†: 5299 æ°åŠ›\n",
            "[1457/1912] æ­£åœ¨è™•ç†: 5301 å¯¶å¾—åˆ©\n",
            "[1458/1912] æ­£åœ¨è™•ç†: 5302 å¤ªæ¬£\n",
            "[1459/1912] æ­£åœ¨è™•ç†: 5309 ç³»çµ±é›»\n",
            "[1460/1912] æ­£åœ¨è™•ç†: 5310 å¤©å‰›\n",
            "[1461/1912] æ­£åœ¨è™•ç†: 5312 å¯¶å³¶ç§‘\n",
            "[1462/1912] æ­£åœ¨è™•ç†: 5314 ä¸–ç´€*\n",
            "[1463/1912] æ­£åœ¨è™•ç†: 5315 å…‰è¯\n",
            "[1464/1912] æ­£åœ¨è™•ç†: 5321 ç¾è€Œå¿«\n",
            "[1465/1912] æ­£åœ¨è™•ç†: 5324 å£«é–‹\n",
            "[1466/1912] æ­£åœ¨è™•ç†: 5328 è¯å®¹\n",
            "[1467/1912] æ­£åœ¨è™•ç†: 5340 å»ºæ¦®\n",
            "[1468/1912] æ­£åœ¨è™•ç†: 5344 ç«‹è¡›\n",
            "[1469/1912] æ­£åœ¨è™•ç†: 5345 å¤©æš\n",
            "[1470/1912] æ­£åœ¨è™•ç†: 5347 ä¸–ç•Œ\n",
            "[1471/1912] æ­£åœ¨è™•ç†: 5348 æ­£èƒ½é‡æ™ºèƒ½\n",
            "[1472/1912] æ­£åœ¨è™•ç†: 5351 éˆºå‰µ\n",
            "[1473/1912] æ­£åœ¨è™•ç†: 5353 å°æ—\n",
            "[1474/1912] æ­£åœ¨è™•ç†: 5355 ä½³ç¸½\n",
            "[1475/1912] æ­£åœ¨è™•ç†: 5356 å”ç›Š\n",
            "[1476/1912] æ­£åœ¨è™•ç†: 5364 åŠ›éº—åº—\n",
            "[1477/1912] æ­£åœ¨è™•ç†: 5371 ä¸­å…‰é›»\n",
            "[1478/1912] æ­£åœ¨è™•ç†: 5381 åˆæ­£\n",
            "[1479/1912] æ­£åœ¨è™•ç†: 5386 é’é›²\n",
            "[1480/1912] æ­£åœ¨è™•ç†: 5392 èƒ½ç‡\n",
            "[1481/1912] æ­£åœ¨è™•ç†: 5398 æ…•åº·ç”Ÿé†«\n",
            "[1482/1912] æ­£åœ¨è™•ç†: 5403 ä¸­è²\n",
            "[1483/1912] æ­£åœ¨è™•ç†: 5410 åœ‹çœ¾\n",
            "[1484/1912] æ­£åœ¨è™•ç†: 5425 å°åŠ\n",
            "[1485/1912] æ­£åœ¨è™•ç†: 5426 æŒ¯ç™¼\n",
            "[1486/1912] æ­£åœ¨è™•ç†: 5432 æ–°é–€\n",
            "[1487/1912] æ­£åœ¨è™•ç†: 5438 æ±å‹\n",
            "[1488/1912] æ­£åœ¨è™•ç†: 5439 é«˜æŠ€\n",
            "[1489/1912] æ­£åœ¨è™•ç†: 5443 å‡è±ª\n",
            "[1490/1912] æ­£åœ¨è™•ç†: 5450 å—è‰¯\n",
            "[1491/1912] æ­£åœ¨è™•ç†: 5452 ä½¶å„ª\n",
            "[1492/1912] æ­£åœ¨è™•ç†: 5455 æ˜‡ç›Š\n",
            "[1493/1912] æ­£åœ¨è™•ç†: 5457 å®£å¾·\n",
            "[1494/1912] æ­£åœ¨è™•ç†: 5460 åŒå”\n",
            "[1495/1912] æ­£åœ¨è™•ç†: 5464 éœ–å®\n",
            "[1496/1912] æ­£åœ¨è™•ç†: 5465 å¯Œé©Š\n",
            "[1497/1912] æ­£åœ¨è™•ç†: 5468 å‡±éˆº\n",
            "[1498/1912] æ­£åœ¨è™•ç†: 5474 è°æ³°\n",
            "[1499/1912] æ­£åœ¨è™•ç†: 5475 å¾·å®\n",
            "[1500/1912] æ­£åœ¨è™•ç†: 5478 æ™ºå† \n",
            "[1501/1912] æ­£åœ¨è™•ç†: 5481 æ–°è¯\n",
            "[1502/1912] æ­£åœ¨è™•ç†: 5483 ä¸­ç¾æ™¶\n",
            "[1503/1912] æ­£åœ¨è™•ç†: 5487 é€šæ³°\n",
            "[1504/1912] æ­£åœ¨è™•ç†: 5488 æ¾æ™®\n",
            "[1505/1912] æ­£åœ¨è™•ç†: 5489 å½©å¯Œ\n",
            "[1506/1912] æ­£åœ¨è™•ç†: 5490 åŒäº¨\n",
            "[1507/1912] æ­£åœ¨è™•ç†: 5493 ä¸‰è¯\n",
            "[1508/1912] æ­£åœ¨è™•ç†: 5498 å‡±å´´\n",
            "[1509/1912] æ­£åœ¨è™•ç†: 5508 æ°¸ä¿¡å»º\n",
            "[1510/1912] æ­£åœ¨è™•ç†: 5511 å¾·æ˜Œ\n",
            "[1511/1912] æ­£åœ¨è™•ç†: 5512 åŠ›éº’\n",
            "[1512/1912] æ­£åœ¨è™•ç†: 5514 ä¸‰è±\n",
            "[1513/1912] æ­£åœ¨è™•ç†: 5516 é›™å–œ\n",
            "[1514/1912] æ­£åœ¨è™•ç†: 5520 åŠ›æ³°\n",
            "[1515/1912] æ­£åœ¨è™•ç†: 5523 è±è¬™\n",
            "[1516/1912] æ­£åœ¨è™•ç†: 5529 é‰…é™\n",
            "[1517/1912] æ­£åœ¨è™•ç†: 5530 é¾å·–\n",
            "[1518/1912] æ­£åœ¨è™•ç†: 5536 è–æš‰*\n",
            "[1519/1912] æ­£åœ¨è™•ç†: 5543 æ¡“é¼-KY\n",
            "[1520/1912] æ­£åœ¨è™•ç†: 5548 å®‰å€‰\n",
            "[1521/1912] æ­£åœ¨è™•ç†: 5601 å°è¯æ«ƒ\n",
            "[1522/1912] æ­£åœ¨è™•ç†: 5603 é™¸æµ·\n",
            "[1523/1912] æ­£åœ¨è™•ç†: 5604 ä¸­é€£\n",
            "[1524/1912] æ­£åœ¨è™•ç†: 5609 ä¸­è²è¡Œ\n",
            "[1525/1912] æ­£åœ¨è™•ç†: 5701 åŠæ¹–å±±\n",
            "[1526/1912] æ­£åœ¨è™•ç†: 5703 äºéƒ½\n",
            "[1527/1912] æ­£åœ¨è™•ç†: 5704 è€çˆºçŸ¥\n",
            "[1528/1912] æ­£åœ¨è™•ç†: 5864 è‡´å’Œè­‰\n",
            "[1529/1912] æ­£åœ¨è™•ç†: 5878 å°å\n",
            "[1530/1912] æ­£åœ¨è™•ç†: 5902 å¾·è¨˜\n",
            "[1531/1912] æ­£åœ¨è™•ç†: 5903 å…¨å®¶\n",
            "[1532/1912] æ­£åœ¨è™•ç†: 5904 å¯¶é›…\n",
            "[1533/1912] æ­£åœ¨è™•ç†: 5905 å—ä»æ¹–\n",
            "[1534/1912] æ­£åœ¨è™•ç†: 6015 å®é è­‰\n",
            "[1535/1912] æ­£åœ¨è™•ç†: 6016 åº·å’Œè­‰\n",
            "[1536/1912] æ­£åœ¨è™•ç†: 6020 å¤§å±•è­‰\n",
            "[1537/1912] æ­£åœ¨è™•ç†: 6021 ç¾å¥½è­‰\n",
            "[1538/1912] æ­£åœ¨è™•ç†: 6023 å…ƒå¤§æœŸ\n",
            "[1539/1912] æ­£åœ¨è™•ç†: 6026 ç¦é‚¦è­‰\n",
            "[1540/1912] æ­£åœ¨è™•ç†: 6101 å¯¬é­šåœ‹éš›\n",
            "[1541/1912] æ­£åœ¨è™•ç†: 6103 åˆé‚¦\n",
            "[1542/1912] æ­£åœ¨è™•ç†: 6104 å‰µæƒŸ\n",
            "[1543/1912] æ­£åœ¨è™•ç†: 6109 äºå…ƒ\n",
            "[1544/1912] æ­£åœ¨è™•ç†: 6111 å¤§å®‡è³‡\n",
            "[1545/1912] æ­£åœ¨è™•ç†: 6113 äºçŸ½\n",
            "[1546/1912] æ­£åœ¨è™•ç†: 6114 ä¹…å¨\n",
            "[1547/1912] æ­£åœ¨è™•ç†: 6118 å»ºé”\n",
            "[1548/1912] æ­£åœ¨è™•ç†: 6121 æ–°æ™®\n",
            "[1549/1912] æ­£åœ¨è™•ç†: 6122 æ“é‚¦\n",
            "[1550/1912] æ­£åœ¨è™•ç†: 6123 ä¸Šå¥‡\n",
            "[1551/1912] æ­£åœ¨è™•ç†: 6124 æ¥­å¼·\n",
            "[1552/1912] æ­£åœ¨è™•ç†: 6125 å»£é‹\n",
            "[1553/1912] æ­£åœ¨è™•ç†: 6126 ä¿¡éŸ³\n",
            "[1554/1912] æ­£åœ¨è™•ç†: 6127 ä¹è±ª\n",
            "[1555/1912] æ­£åœ¨è™•ç†: 6129 æ™®èª \n",
            "[1556/1912] æ­£åœ¨è™•ç†: 6130 ä¸Šäºç§‘æŠ€\n",
            "[1557/1912] æ­£åœ¨è™•ç†: 6134 è¬æ—­\n",
            "[1558/1912] æ­£åœ¨è™•ç†: 6138 èŒ‚é”\n",
            "[1559/1912] æ­£åœ¨è™•ç†: 6140 è¨Šé”\n",
            "[1560/1912] æ­£åœ¨è™•ç†: 6143 æŒ¯æ›œ\n",
            "[1561/1912] æ­£åœ¨è™•ç†: 6144 å¾—åˆ©å½±\n",
            "[1562/1912] æ­£åœ¨è™•ç†: 6146 è€•èˆˆ\n",
            "[1563/1912] æ­£åœ¨è™•ç†: 6147 é é‚¦\n",
            "[1564/1912] æ­£åœ¨è™•ç†: 6148 é©Šå®è³‡\n",
            "[1565/1912] æ­£åœ¨è™•ç†: 6150 æ’¼è¨Š\n",
            "[1566/1912] æ­£åœ¨è™•ç†: 6151 æ™‰å€«\n",
            "[1567/1912] æ­£åœ¨è™•ç†: 6154 é †ç™¼\n",
            "[1568/1912] æ­£åœ¨è™•ç†: 6156 æ¾ä¸Š\n",
            "[1569/1912] æ­£åœ¨è™•ç†: 6158 ç¦¾æ˜Œ\n",
            "[1570/1912] æ­£åœ¨è™•ç†: 6160 æ¬£æŠ€\n",
            "[1571/1912] æ­£åœ¨è™•ç†: 6161 æ·æ³¢\n",
            "[1572/1912] æ­£åœ¨è™•ç†: 6163 è¯é›»ç¶²\n",
            "[1573/1912] æ­£åœ¨è™•ç†: 6167 ä¹…æ­£\n",
            "[1574/1912] æ­£åœ¨è™•ç†: 6169 æ˜±æ³‰\n",
            "[1575/1912] æ­£åœ¨è™•ç†: 6170 çµ±æŒ¯\n",
            "[1576/1912] æ­£åœ¨è™•ç†: 6171 å¤§åŸåœ°ç”¢\n",
            "[1577/1912] æ­£åœ¨è™•ç†: 6173 ä¿¡æ˜Œé›»\n",
            "[1578/1912] æ­£åœ¨è™•ç†: 6174 å®‰ï¿½ï¿½\n",
            "[1579/1912] æ­£åœ¨è™•ç†: 6175 ç«‹æ•¦\n",
            "[1580/1912] æ­£åœ¨è™•ç†: 6179 äºé€š\n",
            "[1581/1912] æ­£åœ¨è™•ç†: 6180 æ©˜å­\n",
            "[1582/1912] æ­£åœ¨è™•ç†: 6182 åˆæ™¶\n",
            "[1583/1912] æ­£åœ¨è™•ç†: 6185 å¹ƒç¿”\n",
            "[1584/1912] æ­£åœ¨è™•ç†: 6186 æ–°æ½¤\n",
            "[1585/1912] æ­£åœ¨è™•ç†: 6187 è¬æ½¤\n",
            "[1586/1912] æ­£åœ¨è™•ç†: 6188 å»£æ˜\n",
            "[1587/1912] æ­£åœ¨è™•ç†: 6190 è¬æ³°ç§‘\n",
            "[1588/1912] æ­£åœ¨è™•ç†: 6194 è‚²å¯Œ\n",
            "[1589/1912] æ­£åœ¨è™•ç†: 6195 è©©è‚¯\n",
            "[1590/1912] æ­£åœ¨è™•ç†: 6198 ç‘ç¯‰\n",
            "[1591/1912] æ­£åœ¨è™•ç†: 6199 å¤©å“\n",
            "[1592/1912] æ­£åœ¨è™•ç†: 6203 æµ·éŸ»é›»\n",
            "[1593/1912] æ­£åœ¨è™•ç†: 6204 è‰¾è¯\n",
            "[1594/1912] æ­£åœ¨è™•ç†: 6207 é›·ç§‘\n",
            "[1595/1912] æ­£åœ¨è™•ç†: 6208 æ—¥æš\n",
            "[1596/1912] æ­£åœ¨è™•ç†: 6210 æ…¶ç”Ÿ\n",
            "[1597/1912] æ­£åœ¨è™•ç†: 6212 ç†éŠ˜\n",
            "[1598/1912] æ­£åœ¨è™•ç†: 6217 ä¸­æ¢é‡\n",
            "[1599/1912] æ­£åœ¨è™•ç†: 6218 è±ªå‹‰\n",
            "[1600/1912] æ­£åœ¨è™•ç†: 6219 å¯Œæ—º\n",
            "[1601/1912] æ­£åœ¨è™•ç†: 6220 å²³è±\n",
            "[1602/1912] æ­£åœ¨è™•ç†: 6221 æ™‰æ³°\n",
            "[1603/1912] æ­£åœ¨è™•ç†: 6222 ç«‹è»’\n",
            "[1604/1912] æ­£åœ¨è™•ç†: 6223 æ—ºçŸ½\n",
            "[1605/1912] æ­£åœ¨è™•ç†: 6227 èŒ‚ç¶¸\n",
            "[1606/1912] æ­£åœ¨è™•ç†: 6228 å…¨è­œ\n",
            "[1607/1912] æ­£åœ¨è™•ç†: 6229 ç ”é€š\n",
            "[1608/1912] æ­£åœ¨è™•ç†: 6231 ç³»å¾®\n",
            "[1609/1912] æ­£åœ¨è™•ç†: 6233 æ—ºç–\n",
            "[1610/1912] æ­£åœ¨è™•ç†: 6234 é«˜åƒ‘\n",
            "[1611/1912] æ­£åœ¨è™•ç†: 6236 ä¸­æ¹›\n",
            "[1612/1912] æ­£åœ¨è™•ç†: 6237 é©Šè¨Š\n",
            "[1613/1912] æ­£åœ¨è™•ç†: 6240 æ¾å´—\n",
            "[1614/1912] æ­£åœ¨è™•ç†: 6241 æ˜“é€šå±•\n",
            "[1615/1912] æ­£åœ¨è™•ç†: 6242 ç«‹åº·\n",
            "[1616/1912] æ­£åœ¨è™•ç†: 6244 èŒ‚è¿ª\n",
            "[1617/1912] æ­£åœ¨è™•ç†: 6245 ç«‹ç«¯\n",
            "[1618/1912] æ­£åœ¨è™•ç†: 6246 è‡ºé¾\n",
            "[1619/1912] æ­£åœ¨è™•ç†: 6248 æ²›æ³¢\n",
            "[1620/1912] æ­£åœ¨è™•ç†: 6259 ç™¾å¾½\n",
            "[1621/1912] æ­£åœ¨è™•ç†: 6261 ä¹…å…ƒ\n",
            "[1622/1912] æ­£åœ¨è™•ç†: 6263 æ™®èŠå¾·\n",
            "[1623/1912] æ­£åœ¨è™•ç†: 6264 å¯Œè£”\n",
            "[1624/1912] æ­£åœ¨è™•ç†: 6265 æ–¹åœŸæ˜¶\n",
            "[1625/1912] æ­£åœ¨è™•ç†: 6266 æ³°è© \n",
            "[1626/1912] æ­£åœ¨è™•ç†: 6270 å€å¾®\n",
            "[1627/1912] æ­£åœ¨è™•ç†: 6274 å°ç‡¿\n",
            "[1628/1912] æ­£åœ¨è™•ç†: 6275 å…ƒå±±\n",
            "[1629/1912] æ­£åœ¨è™•ç†: 6276 å®‰éˆ¦å…‹\n",
            "[1630/1912] æ­£åœ¨è™•ç†: 6279 èƒ¡é€£\n",
            "[1631/1912] æ­£åœ¨è™•ç†: 6284 ä½³é‚¦\n",
            "[1632/1912] æ­£åœ¨è™•ç†: 6290 è‰¯ç¶­\n",
            "[1633/1912] æ­£åœ¨è™•ç†: 6291 æ²›äº¨\n",
            "[1634/1912] æ­£åœ¨è™•ç†: 6292 è¿…å¾·\n",
            "[1635/1912] æ­£åœ¨è™•ç†: 6294 æ™ºåŸº\n",
            "[1636/1912] æ­£åœ¨è™•ç†: 6411 æ™¶ç„±\n",
            "[1637/1912] æ­£åœ¨è™•ç†: 6417 éŸ‹åƒ‘\n",
            "[1638/1912] æ­£åœ¨è™•ç†: 6418 è© æ˜‡\n",
            "[1639/1912] æ­£åœ¨è™•ç†: 6419 äº¬æ™¨ç§‘\n",
            "[1640/1912] æ­£åœ¨è™•ç†: 6425 æ˜“ç™¼\n",
            "[1641/1912] æ­£åœ¨è™•ç†: 6432 ä»Šå±•ç§‘\n",
            "[1642/1912] æ­£åœ¨è™•ç†: 6435 å¤§ä¸­\n",
            "[1643/1912] æ­£åœ¨è™•ç†: 6441 å»£éŒ \n",
            "[1644/1912] æ­£åœ¨è™•ç†: 6461 ç›Šå¾—\n",
            "[1645/1912] æ­£åœ¨è™•ç†: 6462 ç¥ç›¾\n",
            "[1646/1912] æ­£åœ¨è™•ç†: 6465 å¨æ½¤\n",
            "[1647/1912] æ­£åœ¨è™•ç†: 6469 å¤§æ¨¹\n",
            "[1648/1912] æ­£åœ¨è™•ç†: 6470 å®‡æ™º\n",
            "[1649/1912] æ­£åœ¨è™•ç†: 6482 å¼˜ç…œç§‘\n",
            "[1650/1912] æ­£åœ¨è™•ç†: 6485 é»åº\n",
            "[1651/1912] æ­£åœ¨è™•ç†: 6486 äº’å‹•\n",
            "[1652/1912] æ­£åœ¨è™•ç†: 6488 ç’°çƒæ™¶\n",
            "[1653/1912] æ­£åœ¨è™•ç†: 6492 ç”Ÿè¯ç§‘\n",
            "[1654/1912] æ­£åœ¨è™•ç†: 6494 ä¹é½Š\n",
            "[1655/1912] æ­£åœ¨è™•ç†: 6496 ç§‘æ‡‹\n",
            "[1656/1912] æ­£åœ¨è™•ç†: 6498 ä¹…ç¦¾å…‰\n",
            "[1657/1912] æ­£åœ¨è™•ç†: 6499 ç›Šå®‰\n",
            "[1658/1912] æ­£åœ¨è™•ç†: 6506 é›™é‚¦\n",
            "[1659/1912] æ­£åœ¨è™•ç†: 6508 æƒ å…‰\n",
            "[1660/1912] æ­£åœ¨è™•ç†: 6509 èšå’Œ\n",
            "[1661/1912] æ­£åœ¨è™•ç†: 6510 ç²¾æ¸¬\n",
            "[1662/1912] æ­£åœ¨è™•ç†: 6512 å•Ÿç™¼é›»\n",
            "[1663/1912] æ­£åœ¨è™•ç†: 6516 å‹¤å´´åœ‹éš›\n",
            "[1664/1912] æ­£åœ¨è™•ç†: 6517 ä¿å‹å…‰å­¸\n",
            "[1665/1912] æ­£åœ¨è™•ç†: 6523 é”çˆ¾è†š\n",
            "[1666/1912] æ­£åœ¨è™•ç†: 6527 æ˜é”é†«\n",
            "[1667/1912] æ­£åœ¨è™•ç†: 6530 å‰µå¨\n",
            "[1668/1912] æ­£åœ¨è™•ç†: 6532 ç‘è€˜\n",
            "[1669/1912] æ­£åœ¨è™•ç†: 6535 é †è—¥\n",
            "[1670/1912] æ­£åœ¨è™•ç†: 6538 å€‰å’Œ\n",
            "[1671/1912] æ­£åœ¨è™•ç†: 6542 éš†ä¸­\n",
            "[1672/1912] æ­£åœ¨è™•ç†: 6546 æ­£åŸº\n",
            "[1673/1912] æ­£åœ¨è™•ç†: 6547 é«˜ç«¯ç–«è‹—\n",
            "[1674/1912] æ­£åœ¨è™•ç†: 6548 é•·ç§‘*\n",
            "[1675/1912] æ­£åœ¨è™•ç†: 6556 å‹å“\n",
            "[1676/1912] æ­£åœ¨è™•ç†: 6560 æ¬£æ™®ç¾…\n",
            "[1677/1912] æ­£åœ¨è™•ç†: 6561 æ˜¯æ–¹\n",
            "[1678/1912] æ­£åœ¨è™•ç†: 6568 å®è§€\n",
            "[1679/1912] æ­£åœ¨è™•ç†: 6569 é†«æš\n",
            "[1680/1912] æ­£åœ¨è™•ç†: 6570 ç¶­ç”°\n",
            "[1681/1912] æ­£åœ¨è™•ç†: 6574 éœˆæ–¹\n",
            "[1682/1912] æ­£åœ¨è™•ç†: 6576 é€¸é”\n",
            "[1683/1912] æ­£åœ¨è™•ç†: 6577 å‹è±\n",
            "[1684/1912] æ­£åœ¨è™•ç†: 6578 é”é‚¦è›‹ç™½\n",
            "[1685/1912] æ­£åœ¨è™•ç†: 6584 å—ä¿Šåœ‹éš›\n",
            "[1686/1912] æ­£åœ¨è™•ç†: 6588 æ±å…¸å…‰é›»\n",
            "[1687/1912] æ­£åœ¨è™•ç†: 6590 æ™®é´»\n",
            "[1688/1912] æ­£åœ¨è™•ç†: 6593 å°ç£éŠ˜æ¿\n",
            "[1689/1912] æ­£åœ¨è™•ç†: 6596 å¯¬å®è—è¡“\n",
            "[1690/1912] æ­£åœ¨è™•ç†: 6597 ç«‹èª \n",
            "[1691/1912] æ­£åœ¨è™•ç†: 6603 å¯Œå¼·é‘«\n",
            "[1692/1912] æ­£åœ¨è™•ç†: 6609 ç€§æ¾¤ç§‘\n",
            "[1693/1912] æ­£åœ¨è™•ç†: 6612 å¥ˆç±³é†«æ\n",
            "[1694/1912] æ­£åœ¨è™•ç†: 6613 æœ‹å„„*\n",
            "[1695/1912] æ­£åœ¨è™•ç†: 6615 æ…§æ™º\n",
            "[1696/1912] æ­£åœ¨è™•ç†: 6616 ç‰¹æ˜‡-KY\n",
            "[1697/1912] æ­£åœ¨è™•ç†: 6617 å…±ä¿¡-KY\n",
            "[1698/1912] æ­£åœ¨è™•ç†: 6624 è¬å¹´æ¸…\n",
            "[1699/1912] æ­£åœ¨è™•ç†: 6629 æ³°é‡‘-KY\n",
            "[1700/1912] æ­£åœ¨è™•ç†: 6637 é†«å½±\n",
            "[1701/1912] æ­£åœ¨è™•ç†: 6640 å‡è¯\n",
            "[1702/1912] æ­£åœ¨è™•ç†: 6642 å¯Œè‡´\n",
            "[1703/1912] æ­£åœ¨è™•ç†: 6643 M31\n",
            "[1704/1912] æ­£åœ¨è™•ç†: 6649 å°ç”Ÿæ\n",
            "[1705/1912] æ­£åœ¨è™•ç†: 6651 å…¨å®‡æ˜•\n",
            "[1706/1912] æ­£åœ¨è™•ç†: 6654 å¤©æ­£åœ‹éš›\n",
            "[1707/1912] æ­£åœ¨è™•ç†: 6661 å¨å¥ç”ŸæŠ€\n",
            "[1708/1912] æ­£åœ¨è™•ç†: 6662 æ¨‚æ–¯ç§‘\n",
            "[1709/1912] æ­£åœ¨è™•ç†: 6664 ç¾¤ç¿Š\n",
            "[1710/1912] æ­£åœ¨è™•ç†: 6667 ä¿¡ç´˜ç§‘\n",
            "[1711/1912] æ­£åœ¨è™•ç†: 6679 éˆºå¤ª\n",
            "[1712/1912] æ­£åœ¨è™•ç†: 6680 é‘«å‰µé›»å­\n",
            "[1713/1912] æ­£åœ¨è™•ç†: 6683 é›æ™ºç§‘æŠ€\n",
            "[1714/1912] æ­£åœ¨è™•ç†: 6684 å®‰æ ¼\n",
            "[1715/1912] æ­£åœ¨è™•ç†: 6690 å®‰ï¿½ç¡Œç©ˆT\n",
            "[1716/1912] æ­£åœ¨è™•ç†: 6692 é€²èƒ½æœ\n",
            "[1717/1912] æ­£åœ¨è™•ç†: 6693 å»£é–ç§‘\n",
            "[1718/1912] æ­£åœ¨è™•ç†: 6697 æ±æ·è³‡è¨Š\n",
            "[1719/1912] æ­£åœ¨è™•ç†: 6703 è»’éƒ\n",
            "[1720/1912] æ­£åœ¨è™•ç†: 6708 å¤©æ“\n",
            "[1721/1912] æ­£åœ¨è™•ç†: 6712 é•·è–\n",
            "[1722/1912] æ­£åœ¨è™•ç†: 6716 æ‡‰å»£\n",
            "[1723/1912] æ­£åœ¨è™•ç†: 6720 ä¹…æ˜Œ\n",
            "[1724/1912] æ­£åœ¨è™•ç†: 6721 ä¿¡å¯¦\n",
            "[1725/1912] æ­£åœ¨è™•ç†: 6727 äºæ³°é‡‘å±¬\n",
            "[1726/1912] æ­£åœ¨è™•ç†: 6728 ä¸Šæ´‹\n",
            "[1727/1912] æ­£åœ¨è™•ç†: 6732 æ˜‡ä½³é›»å­\n",
            "[1728/1912] æ­£åœ¨è™•ç†: 6733 åšæ™Ÿç”Ÿé†«\n",
            "[1729/1912] æ­£åœ¨è™•ç†: 6735 ç¾é”ç§‘æŠ€\n",
            "[1730/1912] æ­£åœ¨è™•ç†: 6739 ç«¹é™ç§‘æŠ€\n",
            "[1731/1912] æ­£åœ¨è™•ç†: 6741 91APP*-KY\n",
            "[1732/1912] æ­£åœ¨è™•ç†: 6747 äº¨æ³°å…‰\n",
            "[1733/1912] æ­£åœ¨è™•ç†: 6751 æ™ºè¯æœå‹™\n",
            "[1734/1912] æ­£åœ¨è™•ç†: 6752 å¡æš\n",
            "[1735/1912] æ­£åœ¨è™•ç†: 6761 ç©©å¾—\n",
            "[1736/1912] æ­£åœ¨è™•ç†: 6762 é”äº\n",
            "[1737/1912] æ­£åœ¨è™•ç†: 6763 ç¶ ç•Œç§‘æŠ€*\n",
            "[1738/1912] æ­£åœ¨è™•ç†: 6767 å°å¾®é†«\n",
            "[1739/1912] æ­£åœ¨è™•ç†: 6785 æ˜±å±•æ–°è—¥\n",
            "[1740/1912] æ­£åœ¨è™•ç†: 6788 è¯æ™¯é›»\n",
            "[1741/1912] æ­£åœ¨è™•ç†: 6791 è™é–€ç§‘æŠ€\n",
            "[1742/1912] æ­£åœ¨è™•ç†: 6803 å´‘é¼\n",
            "[1743/1912] æ­£åœ¨è™•ç†: 6804 æ˜ä¿‚\n",
            "[1744/1912] æ­£åœ¨è™•ç†: 6811 å®ï¿½ç¡Œç©ˆT\n",
            "[1745/1912] æ­£åœ¨è™•ç†: 6821 è¯å¯¶\n",
            "[1746/1912] æ­£åœ¨è™•ç†: 6823 æ¿¾èƒ½\n",
            "[1747/1912] æ­£åœ¨è™•ç†: 6829 åƒé™„ç²¾å¯†\n",
            "[1748/1912] æ­£åœ¨è™•ç†: 6840 æ±ç ”ä¿¡è¶…\n",
            "[1749/1912] æ­£åœ¨è™•ç†: 6841 é•·ä½³æ™ºèƒ½\n",
            "[1750/1912] æ­£åœ¨è™•ç†: 6843 é€²å…¸\n",
            "[1751/1912] æ­£åœ¨è™•ç†: 6844 è«¾è²å…’\n",
            "[1752/1912] æ­£åœ¨è™•ç†: 6846 ç¶ èŒµ\n",
            "[1753/1912] æ­£åœ¨è™•ç†: 6855 æ•¸æ³“ç§‘\n",
            "[1754/1912] æ­£åœ¨è™•ç†: 6856 é‘«å‚³\n",
            "[1755/1912] æ­£åœ¨è™•ç†: 6859 ä¼¯ç‰¹å…‰\n",
            "[1756/1912] æ­£åœ¨è™•ç†: 6865 å‰åº·ç§‘æŠ€\n",
            "[1757/1912] æ­£åœ¨è™•ç†: 6870 é¨°é›²\n",
            "[1758/1912] æ­£åœ¨è™•ç†: 6872 æµ©å®‡ç”Ÿé†«\n",
            "[1759/1912] æ­£åœ¨è™•ç†: 6874 å€åŠ›\n",
            "[1760/1912] æ­£åœ¨è™•ç†: 6875 åœ‹é‚‘*\n",
            "[1761/1912] æ­£åœ¨è™•ç†: 6877 éµå‹ç›Š\n",
            "[1762/1912] æ­£åœ¨è™•ç†: 6881 æ½¤å¾·\n",
            "[1763/1912] æ­£åœ¨è™•ç†: 6894 è¡›å¸ç‰¹\n",
            "[1764/1912] æ­£åœ¨è™•ç†: 6895 å®ç¢©ç³»çµ±\n",
            "[1765/1912] æ­£åœ¨è™•ç†: 6899 å‰µç‚ºç²¾å¯†\n",
            "[1766/1912] æ­£åœ¨è™•ç†: 6903 å·¨æ¼¢\n",
            "[1767/1912] æ­£åœ¨è™•ç†: 6904 ä¼¯é‘«\n",
            "[1768/1912] æ­£åœ¨è™•ç†: 6913 é´»å‘ˆ\n",
            "[1769/1912] æ­£åœ¨è™•ç†: 6922 å®¸æ›œ\n",
            "[1770/1912] æ­£åœ¨è™•ç†: 6925 æ„è—\n",
            "[1771/1912] æ­£åœ¨è™•ç†: 6929 ä½‘å…¨\n",
            "[1772/1912] æ­£åœ¨è™•ç†: 6953 å®¶ç¢©\n",
            "[1773/1912] æ­£åœ¨è™•ç†: 6967 æ±ç‘‹ææ–™\n",
            "[1774/1912] æ­£åœ¨è™•ç†: 6968 è¬é”å¯µç‰©\n",
            "[1775/1912] æ­£åœ¨è™•ç†: 6982 å¤§äº•æ³µæµ¦\n",
            "[1776/1912] æ­£åœ¨è™•ç†: 6996 åŠ›é ˜ç§‘æŠ€\n",
            "[1777/1912] æ­£åœ¨è™•ç†: 6997 åšå¼˜\n",
            "[1778/1912] æ­£åœ¨è™•ç†: 7402 é‚‘éŒ¡\n",
            "[1779/1912] æ­£åœ¨è™•ç†: 7547 ç¢©ç¶²\n",
            "[1780/1912] æ­£åœ¨è™•ç†: 7556 æ„å¾·å£«\n",
            "[1781/1912] æ­£åœ¨è™•ç†: 7584 æ¨‚æ„\n",
            "[1782/1912] æ­£åœ¨è™•ç†: 7642 æ˜¶ç‘æ©Ÿé›»\n",
            "[1783/1912] æ­£åœ¨è™•ç†: 7703 éŠ³æ¾¤\n",
            "[1784/1912] æ­£åœ¨è™•ç†: 7704 æ˜é ç²¾å¯†\n",
            "[1785/1912] æ­£åœ¨è™•ç†: 7708 å…¨å®¶é¤é£²\n",
            "[1786/1912] æ­£åœ¨è™•ç†: 7709 æ¦®ç”°\n",
            "[1787/1912] æ­£åœ¨è™•ç†: 7712 åšç››åŠå°é«”\n",
            "[1788/1912] æ­£åœ¨è™•ç†: 7713 å¨åŠ›å¾·ç”Ÿé†«\n",
            "[1789/1912] æ­£åœ¨è™•ç†: 7714 å‰µæ³“ç§‘æŠ€\n",
            "[1790/1912] æ­£åœ¨è™•ç†: 7715 è£•å±±\n",
            "[1791/1912] æ­£åœ¨è™•ç†: 7718 å‹é‹®\n",
            "[1792/1912] æ­£åœ¨è™•ç†: 7723 ç¯‰é–“\n",
            "[1793/1912] æ­£åœ¨è™•ç†: 7728 å…‰ç„±ç§‘æŠ€\n",
            "[1794/1912] æ­£åœ¨è™•ç†: 7734 å°èƒ½ç§‘æŠ€\n",
            "[1795/1912] æ­£åœ¨è™•ç†: 7743 é‡‘åˆ©é£Ÿå®‰\n",
            "[1796/1912] æ­£åœ¨è™•ç†: 7747 æ˜•å¥‡é›²ç«¯\n",
            "[1797/1912] æ­£åœ¨è™•ç†: 7753 æ˜Ÿäº\n",
            "[1798/1912] æ­£åœ¨è™•ç†: 8024 ä½‘è¯\n",
            "[1799/1912] æ­£åœ¨è™•ç†: 8027 éˆ¦æ˜‡\n",
            "[1800/1912] æ­£åœ¨è™•ç†: 8032 å…‰è±\n",
            "[1801/1912] æ­£åœ¨è™•ç†: 8034 æ¦®ç¾¤\n",
            "[1802/1912] æ­£åœ¨è™•ç†: 8038 é•·åœ’ç§‘\n",
            "[1803/1912] æ­£åœ¨è™•ç†: 8040 ä¹æš˜\n",
            "[1804/1912] æ­£åœ¨è™•ç†: 8042 é‡‘å±±é›»\n",
            "[1805/1912] æ­£åœ¨è™•ç†: 8043 èœœæœ›å¯¦\n",
            "[1806/1912] æ­£åœ¨è™•ç†: 8044 ç¶²å®¶\n",
            "[1807/1912] æ­£åœ¨è™•ç†: 8047 æ˜Ÿé›²\n",
            "[1808/1912] æ­£åœ¨è™•ç†: 8048 å¾·å‹\n",
            "[1809/1912] æ­£åœ¨è™•ç†: 8049 æ™¶é‡‡\n",
            "[1810/1912] æ­£åœ¨è™•ç†: 8050 å»£ç©\n",
            "[1811/1912] æ­£åœ¨è™•ç†: 8054 å®‰åœ‹\n",
            "[1812/1912] æ­£åœ¨è™•ç†: 8059 å‡±ç¢©\n",
            "[1813/1912] æ­£åœ¨è™•ç†: 8064 æ±æ·\n",
            "[1814/1912] æ­£åœ¨è™•ç†: 8066 ä¾†æ€é”\n",
            "[1815/1912] æ­£åœ¨è™•ç†: 8067 å¿—æ—­\n",
            "[1816/1912] æ­£åœ¨è™•ç†: 8068 å…¨é”\n",
            "[1817/1912] æ­£åœ¨è™•ç†: 8069 å…ƒå¤ª\n",
            "[1818/1912] æ­£åœ¨è™•ç†: 8071 èƒ½ç‡ç¶²é€š\n",
            "[1819/1912] æ­£åœ¨è™•ç†: 8074 é‰…æ©¡\n",
            "[1820/1912] æ­£åœ¨è™•ç†: 8076 ä¼è±\n",
            "[1821/1912] æ­£åœ¨è™•ç†: 8077 æ´›ï¿½ï¿½\n",
            "[1822/1912] æ­£åœ¨è™•ç†: 8080 æ³°éœ–\n",
            "[1823/1912] æ­£åœ¨è™•ç†: 8083 ç‘ç©\n",
            "[1824/1912] æ­£åœ¨è™•ç†: 8084 å·¨è™¹\n",
            "[1825/1912] æ­£åœ¨è™•ç†: 8085 ç¦è¯\n",
            "[1826/1912] æ­£åœ¨è™•ç†: 8086 å®æ·ç§‘\n",
            "[1827/1912] æ­£åœ¨è™•ç†: 8087 éº—å‡èƒ½æº\n",
            "[1828/1912] æ­£åœ¨è™•ç†: 8088 å“å®‰\n",
            "[1829/1912] æ­£åœ¨è™•ç†: 8089 åº·å…¨é›»è¨Š\n",
            "[1830/1912] æ­£åœ¨è™•ç†: 8091 ç¿”å\n",
            "[1831/1912] æ­£åœ¨è™•ç†: 8092 å»ºæš\n",
            "[1832/1912] æ­£åœ¨è™•ç†: 8093 ä¿éŠ³\n",
            "[1833/1912] æ­£åœ¨è™•ç†: 8096 æ“äº\n",
            "[1834/1912] æ­£åœ¨è™•ç†: 8097 å¸¸çµ\n",
            "[1835/1912] æ­£åœ¨è™•ç†: 8099 å¤§ä¸–ç§‘\n",
            "[1836/1912] æ­£åœ¨è™•ç†: 8107 å¤§å„„é‡‘èŒ‚\n",
            "[1837/1912] æ­£åœ¨è™•ç†: 8109 åšå¤§\n",
            "[1838/1912] æ­£åœ¨è™•ç†: 8111 ç«‹ï¿½ï¿½\n",
            "[1839/1912] æ­£åœ¨è™•ç†: 8121 è¶Šå³°\n",
            "[1840/1912] æ­£åœ¨è™•ç†: 8147 æ­£æ·©\n",
            "[1841/1912] æ­£åœ¨è™•ç†: 8155 åšæ™º\n",
            "[1842/1912] æ­£åœ¨è™•ç†: 8171 å¤©å®‡\n",
            "[1843/1912] æ­£åœ¨è™•ç†: 8176 æ™ºæ·\n",
            "[1844/1912] æ­£åœ¨è™•ç†: 8182 åŠ é«˜\n",
            "[1845/1912] æ­£åœ¨è™•ç†: 8183 ç²¾æ˜Ÿ\n",
            "[1846/1912] æ­£åœ¨è™•ç†: 8227 å·¨æœ‰ç§‘æŠ€\n",
            "[1847/1912] æ­£åœ¨è™•ç†: 8234 æ–°æ¼¢\n",
            "[1848/1912] æ­£åœ¨è™•ç†: 8240 è¯å®\n",
            "[1849/1912] æ­£åœ¨è™•ç†: 8255 æœ‹ç¨‹\n",
            "[1850/1912] æ­£åœ¨è™•ç†: 8272 å…¨æ™¯è»Ÿé«”\n",
            "[1851/1912] æ­£åœ¨è™•ç†: 8277 å•†ä¸\n",
            "[1852/1912] æ­£åœ¨è™•ç†: 8279 ç”Ÿå±•\n",
            "[1853/1912] æ­£åœ¨è™•ç†: 8284 ä¸‰ç«¹\n",
            "[1854/1912] æ­£åœ¨è™•ç†: 8289 æ³°è—\n",
            "[1855/1912] æ­£åœ¨è™•ç†: 8291 å°šèŒ‚\n",
            "[1856/1912] æ­£åœ¨è™•ç†: 8299 ç¾¤è¯\n",
            "[1857/1912] æ­£åœ¨è™•ç†: 8342 ç›Šå¼µ\n",
            "[1858/1912] æ­£åœ¨è™•ç†: 8349 ï¿½çŸ¬ï¿½\n",
            "[1859/1912] æ­£åœ¨è™•ç†: 8354 å† å¥½\n",
            "[1860/1912] æ­£åœ¨è™•ç†: 8358 é‡‘å±…\n",
            "[1861/1912] æ­£åœ¨è™•ç†: 8383 åƒé™„\n",
            "[1862/1912] æ­£åœ¨è™•ç†: 8390 é‡‘ç›Šé¼\n",
            "[1863/1912] æ­£åœ¨è™•ç†: 8401 ç™½ç´—ç§‘\n",
            "[1864/1912] æ­£åœ¨è™•ç†: 8403 ç››å¼˜\n",
            "[1865/1912] æ­£åœ¨è™•ç†: 8409 å•†ä¹‹å™¨\n",
            "[1866/1912] æ­£åœ¨è™•ç†: 8410 æ£®ç”°\n",
            "[1867/1912] æ­£åœ¨è™•ç†: 8415 å¤§åœ‹é‹¼\n",
            "[1868/1912] æ­£åœ¨è™•ç†: 8416 å¯¦å¨\n",
            "[1869/1912] æ­£åœ¨è™•ç†: 8421 æ—­æº\n",
            "[1870/1912] æ­£åœ¨è™•ç†: 8423 ä¿ç¶ -KY\n",
            "[1871/1912] æ­£åœ¨è™•ç†: 8424 æƒ æ™®\n",
            "[1872/1912] æ­£åœ¨è™•ç†: 8426 ç´…æœ¨-KY\n",
            "[1873/1912] æ­£åœ¨è™•ç†: 8431 åŒ¯é‘½ç§‘\n",
            "[1874/1912] æ­£åœ¨è™•ç†: 8432 æ±ç”Ÿè¯\n",
            "[1875/1912] æ­£åœ¨è™•ç†: 8433 å¼˜å¸†\n",
            "[1876/1912] æ­£åœ¨è™•ç†: 8435 é‰…é‚\n",
            "[1877/1912] æ­£åœ¨è™•ç†: 8436 å¤§æ±Ÿ\n",
            "[1878/1912] æ­£åœ¨è™•ç†: 8437 å¤§åœ°-KY\n",
            "[1879/1912] æ­£åœ¨è™•ç†: 8440 ç¶ é›»\n",
            "[1880/1912] æ­£åœ¨è™•ç†: 8444 ç¶ æ²³-KY\n",
            "[1881/1912] æ­£åœ¨è™•ç†: 8446 è¯ç ”\n",
            "[1882/1912] æ­£åœ¨è™•ç†: 8450 éœ¹é‚\n",
            "[1883/1912] æ­£åœ¨è™•ç†: 8455 å¤§æ‹“-KY\n",
            "[1884/1912] æ­£åœ¨è™•ç†: 8472 å¤ éº»å‰\n",
            "[1885/1912] æ­£åœ¨è™•ç†: 8477 å‰µæ¥­å®¶\n",
            "[1886/1912] æ­£åœ¨è™•ç†: 8489 ä¸‰è²å¾·\n",
            "[1887/1912] æ­£åœ¨è™•ç†: 8905 è£•åœ‹\n",
            "[1888/1912] æ­£åœ¨è™•ç†: 8906 èŠ±ç‹\n",
            "[1889/1912] æ­£åœ¨è™•ç†: 8908 æ¬£é›„\n",
            "[1890/1912] æ­£åœ¨è™•ç†: 8916 å…‰éš†\n",
            "[1891/1912] æ­£åœ¨è™•ç†: 8917 æ¬£æ³°\n",
            "[1892/1912] æ­£åœ¨è™•ç†: 8921 æ²ˆæ°\n",
            "[1893/1912] æ­£åœ¨è™•ç†: 8923 æ™‚å ±\n",
            "[1894/1912] æ­£åœ¨è™•ç†: 8924 å¤§ç”°\n",
            "[1895/1912] æ­£åœ¨è™•ç†: 8927 åŒ—åŸº\n",
            "[1896/1912] æ­£åœ¨è™•ç†: 8928 é‰…æ˜\n",
            "[1897/1912] æ­£åœ¨è™•ç†: 8929 å¯Œå ¡\n",
            "[1898/1912] æ­£åœ¨è™•ç†: 8930 é’é‹¼\n",
            "[1899/1912] æ­£åœ¨è™•ç†: 8931 å¤§æ±½é›»\n",
            "[1900/1912] æ­£åœ¨è™•ç†: 8932 æ™ºé€š*\n",
            "[1901/1912] æ­£åœ¨è™•ç†: 8933 æ„›åœ°é›…\n",
            "[1902/1912] æ­£åœ¨è™•ç†: 8935 é‚¦æ³°\n",
            "[1903/1912] æ­£åœ¨è™•ç†: 8936 åœ‹çµ±\n",
            "[1904/1912] æ­£åœ¨è™•ç†: 8937 åˆé¨\n",
            "[1905/1912] æ­£åœ¨è™•ç†: 8938 æ˜å®‰\n",
            "[1906/1912] æ­£åœ¨è™•ç†: 8941 é—œä¸­\n",
            "[1907/1912] æ­£åœ¨è™•ç†: 8942 æ£®é‰…\n",
            "[1908/1912] æ­£åœ¨è™•ç†: 9949 ç‰åœ’\n",
            "[1909/1912] æ­£åœ¨è™•ç†: 9950 è¬åœ‹é€š\n",
            "[1910/1912] æ­£åœ¨è™•ç†: 9951 çš‡ç”°\n",
            "[1911/1912] æ­£åœ¨è™•ç†: 9960 é‚é”åº·\n",
            "[1912/1912] æ­£åœ¨è™•ç†: 9962 æœ‰ç›Š\n",
            "\n",
            "[éšæ®µ3/7] éæ¿¾ä½æˆäº¤é‡è‚¡ç¥¨...\n",
            "\n",
            "=== é€šçŸ¥è¨Šæ¯ ===\n",
            "ğŸ“Š *è‚¡ç¥¨åˆ†æé€²åº¦å ±å‘Š*\n",
            "\n",
            "âœ… å·²ç²å– 1912 æ”¯è‚¡ç¥¨è³‡æ–™\n",
            "âœ… ç¬¦åˆæˆäº¤é‡æ¨™æº–: 545 æ”¯\n",
            "ğŸ”„ é–‹å§‹é€²è¡ŒæŠ€è¡“åˆ†æ...\n",
            "===============\n",
            "\n",
            "\n",
            "[éšæ®µ4/7] é€²è¡Œæ ¸å¿ƒåˆ†æèˆ‡ç¶œåˆè©•åˆ† (545 æ”¯)...\n",
            "  åˆ†æä¸­ (1/545): 1101 å°æ³¥\n",
            "  åˆ†æä¸­ (2/545): 1102 äºæ³¥\n",
            "  åˆ†æä¸­ (3/545): 1210 å¤§æˆ\n",
            "  åˆ†æä¸­ (4/545): 1216 çµ±ä¸€\n",
            "  åˆ†æä¸­ (5/545): 1229 è¯è¯\n",
            "  åˆ†æä¸­ (6/545): 1301 å°å¡‘\n",
            "  åˆ†æä¸­ (7/545): 1303 å—äº\n",
            "  åˆ†æä¸­ (8/545): 1304 å°èš\n",
            "  åˆ†æä¸­ (9/545): 1305 è¯å¤\n",
            "  åˆ†æä¸­ (10/545): 1307 ä¸‰èŠ³\n",
            "  åˆ†æä¸­ (11/545): 1308 äºèš\n",
            "  åˆ†æä¸­ (12/545): 1310 å°è‹¯\n",
            "  åˆ†æä¸­ (13/545): 1312 åœ‹å–¬\n",
            "  åˆ†æä¸­ (14/545): 1313 è¯æˆ\n",
            "  åˆ†æä¸­ (15/545): 1314 ä¸­çŸ³åŒ–\n",
            "  åˆ†æä¸­ (16/545): 1316 ä¸Šæ›œ\n",
            "  åˆ†æä¸­ (17/545): 1319 æ±é™½\n",
            "  åˆ†æä¸­ (18/545): 1326 å°åŒ–\n",
            "  åˆ†æä¸­ (19/545): 1402 é æ±æ–°\n",
            "  åˆ†æä¸­ (20/545): 1409 æ–°çº–\n",
            "  åˆ†æä¸­ (21/545): 1434 ç¦æ‡‹\n",
            "  åˆ†æä¸­ (22/545): 1476 å„’é´»\n",
            "  åˆ†æä¸­ (23/545): 1477 èšé™½\n",
            "  åˆ†æä¸­ (24/545): 1503 å£«é›»\n",
            "  åˆ†æä¸­ (25/545): 1504 æ±å…ƒ\n",
            "  åˆ†æä¸­ (26/545): 1513 ä¸­èˆˆé›»\n",
            "  åˆ†æä¸­ (27/545): 1514 äºåŠ›\n",
            "  åˆ†æä¸­ (28/545): 1519 è¯åŸ\n",
            "  åˆ†æä¸­ (29/545): 1522 å ¤ç¶­è¥¿\n",
            "  åˆ†æä¸­ (30/545): 1528 æ©å¾·\n",
            "  åˆ†æä¸­ (31/545): 1536 å’Œå¤§\n",
            "  åˆ†æä¸­ (32/545): 1560 ä¸­ç ‚\n",
            "  åˆ†æä¸­ (33/545): 1597 ç›´å¾—\n",
            "  åˆ†æä¸­ (34/545): 1605 è¯æ–°\n",
            "  åˆ†æä¸­ (35/545): 1608 è¯æ¦®\n",
            "  åˆ†æä¸­ (36/545): 1609 å¤§äº\n",
            "  åˆ†æä¸­ (37/545): 1612 å®æ³°\n",
            "  åˆ†æä¸­ (38/545): 1616 å„„æ³°\n",
            "  åˆ†æä¸­ (39/545): 1618 åˆæ©Ÿ\n",
            "  åˆ†æä¸­ (40/545): 1710 æ±è¯\n",
            "  åˆ†æä¸­ (41/545): 1711 æ°¸å…‰\n",
            "  åˆ†æä¸­ (42/545): 1717 é•·èˆˆ\n",
            "  åˆ†æä¸­ (43/545): 1718 ä¸­çº–\n",
            "  åˆ†æä¸­ (44/545): 1721 ä¸‰æ™ƒ\n",
            "  åˆ†æä¸­ (45/545): 1722 å°è‚¥\n",
            "  åˆ†æä¸­ (46/545): 1727 ä¸­è¯åŒ–\n",
            "  åˆ†æä¸­ (47/545): 1786 ç§‘å¦\n",
            "  åˆ†æä¸­ (48/545): 1802 å°ç»\n",
            "  åˆ†æä¸­ (49/545): 1806 å† è»\n",
            "  åˆ†æä¸­ (50/545): 1808 æ½¤éš†\n",
            "  åˆ†æä¸­ (51/545): 1809 ä¸­é‡‰\n",
            "  åˆ†æä¸­ (52/545): 1810 å’Œæˆ\n",
            "  åˆ†æä¸­ (53/545): 1905 è¯ç´™\n",
            "  åˆ†æä¸­ (54/545): 1909 æ¦®æˆ\n",
            "  åˆ†æä¸­ (55/545): 2002 ä¸­é‹¼\n",
            "  åˆ†æä¸­ (56/545): 2009 ç¬¬ä¸€éŠ…\n",
            "  åˆ†æä¸­ (57/545): 2010 æ˜¥æº\n",
            "  åˆ†æä¸­ (58/545): 2014 ä¸­é´»\n",
            "  åˆ†æä¸­ (59/545): 2023 ç‡è¼\n",
            "  åˆ†æä¸­ (60/545): 2027 å¤§æˆé‹¼\n",
            "  åˆ†æä¸­ (61/545): 2034 å…å¼·\n",
            "  åˆ†æä¸­ (62/545): 2049 ä¸ŠéŠ€\n",
            "  åˆ†æä¸­ (63/545): 2101 å—æ¸¯\n",
            "  åˆ†æä¸­ (64/545): 2104 åœ‹éš›ä¸­æ©¡\n",
            "  åˆ†æä¸­ (65/545): 2105 æ­£æ–°\n",
            "  åˆ†æä¸­ (66/545): 2201 è£•éš†\n",
            "  åˆ†æä¸­ (67/545): 2204 ä¸­è¯\n",
            "  åˆ†æä¸­ (68/545): 2208 å°èˆ¹\n",
            "  åˆ†æä¸­ (69/545): 2211 é•·æ¦®é‹¼\n",
            "  åˆ†æä¸­ (70/545): 2228 åŠéºŸ\n",
            "  åˆ†æä¸­ (71/545): 2233 å®‡éš†\n",
            "  åˆ†æä¸­ (72/545): 2301 å…‰å¯¶ç§‘\n",
            "  åˆ†æä¸­ (73/545): 2303 è¯é›»\n",
            "  åˆ†æä¸­ (74/545): 2308 å°é”é›»\n",
            "  åˆ†æä¸­ (75/545): 2312 é‡‘å¯¶\n",
            "  åˆ†æä¸­ (76/545): 2313 è¯é€š\n",
            "  åˆ†æä¸­ (77/545): 2316 æ¥ æ¢“é›»\n",
            "  åˆ†æä¸­ (78/545): 2317 é´»æµ·\n",
            "  åˆ†æä¸­ (79/545): 2323 ä¸­ç’°\n",
            "  åˆ†æä¸­ (80/545): 2324 ä»å¯¶\n",
            "  åˆ†æä¸­ (81/545): 2327 åœ‹å·¨\n",
            "  åˆ†æä¸­ (82/545): 2328 å»£å®‡\n",
            "  åˆ†æä¸­ (83/545): 2329 è¯æ³°\n",
            "  åˆ†æä¸­ (84/545): 2330 å°ç©é›»\n",
            "  åˆ†æä¸­ (85/545): 2331 ç²¾è‹±\n",
            "  åˆ†æä¸­ (86/545): 2332 å‹è¨Š\n",
            "  åˆ†æä¸­ (87/545): 2337 æ—ºå®\n",
            "  åˆ†æä¸­ (88/545): 2338 å…‰ç½©\n",
            "  åˆ†æä¸­ (89/545): 2340 å°äº\n",
            "  åˆ†æä¸­ (90/545): 2344 è¯é‚¦é›»\n",
            "  åˆ†æä¸­ (91/545): 2345 æ™ºé‚¦\n",
            "  åˆ†æä¸­ (92/545): 2347 è¯å¼·\n",
            "  åˆ†æä¸­ (93/545): 2349 éŒ¸å¾·\n",
            "  åˆ†æä¸­ (94/545): 2351 é †å¾·\n",
            "  åˆ†æä¸­ (95/545): 2352 ä½³ä¸–é”\n",
            "  åˆ†æä¸­ (96/545): 2353 å®ï¿½ï¿½\n",
            "  åˆ†æä¸­ (97/545): 2354 é´»æº–\n",
            "  åˆ†æä¸­ (98/545): 2355 æ•¬éµ¬\n",
            "  åˆ†æä¸­ (99/545): 2356 è‹±æ¥­é”\n",
            "  åˆ†æä¸­ (100/545): 2357 è¯ç¢©\n",
            "  åˆ†æä¸­ (101/545): 2359 æ‰€ç¾…é–€\n",
            "  åˆ†æä¸­ (102/545): 2360 è‡´èŒ‚\n",
            "  åˆ†æä¸­ (103/545): 2363 çŸ½çµ±\n",
            "  åˆ†æä¸­ (104/545): 2365 æ˜†ç›ˆ\n",
            "  åˆ†æä¸­ (105/545): 2367 ç‡¿è¯\n",
            "  åˆ†æä¸­ (106/545): 2368 é‡‘åƒé›»\n",
            "  åˆ†æä¸­ (107/545): 2371 å¤§åŒ\n",
            "  åˆ†æä¸­ (108/545): 2374 ä½³èƒ½\n",
            "  åˆ†æä¸­ (109/545): 2376 æŠ€å˜‰\n",
            "  åˆ†æä¸­ (110/545): 2377 å¾®æ˜Ÿ\n",
            "  åˆ†æä¸­ (111/545): 2379 ç‘æ˜±\n",
            "  åˆ†æä¸­ (112/545): 2382 å»£é”\n",
            "  åˆ†æä¸­ (113/545): 2383 å°å…‰é›»\n",
            "  åˆ†æä¸­ (114/545): 2385 ç¾¤å…‰\n",
            "  åˆ†æä¸­ (115/545): 2388 å¨ç››\n",
            "  åˆ†æä¸­ (116/545): 2392 æ­£å´´\n",
            "  åˆ†æä¸­ (117/545): 2393 å„„å…‰\n",
            "  åˆ†æä¸­ (118/545): 2395 ç ”è¯\n",
            "  åˆ†æä¸­ (119/545): 2397 å‹é€š\n",
            "  åˆ†æä¸­ (120/545): 2401 å‡Œé™½\n",
            "  åˆ†æä¸­ (121/545): 2402 æ¯…å˜‰\n",
            "  åˆ†æä¸­ (122/545): 2404 æ¼¢å”\n",
            "  åˆ†æä¸­ (123/545): 2405 è¼”ä¿¡\n",
            "  åˆ†æä¸­ (124/545): 2406 åœ‹ç¢©\n",
            "  åˆ†æä¸­ (125/545): 2408 å—äºç§‘\n",
            "  åˆ†æä¸­ (126/545): 2409 å‹é”\n",
            "  åˆ†æä¸­ (127/545): 2412 ä¸­è¯é›»\n",
            "  åˆ†æä¸­ (128/545): 2417 åœ“å‰›\n",
            "  åˆ†æä¸­ (129/545): 2421 å»ºæº–\n",
            "  åˆ†æä¸­ (130/545): 2427 ä¸‰å•†é›»\n",
            "  åˆ†æä¸­ (131/545): 2429 éŠ˜æ—ºç§‘\n",
            "  åˆ†æä¸­ (132/545): 2431 è¯æ˜Œ\n",
            "  åˆ†æä¸­ (133/545): 2436 å‰è©®é›»\n",
            "  åˆ†æä¸­ (134/545): 2439 ç¾å¾‹\n",
            "  åˆ†æä¸­ (135/545): 2449 äº¬å…ƒé›»å­\n",
            "  åˆ†æä¸­ (136/545): 2451 å‰µè¦‹\n",
            "  åˆ†æä¸­ (137/545): 2453 å‡Œç¾¤\n",
            "  åˆ†æä¸­ (138/545): 2454 è¯ç™¼ç§‘\n",
            "  åˆ†æä¸­ (139/545): 2455 å…¨æ–°\n",
            "  åˆ†æä¸­ (140/545): 2457 é£›å®\n",
            "  åˆ†æä¸­ (141/545): 2458 ç¾©éš†\n",
            "  åˆ†æä¸­ (142/545): 2462 è‰¯å¾—é›»\n",
            "  åˆ†æä¸­ (143/545): 2464 ç›Ÿç«‹\n",
            "  åˆ†æä¸­ (144/545): 2466 å† è¥¿é›»\n",
            "  åˆ†æä¸­ (145/545): 2467 å¿—è–\n",
            "  åˆ†æä¸­ (146/545): 2468 è¯ç¶“\n",
            "  åˆ†æä¸­ (147/545): 2472 ç«‹éš†é›»\n",
            "  åˆ†æä¸­ (148/545): 2474 å¯æˆ\n",
            "  åˆ†æä¸­ (149/545): 2476 é‰…ç¥¥\n",
            "  åˆ†æä¸­ (150/545): 2481 å¼·èŒ‚\n",
            "  åˆ†æä¸­ (151/545): 2486 ä¸€è©®\n",
            "  åˆ†æä¸­ (152/545): 2489 ç‘è»’\n",
            "  åˆ†æä¸­ (153/545): 2492 è¯æ–°ç§‘\n",
            "  åˆ†æä¸­ (154/545): 2493 æšåš\n",
            "  åˆ†æä¸­ (155/545): 2498 å®é”é›»\n",
            "  åˆ†æä¸­ (156/545): 2501 åœ‹å»º\n",
            "  åˆ†æä¸­ (157/545): 2504 åœ‹ç”¢\n",
            "  åˆ†æä¸­ (158/545): 2515 ä¸­å·¥\n",
            "  åˆ†æä¸­ (159/545): 2520 å† å¾·\n",
            "  åˆ†æä¸­ (160/545): 2542 èˆˆå¯Œç™¼\n",
            "  åˆ†æä¸­ (161/545): 2543 çš‡æ˜Œ\n",
            "  åˆ†æä¸­ (162/545): 2547 æ—¥å‹ç”Ÿ\n",
            "  åˆ†æä¸­ (163/545): 2548 è¯å›º\n",
            "  åˆ†æä¸­ (164/545): 2601 ç›Šèˆª\n",
            "  åˆ†æä¸­ (165/545): 2603 é•·æ¦®\n",
            "  åˆ†æä¸­ (166/545): 2605 æ–°èˆˆ\n",
            "  åˆ†æä¸­ (167/545): 2606 è£•æ°‘\n",
            "  åˆ†æä¸­ (168/545): 2607 æ¦®é‹\n",
            "  åˆ†æä¸­ (169/545): 2609 é™½æ˜\n",
            "  åˆ†æä¸­ (170/545): 2610 è¯èˆª\n",
            "  åˆ†æä¸­ (171/545): 2612 ä¸­èˆª\n",
            "  åˆ†æä¸­ (172/545): 2615 è¬æµ·\n",
            "  åˆ†æä¸­ (173/545): 2618 é•·æ¦®èˆª\n",
            "  åˆ†æä¸­ (174/545): 2630 äºèˆª\n",
            "  åˆ†æä¸­ (175/545): 2633 å°ç£é«˜éµ\n",
            "  åˆ†æä¸­ (176/545): 2634 æ¼¢ç¿”\n",
            "  åˆ†æä¸­ (177/545): 2637 æ…§æ´‹-KY\n",
            "  åˆ†æä¸­ (178/545): 2645 é•·æ¦®èˆªå¤ª\n",
            "  åˆ†æä¸­ (179/545): 2646 æ˜Ÿå®‡èˆªç©º\n",
            "  åˆ†æä¸­ (180/545): 2731 é›„ç…\n",
            "  åˆ†æä¸­ (181/545): 2801 å½°éŠ€\n",
            "  åˆ†æä¸­ (182/545): 2809 äº¬åŸéŠ€\n",
            "  åˆ†æä¸­ (183/545): 2812 å°ä¸­éŠ€\n",
            "  åˆ†æä¸­ (184/545): 2834 è‡ºä¼éŠ€\n",
            "  åˆ†æä¸­ (185/545): 2836 é«˜é›„éŠ€\n",
            "  åˆ†æä¸­ (186/545): 2838 è¯é‚¦éŠ€\n",
            "  åˆ†æä¸­ (187/545): 2845 é æ±éŠ€\n",
            "  åˆ†æä¸­ (188/545): 2851 ä¸­å†ä¿\n",
            "  åˆ†æä¸­ (189/545): 2855 çµ±ä¸€è­‰\n",
            "  åˆ†æä¸­ (190/545): 2867 ä¸‰å•†å£½\n",
            "  åˆ†æä¸­ (191/545): 2880 è¯å—é‡‘\n",
            "  åˆ†æä¸­ (192/545): 2881 å¯Œé‚¦é‡‘\n",
            "  åˆ†æä¸­ (193/545): 2882 åœ‹æ³°é‡‘\n",
            "  åˆ†æä¸­ (194/545): 2883 å‡±åŸºé‡‘\n",
            "  åˆ†æä¸­ (195/545): 2884 ç‰å±±é‡‘\n",
            "  åˆ†æä¸­ (196/545): 2885 å…ƒå¤§é‡‘\n",
            "  åˆ†æä¸­ (197/545): 2886 å…†è±é‡‘\n",
            "  åˆ†æä¸­ (198/545): 2887 å°æ–°é‡‘\n",
            "  åˆ†æä¸­ (199/545): 2889 åœ‹ç¥¨é‡‘\n",
            "  åˆ†æä¸­ (200/545): 2890 æ°¸è±é‡‘\n",
            "  åˆ†æä¸­ (201/545): 2891 ä¸­ä¿¡é‡‘\n",
            "  åˆ†æä¸­ (202/545): 2892 ç¬¬ä¸€é‡‘\n",
            "  åˆ†æä¸­ (203/545): 2897 ç‹é“éŠ€è¡Œ\n",
            "  åˆ†æä¸­ (204/545): 2903 é ç™¾\n",
            "  åˆ†æä¸­ (205/545): 2912 çµ±ä¸€è¶…\n",
            "  åˆ†æä¸­ (206/545): 2913 è¾²æ—\n",
            "  åˆ†æä¸­ (207/545): 2915 æ½¤æ³°å…¨\n",
            "  åˆ†æä¸­ (208/545): 3004 è±é”ç§‘\n",
            "  åˆ†æä¸­ (209/545): 3005 ç¥åŸº\n",
            "  åˆ†æä¸­ (210/545): 3006 æ™¶è±ªç§‘\n",
            "  åˆ†æä¸­ (211/545): 3010 è¯ç«‹\n",
            "  åˆ†æä¸­ (212/545): 3011 ä»Šçš“\n",
            "  åˆ†æä¸­ (213/545): 3013 æ™ŸéŠ˜é›»\n",
            "  åˆ†æä¸­ (214/545): 3016 å˜‰æ™¶\n",
            "  åˆ†æä¸­ (215/545): 3017 å¥‡é‹\n",
            "  åˆ†æä¸­ (216/545): 3019 äºå…‰\n",
            "  åˆ†æä¸­ (217/545): 3022 å¨å¼·é›»\n",
            "  åˆ†æä¸­ (218/545): 3023 ä¿¡é‚¦\n",
            "  åˆ†æä¸­ (219/545): 3029 é›¶å£¹\n",
            "  åˆ†æä¸­ (220/545): 3030 å¾·å¾‹\n",
            "  åˆ†æä¸­ (221/545): 3032 å‰è¨“\n",
            "  åˆ†æä¸­ (222/545): 3033 å¨å¥\n",
            "  åˆ†æä¸­ (223/545): 3034 è¯è© \n",
            "  åˆ†æä¸­ (224/545): 3035 æ™ºåŸ\n",
            "  åˆ†æä¸­ (225/545): 3036 æ–‡æ›„\n",
            "  åˆ†æä¸­ (226/545): 3037 æ¬£èˆˆ\n",
            "  åˆ†æä¸­ (227/545): 3040 é è¦‹\n",
            "  åˆ†æä¸­ (228/545): 3041 æšæ™º\n",
            "  åˆ†æä¸­ (229/545): 3042 æ™¶æŠ€\n",
            "  åˆ†æä¸­ (230/545): 3044 å¥é¼\n",
            "  åˆ†æä¸­ (231/545): 3045 å°ç£å¤§\n",
            "  åˆ†æä¸­ (232/545): 3047 è¨ŠèˆŸ\n",
            "  åˆ†æä¸­ (233/545): 3052 å¤†å…¸\n",
            "  åˆ†æä¸­ (234/545): 3056 å¯Œè¯æ–°\n",
            "  åˆ†æä¸­ (235/545): 3059 è¯æ™¶ç§‘\n",
            "  åˆ†æä¸­ (236/545): 3062 å»ºæ¼¢\n",
            "  åˆ†æä¸­ (237/545): 3090 æ—¥é›»è²¿\n",
            "  åˆ†æä¸­ (238/545): 3167 å¤§é‡\n",
            "  åˆ†æä¸­ (239/545): 3189 æ™¯ç¢©\n",
            "  åˆ†æä¸­ (240/545): 3231 ç·¯å‰µ\n",
            "  åˆ†æä¸­ (241/545): 3305 æ˜‡è²¿\n",
            "  åˆ†æä¸­ (242/545): 3311 é–æš‰\n",
            "  åˆ†æä¸­ (243/545): 3338 æ³°ç¢©\n",
            "  åˆ†æä¸­ (244/545): 3376 æ–°æ—¥èˆˆ\n",
            "  åˆ†æä¸­ (245/545): 3416 èç¨‹é›»\n",
            "  åˆ†æä¸­ (246/545): 3443 å‰µæ„\n",
            "  åˆ†æä¸­ (247/545): 3447 å±•é”\n",
            "  åˆ†æä¸­ (248/545): 3450 è¯éˆ\n",
            "  åˆ†æä¸­ (249/545): 3481 ç¾¤å‰µ\n",
            "  åˆ†æä¸­ (250/545): 3515 è¯æ“\n",
            "  åˆ†æä¸­ (251/545): 3528 å®‰é¦³\n",
            "  åˆ†æä¸­ (252/545): 3532 å°å‹ç§‘\n",
            "  åˆ†æä¸­ (253/545): 3535 æ™¶å½©ç§‘\n",
            "  åˆ†æä¸­ (254/545): 3543 å·å·§\n",
            "  åˆ†æä¸­ (255/545): 3545 æ•¦æ³°\n",
            "  åˆ†æä¸­ (256/545): 3563 ç‰§å¾·\n",
            "  åˆ†æä¸­ (257/545): 3576 è¯åˆå†ç”Ÿ\n",
            "  åˆ†æä¸­ (258/545): 3583 è¾›è€˜\n",
            "  åˆ†æä¸­ (259/545): 3596 æ™ºæ˜“\n",
            "  åˆ†æä¸­ (260/545): 3605 å®è‡´\n",
            "  åˆ†æä¸­ (261/545): 3617 ç¢©å¤©\n",
            "  åˆ†æä¸­ (262/545): 3645 é”é‚\n",
            "  åˆ†æä¸­ (263/545): 3653 å¥ç­–\n",
            "  åˆ†æä¸­ (264/545): 3661 ä¸–èŠ¯-KY\n",
            "  åˆ†æä¸­ (265/545): 3665 è²¿è¯-KY\n",
            "  åˆ†æä¸­ (266/545): 3673 TPK-KY\n",
            "  åˆ†æä¸­ (267/545): 3694 æµ·è¯\n",
            "  åˆ†æä¸­ (268/545): 3702 å¤§è¯å¤§\n",
            "  åˆ†æä¸­ (269/545): 3704 åˆå‹¤æ§\n",
            "  åˆ†æä¸­ (270/545): 3706 ç¥é”\n",
            "  åˆ†æä¸­ (271/545): 3708 ä¸Šç·¯æŠ•æ§\n",
            "  åˆ†æä¸­ (272/545): 3711 æ—¥æœˆå…‰æŠ•æ§\n",
            "  åˆ†æä¸­ (273/545): 3712 æ°¸å´´æŠ•æ§\n",
            "  åˆ†æä¸­ (274/545): 3714 å¯Œé‡‡\n",
            "  åˆ†æä¸­ (275/545): 3715 å®šç©æŠ•æ§\n",
            "  åˆ†æä¸­ (276/545): 4164 æ‰¿æ¥­é†«\n",
            "  åˆ†æä¸­ (277/545): 4526 æ±å°\n",
            "  åˆ†æä¸­ (278/545): 4532 ç‘æ™º\n",
            "  åˆ†æä¸­ (279/545): 4540 å…¨çƒå‚³å‹•\n",
            "  åˆ†æä¸­ (280/545): 4551 æ™ºä¼¸ç§‘\n",
            "  åˆ†æä¸­ (281/545): 4562 ç©æ¼¢\n",
            "  åˆ†æä¸­ (282/545): 4576 å¤§éŠ€å¾®ç³»çµ±\n",
            "  åˆ†æä¸­ (283/545): 4722 åœ‹ç²¾åŒ–\n",
            "  åˆ†æä¸­ (284/545): 4739 åº·æ™®\n",
            "  åˆ†æä¸­ (285/545): 4763 ææ–™*-KY\n",
            "  åˆ†æä¸­ (286/545): 4770 ä¸Šå“\n",
            "  åˆ†æä¸­ (287/545): 4904 é å‚³\n",
            "  åˆ†æä¸­ (288/545): 4906 æ­£æ–‡\n",
            "  åˆ†æä¸­ (289/545): 4915 è‡´ä¼¸\n",
            "  åˆ†æä¸­ (290/545): 4916 äº‹æ¬£ç§‘\n",
            "  åˆ†æä¸­ (291/545): 4919 æ–°å”\n",
            "  åˆ†æä¸­ (292/545): 4927 æ³°é¼-KY\n",
            "  åˆ†æä¸­ (293/545): 4938 å’Œç¢©\n",
            "  åˆ†æä¸­ (294/545): 4949 æœ‰æˆç²¾å¯†\n",
            "  åˆ†æä¸­ (295/545): 4958 è‡»é¼-KY\n",
            "  åˆ†æä¸­ (296/545): 4960 èª ç¾æ\n",
            "  åˆ†æä¸­ (297/545): 4968 ç«‹ç©\n",
            "  åˆ†æä¸­ (298/545): 4977 çœ¾é”-KY\n",
            "  åˆ†æä¸­ (299/545): 4989 æ¦®ç§‘\n",
            "  åˆ†æä¸­ (300/545): 5234 é”èˆˆææ–™\n",
            "  åˆ†æä¸­ (301/545): 5243 ä¹™ç››-KY\n",
            "  åˆ†æä¸­ (302/545): 5244 å¼˜å‡±\n",
            "  åˆ†æä¸­ (303/545): 5284 jpp-KY\n",
            "  åˆ†æä¸­ (304/545): 5388 ä¸­ç£Š\n",
            "  åˆ†æä¸­ (305/545): 5469 ç€šå®‡åš\n",
            "  åˆ†æä¸­ (306/545): 5531 é„‰æ—\n",
            "  åˆ†æä¸­ (307/545): 5608 å››ç¶­èˆª\n",
            "  åˆ†æä¸­ (308/545): 5871 ä¸­ç§Ÿ-KY\n",
            "  åˆ†æä¸­ (309/545): 5876 ä¸Šæµ·å•†éŠ€\n",
            "  åˆ†æä¸­ (310/545): 5880 åˆåº«é‡‘\n",
            "  åˆ†æä¸­ (311/545): 6005 ç¾¤ç›Šè­‰\n",
            "  åˆ†æä¸­ (312/545): 6112 é‚é”ç‰¹\n",
            "  åˆ†æä¸­ (313/545): 6116 å½©æ™¶\n",
            "  åˆ†æä¸­ (314/545): 6117 è¿å»£\n",
            "  åˆ†æä¸­ (315/545): 6120 é”é‹\n",
            "  åˆ†æä¸­ (316/545): 6133 é‡‘æ©‹\n",
            "  åˆ†æä¸­ (317/545): 6139 äºç¿”\n",
            "  åˆ†æä¸­ (318/545): 6141 æŸæ‰¿\n",
            "  åˆ†æä¸­ (319/545): 6153 å˜‰è¯ç›Š\n",
            "  åˆ†æä¸­ (320/545): 6166 å‡Œè¯\n",
            "  åˆ†æä¸­ (321/545): 6176 ç‘å„€\n",
            "  åˆ†æä¸­ (322/545): 6177 é”éº—\n",
            "  åˆ†æä¸­ (323/545): 6189 è±è—\n",
            "  åˆ†æä¸­ (324/545): 6191 ç²¾æˆç§‘\n",
            "  åˆ†æä¸­ (325/545): 6196 å¸†å®£\n",
            "  åˆ†æä¸­ (326/545): 6197 ä½³å¿…çª\n",
            "  åˆ†æä¸­ (327/545): 6206 é£›æ·\n",
            "  åˆ†æä¸­ (328/545): 6209 ä»Šåœ‹å…‰\n",
            "  åˆ†æä¸­ (329/545): 6213 è¯èŒ‚\n",
            "  åˆ†æä¸­ (330/545): 6215 å’Œæ¤¿\n",
            "  åˆ†æä¸­ (331/545): 6239 åŠ›æˆ\n",
            "  åˆ†æä¸­ (332/545): 6257 çŸ½æ ¼\n",
            "  åˆ†æä¸­ (333/545): 6269 å°éƒ¡\n",
            "  åˆ†æä¸­ (334/545): 6271 åŒæ¬£é›»\n",
            "  åˆ†æä¸­ (335/545): 6278 å°è¡¨ç§‘\n",
            "  åˆ†æä¸­ (336/545): 6282 åº·èˆ’\n",
            "  åˆ†æä¸­ (337/545): 6285 å•Ÿï¿½ï¿½\n",
            "  åˆ†æä¸­ (338/545): 6412 ç¾¤é›»\n",
            "  åˆ†æä¸­ (339/545): 6415 çŸ½åŠ›*-KY\n",
            "  åˆ†æä¸­ (340/545): 6438 è¿…å¾—\n",
            "  åˆ†æä¸­ (341/545): 6442 å…‰è–\n",
            "  åˆ†æä¸­ (342/545): 6443 å…ƒæ™¶\n",
            "  åˆ†æä¸­ (343/545): 6446 è—¥è¯è—¥\n",
            "  åˆ†æä¸­ (344/545): 6451 è¨ŠèŠ¯-KY\n",
            "  åˆ†æä¸­ (345/545): 6472 ä¿ç‘\n",
            "  åˆ†æä¸­ (346/545): 6477 å®‰é›†\n",
            "  åˆ†æä¸­ (347/545): 6505 å°å¡‘åŒ–\n",
            "  åˆ†æä¸­ (348/545): 6515 ç©å´´\n",
            "  åˆ†æä¸­ (349/545): 6531 æ„›æ™®*\n",
            "  åˆ†æä¸­ (350/545): 6558 èˆˆèƒ½é«˜\n",
            "  åˆ†æä¸­ (351/545): 6591 å‹•åŠ›-KY\n",
            "  åˆ†æä¸­ (352/545): 6625 å¿…æ‡‰\n",
            "  åˆ†æä¸­ (353/545): 6658 è¯ç­–\n",
            "  åˆ†æä¸­ (354/545): 6669 ç·¯ç©\n",
            "  åˆ†æä¸­ (355/545): 6672 é¨°è¼é›»å­-KY\n",
            "  åˆ†æä¸­ (356/545): 6691 æ´‹åŸºå·¥ç¨‹\n",
            "  åˆ†æä¸­ (357/545): 6695 èŠ¯é¼\n",
            "  åˆ†æä¸­ (358/545): 6706 æƒ ç‰¹\n",
            "  åˆ†æä¸­ (359/545): 6742 æ¾¤ç±³\n",
            "  åˆ†æä¸­ (360/545): 6753 é¾å¾·é€ èˆ¹\n",
            "  åˆ†æä¸­ (361/545): 6757 å°ç£è™èˆª\n",
            "  åˆ†æä¸­ (362/545): 6768 å¿—å¼·-KY\n",
            "  åˆ†æä¸­ (363/545): 6770 åŠ›ç©é›»\n",
            "  åˆ†æä¸­ (364/545): 6781 AES-KY\n",
            "  åˆ†æä¸­ (365/545): 6789 é‡‡éˆº\n",
            "  åˆ†æä¸­ (366/545): 6805 å¯Œä¸–é”\n",
            "  åˆ†æä¸­ (367/545): 6806 æ£®å´´èƒ½æº\n",
            "  åˆ†æä¸­ (368/545): 6890 ä¾†å„„-KY\n",
            "  åˆ†æä¸­ (369/545): 6919 åº·éœˆ*\n",
            "  åˆ†æä¸­ (370/545): 6928 æ”¸æ³°ç§‘æŠ€\n",
            "  åˆ†æä¸­ (371/545): 6962 å¥•åŠ›-KY\n",
            "  åˆ†æä¸­ (372/545): 8011 å°é€š\n",
            "  åˆ†æä¸­ (373/545): 8021 å°–é»\n",
            "  åˆ†æä¸­ (374/545): 8028 æ˜‡é™½åŠå°é«”\n",
            "  åˆ†æä¸­ (375/545): 8033 é›·è™\n",
            "  åˆ†æä¸­ (376/545): 8039 å°è™¹\n",
            "  åˆ†æä¸­ (377/545): 8046 å—é›»\n",
            "  åˆ†æä¸­ (378/545): 8070 é•·è¯*\n",
            "  åˆ†æä¸­ (379/545): 8072 é™æ³°\n",
            "  åˆ†æä¸­ (380/545): 8103 ç€šèƒ\n",
            "  åˆ†æä¸­ (381/545): 8104 éŒ¸å¯¶\n",
            "  åˆ†æä¸­ (382/545): 8105 å‡Œå·¨\n",
            "  åˆ†æä¸­ (383/545): 8110 è¯æ±\n",
            "  åˆ†æä¸­ (384/545): 8112 è‡³ä¸Š\n",
            "  åˆ†æä¸­ (385/545): 8150 å—èŒ‚\n",
            "  åˆ†æä¸­ (386/545): 8210 å‹¤èª \n",
            "  åˆ†æä¸­ (387/545): 8222 å¯¶ä¸€\n",
            "  åˆ†æä¸­ (388/545): 8249 è±å…‰\n",
            "  åˆ†æä¸­ (389/545): 8271 å®‡ç»\n",
            "  åˆ†æä¸­ (390/545): 8374 ç¾…æ˜‡\n",
            "  åˆ†æä¸­ (391/545): 8478 æ±å“¥éŠè‰‡\n",
            "  åˆ†æä¸­ (392/545): 8926 å°æ±½é›»\n",
            "  åˆ†æä¸­ (393/545): 8996 é«˜åŠ›\n",
            "  åˆ†æä¸­ (394/545): 9802 éˆºé½Š-KY\n",
            "  åˆ†æä¸­ (395/545): 9904 å¯¶æˆ\n",
            "  åˆ†æä¸­ (396/545): 9907 çµ±ä¸€å¯¦\n",
            "  åˆ†æä¸­ (397/545): 9914 ç¾åˆ©é”\n",
            "  åˆ†æä¸­ (398/545): 9933 ä¸­é¼\n",
            "  åˆ†æä¸­ (399/545): 9938 ç™¾å’Œ\n",
            "  åˆ†æä¸­ (400/545): 9945 æ½¤æ³°æ–°\n",
            "  åˆ†æä¸­ (401/545): 9958 ä¸–ç´€é‹¼\n",
            "  åˆ†æä¸­ (402/545): 0050 å…ƒå¤§å°ç£50\n",
            "  åˆ†æä¸­ (403/545): 0056 å…ƒå¤§é«˜è‚¡æ¯\n",
            "  åˆ†æä¸­ (404/545): 9105 æ³°é‡‘å¯¶-DR\n",
            "  åˆ†æä¸­ (405/545): 1295 ç”Ÿåˆ\n",
            "  åˆ†æä¸­ (406/545): 1569 æ¿±å·\n",
            "  åˆ†æä¸­ (407/545): 1785 å…‰æ´‹ç§‘\n",
            "  åˆ†æä¸­ (408/545): 1815 å¯Œå–¬\n",
            "  åˆ†æä¸­ (409/545): 2641 æ­£å¾·\n",
            "  åˆ†æä¸­ (410/545): 2743 å±±å¯Œ\n",
            "  åˆ†æä¸­ (411/545): 2745 äº”ç¦\n",
            "  åˆ†æä¸­ (412/545): 3078 åƒ‘å¨\n",
            "  åˆ†æä¸­ (413/545): 3081 è¯äº\n",
            "  åˆ†æä¸­ (414/545): 3105 ç©©æ‡‹\n",
            "  åˆ†æä¸­ (415/545): 3128 æ˜‡éŠ³\n",
            "  åˆ†æä¸­ (416/545): 3163 æ³¢è‹¥å¨\n",
            "  åˆ†æä¸­ (417/545): 3211 é †é”\n",
            "  åˆ†æä¸­ (418/545): 3213 èŒ‚è¨Š\n",
            "  åˆ†æä¸­ (419/545): 3217 å„ªç¾¤\n",
            "  åˆ†æä¸­ (420/545): 3219 å€šå¼·ç§‘\n",
            "  åˆ†æä¸­ (421/545): 3227 åŸç›¸\n",
            "  åˆ†æä¸­ (422/545): 3230 éŒ¦æ˜\n",
            "  åˆ†æä¸­ (423/545): 3260 å¨å‰›\n",
            "  åˆ†æä¸­ (424/545): 3264 æ¬£éŠ“\n",
            "  åˆ†æä¸­ (425/545): 3289 å®œç‰¹\n",
            "  åˆ†æä¸­ (426/545): 3293 éˆŠè±¡\n",
            "  åˆ†æä¸­ (427/545): 3294 è‹±æ¿Ÿ\n",
            "  åˆ†æä¸­ (428/545): 3297 æ­ç‰¹\n",
            "  åˆ†æä¸­ (429/545): 3323 åŠ ç™¾è£•\n",
            "  åˆ†æä¸­ (430/545): 3324 é›™é´»\n",
            "  åˆ†æä¸­ (431/545): 3339 æ³°è°·\n",
            "  åˆ†æä¸­ (432/545): 3363 ä¸Šè©®\n",
            "  åˆ†æä¸­ (433/545): 3374 ç²¾æ\n",
            "  åˆ†æä¸­ (434/545): 3379 å½¬å°\n",
            "  åˆ†æä¸­ (435/545): 3434 å“²å›º\n",
            "  åˆ†æä¸­ (436/545): 3491 æ˜‡é”ç§‘\n",
            "  åˆ†æä¸­ (437/545): 3498 é™½ç¨‹\n",
            "  åˆ†æä¸­ (438/545): 3546 å®‡å³»\n",
            "  åˆ†æä¸­ (439/545): 3551 ä¸–ç¦¾\n",
            "  åˆ†æä¸­ (440/545): 3577 æ³“æ ¼\n",
            "  åˆ†æä¸­ (441/545): 3587 é–åº·\n",
            "  åˆ†æä¸­ (442/545): 3630 æ–°é‰…ç§‘\n",
            "  åˆ†æä¸­ (443/545): 3663 é‘«ç§‘\n",
            "  åˆ†æä¸­ (444/545): 3680 å®¶ç™»\n",
            "  åˆ†æä¸­ (445/545): 3689 æ¹§å¾·\n",
            "  åˆ†æä¸­ (446/545): 3707 æ¼¢ç£Š\n",
            "  åˆ†æä¸­ (447/545): 3709 é‘«è¯å¤§æŠ•æ§\n",
            "  åˆ†æä¸­ (448/545): 4114 å¥å–¬\n",
            "  åˆ†æä¸­ (449/545): 4128 ä¸­å¤©\n",
            "  åˆ†æä¸­ (450/545): 4174 æµ©é¼\n",
            "  åˆ†æä¸­ (451/545): 4303 ä¿¡ç«‹\n",
            "  åˆ†æä¸­ (452/545): 4503 é‡‘é›¨\n",
            "  åˆ†æä¸­ (453/545): 4510 é«˜é‹’\n",
            "  åˆ†æä¸­ (454/545): 4541 æ™Ÿç”°\n",
            "  åˆ†æä¸­ (455/545): 4714 æ°¸æ·\n",
            "  åˆ†æä¸­ (456/545): 4721 ç¾çªç‘ª\n",
            "  åˆ†æä¸­ (457/545): 4729 ç†’èŒ‚\n",
            "  åˆ†æä¸­ (458/545): 4743 åˆä¸€\n",
            "  åˆ†æä¸­ (459/545): 4749 æ–°æ‡‰æ\n",
            "  åˆ†æä¸­ (460/545): 4760 å‹¤å‡±\n",
            "  åˆ†æä¸­ (461/545): 4772 å°ç‰¹åŒ–\n",
            "  åˆ†æä¸­ (462/545): 4903 è¯å…‰é€š\n",
            "  åˆ†æä¸­ (463/545): 4908 å‰é¼\n",
            "  åˆ†æä¸­ (464/545): 4909 æ–°å¾©èˆˆ\n",
            "  åˆ†æä¸­ (465/545): 4931 æ–°ç››åŠ›\n",
            "  åˆ†æä¸­ (466/545): 4966 è­œç‘-KY\n",
            "  åˆ†æä¸­ (467/545): 4971 IET-KY\n",
            "  åˆ†æä¸­ (468/545): 4979 è¯æ˜Ÿå…‰\n",
            "  åˆ†æä¸­ (469/545): 4991 ç’°å®‡-KY\n",
            "  åˆ†æä¸­ (470/545): 5009 æ¦®å‰›\n",
            "  åˆ†æä¸­ (471/545): 5201 å‡±è¡›\n",
            "  åˆ†æä¸­ (472/545): 5251 å¤©é‰é›»\n",
            "  åˆ†æä¸­ (473/545): 5278 å°šå‡¡*\n",
            "  åˆ†æä¸­ (474/545): 5309 ç³»çµ±é›»\n",
            "  åˆ†æä¸­ (475/545): 5314 ä¸–ç´€*\n",
            "  åˆ†æä¸­ (476/545): 5340 å»ºæ¦®\n",
            "  åˆ†æä¸­ (477/545): 5347 ä¸–ç•Œ\n",
            "  åˆ†æä¸­ (478/545): 5351 éˆºå‰µ\n",
            "  åˆ†æä¸­ (479/545): 5371 ä¸­å…‰é›»\n",
            "  åˆ†æä¸­ (480/545): 5381 åˆæ­£\n",
            "  åˆ†æä¸­ (481/545): 5392 èƒ½ç‡\n",
            "  åˆ†æä¸­ (482/545): 5425 å°åŠ\n",
            "  åˆ†æä¸­ (483/545): 5426 æŒ¯ç™¼\n",
            "  åˆ†æä¸­ (484/545): 5439 é«˜æŠ€\n",
            "  åˆ†æä¸­ (485/545): 5443 å‡è±ª\n",
            "  åˆ†æä¸­ (486/545): 5465 å¯Œé©Š\n",
            "  åˆ†æä¸­ (487/545): 5475 å¾·å®\n",
            "  åˆ†æä¸­ (488/545): 5483 ä¸­ç¾æ™¶\n",
            "  åˆ†æä¸­ (489/545): 5490 åŒäº¨\n",
            "  åˆ†æä¸­ (490/545): 5498 å‡±å´´\n",
            "  åˆ†æä¸­ (491/545): 5536 è–æš‰*\n",
            "  åˆ†æä¸­ (492/545): 6016 åº·å’Œè­‰\n",
            "  åˆ†æä¸­ (493/545): 6104 å‰µæƒŸ\n",
            "  åˆ†æä¸­ (494/545): 6125 å»£é‹\n",
            "  åˆ†æä¸­ (495/545): 6127 ä¹è±ª\n",
            "  åˆ†æä¸­ (496/545): 6134 è¬æ—­\n",
            "  åˆ†æä¸­ (497/545): 6140 è¨Šé”\n",
            "  åˆ†æä¸­ (498/545): 6147 é é‚¦\n",
            "  åˆ†æä¸­ (499/545): 6148 é©Šå®è³‡\n",
            "  åˆ†æä¸­ (500/545): 6156 æ¾ä¸Š\n",
            "  åˆ†æä¸­ (501/545): 6179 äºé€š\n",
            "  åˆ†æä¸­ (502/545): 6182 åˆæ™¶\n",
            "  åˆ†æä¸­ (503/545): 6187 è¬æ½¤\n",
            "  åˆ†æä¸­ (504/545): 6188 å»£æ˜\n",
            "  åˆ†æä¸­ (505/545): 6190 è¬æ³°ç§‘\n",
            "  åˆ†æä¸­ (506/545): 6207 é›·ç§‘\n",
            "  åˆ†æä¸­ (507/545): 6217 ä¸­æ¢é‡\n",
            "  åˆ†æä¸­ (508/545): 6223 æ—ºçŸ½\n",
            "  åˆ†æä¸­ (509/545): 6227 èŒ‚ç¶¸\n",
            "  åˆ†æä¸­ (510/545): 6234 é«˜åƒ‘\n",
            "  åˆ†æä¸­ (511/545): 6244 èŒ‚è¿ª\n",
            "  åˆ†æä¸­ (512/545): 6274 å°ç‡¿\n",
            "  åˆ†æä¸­ (513/545): 6290 è‰¯ç¶­\n",
            "  åˆ†æä¸­ (514/545): 6425 æ˜“ç™¼\n",
            "  åˆ†æä¸­ (515/545): 6462 ç¥ç›¾\n",
            "  åˆ†æä¸­ (516/545): 6488 ç’°çƒæ™¶\n",
            "  åˆ†æä¸­ (517/545): 6499 ç›Šå®‰\n",
            "  åˆ†æä¸­ (518/545): 6517 ä¿å‹å…‰å­¸\n",
            "  åˆ†æä¸­ (519/545): 6530 å‰µå¨\n",
            "  åˆ†æä¸­ (520/545): 6532 ç‘è€˜\n",
            "  åˆ†æä¸­ (521/545): 6584 å—ä¿Šåœ‹éš›\n",
            "  åˆ†æä¸­ (522/545): 6596 å¯¬å®è—è¡“\n",
            "  åˆ†æä¸­ (523/545): 6667 ä¿¡ç´˜ç§‘\n",
            "  åˆ†æä¸­ (524/545): 6763 ç¶ ç•Œç§‘æŠ€*\n",
            "  åˆ†æä¸­ (525/545): 6788 è¯æ™¯é›»\n",
            "  åˆ†æä¸­ (526/545): 6925 æ„è—\n",
            "  åˆ†æä¸­ (527/545): 7402 é‚‘éŒ¡\n",
            "  åˆ†æä¸­ (528/545): 8038 é•·åœ’ç§‘\n",
            "  åˆ†æä¸­ (529/545): 8043 èœœæœ›å¯¦\n",
            "  åˆ†æä¸­ (530/545): 8054 å®‰åœ‹\n",
            "  åˆ†æä¸­ (531/545): 8059 å‡±ç¢©\n",
            "  åˆ†æä¸­ (532/545): 8064 æ±æ·\n",
            "  åˆ†æä¸­ (533/545): 8069 å…ƒå¤ª\n",
            "  åˆ†æä¸­ (534/545): 8074 é‰…æ©¡\n",
            "  åˆ†æä¸­ (535/545): 8086 å®æ·ç§‘\n",
            "  åˆ†æä¸­ (536/545): 8088 å“å®‰\n",
            "  åˆ†æä¸­ (537/545): 8096 æ“äº\n",
            "  åˆ†æä¸­ (538/545): 8111 ç«‹ï¿½ï¿½\n",
            "  åˆ†æä¸­ (539/545): 8155 åšæ™º\n",
            "  åˆ†æä¸­ (540/545): 8227 å·¨æœ‰ç§‘æŠ€\n",
            "  åˆ†æä¸­ (541/545): 8234 æ–°æ¼¢\n",
            "  åˆ†æä¸­ (542/545): 8299 ç¾¤è¯\n",
            "  åˆ†æä¸­ (543/545): 8358 é‡‘å±…\n",
            "  åˆ†æä¸­ (544/545): 8932 æ™ºé€š*\n",
            "  åˆ†æä¸­ (545/545): 8936 åœ‹çµ±\n",
            "\n",
            "åˆ†æå®Œæˆ: æˆåŠŸ 545 æ”¯ï¼Œå¤±æ•— 0 æ”¯\n",
            "\n",
            "[éšæ®µ5/7] ç¯©é¸é ‚å°–å€‹è‚¡ä¸¦ç”Ÿæˆå ±å‘Šèˆ‡å»ºè­°...\n",
            "âœ… å·²ç¯©é¸å‡ºåˆ†æ•¸æœ€é«˜çš„ 10 æ”¯è‚¡ç¥¨é€²è¡Œæœ€çµ‚å ±å‘Šã€‚\n",
            "  è™•ç†ä¸­ (1/10): 1316\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "  è™•ç†ä¸­ (1/10): 1409\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "  è™•ç†ä¸­ (1/10): 1528\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "  è™•ç†ä¸­ (1/10): 1618\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "  è™•ç†ä¸­ (1/10): 1711\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "  è™•ç†ä¸­ (1/10): 1717\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "  è™•ç†ä¸­ (1/10): 1802\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "  è™•ç†ä¸­ (1/10): 1806\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "  è™•ç†ä¸­ (1/10): 1809\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "  è™•ç†ä¸­ (1/10): 1810\n",
            "    combined_score: 54 (type: <class 'int'>)\n",
            "    report_summary: True\n",
            "\n",
            "ğŸ† å‰ 10 åæ¨è–¦è‚¡ç¥¨:\n",
            "================================================================================\n",
            " 1. 1316 ä¸Šæ›œ\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "    ä¿¡å¿ƒåº¦: 13%\n",
            "--------------------------------------------------------------------------------\n",
            " 2. 1409 æ–°çº–\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "    ä¿¡å¿ƒåº¦: 13%\n",
            "--------------------------------------------------------------------------------\n",
            " 3. 1528 æ©å¾·\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "    ä¿¡å¿ƒåº¦: 8%\n",
            "--------------------------------------------------------------------------------\n",
            " 4. 1618 åˆæ©Ÿ\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "    ä¿¡å¿ƒåº¦: 13%\n",
            "--------------------------------------------------------------------------------\n",
            " 5. 1711 æ°¸å…‰\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "    ä¿¡å¿ƒåº¦: 13%\n",
            "--------------------------------------------------------------------------------\n",
            " 6. 1717 é•·èˆˆ\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "    ä¿¡å¿ƒåº¦: 13%\n",
            "--------------------------------------------------------------------------------\n",
            " 7. 1802 å°ç»\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: å¼·çƒˆè²·å…¥\n",
            "    ä¿¡å¿ƒåº¦: 28%\n",
            "--------------------------------------------------------------------------------\n",
            " 8. 1806 å† è»\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "    ä¿¡å¿ƒåº¦: 13%\n",
            "--------------------------------------------------------------------------------\n",
            " 9. 1809 ä¸­é‡‰\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: è³£å‡ºè§€æœ›\n",
            "    ä¿¡å¿ƒåº¦: 18%\n",
            "--------------------------------------------------------------------------------\n",
            "10. 1810 å’Œæˆ\n",
            "    ç¶œåˆè©•åˆ†: 54/100\n",
            "    æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "    ä¿¡å¿ƒåº¦: 8%\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "å ±å‘Šç”Ÿæˆçµæœ: æˆåŠŸ 0 æ”¯ï¼Œå¤±æ•— 0 æ”¯\n",
            "âœ… æ‰€æœ‰é ‚å°–å€‹è‚¡å ±å‘Šèˆ‡å»ºè­°å·²ç”Ÿæˆã€‚\n",
            "\n",
            "[éšæ®µ6/7] ç”Ÿæˆå ±å‘Šã€åœ–è¡¨èˆ‡ç™¼é€é€šçŸ¥...\n",
            "  ç”Ÿæˆåœ–è¡¨: 1316\n",
            "  ç”Ÿæˆåœ–è¡¨: 1409\n",
            "  ç”Ÿæˆåœ–è¡¨: 1528\n",
            "  ç”Ÿæˆåœ–è¡¨: 1618\n",
            "  ç”Ÿæˆåœ–è¡¨: 1711\n",
            "\n",
            "=== é€šçŸ¥è¨Šæ¯ ===\n",
            "ğŸ¤– *å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š*\n",
            "ğŸ“… åˆ†ææ™‚é–“: 2025-08-13 03:33:00\n",
            "\n",
            "*ğŸ“ˆ åˆ†æçµ±è¨ˆ:*\n",
            "> â€¢ ç¬¦åˆæˆäº¤é‡æ¨™æº–: 545 æ”¯\n",
            "> â€¢ æˆåŠŸåˆ†æ: 545 æ”¯\n",
            "> â€¢ åˆ†æå¤±æ•—: 0 æ”¯\n",
            "\n",
            "ğŸ† *TOP 5 æ¨è–¦è‚¡ç¥¨:*\n",
            "\n",
            "*1. ä¸Šæ›œ (1316)*\n",
            "   ğŸ’° æœ€æ–°åƒ¹æ ¼: 14.20 TWD\n",
            "   ğŸ“ˆ ç¶œåˆè©•åˆ†: *54.0 / 100*\n",
            "   ğŸ¯ æŠ•è³‡å»ºè­°: *ä¸­ç«‹è§€å¯Ÿ*\n",
            "\n",
            "*2. æ–°çº– (1409)*\n",
            "   ğŸ’° æœ€æ–°åƒ¹æ ¼: 13.80 TWD\n",
            "   ğŸ“ˆ ç¶œåˆè©•åˆ†: *54.0 / 100*\n",
            "   ğŸ¯ æŠ•è³‡å»ºè­°: *ä¸­ç«‹è§€å¯Ÿ*\n",
            "\n",
            "*3. æ©å¾· (1528)*\n",
            "   ğŸ’° æœ€æ–°åƒ¹æ ¼: 19.55 TWD\n",
            "   ğŸ“ˆ ç¶œåˆè©•åˆ†: *54.0 / 100*\n",
            "   ğŸ¯ æŠ•è³‡å»ºè­°: *ä¸­ç«‹è§€å¯Ÿ*\n",
            "\n",
            "*4. åˆæ©Ÿ (1618)*\n",
            "   ğŸ’° æœ€æ–°åƒ¹æ ¼: 47.55 TWD\n",
            "   ğŸ“ˆ ç¶œåˆè©•åˆ†: *54.0 / 100*\n",
            "   ğŸ¯ æŠ•è³‡å»ºè­°: *ä¸­ç«‹è§€å¯Ÿ*\n",
            "\n",
            "*5. æ°¸å…‰ (1711)*\n",
            "   ğŸ’° æœ€æ–°åƒ¹æ ¼: 17.45 TWD\n",
            "   ğŸ“ˆ ç¶œåˆè©•åˆ†: *54.0 / 100*\n",
            "   ğŸ¯ æŠ•è³‡å»ºè­°: *ä¸­ç«‹è§€å¯Ÿ*\n",
            "\n",
            "âš ï¸ *æŠ•è³‡æé†’:*\n",
            "â€¢ æœ¬åˆ†æåƒ…ç‚ºæŠ€è¡“æŒ‡æ¨™åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡å»ºè­°ã€‚\n",
            "â€¢ æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹çµåˆåŸºæœ¬é¢åˆ†æä¸¦åšå¥½é¢¨éšªæ§ç®¡ã€‚\n",
            "\n",
            "ğŸ“Š å·²ç”Ÿæˆ 5 å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
            "ğŸ“‹ HTML è©³ç´°å ±å‘Šå·²åŒ¯å‡º\n",
            "é™„åŠ æª”æ¡ˆ: reports/1316_technical_analysis.png, reports/1409_technical_analysis.png, reports/1528_technical_analysis.png, reports/1618_technical_analysis.png, reports/1711_technical_analysis.png\n",
            "===============\n",
            "\n",
            "\n",
            "\n",
            "========== ğŸ† é ‚å°–å€‹è‚¡åˆ†æå ±å‘Š ğŸ† ==========\n",
            "\n",
            "ã€1316 ä¸Šæ›œã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "é€±ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: å¤šé ­åå™¬\n",
            "\n",
            "æœˆç·šåˆ†æ:\n",
            "â€¢ ä¸­æ€§: ç´¡éŒ˜\n",
            "\n",
            "æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚ Kç·šå‹æ…‹æ•´é«”åå‘çœ‹æ¼²ã€‚\n",
            "ä¿¡å¿ƒåº¦: 13%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ é€±ç·š: çœ‹æ¼²: å¤šé ­åå™¬\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "ã€1409 æ–°çº–ã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "é€±ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: å¤šé ­åå™¬\n",
            "\n",
            "æœˆç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "\n",
            "æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚ Kç·šå‹æ…‹æ•´é«”åå‘çœ‹æ¼²ã€‚\n",
            "ä¿¡å¿ƒåº¦: 13%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ é€±ç·š: çœ‹æ¼²: å¤šé ­åå™¬\n",
            "  â€¢ æœˆç·š: çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "ã€1528 æ©å¾·ã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "æ—¥ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "â€¢ çœ‹è·Œ: çœ‹è·ŒåŠéŒ˜\n",
            "â€¢ ä¸­æ€§: ç´¡éŒ˜\n",
            "\n",
            "æœˆç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "\n",
            "æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚\n",
            "ä¿¡å¿ƒåº¦: 8%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ æ—¥ç·š: çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­; çœ‹è·Œ: çœ‹è·ŒåŠéŒ˜\n",
            "  â€¢ æœˆç·š: çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "ã€1618 åˆæ©Ÿã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "æ—¥ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "\n",
            "é€±ç·šåˆ†æ:\n",
            "â€¢ çœ‹è·Œ: ç©ºé ­åå™¬\n",
            "\n",
            "æœˆç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "â€¢ ä¸­æ€§: åå­—æ˜Ÿ, é•·è…¿åå­—\n",
            "\n",
            "æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚ Kç·šå‹æ…‹æ•´é«”åå‘çœ‹è·Œã€‚\n",
            "ä¿¡å¿ƒåº¦: 13%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ æ—¥ç·š: çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "  â€¢ é€±ç·š: çœ‹è·Œ: ç©ºé ­åå™¬\n",
            "  â€¢ æœˆç·š: çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "ã€1711 æ°¸å…‰ã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "æ—¥ç·šåˆ†æ:\n",
            "â€¢ ä¸­æ€§: åå­—æ˜Ÿ, é•·è…¿åå­—, ç´¡éŒ˜\n",
            "\n",
            "é€±ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "\n",
            "æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚ Kç·šå‹æ…‹æ•´é«”åå‘çœ‹æ¼²ã€‚\n",
            "ä¿¡å¿ƒåº¦: 13%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ é€±ç·š: çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "ã€1717 é•·èˆˆã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "é€±ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "\n",
            "æœˆç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "\n",
            "æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚ Kç·šå‹æ…‹æ•´é«”åå‘çœ‹æ¼²ã€‚\n",
            "ä¿¡å¿ƒåº¦: 13%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ é€±ç·š: çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "  â€¢ æœˆç·š: çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "ã€1802 å°ç»ã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "æ—¥ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "\n",
            "é€±ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "\n",
            "æœˆç·šåˆ†æ:\n",
            "â€¢ ä¸­æ€§: ç´¡éŒ˜\n",
            "\n",
            "æŠ•è³‡å»ºè­°: å¼·çƒˆè²·å…¥\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚ å¤šå€‹çœ‹æ¼²Kç·šå‹æ…‹æä¾›å¼·åŠ›æ”¯æ’ã€‚\n",
            "ä¿¡å¿ƒåº¦: 28%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ æ—¥ç·š: çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "  â€¢ é€±ç·š: çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "ã€1806 å† è»ã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "æ—¥ç·šåˆ†æ:\n",
            "â€¢ çœ‹è·Œ: çœ‹è·ŒåŠéŒ˜\n",
            "\n",
            "é€±ç·šåˆ†æ:\n",
            "â€¢ ä¸­æ€§: åå­—æ˜Ÿ, é•·è…¿åå­—, ç´¡éŒ˜\n",
            "\n",
            "æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚ Kç·šå‹æ…‹æ•´é«”åå‘çœ‹è·Œã€‚\n",
            "ä¿¡å¿ƒåº¦: 13%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ æ—¥ç·š: çœ‹è·Œ: çœ‹è·ŒåŠéŒ˜\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "ã€1809 ä¸­é‡‰ã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "æ—¥ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "\n",
            "æœˆç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "â€¢ çœ‹è·Œ: çœ‹è·ŒåŠéŒ˜\n",
            "â€¢ ä¸­æ€§: åå­—æ˜Ÿ, é•·è…¿åå­—\n",
            "\n",
            "æŠ•è³‡å»ºè­°: è³£å‡ºè§€æœ›\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚ Kç·šå‹æ…‹çœ‹è·Œï¼Œä½†éœ€æ³¨æ„æŠ€è¡“æŒ‡æ¨™è¼ƒå¼·ã€‚\n",
            "ä¿¡å¿ƒåº¦: 18%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ æ—¥ç·š: çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "  â€¢ æœˆç·š: çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­; çœ‹è·Œ: çœ‹è·ŒåŠéŒ˜\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "ã€1810 å’Œæˆã€‘\n",
            "ç¶œåˆè©•åˆ†: 54\n",
            "Kç·šåˆ†æ:\n",
            "æ—¥ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "\n",
            "é€±ç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "\n",
            "æœˆç·šåˆ†æ:\n",
            "â€¢ çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­\n",
            "â€¢ çœ‹è·Œ: çœ‹è·ŒåŠéŒ˜\n",
            "â€¢ ä¸­æ€§: åå­—æ˜Ÿ, é•·è…¿åå­—\n",
            "\n",
            "æŠ•è³‡å»ºè­°: ä¸­ç«‹è§€å¯Ÿ\n",
            "å»ºè­°ç†ç”±: ç¶œåˆè©•åˆ†ä¸­æ€§ (54.00)ã€‚\n",
            "ä¿¡å¿ƒåº¦: 8%\n",
            "å‹æ…‹è©³æƒ…:\n",
            "  â€¢ æ—¥ç·š: çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "  â€¢ é€±ç·š: çœ‹æ¼²: ä¸‰ç™½å…µ\n",
            "  â€¢ æœˆç·š: çœ‹æ¼²: çœ‹æ¼²éŒ˜é ­; çœ‹è·Œ: çœ‹è·ŒåŠéŒ˜\n",
            "\n",
            "é—œéµæŒ‡æ¨™:\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "ğŸ‰ å…¨éƒ¨æµç¨‹åŸ·è¡Œå®Œç•¢ï¼\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…·\n",
        "=======================\n",
        "åŠŸèƒ½ï¼š\n",
        "- è‡ªå‹•ç²å–å°è‚¡æ¸…å–®\n",
        "- æ‰¹æ¬¡ä¸‹è¼‰æ­·å²æ•¸æ“š\n",
        "- æŠ€è¡“æŒ‡æ¨™åˆ†æ\n",
        "- ç¶œåˆè©•åˆ†æ’å\n",
        "- è‡ªå‹•é€šçŸ¥æ¨é€\n",
        "- åœ–è¡¨ç”Ÿæˆèˆ‡å ±å‘ŠåŒ¯å‡º\n",
        "\n",
        "ä½œè€…ï¼šè‚¡ç¥¨åˆ†æç³»çµ±\n",
        "ç‰ˆæœ¬ï¼šv2.0\n",
        "æ›´æ–°æ—¥æœŸï¼š2025-08-08\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. åŸºç¤ Python æ¨™æº–åº«\n",
        "# ==============================================================================\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import platform\n",
        "import re\n",
        "from io import StringIO\n",
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "import re  # ç”¨æ–¼æ­£å‰‡è¡¨é”å¼è™•ç†\n",
        "# ==============================================================================\n",
        "# 2. ç¬¬ä¸‰æ–¹å¥—ä»¶\n",
        "# ==============================================================================\n",
        "# æ•¸æ“šè™•ç†èˆ‡ç§‘å­¸è¨ˆç®—\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ç¶²è·¯è«‹æ±‚\n",
        "import requests\n",
        "\n",
        "# é‡‘èæ•¸æ“šæº\n",
        "import yfinance as yf\n",
        "\n",
        "# æ•¸æ“šå¯è¦–åŒ–\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "import mplfinance as mpf\n",
        "import plotly.graph_objects as go\n",
        "from pathlib import Path\n",
        "\n",
        "# é€šçŸ¥å¥—ä»¶ (ä¿®æ­£ï¼šæ–°å¢ discord_webhook åŒ¯å…¥)\n",
        "from discord_webhook import DiscordWebhook\n",
        "import telegram\n",
        "# ä¸­æ–‡å­—é«”æ”¯æ´ï¼ˆå¦‚æœæœ‰å®‰è£çš„è©±ï¼‰\n",
        "try:\n",
        "    import chineseize_matplotlib\n",
        "    chineseize_matplotlib.chineseize()\n",
        "    print(\"âœ… å·²è¼‰å…¥ chineseize_matplotlib ä¸­æ–‡å­—é«”æ”¯æ´\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ æœªå®‰è£ chineseize_matplotlibï¼Œå°‡ä½¿ç”¨è‡ªå®šç¾©å­—é«”è¨­å®š\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import re\n",
        "# ==============================================================================\n",
        "# 3. å…¨åŸŸè¨­å®šèˆ‡ç›®éŒ„çµæ§‹\n",
        "# ==============================================================================\n",
        "# ç›®éŒ„çµæ§‹è¨­å®š\n",
        "CACHE_DIR = 'cache'\n",
        "RESULTS_DIR = 'results'\n",
        "CHARTS_DIR = os.path.join(RESULTS_DIR, 'charts')\n",
        "STOCK_LIST_PATH = os.path.join(CACHE_DIR, 'stock_list.csv')\n",
        "HISTORY_DATA_CACHE_DIR = os.path.join(CACHE_DIR, 'history_data')\n",
        "\n",
        "# åˆå§‹åŒ–ç›®éŒ„\n",
        "for directory in [CACHE_DIR, RESULTS_DIR, CHARTS_DIR, HISTORY_DATA_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. é€šè¨Šèˆ‡é€šçŸ¥è¨­å®š\n",
        "# ==============================================================================\n",
        "# å»ºè­°å°‡ä¾†ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ– .env æª”æ¡ˆç®¡ç†å¯†é‘°ï¼Œä»¥ç­–å®‰å…¨\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. æ—¥èªŒç³»çµ±è¨­å®š\n",
        "# ==============================================================================\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"stock_analysis.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. è¼”åŠ©å‡½å¼èˆ‡ç’°å¢ƒè¨­å®š\n",
        "# ==============================================================================\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "\n",
        "    æ”¯æ´çš„ä½œæ¥­ç³»çµ±ï¼š\n",
        "    - Windows: Microsoft YaHei\n",
        "    - macOS: PingFang HK\n",
        "    - Linux: Noto Sans CJK / WenQuanYi Zen Hei\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            # Windows ç³»çµ±å­—é«”è¨­å®š\n",
        "            font_candidates = ['Microsoft YaHei', 'SimHei', 'KaiTi']\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        elif system == 'Darwin':  # macOS\n",
        "            # macOS ç³»çµ±å­—é«”è¨­å®š\n",
        "            font_candidates = ['PingFang HK', 'PingFang SC', 'Heiti TC', 'STHeiti']\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        else:  # Linux å’Œå…¶ä»–ç³»çµ±\n",
        "            # Linux ç³»çµ±å­—é«”è·¯å¾‘\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/ukai.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/uming.ttc',\n",
        "            ]\n",
        "\n",
        "            found_font_path = None\n",
        "            for path in font_paths:\n",
        "                if os.path.exists(path):\n",
        "                    found_font_path = path\n",
        "                    break\n",
        "\n",
        "            if found_font_path:\n",
        "                try:\n",
        "                    font_manager.fontManager.addfont(found_font_path)\n",
        "                    font_prop = font_manager.FontProperties(fname=found_font_path)\n",
        "                    font_name = font_prop.get_name()\n",
        "                    plt.rcParams['font.sans-serif'] = [font_name]\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"è¼‰å…¥å­—é«”å¤±æ•—: {e}\")\n",
        "                    font_name = \"DejaVu Sans\"\n",
        "            else:\n",
        "                print(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                font_name = \"DejaVu Sans\"\n",
        "\n",
        "        # è¨­å®šè² è™Ÿé¡¯ç¤º\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "        # è¨­å®šå­—é«”å¤§å°\n",
        "        plt.rcParams['font.size'] = 10\n",
        "        plt.rcParams['axes.titlesize'] = 12\n",
        "        plt.rcParams['axes.labelsize'] = 10\n",
        "        plt.rcParams['xtick.labelsize'] = 9\n",
        "        plt.rcParams['ytick.labelsize'] = 9\n",
        "        plt.rcParams['legend.fontsize'] = 9\n",
        "\n",
        "        if font_name and font_name != \"DejaVu Sans\":\n",
        "            print(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name} ({system})\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ä½¿ç”¨é è¨­å­—é«”: {font_name}\")\n",
        "            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"\n",
        "    æª¢æŸ¥åŸ·è¡Œç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶\n",
        "    \"\"\"\n",
        "    print(\"ğŸ” æª¢æŸ¥åŸ·è¡Œç’°å¢ƒ...\")\n",
        "    print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
        "    print(f\"ä½œæ¥­ç³»çµ±: {platform.system()} {platform.release()}\")\n",
        "\n",
        "    # æª¢æŸ¥é‡è¦å¥—ä»¶ç‰ˆæœ¬\n",
        "    required_packages = {\n",
        "        'pandas': pd.__version__,\n",
        "        'numpy': np.__version__,\n",
        "        'matplotlib': plt.matplotlib.__version__,\n",
        "        'requests': requests.__version__,\n",
        "        'yfinance': yf.__version__ if hasattr(yf, '__version__') else 'Unknown'\n",
        "    }\n",
        "\n",
        "    print(\"\\nğŸ“¦ å¥—ä»¶ç‰ˆæœ¬:\")\n",
        "    for package, version in required_packages.items():\n",
        "        print(f\"  {package}: {version}\")\n",
        "\n",
        "    # æª¢æŸ¥ç›®éŒ„æ¬Šé™\n",
        "    print(f\"\\nğŸ“ å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "    print(f\"å¿«å–ç›®éŒ„: {CACHE_DIR} {'âœ…' if os.access(CACHE_DIR, os.W_OK) else 'âŒ'}\")\n",
        "    print(f\"çµæœç›®éŒ„: {RESULTS_DIR} {'âœ…' if os.access(RESULTS_DIR, os.W_OK) else 'âŒ'}\")\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "# ==============================================================================\n",
        "# 1. æ–°å¢ï¼šKç·šå‹æ…‹ä¸­æ–‡ç¿»è­¯å­—å…¸èˆ‡è¼”åŠ©å‡½æ•¸\n",
        "# ==============================================================================\n",
        "import re\n",
        "\n",
        "# ä¸­æ–‡ç¿»è­¯å­—å…¸\n",
        "PATTERN_TRANSLATIONS = {\n",
        "    # å‡ç·šæŒ‡æ¨™ (MA)\n",
        "    \"ma5\": \"5æ—¥å‡ç·š\",\n",
        "    \"ma10\": \"10æ—¥å‡ç·š\",\n",
        "    \"ma20\": \"20æ—¥å‡ç·š (æœˆç·š)\",\n",
        "    \"ma60\": \"60æ—¥å‡ç·š (å­£ç·š)\",\n",
        "    \"ma120\": \"120æ—¥å‡ç·š (åŠå¹´ç·š)\",\n",
        "\n",
        "    # Kç·šåŸºç¤å±¬æ€§\n",
        "    \"body size\": \"å¯¦é«”å¤§å°\",\n",
        "    \"upper shadow\": \"ä¸Šå½±ç·š\",\n",
        "    \"lower shadow\": \"ä¸‹å½±ç·š\",\n",
        "    \"total range\": \"ç¸½æ³¢å¹…\",\n",
        "    \"prev open\": \"æ˜¨æ—¥é–‹ç›¤åƒ¹\",\n",
        "    \"prev high\": \"æ˜¨æ—¥æœ€é«˜åƒ¹\",\n",
        "    \"prev low\": \"æ˜¨æ—¥æœ€ä½åƒ¹\",\n",
        "    \"prev close\": \"æ˜¨æ—¥æ”¶ç›¤åƒ¹\",\n",
        "    \"prev volume\": \"æ˜¨æ—¥æˆäº¤é‡\",\n",
        "\n",
        "    # å¸¸è¦‹Kç·šå‹æ…‹ (å¯æ ¹æ“šæ‚¨çš„åˆ†æåº«æ“´å……)\n",
        "    \"hammer\": \"éšå­ç·š\",\n",
        "    \"hanging man\": \"åŠäººç·š\",\n",
        "    \"inverted hammer\": \"å€’éšå­ç·š\",\n",
        "    \"shooting star\": \"å°„æ“Šä¹‹æ˜Ÿ\",\n",
        "    \"doji\": \"åå­—æ˜Ÿ\",\n",
        "    \"dragonfly doji\": \"èœ»èœ“åå­—\",\n",
        "    \"gravestone doji\": \"å¢“ç¢‘åå­—\",\n",
        "    \"bullish engulfing\": \"çœ‹æ¼²åå™¬\",\n",
        "    \"bearish engulfing\": \"çœ‹è·Œåå™¬\",\n",
        "    \"morning star\": \"æ™¨æ˜Ÿ\",\n",
        "    \"evening star\": \"å¤œæ˜Ÿ\",\n",
        "    \"marubozu\": \"å…‰é ­å…‰è…³Kç·š\"\n",
        "}\n",
        "\n",
        "def translate_pattern(pattern_name):\n",
        "    \"\"\" ç¿»è­¯è‹±æ–‡patternç‚ºä¸­æ–‡ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å›åŸæ–‡ \"\"\"\n",
        "    # ç§»é™¤ \"çœ‹æ¼²\" æˆ– \"çœ‹è·Œ\" å‰ç¶´ä¾†æŸ¥æ‰¾åŸºç¤æ¨¡å¼\n",
        "    clean_name = pattern_name.replace(\"çœ‹æ¼²\", \"\").replace(\"çœ‹è·Œ\", \"\").strip()\n",
        "\n",
        "    # è™•ç†å¸¶æœ‰æ¯”è¼ƒè©çš„æ¨¡å¼ (ä¾‹å¦‚ \"body size > prev body size\")\n",
        "    parts = re.split(r'([<>=])', clean_name)\n",
        "    if len(parts) > 1:\n",
        "        translated_parts = [PATTERN_TRANSLATIONS.get(p.strip(), p.strip()) for p in parts]\n",
        "        return \" \".join(translated_parts)\n",
        "\n",
        "    return PATTERN_TRANSLATIONS.get(clean_name, clean_name)\n",
        "\n",
        "# æ ¸å¿ƒåŠŸèƒ½å‡½å¼ (è³‡æ–™ç²å–ã€åˆ†æã€è©•åˆ†)\n",
        "def get_taiwan_stocks(cache_path=STOCK_LIST_PATH, force_update=False):\n",
        "    if not force_update and os.path.exists(cache_path) and (time.time() - os.path.getmtime(cache_path)) < 86400:\n",
        "        try:\n",
        "            df = pd.read_csv(cache_path, dtype={'stock_id': str})\n",
        "            if not df.empty and 'yahoo_symbol' in df.columns:\n",
        "                print(f\"âœ… å¾å¿«å–è¼‰å…¥ {len(df)} æ”¯è‚¡ç¥¨æ¸…å–®ã€‚\")\n",
        "                return df\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ è¼‰å…¥è‚¡ç¥¨æ¸…å–®å¿«å–å¤±æ•—: {e}ã€‚\")\n",
        "\n",
        "    print(\"ğŸŒ æ­£åœ¨ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–® (å¾è­‰äº¤æ‰€)...\")\n",
        "    try:\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        for market, url in urls.items():\n",
        "            response = requests.get(url, timeout=20)\n",
        "            df = pd.read_html(StringIO(response.text))[0]\n",
        "            df.columns = df.iloc[0]\n",
        "            df = df.iloc[1:].dropna(thresh=3, axis=0)\n",
        "            df['å¸‚å ´åˆ¥'] = market\n",
        "            all_stocks_df.append(df)\n",
        "\n",
        "        df_combined = pd.concat(all_stocks_df, ignore_index=True)\n",
        "        df_combined.columns = ['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±', 'åœ‹éš›è­‰åˆ¸è­˜åˆ¥ç¢¼', 'ä¸Šå¸‚æ—¥', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'CFI', 'å‚™è¨»']\n",
        "        df_combined[['stock_id', 'stock_name']] = df_combined['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', n=1, expand=True)\n",
        "        df_combined['stock_id'] = df_combined['stock_id'].str.strip()\n",
        "        df_combined['stock_name'] = df_combined['stock_name'].str.strip()\n",
        "        df_stocks = df_combined[df_combined['stock_id'].str.match(r'^\\d{4}$')].copy()\n",
        "        exclude_keywords = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š']\n",
        "        df_stocks = df_stocks[~df_stocks['stock_name'].str.contains('|'.join(exclude_keywords), na=False)]\n",
        "        df_stocks['yahoo_symbol'] = df_stocks.apply(\n",
        "            lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['å¸‚å ´åˆ¥'] else f\"{row['stock_id']}.TWO\",\n",
        "            axis=1\n",
        "        )\n",
        "        final_df = df_stocks[['stock_id', 'stock_name', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "        final_df.rename(columns={'å¸‚å ´åˆ¥': 'market', 'ç”¢æ¥­åˆ¥': 'industry'}, inplace=True)\n",
        "        final_df.to_csv(cache_path, index=False)\n",
        "        print(f\"âœ… æˆåŠŸå¾è­‰äº¤æ‰€ç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜ã€‚\")\n",
        "        return final_df\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å¾è­‰äº¤æ‰€ç²å–è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        if os.path.exists(cache_path):\n",
        "            print(\"â— é™ç´šä½¿ç”¨èˆŠçš„å¿«å–è‚¡ç¥¨æ¸…å–®ã€‚\")\n",
        "            return pd.read_csv(cache_path, dtype={'stock_id': str})\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def get_stock_basic_info(force_update=False):\n",
        "    stocks_df = get_taiwan_stocks(force_update=force_update)\n",
        "    if stocks_df.empty: return {}\n",
        "    return {str(row['stock_id']): row.to_dict() for _, row in stocks_df.iterrows()}\n",
        "\n",
        "# ***** é—œéµä¿®æ­£å‡½å¼ *****\n",
        "# ==============================================================================\n",
        "# è«‹ç”¨é€™å…©å€‹å„ªåŒ–å¾Œçš„å‡½æ•¸ï¼Œå®Œæ•´æ›¿æ›æ‚¨ç¨‹å¼ç¢¼ä¸­å°æ‡‰çš„å‡½æ•¸\n",
        "# ==============================================================================\n",
        "\n",
        "import traceback\n",
        "import requests # ç¢ºä¿å°å…¥ requests\n",
        "\n",
        "def fetch_stock_data(stock_id, yahoo_symbol, period='1y', force_update=False, retries=3, delay=3, cache_dir=HISTORY_DATA_CACHE_DIR):\n",
        "    \"\"\"\n",
        "    ã€å„ªåŒ–ç‰ˆã€‘ä¸‹è¼‰å–®ä¸€è‚¡ç¥¨æ•¸æ“šï¼Œå…·å‚™æ›´å¼·çš„éŒ¯èª¤è™•ç†ã€æ—¥èªŒè¨˜éŒ„å’Œç©©å¥æ€§ã€‚\n",
        "    \"\"\"\n",
        "    formatted_id = str(stock_id)\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    cache_path = os.path.join(cache_dir, f\"{formatted_id}.json\")\n",
        "\n",
        "    if not force_update and os.path.exists(cache_path) and (time.time() - os.path.getmtime(cache_path)) < 86400:\n",
        "        try:\n",
        "            with open(cache_path, 'r', encoding='utf-8') as f:\n",
        "                logger.info(f\"å¾å¿«å–è¼‰å…¥ {stock_id} ({yahoo_symbol}) çš„æ•¸æ“šã€‚\")\n",
        "                return json.load(f)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è®€å– {stock_id} çš„å¿«å–æª”æ¡ˆå¤±æ•—: {e}ï¼Œå°‡é‡æ–°å¾ç¶²è·¯ç²å–ã€‚\")\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            time.sleep(0.5)\n",
        "            logger.info(f\"å˜—è©¦ç²å– {stock_id} ({yahoo_symbol}) æ•¸æ“š... (ç¬¬ {attempt + 1}/{retries} æ¬¡)\")\n",
        "            temp_df = yf.download(yahoo_symbol, period=period, progress=False, auto_adjust=True, timeout=20)\n",
        "\n",
        "            if temp_df.empty:\n",
        "                logger.warning(f\"è‚¡ç¥¨ {stock_id} ({yahoo_symbol}) ä¸‹è¼‰å¾Œæ•¸æ“šç‚ºç©ºã€‚å¯èƒ½åŸå› ï¼šä»£è™ŸéŒ¯èª¤ã€å·²ä¸‹å¸‚æˆ–è©²æ™‚æ®µç„¡äº¤æ˜“æ•¸æ“šã€‚\")\n",
        "                return None\n",
        "\n",
        "            if isinstance(temp_df.columns, pd.MultiIndex):\n",
        "                temp_df.columns = temp_df.columns.get_level_values(0)\n",
        "\n",
        "            df = temp_df.reset_index()\n",
        "            df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
        "            result = {\n",
        "                'data': df.to_dict('records'), 'stock_id': formatted_id, 'yahoo_symbol': yahoo_symbol,\n",
        "                'last_price': df['Close'].iloc[-1] if not df.empty else 0,\n",
        "                'fetch_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            }\n",
        "            with open(cache_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "            return result\n",
        "        except requests.exceptions.ConnectionError as e:\n",
        "            logger.error(f\"ä¸‹è¼‰ {yahoo_symbol} æ™‚ç™¼ç”Ÿç¶²è·¯é€£ç·šéŒ¯èª¤: {e}ã€‚è«‹æª¢æŸ¥æ‚¨çš„ç¶²è·¯é€£ç·šæˆ–é˜²ç«ç‰†è¨­å®šã€‚\")\n",
        "            if attempt < retries - 1: time.sleep(delay)\n",
        "            else: return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ä¸‹è¼‰ {yahoo_symbol} æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}\")\n",
        "            logger.debug(traceback.format_exc())\n",
        "            if attempt < retries - 1: time.sleep(delay)\n",
        "            else: return None\n",
        "    return None\n",
        "\n",
        "def fetch_multiple_stocks_data(stocks_info, period='1y', force_update=False):\n",
        "    \"\"\"\n",
        "    ã€å„ªåŒ–ç‰ˆã€‘æ‰¹æ¬¡ç²å–å¤šæ”¯è‚¡ç¥¨æ•¸æ“šï¼Œä¸¦æä¾›è©³ç´°çš„æˆåŠŸ/å¤±æ•—æ‘˜è¦ã€‚\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    failed_stocks = []\n",
        "    stocks_list = list(stocks_info.values())\n",
        "    total_stocks = len(stocks_list)\n",
        "\n",
        "    if total_stocks == 0:\n",
        "        logger.warning(\"å‚³å…¥çš„è‚¡ç¥¨æ¸…å–®ç‚ºç©ºï¼Œç„¡éœ€ç²å–æ•¸æ“šã€‚\")\n",
        "        return {}\n",
        "\n",
        "    for idx, stock in enumerate(stocks_list):\n",
        "        stock_id = str(stock.get('stock_id'))\n",
        "        stock_name = stock.get('stock_name', 'N/A')\n",
        "        yahoo_symbol = stock.get('yahoo_symbol')\n",
        "\n",
        "        if not yahoo_symbol:\n",
        "            logger.warning(f\"è‚¡ç¥¨ {stock_id} {stock_name} ç¼ºå°‘ 'yahoo_symbol'ï¼Œå·²è·³éã€‚\")\n",
        "            failed_stocks.append(f\"{stock_id} {stock_name} (ç¼ºå°‘Symbol)\")\n",
        "            continue\n",
        "\n",
        "        # é€™è£¡ä¸å†å°å‡ºæ—¥èªŒï¼Œäº¤çµ¦ fetch_stock_data å…§éƒ¨è™•ç†\n",
        "        print(f\"[{idx + 1}/{total_stocks}] æ­£åœ¨è™•ç†: {stock_id} {stock_name}\")\n",
        "\n",
        "        stock_data = fetch_stock_data(\n",
        "            stock_id=stock_id, yahoo_symbol=yahoo_symbol, period=period, force_update=force_update\n",
        "        )\n",
        "\n",
        "        if stock_data and 'data' in stock_data and stock_data['data']:\n",
        "            stock_data.update(stock)\n",
        "            results[stock_id] = stock_data\n",
        "        else:\n",
        "            failed_stocks.append(f\"{stock_id} {stock_name}\")\n",
        "\n",
        "    logger.info(\"\\n\" + \"=\"*20 + \" æ•¸æ“šç²å–æ‘˜è¦ \" + \"=\"*20)\n",
        "    logger.info(f\"ä»»å‹™å®Œæˆã€‚æˆåŠŸç²å– {len(results)} / {total_stocks} æ”¯è‚¡ç¥¨çš„æ•¸æ“šã€‚\")\n",
        "    if failed_stocks:\n",
        "        logger.warning(f\"æœªèƒ½ç²å–ä»¥ä¸‹ {len(failed_stocks)} æ”¯è‚¡ç¥¨çš„æ•¸æ“š: {', '.join(failed_stocks)}\")\n",
        "    logger.info(\"=\"*58 + \"\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    \"\"\"\n",
        "    ç‚ºæ•¸æ“šæ¡†æ·»åŠ æŠ€è¡“æŒ‡æ¨™ã€‚\n",
        "    æ¥å—å¤§å¯«æ¬„ä½åç¨± (Open, High, Low, Close, Volume)ï¼Œ\n",
        "    å…§éƒ¨ä½¿ç”¨å°å¯«è™•ç†ï¼Œç„¶å¾Œè¿”å›ä¿æŒåŸå§‹å¤§å¯«æ ¼å¼çš„DataFrameã€‚\n",
        "\n",
        "    åƒæ•¸:\n",
        "    df - åŒ…å«OHLCVæ•¸æ“šçš„DataFrameï¼Œä½¿ç”¨å¤§å¯«æ¬„ä½åç¨±\n",
        "\n",
        "    è¿”å›:\n",
        "    DataFrame - æ·»åŠ äº†æŠ€è¡“æŒ‡æ¨™çš„DataFrameï¼Œä¿æŒå¤§å¯«æ¬„ä½åç¨±\n",
        "    \"\"\"\n",
        "    # è¤‡è£½DataFrameä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š\n",
        "    result = df.copy()\n",
        "\n",
        "    # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨\n",
        "    required_cols = ['Close', 'High', 'Low']\n",
        "    missing_cols = [col for col in required_cols if col not in result.columns]\n",
        "    if missing_cols or result.empty:\n",
        "        print(f\"è­¦å‘Š: ç¼ºå°‘è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ‰€éœ€çš„æ¬„ä½: {missing_cols}\")\n",
        "        return df  # è¿”å›åŸå§‹DataFrame\n",
        "\n",
        "    # æš«æ™‚å°‡æ¬„ä½åç¨±è½‰æ›ç‚ºå°å¯«ä»¥é€²è¡Œè¨ˆç®—\n",
        "    lowercase_mapping = {col: col.lower() for col in result.columns if col in ['Open', 'High', 'Low', 'Close', 'Volume']}\n",
        "    result = result.rename(columns=lowercase_mapping)\n",
        "\n",
        "    # è¨ˆç®—ç°¡å–®ç§»å‹•å¹³å‡ç·š (MA)\n",
        "    for days in [5, 10, 20, 60, 120, 200]:\n",
        "        result[f'ma{days}'] = result['close'].rolling(window=days).mean()\n",
        "\n",
        "    # è¨ˆç®—ç›¸å°å¼·å¼±æŒ‡æ¨™ (RSI)\n",
        "    delta = result['close'].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean()\n",
        "    avg_loss = loss.rolling(window=14).mean()\n",
        "    rs = avg_gain / (avg_loss + 1e-9)  # é¿å…é™¤ä»¥é›¶\n",
        "    result['rsi'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # è¨ˆç®—MACD\n",
        "    exp1 = result['close'].ewm(span=12, adjust=False).mean()\n",
        "    exp2 = result['close'].ewm(span=26, adjust=False).mean()\n",
        "    result['macd'] = exp1 - exp2\n",
        "    result['macdsignal'] = result['macd'].ewm(span=9, adjust=False).mean()\n",
        "    result['histogram'] = result['macd'] - result['macdsignal']\n",
        "\n",
        "    # è¨ˆç®—å¸ƒæ—é€šé“ (Bollinger Bands)\n",
        "    result['middle_band'] = result['close'].rolling(window=20).mean()\n",
        "    result['std'] = result['close'].rolling(window=20).std()\n",
        "    result['bollinger_upper'] = result['middle_band'] + (result['std'] * 2)\n",
        "    result['bollinger_lower'] = result['middle_band'] - (result['std'] * 2)\n",
        "\n",
        "    # è¨ˆç®—KDæŒ‡æ¨™\n",
        "    low_min = result['low'].rolling(window=9).min()\n",
        "    high_max = result['high'].rolling(window=9).max()\n",
        "    result['rsv'] = 100 * ((result['close'] - low_min) / (high_max - low_min + 1e-9))\n",
        "    result['k'] = result['rsv'].ewm(alpha=1/3, adjust=False).mean()\n",
        "    result['d'] = result['k'].ewm(alpha=1/3, adjust=False).mean()\n",
        "\n",
        "    # å¡«å……NaNå€¼\n",
        "    result = result.fillna(0)\n",
        "\n",
        "    # å°‡åŸå§‹æ¬„ä½åç¨±è½‰æ›å›å¤§å¯«\n",
        "    uppercase_mapping = {col.lower(): col for col in df.columns if col in ['Open', 'High', 'Low', 'Close', 'Volume']}\n",
        "    result = result.rename(columns=uppercase_mapping)\n",
        "\n",
        "    return result\n",
        "\n",
        "# ==============================================================================\n",
        "# è«‹ç”¨é€™æ•´å€‹å‡½æ•¸æ›¿æ›æ‰æ‚¨åŸæœ‰çš„ analyze_stock å‡½æ•¸\n",
        "# ==============================================================================\n",
        "def analyze_stock(stock_id, stock_data, min_periods=60):\n",
        "    \"\"\"\n",
        "    å°å–®ä¸€è‚¡ç¥¨é€²è¡Œå®Œæ•´çš„æŠ€è¡“åˆ†æã€‚\n",
        "\n",
        "    æ­¤ç‰ˆæœ¬ä¿®æ­£äº† NameError ä¸¦é‡æ§‹äº†å…§éƒ¨é‚è¼¯ï¼Œä½¿å…¶æ›´ç©©å¥ã€æ¸…æ™°ã€‚\n",
        "\n",
        "    åƒæ•¸:\n",
        "    stock_id (str): è‚¡ç¥¨ä»£è™Ÿ\n",
        "    stock_data (dict): åŒ…å«è‚¡ç¥¨åŸºæœ¬è³‡æ–™å’Œæ­·å²æ•¸æ“šçš„å­—å…¸\n",
        "    min_periods (int): é€²è¡Œåˆ†ææ‰€éœ€çš„æœ€å°‘æ­·å²æ•¸æ“šé»æ•¸é‡\n",
        "\n",
        "    è¿”å›:\n",
        "    dict or None: åŒ…å«åˆ†æçµæœçš„å­—å…¸ï¼Œå¦‚æœæ•¸æ“šç„¡æ•ˆæˆ–åˆ†æå¤±æ•—å‰‡è¿”å› None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- æ­¥é©Ÿ 1: é©—è­‰å‚³å…¥çš„æ•¸æ“šæ˜¯å¦æœ‰æ•ˆ ---\n",
        "        if not stock_data or not stock_data.get('data'):\n",
        "            logger.warning(f\"åˆ†æè‚¡ç¥¨ {stock_id} å¤±æ•—ï¼šå‚³å…¥çš„ stock_data ç‚ºç©ºæˆ–ç¼ºå°‘ 'data' éµã€‚\")\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame(stock_data['data'])\n",
        "\n",
        "        if df.empty or len(df) < min_periods:\n",
        "            logger.warning(f\"è·³éè‚¡ç¥¨ {stock_id}ï¼šæ•¸æ“šé»ä¸è¶³ {min_periods} å€‹ (å¯¦éš›: {len(df)})ã€‚\")\n",
        "            return None\n",
        "\n",
        "        # --- æ­¥é©Ÿ 2: æ¨™æº–åŒ–æ¬„ä½åç¨±èˆ‡ç´¢å¼• ---\n",
        "        # çµ±ä¸€æ—¥æœŸæ¬„ä½\n",
        "        date_col_candidates = ['Date', 'date', 'æ—¥æœŸ']\n",
        "        date_col = next((col for col in date_col_candidates if col in df.columns), None)\n",
        "\n",
        "        if date_col:\n",
        "            df[date_col] = pd.to_datetime(df[date_col])\n",
        "            df.set_index(date_col, inplace=True)\n",
        "        else:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} å¤±æ•—ï¼šæ‰¾ä¸åˆ°å¯ç”¨çš„æ—¥æœŸæ¬„ä½ã€‚\")\n",
        "            return None\n",
        "\n",
        "        # çµ±ä¸€åƒ¹æ ¼æ¬„ä½ (å°‡ä¸­æ–‡æ¬„ä½å°æ‡‰åˆ°æ¨™æº–è‹±æ–‡æ¬„ä½)\n",
        "        column_mapping = {\n",
        "            'é–‹ç›¤': 'Open', 'æœ€é«˜': 'High', 'æœ€ä½': 'Low', 'æ”¶ç›¤': 'Close', 'æˆäº¤é‡': 'Volume',\n",
        "            'é–‹ç›¤åƒ¹': 'Open', 'æœ€é«˜åƒ¹': 'High', 'æœ€ä½åƒ¹': 'Low', 'æ”¶ç›¤åƒ¹': 'Close'\n",
        "        }\n",
        "        df.rename(columns=column_mapping, inplace=True)\n",
        "\n",
        "        # æª¢æŸ¥å¿…è¦çš„åƒ¹æ ¼æ¬„ä½æ˜¯å¦å­˜åœ¨\n",
        "        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} å¤±æ•—ï¼šç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}ã€‚\")\n",
        "            return None\n",
        "\n",
        "        # --- æ­¥é©Ÿ 3: è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ ---\n",
        "        df_with_indicators = add_technical_indicators(df.copy())\n",
        "\n",
        "        # --- æ­¥é©Ÿ 4: è¨ˆç®—åƒ¹æ ¼è®ŠåŒ–ç‡ ---\n",
        "        price_changes = {}\n",
        "        periods = {'1d': 2, '1w': 5, '1m': 20, '3m': 60}\n",
        "        for label, days in periods.items():\n",
        "            if len(df_with_indicators) >= days:\n",
        "                price_changes[label] = ((df_with_indicators['Close'].iloc[-1] / df_with_indicators['Close'].iloc[-days]) - 1) * 100\n",
        "            else:\n",
        "                price_changes[label] = 0\n",
        "\n",
        "        # --- æ­¥é©Ÿ 5: çµ„åˆåˆ†æçµæœ ---\n",
        "        last_row = df_with_indicators.iloc[-1]\n",
        "        analysis_result = {\n",
        "            'success': True,\n",
        "            'stock_id': stock_id,\n",
        "            'stock_name': stock_data.get('stock_name', 'N/A'),\n",
        "            'market': stock_data.get('market', 'Unknown'),\n",
        "            'industry': stock_data.get('industry', 'Unknown'),\n",
        "            'last_price': last_row['Close'],\n",
        "            'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'price_change': price_changes,\n",
        "            'data_df': df_with_indicators # ä¿ç•™ DataFrame ä»¥ä¾›å¾ŒçºŒè©•åˆ†å’Œç¹ªåœ–ä½¿ç”¨\n",
        "        }\n",
        "        return analysis_result\n",
        "\n",
        "    except Exception as e:\n",
        "        # æ•æ‰æ‰€æœ‰æœªé æœŸçš„éŒ¯èª¤ï¼Œç¢ºä¿ä¸»ç¨‹åºä¸æœƒå› å–®ä¸€è‚¡ç¥¨è€Œä¸­æ–·\n",
        "        logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”Ÿç„¡æ³•é æœŸçš„ç•°å¸¸: {e}\")\n",
        "        logger.debug(traceback.format_exc()) # åœ¨æ—¥èªŒä¸­è¨˜éŒ„è©³ç´°çš„éŒ¯èª¤å †ç–Š\n",
        "        return None\n",
        "def calculate_comprehensive_score(analysis_result):\n",
        "    \"\"\"\n",
        "    è¨ˆç®—ç¶œåˆè©•åˆ†ã€‚\n",
        "    \"\"\"\n",
        "    scores = {'trend_score': 50, 'momentum_score': 50, 'volume_score': 50}\n",
        "    df = analysis_result.get('data_df')\n",
        "    if df is None or df.empty or len(df) < 60:\n",
        "        return scores, 50\n",
        "\n",
        "    try:\n",
        "        # è¶¨å‹¢è©•åˆ†\n",
        "        if all(col in df.columns for col in ['MA5', 'MA10', 'MA20', 'MA60']):\n",
        "            if df['MA5'].iloc[-1] > df['MA10'].iloc[-1] > df['MA20'].iloc[-1] > df['MA60'].iloc[-1]:\n",
        "                scores['trend_score'] = 85\n",
        "            else:\n",
        "                scores['trend_score'] = 20\n",
        "\n",
        "        # å‹•é‡è©•åˆ†\n",
        "        momentum_points = 50\n",
        "        if 'RSI' in df.columns and df['RSI'].iloc[-1] > 60:\n",
        "            momentum_points += 15\n",
        "        if all(col in df.columns for col in ['MACD', 'Signal']) and df['MACD'].iloc[-1] > df['Signal'].iloc[-1]:\n",
        "            momentum_points += 20\n",
        "        if all(col in df.columns for col in ['K', 'D']) and df['K'].iloc[-1] > df['D'].iloc[-1]:\n",
        "            momentum_points += 15\n",
        "        scores['momentum_score'] = max(0, min(100, momentum_points))\n",
        "\n",
        "        # æˆäº¤é‡è©•åˆ†\n",
        "        if 'Volume' in df.columns:\n",
        "            current_volume = df['Volume'].iloc[-1]\n",
        "            avg_volume = df['Volume'].rolling(window=20).mean().iloc[-1]\n",
        "            if current_volume > avg_volume * 1.5:\n",
        "                scores['volume_score'] = 80\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"è¨ˆç®—è©•åˆ†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    final_score = scores['trend_score'] * 0.4 + scores['momentum_score'] * 0.45 + scores['volume_score'] * 0.15\n",
        "    return scores, final_score\n",
        "\n",
        "def generate_recommendation(score):\n",
        "    \"\"\"\n",
        "    æ ¹æ“šè©•åˆ†ç”Ÿæˆäº¤æ˜“å»ºè­°ã€‚\n",
        "    \"\"\"\n",
        "    if score >= 75:\n",
        "        return {\n",
        "            'action': 'å¼·åŠ›è²·å…¥',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™é¡¯ç¤ºå¼·å‹¢', 'æˆäº¤é‡æ”¾å¤§', 'åƒ¹æ ¼è¶¨å‹¢å‘ä¸Š'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'ä¸­ç­‰',\n",
        "            'time_frame': '1-3å€‹æœˆ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "    elif score >= 60:\n",
        "        return {\n",
        "            'action': 'è²·å…¥',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™æ­£é¢', 'æˆäº¤é‡ç©©å®š'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'ä½',\n",
        "            'time_frame': '1-3å€‹æœˆ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "    elif score >= 40:\n",
        "        return {\n",
        "            'action': 'æŒæœ‰',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™ä¸­æ€§', 'ç„¡æ˜é¡¯è¶¨å‹¢'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'ä½',\n",
        "            'time_frame': '1å€‹æœˆ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "    elif score >= 25:\n",
        "        return {\n",
        "            'action': 'è§€æœ›',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™åå¼±', 'æˆäº¤é‡ä¸è¶³'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'é«˜',\n",
        "            'time_frame': 'çŸ­æœŸ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            'action': 'è³£å‡º',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™çœ‹è·Œ', 'æˆäº¤é‡èç¸®'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'é«˜',\n",
        "            'time_frame': 'çŸ­æœŸ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "\n",
        "def generate_detailed_analysis_report(stock_id, stock_name, stock_data, save_path=None):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆè©³ç´°åˆ†æåœ–è¡¨ï¼ˆKç·šåœ–ã€æŠ€è¡“æŒ‡æ¨™ï¼‰ - ä¿®æ­£ç‰ˆæœ¬ã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df_plot = stock_data.get('data_df')\n",
        "        if df_plot is None or df_plot.empty:\n",
        "            logger.error(f\"ç„¡æ³•ç”Ÿæˆåœ–è¡¨: {stock_id} ç„¡æœ‰æ•ˆæ•¸æ“š\")\n",
        "            return None\n",
        "\n",
        "        # ç¢ºä¿æ•¸æ“šæ¡†æœ‰è¶³å¤ çš„æ•¸æ“š\n",
        "        if len(df_plot) < 20:\n",
        "            logger.error(f\"æ•¸æ“šä¸è¶³ä»¥ç”Ÿæˆåœ–è¡¨: {stock_id}\")\n",
        "            return None\n",
        "\n",
        "        df_plot = df_plot.tail(120).copy()\n",
        "\n",
        "        # ç¢ºä¿å¿…è¦çš„æ¬„ä½å­˜åœ¨\n",
        "        required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "        missing_columns = [col for col in required_columns if col not in df_plot.columns]\n",
        "        if missing_columns:\n",
        "            logger.error(f\"åœ–è¡¨ç”Ÿæˆå¤±æ•—ï¼Œç¼ºå°‘æ¬„ä½: {missing_columns}\")\n",
        "            return None\n",
        "\n",
        "        # ç¢ºä¿ç´¢å¼•æ˜¯æ—¥æœŸæ™‚é–“æ ¼å¼\n",
        "        if not isinstance(df_plot.index, pd.DatetimeIndex):\n",
        "            if 'Date' in df_plot.columns:\n",
        "                df_plot['Date'] = pd.to_datetime(df_plot['Date'])\n",
        "                df_plot.set_index('Date', inplace=True)\n",
        "            else:\n",
        "                df_plot.index = pd.date_range(start='2023-01-01', periods=len(df_plot), freq='D')\n",
        "\n",
        "        # è¨­å®šåœ–è¡¨æ¨£å¼\n",
        "        mc = mpf.make_marketcolors(up='r', down='g', inherit=True)\n",
        "        s = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=mc)\n",
        "\n",
        "        # æº–å‚™é™„åŠ åœ–è¡¨\n",
        "        apds = []\n",
        "\n",
        "        # æ·»åŠ ç§»å‹•å¹³å‡ç·š\n",
        "        if all(col in df_plot.columns for col in ['MA5', 'MA20']):\n",
        "            apds.append(mpf.make_addplot(df_plot[['MA5', 'MA20']], width=0.7))\n",
        "\n",
        "        # æ·»åŠ  MACD\n",
        "        if all(col in df_plot.columns for col in ['MACD', 'Signal']):\n",
        "            apds.append(mpf.make_addplot(df_plot[['MACD', 'Signal']], panel=2))\n",
        "\n",
        "        # æ·»åŠ  RSI\n",
        "        if 'RSI' in df_plot.columns:\n",
        "            apds.append(mpf.make_addplot(df_plot['RSI'], panel=3))\n",
        "\n",
        "        title = f\"{stock_id} {stock_name} (åˆ†æ•¸: {int(round(stock_data.get('combined_score', 0)))})\"\n",
        "\n",
        "        if not save_path:\n",
        "            save_path = os.path.join(CHARTS_DIR, f\"{stock_id}_report.png\")\n",
        "\n",
        "        # ç”Ÿæˆåœ–è¡¨\n",
        "        mpf.plot(\n",
        "            df_plot,\n",
        "            type='candle',\n",
        "            style=s,\n",
        "            title=title,\n",
        "            volume=True,\n",
        "            addplot=apds if apds else None,\n",
        "            panel_ratios=(6, 2, 2, 2) if len(apds) >= 2 else (6, 2),\n",
        "            figsize=(16, 9),\n",
        "            savefig=dict(fname=save_path, dpi=150, bbox_inches='tight')\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… åœ–è¡¨å ±å‘Šå·²å„²å­˜è‡³: {save_path}\")\n",
        "        plt.close('all')\n",
        "        return save_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”Ÿæˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "def identify_candlestick_patterns(df):\n",
        "    \"\"\"\n",
        "    è­˜åˆ¥å¸¸è¦‹çš„Kç·šå‹æ…‹ï¼Œä¸ä½¿ç”¨ talibã€ta-lib æˆ– pandas_ta\n",
        "\n",
        "    åƒæ•¸:\n",
        "    df - åŒ…å«OHLCVæ•¸æ“šçš„DataFrame\n",
        "\n",
        "    è¿”å›:\n",
        "    DataFrame - åŒ…å«å„ç¨®Kç·šå‹æ…‹çš„è­˜åˆ¥çµæœ\n",
        "    \"\"\"\n",
        "    # è¤‡è£½æ•¸æ“šä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š\n",
        "    result_df = df.copy()\n",
        "\n",
        "    # è¨ˆç®—å¯¦é«”é•·åº¦å’Œå½±ç·šé•·åº¦\n",
        "    result_df['body_size'] = abs(result_df['close'] - result_df['open'])\n",
        "    result_df['upper_shadow'] = result_df['high'] - result_df[['open', 'close']].max(axis=1)\n",
        "    result_df['lower_shadow'] = result_df[['open', 'close']].min(axis=1) - result_df['low']\n",
        "    result_df['total_range'] = result_df['high'] - result_df['low']\n",
        "\n",
        "    # è¨ˆç®—å‰ä¸€å¤©çš„æ•¸æ“š\n",
        "    result_df['prev_open'] = result_df['open'].shift(1)\n",
        "    result_df['prev_high'] = result_df['high'].shift(1)\n",
        "    result_df['prev_low'] = result_df['low'].shift(1)\n",
        "    result_df['prev_close'] = result_df['close'].shift(1)\n",
        "    result_df['prev_body_size'] = result_df['body_size'].shift(1)\n",
        "    result_df['prev_total_range'] = result_df['total_range'].shift(1)\n",
        "\n",
        "    # è¨ˆç®—å‰å…©å¤©çš„æ•¸æ“š\n",
        "    result_df['prev2_open'] = result_df['open'].shift(2)\n",
        "    result_df['prev2_high'] = result_df['high'].shift(2)\n",
        "    result_df['prev2_low'] = result_df['low'].shift(2)\n",
        "    result_df['prev2_close'] = result_df['close'].shift(2)\n",
        "\n",
        "    # è¨ˆç®—å‰ä¸‰å¤©çš„æ•¸æ“š\n",
        "    result_df['prev3_open'] = result_df['open'].shift(3)\n",
        "    result_df['prev3_high'] = result_df['high'].shift(3)\n",
        "    result_df['prev3_low'] = result_df['low'].shift(3)\n",
        "    result_df['prev3_close'] = result_df['close'].shift(3)\n",
        "\n",
        "    # è¨ˆç®—Kç·šè¶¨å‹¢\n",
        "    result_df['is_bullish'] = result_df['close'] > result_df['open']\n",
        "    result_df['prev_is_bullish'] = result_df['prev_close'] > result_df['prev_open']\n",
        "    result_df['prev2_is_bullish'] = result_df['prev2_close'] > result_df['prev2_open']\n",
        "    result_df['prev3_is_bullish'] = result_df['prev3_close'] > result_df['prev3_open']\n",
        "\n",
        "    # è¨ˆç®—ç°¡å–®ç§»å‹•å¹³å‡ç·šç”¨æ–¼åˆ¤æ–·è¶¨å‹¢\n",
        "    result_df['sma5'] = result_df['close'].rolling(window=5).mean()\n",
        "    result_df['sma10'] = result_df['close'].rolling(window=10).mean()\n",
        "    result_df['sma20'] = result_df['close'].rolling(window=20).mean()\n",
        "\n",
        "    # åˆ¤æ–·è¶¨å‹¢\n",
        "    result_df['uptrend'] = (result_df['sma5'] > result_df['sma20']) & (result_df['close'] > result_df['sma20'])\n",
        "    result_df['downtrend'] = (result_df['sma5'] < result_df['sma20']) & (result_df['close'] < result_df['sma20'])\n",
        "\n",
        "    # åˆå§‹åŒ–æ‰€æœ‰å‹æ…‹ç‚º0\n",
        "    pattern_columns = [\n",
        "        'åå­—æ˜Ÿ_ä¸­æ€§', 'éŒ˜å­ç·š_çœ‹æ¼²', 'éŒ˜å­ç·š_çœ‹è·Œ', 'æµæ˜Ÿç·š_çœ‹è·Œ',\n",
        "        'åå™¬_çœ‹æ¼²', 'åå™¬_çœ‹è·Œ', 'æ¯å­ç·š_çœ‹æ¼²', 'æ¯å­ç·š_çœ‹è·Œ',\n",
        "        'æ™¨æ˜Ÿ_çœ‹æ¼²', 'æš®æ˜Ÿ_çœ‹è·Œ', 'ä¸‰ç™½å…µ_çœ‹æ¼²', 'ä¸‰é»‘é´‰_çœ‹è·Œ',\n",
        "        'ç©¿åˆºç·š_çœ‹æ¼²', 'çƒé›²è“‹é ‚_çœ‹è·Œ', 'é•·è…³åå­—ç·š_ä¸­æ€§', 'ä¸ŠåŠç·š_çœ‹è·Œ',\n",
        "        'é™€èº_ä¸­æ€§', 'åè½‰_çœ‹æ¼²', 'åè½‰_çœ‹è·Œ', 'å³¶å½¢åè½‰_çœ‹æ¼²', 'å³¶å½¢åè½‰_çœ‹è·Œ',\n",
        "        'é ­è‚©é ‚_çœ‹è·Œ', 'é ­è‚©åº•_çœ‹æ¼²', 'é›™é ‚_çœ‹è·Œ', 'é›™åº•_çœ‹æ¼²'\n",
        "    ]\n",
        "\n",
        "    for col in pattern_columns:\n",
        "        result_df[col] = 0\n",
        "\n",
        "    # 1. è­˜åˆ¥åå­—æ˜Ÿ (Doji)\n",
        "    # åå­—æ˜Ÿ: é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒ\n",
        "    doji_condition = result_df['body_size'] <= 0.1 * result_df['total_range']\n",
        "    result_df.loc[doji_condition, 'åå­—æ˜Ÿ_ä¸­æ€§'] = 1\n",
        "\n",
        "    # 2. è­˜åˆ¥éŒ˜å­ç·š (Hammer) å’Œæµæ˜Ÿç·š (Shooting Star)\n",
        "    hammer_condition = (\n",
        "        (result_df['lower_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['upper_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "\n",
        "    shooting_star_condition = (\n",
        "        (result_df['upper_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['lower_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "\n",
        "    # åœ¨ä¸‹è·Œè¶¨å‹¢ä¸­çš„éŒ˜å­ç·šæ˜¯çœ‹æ¼²ä¿¡è™Ÿ\n",
        "    result_df.loc[hammer_condition & result_df['downtrend'], 'éŒ˜å­ç·š_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­çš„éŒ˜å­ç·šæ˜¯çœ‹è·Œä¿¡è™Ÿ\n",
        "    result_df.loc[hammer_condition & result_df['uptrend'], 'éŒ˜å­ç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # æµæ˜Ÿç·šé€šå¸¸æ˜¯çœ‹è·Œä¿¡è™Ÿ\n",
        "    result_df.loc[shooting_star_condition & result_df['uptrend'], 'æµæ˜Ÿç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 3. è­˜åˆ¥åå™¬å‹æ…‹ (Engulfing)\n",
        "    bullish_engulfing = (\n",
        "        (~result_df['prev_is_bullish']) &  # å‰ä¸€å¤©æ˜¯ä¸‹è·Œ\n",
        "        result_df['is_bullish'] &          # ç•¶å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['open'] < result_df['prev_close']) &  # é–‹ç›¤ä½æ–¼å‰ä¸€å¤©æ”¶ç›¤\n",
        "        (result_df['close'] > result_df['prev_open'])    # æ”¶ç›¤é«˜æ–¼å‰ä¸€å¤©é–‹ç›¤\n",
        "    )\n",
        "\n",
        "    bearish_engulfing = (\n",
        "        result_df['prev_is_bullish'] &     # å‰ä¸€å¤©æ˜¯ä¸Šæ¼²\n",
        "        (~result_df['is_bullish']) &       # ç•¶å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['open'] > result_df['prev_close']) &  # é–‹ç›¤é«˜æ–¼å‰ä¸€å¤©æ”¶ç›¤\n",
        "        (result_df['close'] < result_df['prev_open'])    # æ”¶ç›¤ä½æ–¼å‰ä¸€å¤©é–‹ç›¤\n",
        "    )\n",
        "\n",
        "    result_df.loc[bullish_engulfing & result_df['downtrend'], 'åå™¬_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[bearish_engulfing & result_df['uptrend'], 'åå™¬_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 4. è­˜åˆ¥æ¯å­ç·š (Harami)\n",
        "    bullish_harami = (\n",
        "        (~result_df['prev_is_bullish']) &  # å‰ä¸€å¤©æ˜¯ä¸‹è·Œ\n",
        "        result_df['is_bullish'] &          # ç•¶å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['high'] < result_df['prev_high']) &   # æœ€é«˜åƒ¹ä½æ–¼å‰ä¸€å¤©æœ€é«˜åƒ¹\n",
        "        (result_df['low'] > result_df['prev_low']) &     # æœ€ä½åƒ¹é«˜æ–¼å‰ä¸€å¤©æœ€ä½åƒ¹\n",
        "        (result_df['body_size'] < result_df['prev_body_size'])  # å¯¦é«”å°æ–¼å‰ä¸€å¤©\n",
        "    )\n",
        "\n",
        "    bearish_harami = (\n",
        "        result_df['prev_is_bullish'] &     # å‰ä¸€å¤©æ˜¯ä¸Šæ¼²\n",
        "        (~result_df['is_bullish']) &       # ç•¶å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['high'] < result_df['prev_high']) &   # æœ€é«˜åƒ¹ä½æ–¼å‰ä¸€å¤©æœ€é«˜åƒ¹\n",
        "        (result_df['low'] > result_df['prev_low']) &     # æœ€ä½åƒ¹é«˜æ–¼å‰ä¸€å¤©æœ€ä½åƒ¹\n",
        "        (result_df['body_size'] < result_df['prev_body_size'])  # å¯¦é«”å°æ–¼å‰ä¸€å¤©\n",
        "    )\n",
        "\n",
        "    result_df.loc[bullish_harami & result_df['downtrend'], 'æ¯å­ç·š_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[bearish_harami & result_df['uptrend'], 'æ¯å­ç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 5. è­˜åˆ¥æ™¨æ˜Ÿ (Morning Star) å’Œæš®æ˜Ÿ (Evening Star)\n",
        "    morning_star = (\n",
        "        (~result_df['prev2_is_bullish']) &  # å‰å…©å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['prev_body_size'] <= 0.3 * result_df['prev_total_range']) &  # å‰ä¸€å¤©æ˜¯å°å¯¦é«”\n",
        "        result_df['is_bullish'] &           # ç•¶å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['close'] > (result_df['prev2_open'] + result_df['prev2_close']) / 2)  # æ”¶ç›¤åƒ¹é«˜æ–¼å‰å…©å¤©å¯¦é«”ä¸­é»\n",
        "    )\n",
        "\n",
        "    evening_star = (\n",
        "        result_df['prev2_is_bullish'] &     # å‰å…©å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['prev_body_size'] <= 0.3 * result_df['prev_total_range']) &  # å‰ä¸€å¤©æ˜¯å°å¯¦é«”\n",
        "        (~result_df['is_bullish']) &        # ç•¶å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['close'] < (result_df['prev2_open'] + result_df['prev2_close']) / 2)  # æ”¶ç›¤åƒ¹ä½æ–¼å‰å…©å¤©å¯¦é«”ä¸­é»\n",
        "    )\n",
        "\n",
        "    result_df.loc[morning_star & result_df['downtrend'], 'æ™¨æ˜Ÿ_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[evening_star & result_df['uptrend'], 'æš®æ˜Ÿ_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 6. è­˜åˆ¥ä¸‰ç™½å…µ (Three White Soldiers) å’Œä¸‰é»‘é´‰ (Three Black Crows)\n",
        "    # éœ€è¦æª¢æŸ¥é€£çºŒä¸‰å¤©çš„Kç·š\n",
        "    three_white_soldiers = (\n",
        "        result_df['is_bullish'] &\n",
        "        result_df['prev_is_bullish'] &\n",
        "        result_df['prev2_is_bullish'] &\n",
        "        (result_df['close'] > result_df['prev_close']) &\n",
        "        (result_df['prev_close'] > result_df['prev2_close']) &\n",
        "        (result_df['open'] > result_df['prev_open']) &\n",
        "        (result_df['prev_open'] > result_df['prev2_open'])\n",
        "    )\n",
        "\n",
        "    three_black_crows = (\n",
        "        (~result_df['is_bullish']) &\n",
        "        (~result_df['prev_is_bullish']) &\n",
        "        (~result_df['prev2_is_bullish']) &\n",
        "        (result_df['close'] < result_df['prev_close']) &\n",
        "        (result_df['prev_close'] < result_df['prev2_close']) &\n",
        "        (result_df['open'] < result_df['prev_open']) &\n",
        "        (result_df['prev_open'] < result_df['prev2_open'])\n",
        "    )\n",
        "\n",
        "    result_df.loc[three_white_soldiers, 'ä¸‰ç™½å…µ_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[three_black_crows, 'ä¸‰é»‘é´‰_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 7. è­˜åˆ¥ç©¿åˆºç·š (Piercing) å’Œçƒé›²è“‹é ‚ (Dark Cloud Cover)\n",
        "    piercing = (\n",
        "        (~result_df['prev_is_bullish']) &  # å‰ä¸€å¤©æ˜¯ä¸‹è·Œ\n",
        "        result_df['is_bullish'] &          # ç•¶å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['open'] < result_df['prev_low']) &  # é–‹ç›¤ä½æ–¼å‰ä¸€å¤©æœ€ä½åƒ¹\n",
        "        (result_df['close'] > (result_df['prev_open'] + result_df['prev_close']) / 2) &  # æ”¶ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©å¯¦é«”ä¸­é»\n",
        "        (result_df['close'] < result_df['prev_open'])  # æ”¶ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©é–‹ç›¤åƒ¹\n",
        "    )\n",
        "\n",
        "    dark_cloud_cover = (\n",
        "        result_df['prev_is_bullish'] &     # å‰ä¸€å¤©æ˜¯ä¸Šæ¼²\n",
        "        (~result_df['is_bullish']) &       # ç•¶å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['open'] > result_df['prev_high']) &  # é–‹ç›¤é«˜æ–¼å‰ä¸€å¤©æœ€é«˜åƒ¹\n",
        "        (result_df['close'] < (result_df['prev_open'] + result_df['prev_close']) / 2) &  # æ”¶ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©å¯¦é«”ä¸­é»\n",
        "        (result_df['close'] > result_df['prev_close'])  # æ”¶ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©æ”¶ç›¤åƒ¹\n",
        "    )\n",
        "\n",
        "    result_df.loc[piercing & result_df['downtrend'], 'ç©¿åˆºç·š_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[dark_cloud_cover & result_df['uptrend'], 'çƒé›²è“‹é ‚_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 8. è­˜åˆ¥é•·è…³åå­—ç·š (Long-Legged Doji)\n",
        "    long_legged_doji = (\n",
        "        doji_condition &\n",
        "        (result_df['upper_shadow'] >= 0.3 * result_df['total_range']) &\n",
        "        (result_df['lower_shadow'] >= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "\n",
        "    result_df.loc[long_legged_doji, 'é•·è…³åå­—ç·š_ä¸­æ€§'] = 1\n",
        "\n",
        "    # 9. è­˜åˆ¥ä¸ŠåŠç·š (Hanging Man)\n",
        "    hanging_man = (\n",
        "        (result_df['lower_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['upper_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range']) &\n",
        "        result_df['uptrend']\n",
        "    )\n",
        "\n",
        "    result_df.loc[hanging_man, 'ä¸ŠåŠç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 10. è­˜åˆ¥é™€èº (Spinning Top)\n",
        "    spinning_top = (\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range']) &\n",
        "        (result_df['upper_shadow'] >= 0.2 * result_df['total_range']) &\n",
        "        (result_df['lower_shadow'] >= 0.2 * result_df['total_range'])\n",
        "    )\n",
        "\n",
        "    result_df.loc[spinning_top, 'é™€èº_ä¸­æ€§'] = 1\n",
        "\n",
        "    # 11. è­˜åˆ¥åè½‰å‹æ…‹ (Reversal)\n",
        "    # çœ‹æ¼²åè½‰: åœ¨ä¸‹è·Œè¶¨å‹¢ä¸­ï¼Œå‡ºç¾ä¸€æ ¹å¤§é™½ç·šï¼Œæ”¶ç›¤åƒ¹é«˜æ–¼å‰å¹¾å¤©çš„æœ€é«˜åƒ¹\n",
        "    bullish_reversal = (\n",
        "        result_df['is_bullish'] &\n",
        "        result_df['downtrend'] &\n",
        "        (result_df['close'] > result_df[['prev_high', 'prev2_high']].max(axis=1))\n",
        "    )\n",
        "\n",
        "    # çœ‹è·Œåè½‰: åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­ï¼Œå‡ºç¾ä¸€æ ¹å¤§é™°ç·šï¼Œæ”¶ç›¤åƒ¹ä½æ–¼å‰å¹¾å¤©çš„æœ€ä½åƒ¹\n",
        "    bearish_reversal = (\n",
        "        (~result_df['is_bullish']) &\n",
        "        result_df['uptrend'] &\n",
        "        (result_df['close'] < result_df[['prev_low', 'prev2_low']].min(axis=1))\n",
        "    )\n",
        "\n",
        "    result_df.loc[bullish_reversal, 'åè½‰_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[bearish_reversal, 'åè½‰_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 12. è­˜åˆ¥å³¶å½¢åè½‰ (Island Reversal)\n",
        "    # çœ‹æ¼²å³¶å½¢åè½‰: åœ¨ä¸‹è·Œè¶¨å‹¢ä¸­ï¼Œå‡ºç¾å‘ä¸‹è·³ç©ºï¼Œç„¶å¾Œåƒ¹æ ¼åœ¨ä½ä½ç›¤æ•´ï¼Œæœ€å¾Œå‘ä¸Šè·³ç©º\n",
        "    bullish_island_reversal = (\n",
        "        result_df['downtrend'] &\n",
        "        (result_df['low'] > result_df['prev_high']) &  # å‘ä¸Šè·³ç©º\n",
        "        (result_df['prev_low'] > result_df['prev2_high'])  # å‰ä¸€å¤©å‘ä¸‹è·³ç©º\n",
        "    )\n",
        "\n",
        "    # çœ‹è·Œå³¶å½¢åè½‰: åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­ï¼Œå‡ºç¾å‘ä¸Šè·³ç©ºï¼Œç„¶å¾Œåƒ¹æ ¼åœ¨é«˜ä½ç›¤æ•´ï¼Œæœ€å¾Œå‘ä¸‹è·³ç©º\n",
        "    bearish_island_reversal = (\n",
        "        result_df['uptrend'] &\n",
        "        (result_df['high'] < result_df['prev_low']) &  # å‘ä¸‹è·³ç©º\n",
        "        (result_df['prev_high'] < result_df['prev2_low'])  # å‰ä¸€å¤©å‘ä¸Šè·³ç©º\n",
        "    )\n",
        "\n",
        "    result_df.loc[bullish_island_reversal, 'å³¶å½¢åè½‰_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[bearish_island_reversal, 'å³¶å½¢åè½‰_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 13. è­˜åˆ¥é ­è‚©é ‚å’Œé ­è‚©åº•\n",
        "    # é€™äº›å‹æ…‹éœ€è¦æ›´å¤šçš„æ•¸æ“šé»å’Œè¤‡é›œçš„é‚è¼¯ï¼Œé€™è£¡æä¾›ä¸€å€‹ç°¡åŒ–ç‰ˆæœ¬\n",
        "\n",
        "    # é ­è‚©é ‚: ä¸‰å€‹é«˜é»ï¼Œä¸­é–“çš„é«˜é»æœ€é«˜ï¼Œå…©å´é«˜é»å¤§è‡´ç›¸ç­‰\n",
        "    head_shoulders_top = (\n",
        "        result_df['uptrend'] &\n",
        "        (result_df['prev2_high'] < result_df['prev_high']) &  # å·¦è‚©ä½æ–¼é ­éƒ¨\n",
        "        (result_df['high'] < result_df['prev_high']) &        # å³è‚©ä½æ–¼é ­éƒ¨\n",
        "        (abs(result_df['high'] - result_df['prev2_high']) / result_df['prev2_high'] < 0.05)  # å·¦å³è‚©å¤§è‡´ç›¸ç­‰\n",
        "    )\n",
        "\n",
        "    # é ­è‚©åº•: ä¸‰å€‹ä½é»ï¼Œä¸­é–“çš„ä½é»æœ€ä½ï¼Œå…©å´ä½é»å¤§è‡´ç›¸ç­‰\n",
        "    head_shoulders_bottom = (\n",
        "        result_df['downtrend'] &\n",
        "        (result_df['prev2_low'] > result_df['prev_low']) &  # å·¦è‚©é«˜æ–¼é ­éƒ¨\n",
        "        (result_df['low'] > result_df['prev_low']) &        # å³è‚©é«˜æ–¼é ­éƒ¨\n",
        "        (abs(result_df['low'] - result_df['prev2_low']) / result_df['prev2_low'] < 0.05)  # å·¦å³è‚©å¤§è‡´ç›¸ç­‰\n",
        "    )\n",
        "\n",
        "    result_df.loc[head_shoulders_top, 'é ­è‚©é ‚_çœ‹è·Œ'] = -1\n",
        "    result_df.loc[head_shoulders_bottom, 'é ­è‚©åº•_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # 14. è­˜åˆ¥é›™é ‚å’Œé›™åº•\n",
        "    # é›™é ‚: å…©å€‹ç›¸è¿‘çš„é«˜é»ï¼Œä¸­é–“æœ‰ä¸€å€‹ä½é»\n",
        "    double_top = (\n",
        "        result_df['uptrend'] &\n",
        "        (abs(result_df['high'] - result_df['prev2_high']) / result_df['prev2_high'] < 0.03) &  # å…©å€‹é«˜é»ç›¸è¿‘\n",
        "        (result_df['prev_high'] < result_df['high']) &  # ä¸­é–“æœ‰ä¸€å€‹ä½é»\n",
        "        (result_df['prev_high'] < result_df['prev2_high'])\n",
        "    )\n",
        "\n",
        "    # é›™åº•: å…©å€‹ç›¸è¿‘çš„ä½é»ï¼Œä¸­é–“æœ‰ä¸€å€‹é«˜é»\n",
        "    double_bottom = (\n",
        "        result_df['downtrend'] &\n",
        "        (abs(result_df['low'] - result_df['prev2_low']) / result_df['prev2_low'] < 0.03) &  # å…©å€‹ä½é»ç›¸è¿‘\n",
        "        (result_df['prev_low'] > result_df['low']) &  # ä¸­é–“æœ‰ä¸€å€‹é«˜é»\n",
        "        (result_df['prev_low'] > result_df['prev2_low'])\n",
        "    )\n",
        "\n",
        "    result_df.loc[double_top, 'é›™é ‚_çœ‹è·Œ'] = -1\n",
        "    result_df.loc[double_bottom, 'é›™åº•_çœ‹æ¼²'] = 1\n",
        "\n",
        "    return result_df\n",
        "# ==============================================================================\n",
        "# Kç·šå‹æ…‹å„ªå…ˆç´šå®šç¾© (æ•¸å­—è¶Šå¤§å„ªå…ˆç´šè¶Šé«˜)\n",
        "PATTERN_PRIORITY = {\n",
        "    # é ‚éƒ¨åè½‰å‹æ…‹ (é«˜å„ªå…ˆç´š)\n",
        "    \"é ­è‚©é ‚\": 10,\n",
        "    \"é›™é ‚\": 9,\n",
        "    \"ä¸‰é ‚\": 8,\n",
        "    \"åœ“é ‚\": 7,\n",
        "    \"ä¸Šå‡æ¥”å½¢\": 7,\n",
        "    \"ä¸Šå‡ä¸‰è§’å½¢\": 6,\n",
        "\n",
        "    # åº•éƒ¨åè½‰å‹æ…‹ (é«˜å„ªå…ˆç´š)\n",
        "    \"é ­è‚©åº•\": 10,\n",
        "    \"é›™åº•\": 9,\n",
        "    \"ä¸‰åº•\": 8,\n",
        "    \"åœ“åº•\": 7,\n",
        "    \"ä¸‹é™æ¥”å½¢\": 7,\n",
        "    \"ä¸‹é™ä¸‰è§’å½¢\": 6,\n",
        "\n",
        "    # æŒçºŒå‹æ…‹ (ä¸­ç­‰å„ªå…ˆç´š)\n",
        "    \"å°ç¨±ä¸‰è§’å½¢\": 5,\n",
        "    \"çŸ©å½¢\": 5,\n",
        "    \"æ——å½¢\": 4,\n",
        "    \"ä¸‰è§’æ——\": 4,\n",
        "\n",
        "    # å–®æ—¥å‹æ…‹ (è¼ƒä½å„ªå…ˆç´š)\n",
        "    \"åå™¬\": 3,\n",
        "    \"åå­—æ˜Ÿ\": 3,\n",
        "    \"éŒ˜å­\": 3,\n",
        "    \"ä¸ŠåŠç·š\": 3,\n",
        "    \"æµæ˜Ÿ\": 3,\n",
        "    \"å¤šé ­åå™¬\": 3,\n",
        "    \"ç©ºé ­åå™¬\": 3,\n",
        "    \"å¤šé ­åˆºé€\": 2,\n",
        "    \"ç©ºé ­çƒé›²è“‹é ‚\": 2,\n",
        "    \"å¤šé ­åè½‰\": 2,\n",
        "    \"ç©ºé ­åè½‰\": 2,\n",
        "\n",
        "    # ç¼ºå£å‹æ…‹\n",
        "    \"çªç ´ç¼ºå£\": 3,\n",
        "    \"é€ƒé€¸ç¼ºå£\": 3,\n",
        "    \"æ¶ˆè€—ç¼ºå£\": 2,\n",
        "\n",
        "    # å…¶ä»–å¸¸è¦‹å‹æ…‹\n",
        "    \"å³¶ç‹€åè½‰\": 6,\n",
        "    \"Vå‹åè½‰\": 5,\n",
        "    \"Wå‹åè½‰\": 5,\n",
        "    \"ç®±é«”çªç ´\": 4,\n",
        "    \"é»ƒæ˜ä¹‹æ˜Ÿ\": 4,\n",
        "    \"æ›™å…‰ä¹‹æ˜Ÿ\": 4,\n",
        "    \"å¤šé ­ä¸‰æ˜Ÿ\": 3,\n",
        "    \"ç©ºé ­ä¸‰æ˜Ÿ\": 3\n",
        "}\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def generate_condensed_pattern_report_and_summary(full_pattern_report):\n",
        "    \"\"\"\n",
        "    å°‡å®Œæ•´çš„Kç·šå‹æ…‹å ±å‘Šç°¡åŒ–ç‚ºç²¾è¯æ‘˜è¦ï¼Œä¸¦æå–çµæ§‹åŒ–æ•¸æ“š\n",
        "\n",
        "    Args:\n",
        "        full_pattern_report (str): å®Œæ•´çš„Kç·šå‹æ…‹å ±å‘Š\n",
        "\n",
        "    Returns:\n",
        "        tuple: (condensed_report, report_summary)\n",
        "            - condensed_report (str): ç°¡åŒ–å¾Œçš„å ±å‘Šæ–‡æœ¬\n",
        "            - report_summary (dict): çµæ§‹åŒ–çš„å ±å‘Šæ‘˜è¦æ•¸æ“š\n",
        "    \"\"\"\n",
        "    # åˆå§‹åŒ–è¿”å›å€¼\n",
        "    condensed_report = \"\"\n",
        "    report_summary = {\n",
        "        \"daily\": {\"bullish\": [], \"bearish\": [], \"neutral\": []},\n",
        "        \"weekly\": {\"bullish\": [], \"bearish\": [], \"neutral\": []},\n",
        "        \"monthly\": {\"bullish\": [], \"bearish\": [], \"neutral\": []}\n",
        "    }\n",
        "\n",
        "    # æª¢æŸ¥å ±å‘Šæ˜¯å¦ç‚ºç©ºæˆ–ç„¡æ•ˆ\n",
        "    if not full_pattern_report or not isinstance(full_pattern_report, str):\n",
        "        return \"ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼šå ±å‘Šç‚ºç©ºæˆ–æ ¼å¼éŒ¯èª¤\", report_summary\n",
        "\n",
        "    try:\n",
        "        # å°‡å ±å‘Šåˆ†å‰²ç‚ºä¸åŒæ™‚é–“é€±æœŸçš„éƒ¨åˆ†\n",
        "        periods = [\"æ—¥ç·š\", \"é€±ç·š\", \"æœˆç·š\"]\n",
        "        period_keys = [\"daily\", \"weekly\", \"monthly\"]\n",
        "        pattern_types = [\"çœ‹æ¼²\", \"çœ‹è·Œ\", \"ä¸­æ€§\"]\n",
        "        type_keys = [\"bullish\", \"bearish\", \"neutral\"]\n",
        "\n",
        "        # åˆå§‹åŒ–çµæœå­—ç¬¦ä¸²\n",
        "        result_parts = []\n",
        "\n",
        "        # æª¢æŸ¥å ±å‘Šæ ¼å¼ - å˜—è©¦å°‹æ‰¾æ™‚é–“é€±æœŸæ¨™è¨˜\n",
        "        has_valid_format = False\n",
        "        for period in periods:\n",
        "            if period in full_pattern_report:\n",
        "                has_valid_format = True\n",
        "                break\n",
        "\n",
        "        if not has_valid_format:\n",
        "            # å¦‚æœå ±å‘Šæ²’æœ‰é æœŸçš„æ ¼å¼ï¼Œå˜—è©¦ç›´æ¥è§£ææ–‡æœ¬\n",
        "            lines = full_pattern_report.strip().split('\\n')\n",
        "            if lines:\n",
        "                condensed_report = \"Kç·šå‹æ…‹æ‘˜è¦:\\n\"\n",
        "                for line in lines[:10]:  # åªå–å‰10è¡Œ\n",
        "                    if line.strip():\n",
        "                        condensed_report += f\"â€¢ {line.strip()}\\n\"\n",
        "\n",
        "                # ç°¡å–®æª¢æ¸¬å ±å‘Šä¸­çš„é—œéµè©ä¾†å¡«å……æ‘˜è¦\n",
        "                for i, period_key in enumerate(period_keys):\n",
        "                    for j, type_key in enumerate(type_keys):\n",
        "                        for line in lines:\n",
        "                            if pattern_types[j] in line:\n",
        "                                pattern = line.strip()\n",
        "                                report_summary[period_key][type_key].append(pattern)\n",
        "\n",
        "                return condensed_report, report_summary\n",
        "\n",
        "        # æ­£å¸¸è§£ææ ¼å¼åŒ–å ±å‘Š\n",
        "        for i, period in enumerate(periods):\n",
        "            period_key = period_keys[i]\n",
        "            period_section = \"\"\n",
        "\n",
        "            # å°‹æ‰¾è©²æ™‚é–“é€±æœŸçš„éƒ¨åˆ†\n",
        "            start_idx = full_pattern_report.find(f\"{period}åˆ†æ:\")\n",
        "            if start_idx == -1:\n",
        "                continue\n",
        "\n",
        "            end_idx = -1\n",
        "            for next_period in periods[i+1:]:\n",
        "                end_idx = full_pattern_report.find(f\"{next_period}åˆ†æ:\", start_idx)\n",
        "                if end_idx != -1:\n",
        "                    break\n",
        "\n",
        "            if end_idx == -1:\n",
        "                period_content = full_pattern_report[start_idx:]\n",
        "            else:\n",
        "                period_content = full_pattern_report[start_idx:end_idx]\n",
        "\n",
        "            # è§£æè©²æ™‚é–“é€±æœŸä¸‹çš„å‹æ…‹\n",
        "            period_lines = []\n",
        "            for j, pattern_type in enumerate(pattern_types):\n",
        "                type_key = type_keys[j]\n",
        "                type_start = period_content.find(f\"{pattern_type}å‹æ…‹:\")\n",
        "                if type_start == -1:\n",
        "                    continue\n",
        "\n",
        "                type_end = -1\n",
        "                for next_type in pattern_types[j+1:]:\n",
        "                    type_end = period_content.find(f\"{next_type}å‹æ…‹:\", type_start)\n",
        "                    if type_end != -1:\n",
        "                        break\n",
        "\n",
        "                if type_end == -1:\n",
        "                    type_content = period_content[type_start:]\n",
        "                else:\n",
        "                    type_content = period_content[type_start:type_end]\n",
        "\n",
        "                # æå–å‹æ…‹åˆ—è¡¨\n",
        "                pattern_list_start = type_content.find(\":\")\n",
        "                if pattern_list_start != -1:\n",
        "                    pattern_list = type_content[pattern_list_start+1:].strip()\n",
        "                    patterns = [p.strip() for p in pattern_list.split(',') if p.strip() and p.strip() != 'ç„¡']\n",
        "\n",
        "                    # æ·»åŠ åˆ°æ‘˜è¦æ•¸æ“š\n",
        "                    report_summary[period_key][type_key].extend(patterns)\n",
        "\n",
        "                    # åªæœ‰ç•¶æœ‰å‹æ…‹æ™‚æ‰æ·»åŠ åˆ°å ±å‘Šä¸­\n",
        "                    if patterns:\n",
        "                        pattern_line = f\"â€¢ {pattern_type}: {', '.join(patterns)}\"\n",
        "                        period_lines.append(pattern_line)\n",
        "\n",
        "            # åªæœ‰ç•¶è©²æ™‚é–“é€±æœŸæœ‰å‹æ…‹æ™‚æ‰æ·»åŠ åˆ°æœ€çµ‚å ±å‘Š\n",
        "            if period_lines:\n",
        "                period_section = f\"{period}åˆ†æ:\\n\" + \"\\n\".join(period_lines)\n",
        "                result_parts.append(period_section)\n",
        "\n",
        "        # çµ„åˆæœ€çµ‚å ±å‘Š\n",
        "        if result_parts:\n",
        "            condensed_report = \"\\n\\n\".join(result_parts)\n",
        "        else:\n",
        "            condensed_report = \"æœªæª¢æ¸¬åˆ°æ˜é¡¯Kç·šå‹æ…‹\"\n",
        "\n",
        "        return condensed_report, report_summary\n",
        "\n",
        "    except Exception as e:\n",
        "        # å¦‚æœè§£æéç¨‹ä¸­å‡ºç¾ä»»ä½•éŒ¯èª¤ï¼Œè¿”å›ä¸€å€‹ç°¡å–®çš„éŒ¯èª¤ä¿¡æ¯\n",
        "        error_msg = f\"ç„¡æ³•è§£æKç·šå ±å‘Š: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        return \"ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼šè§£æéç¨‹å‡ºéŒ¯\", report_summary\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. æ–°å¢ï¼šæ™ºèƒ½äº¤æ˜“å»ºè­°å¼•æ“\n",
        "# ==============================================================================\n",
        "# ==============================================================================\n",
        "# å‡ç´šï¼šæ™ºèƒ½å»ºè­°å¼•æ“ V2 (æ›¿æ›èˆŠç‰ˆæœ¬)\n",
        "# åŠŸèƒ½ï¼šçµåˆç¶œåˆè©•åˆ†èˆ‡Kç·šçµæ§‹åŒ–å ±å‘Šï¼Œç”Ÿæˆæ›´æ·±å…¥çš„å»ºè­°\n",
        "# ==============================================================================\n",
        "import math\n",
        "import logging\n",
        "\n",
        "def generate_recommendation(combined_score, report_summary=None):\n",
        "    \"\"\"\n",
        "    æ ¹æ“šç¶œåˆè©•åˆ†å’Œè©³ç´°çš„Kç·šå‹æ…‹å ±å‘Šç”ŸæˆæŠ•è³‡å»ºè­°ã€åŸå› ã€ä¿¡å¿ƒåº¦åŠå‹æ…‹è©³æƒ…ã€‚\n",
        "    \"\"\"\n",
        "    # ğŸ” èª¿è©¦ä¿¡æ¯ï¼šç¢ºèªå‡½æ•¸è¢«èª¿ç”¨ä¸”åƒæ•¸æ­£ç¢º\n",
        "    #print(f\"ğŸ” [DEBUG] generate_recommendation è¢«èª¿ç”¨:\")\n",
        "    print(f\"    combined_score: {combined_score} (type: {type(combined_score)})\")\n",
        "    print(f\"    report_summary: {report_summary is not None}\")\n",
        "\n",
        "    # ç¢ºä¿ combined_score æ˜¯æ•¸å­—é¡å‹\n",
        "    try:\n",
        "        combined_score = float(combined_score)\n",
        "    except (ValueError, TypeError):\n",
        "        print(f\"âš ï¸  [WARNING] combined_score ç„¡æ³•è½‰æ›ç‚ºæ•¸å­—ï¼Œä½¿ç”¨é è¨­å€¼ 50\")\n",
        "        combined_score = 50.0\n",
        "\n",
        "    # --- ç¬¬1æ­¥ï¼šæ ¹æ“šç¶œåˆè©•åˆ†è¨­å®šåŸºæœ¬å»ºè­° ---\n",
        "    recommendation = {\n",
        "        \"action\": \"ä¸­ç«‹è§€å¯Ÿ\",\n",
        "        \"reason\": f\"ç¶œåˆè©•åˆ†ä¸­æ€§ ({combined_score:.2f})ã€‚\",\n",
        "        \"pattern_details\": []\n",
        "    }\n",
        "\n",
        "    if combined_score >= 70:\n",
        "        recommendation[\"action\"] = \"è²·å…¥\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†å¼·å‹ ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score >= 60:\n",
        "        recommendation[\"action\"] = \"è²·å…¥è§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼· ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score <= 30:\n",
        "        recommendation[\"action\"] = \"è³£å‡º\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†ç–²å¼± ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score <= 40:\n",
        "        recommendation[\"action\"] = \"è³£å‡ºè§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼± ({combined_score:.2f})ã€‚\"\n",
        "\n",
        "    # --- ç¬¬2æ­¥ï¼šæ ¹æ“šKç·šå‹æ…‹å¾®èª¿å»ºè­° ---\n",
        "    pattern_boost = 0  # Kç·šå‹æ…‹å°ä¿¡å¿ƒåº¦çš„åŠ æˆ\n",
        "\n",
        "    if report_summary:\n",
        "        try:\n",
        "            # è¨ˆç®—åŠ æ¬Šå¾Œçš„Kç·šå‹æ…‹æ•¸é‡\n",
        "            bullish_count = len(report_summary.get('daily', {}).get('bullish', [])) \\\n",
        "                          + len(report_summary.get('weekly', {}).get('bullish', [])) * 2 \\\n",
        "                          + len(report_summary.get('monthly', {}).get('monthly', [])) * 3\n",
        "            bearish_count = len(report_summary.get('daily', {}).get('bearish', [])) \\\n",
        "                          + len(report_summary.get('weekly', {}).get('bearish', [])) * 2 \\\n",
        "                          + len(report_summary.get('monthly', {}).get('bearish', [])) * 3\n",
        "\n",
        "            #print(f\"ğŸ” [DEBUG] Kç·šå‹æ…‹çµ±è¨ˆ: çœ‹æ¼²={bullish_count}, çœ‹è·Œ={bearish_count}\")\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦æœ‰å¼·çƒˆçš„Kç·šä¿¡è™Ÿ\n",
        "            if bullish_count >= 3 and bullish_count > bearish_count * 1.5:\n",
        "                if combined_score >= 50:\n",
        "                    recommendation[\"action\"] = \"å¼·çƒˆè²·å…¥\"\n",
        "                    recommendation[\"reason\"] += \" å¤šå€‹çœ‹æ¼²Kç·šå‹æ…‹æä¾›å¼·åŠ›æ”¯æ’ã€‚\"\n",
        "                    pattern_boost = 20  # å¼·çƒˆä¿¡è™ŸåŠ æˆ\n",
        "                else:\n",
        "                    recommendation[\"action\"] = \"è²·å…¥è§€æœ›\"\n",
        "                    recommendation[\"reason\"] += \" Kç·šå‹æ…‹çœ‹æ¼²ï¼Œä½†éœ€æ³¨æ„æŠ€è¡“æŒ‡æ¨™è¼ƒå¼±ã€‚\"\n",
        "                    pattern_boost = 10\n",
        "            elif bearish_count >= 3 and bearish_count > bullish_count * 1.5:\n",
        "                if combined_score <= 50:\n",
        "                    recommendation[\"action\"] = \"å¼·çƒˆè³£å‡º\"\n",
        "                    recommendation[\"reason\"] += \" å¤šå€‹çœ‹è·ŒKç·šå‹æ…‹æ§‹æˆå¼·åŠ›å£“åŠ›ã€‚\"\n",
        "                    pattern_boost = 20  # å¼·çƒˆä¿¡è™ŸåŠ æˆ\n",
        "                else:\n",
        "                    recommendation[\"action\"] = \"è³£å‡ºè§€æœ›\"\n",
        "                    recommendation[\"reason\"] += \" Kç·šå‹æ…‹çœ‹è·Œï¼Œä½†éœ€æ³¨æ„æŠ€è¡“æŒ‡æ¨™è¼ƒå¼·ã€‚\"\n",
        "                    pattern_boost = 10\n",
        "            elif bullish_count > bearish_count:\n",
        "                recommendation[\"reason\"] += \" Kç·šå‹æ…‹æ•´é«”åå‘çœ‹æ¼²ã€‚\"\n",
        "                pattern_boost = 5\n",
        "            elif bearish_count > bullish_count:\n",
        "                recommendation[\"reason\"] += \" Kç·šå‹æ…‹æ•´é«”åå‘çœ‹è·Œã€‚\"\n",
        "                pattern_boost = 5\n",
        "\n",
        "            # æ•´ç†Kç·šå‹æ…‹è©³æƒ…\n",
        "            pattern_details = []\n",
        "            for period in ['daily', 'weekly', 'monthly']:\n",
        "                period_data = report_summary.get(period, {})\n",
        "                period_patterns = []\n",
        "                if period_data.get('bullish'):\n",
        "                    period_patterns.append(f\"çœ‹æ¼²: {', '.join(period_data['bullish'])}\")\n",
        "                if period_data.get('bearish'):\n",
        "                    period_patterns.append(f\"çœ‹è·Œ: {', '.join(period_data['bearish'])}\")\n",
        "\n",
        "                if period_patterns:\n",
        "                    period_name = {'daily': 'æ—¥ç·š', 'weekly': 'é€±ç·š', 'monthly': 'æœˆç·š'}[period]\n",
        "                    pattern_details.append(f\"{period_name}: {'; '.join(period_patterns)}\")\n",
        "\n",
        "            if pattern_details:\n",
        "                recommendation[\"pattern_details\"] = pattern_details\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†Kç·šå ±å‘Šæ‘˜è¦æ™‚å‡ºéŒ¯: {str(e)}\")\n",
        "\n",
        "    # --- ç¬¬3æ­¥ï¼šè¨ˆç®—ä¿¡å¿ƒåº¦ï¼ˆä¿®æ­£ç‰ˆï¼‰ ---\n",
        "    # ä½¿ç”¨ç·šæ€§å‡½æ•¸è€Œéå¹³æ–¹å‡½æ•¸ï¼Œè®“ä¿¡å¿ƒåº¦æ›´åˆç†\n",
        "    distance_from_center = abs(combined_score - 50)\n",
        "\n",
        "    # åŸºç¤ä¿¡å¿ƒåº¦ï¼šè·é›¢ä¸­å¿ƒè¶Šé ï¼Œä¿¡å¿ƒåº¦è¶Šé«˜\n",
        "    base_confidence = min(distance_from_center * 2, 100)  # æ¯åé›¢1åˆ†å¢åŠ 2%ä¿¡å¿ƒåº¦ï¼Œæœ€é«˜100%\n",
        "\n",
        "    # åŠ ä¸ŠKç·šå‹æ…‹åŠ æˆ\n",
        "    total_confidence = min(base_confidence + pattern_boost, 100)\n",
        "\n",
        "    recommendation['confidence'] = int(total_confidence)\n",
        "\n",
        "    # ğŸ” èª¿è©¦ä¿¡æ¯ï¼šç¢ºèªä¿¡å¿ƒåº¦è¨ˆç®—\n",
        "    #print(f\"ğŸ” [DEBUG] ä¿¡å¿ƒåº¦è¨ˆç®—:\")\n",
        "    #print(f\"    distance_from_center: {distance_from_center}\")\n",
        "    #print(f\"    base_confidence: {base_confidence}\")\n",
        "    #print(f\"    pattern_boost: {pattern_boost}\")\n",
        "    #print(f\"    total_confidence: {total_confidence}\")\n",
        "    #print(f\"ğŸ” [DEBUG] æœ€çµ‚å»ºè­°: {recommendation}\")\n",
        "    #print(\"-\" * 50)\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "\n",
        "def get_pattern_explanation(pattern_name):\n",
        "    \"\"\"\n",
        "    ç²å–Kç·šå‹æ…‹çš„è§£é‡‹å’Œäº¤æ˜“å»ºè­°\n",
        "\n",
        "    åƒæ•¸:\n",
        "    pattern_name - Kç·šå‹æ…‹åç¨±\n",
        "\n",
        "    è¿”å›:\n",
        "    dict - åŒ…å«è§£é‡‹å’Œå»ºè­°çš„å­—å…¸\n",
        "    \"\"\"\n",
        "    pattern_dict = {\n",
        "        \"çœ‹æ¼²éŒ˜å­ç·š\": {\n",
        "            \"explanation\": \"åœ¨ä¸‹è·Œè¶¨å‹¢ä¸­å‡ºç¾ï¼Œå…·æœ‰è¼ƒé•·çš„ä¸‹å½±ç·šï¼Œè¡¨ç¤ºè²·æ–¹åŠ›é‡æ­£åœ¨å¢å¼·ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½æ˜¯åº•éƒ¨åè½‰ä¿¡è™Ÿï¼Œè€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨éŒ˜å­ç·šçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·ŒéŒ˜å­ç·š\": {\n",
        "            \"explanation\": \"åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­å‡ºç¾ï¼Œå…·æœ‰è¼ƒé•·çš„ä¸‹å½±ç·šï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡æ­£åœ¨å¢å¼·ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½æ˜¯é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œè€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨éŒ˜å­ç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œæµæ˜Ÿç·š\": {\n",
        "            \"explanation\": \"åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­å‡ºç¾ï¼Œå…·æœ‰è¼ƒé•·çš„ä¸Šå½±ç·šï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡æ­£åœ¨å¢å¼·ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½æ˜¯é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œè€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨æµæ˜Ÿç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"ä¸­æ€§åå­—æ˜Ÿ\": {\n",
        "            \"explanation\": \"é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒï¼Œè¡¨ç¤ºå¸‚å ´çŒ¶è±«ä¸æ±ºï¼Œå¤šç©ºåŠ›é‡å‡è¡¡ã€‚\",\n",
        "            \"suggestion\": \"é€šå¸¸è¡¨ç¤ºè¶¨å‹¢å¯èƒ½å³å°‡åè½‰ï¼Œå»ºè­°ç­‰å¾…ç¢ºèªä¿¡è™Ÿã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²åå™¬\": {\n",
        "            \"explanation\": \"å°é™°ç·šå¾Œå‡ºç¾å¤§é™½ç·šï¼Œä¸”é™½ç·šå®Œå…¨ã€Œåå™¬ã€äº†å‰ä¸€å¤©çš„é™°ç·šå¯¦é«”ï¼Œè¡¨ç¤ºè²·æ–¹åŠ›é‡å¼·å‹ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„çœ‹æ¼²ä¿¡è™Ÿï¼Œç‰¹åˆ¥æ˜¯åœ¨ä¸‹è·Œè¶¨å‹¢æœ«æœŸï¼Œå¯è€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨åå™¬Kç·šçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œåå™¬\": {\n",
        "            \"explanation\": \"å°é™½ç·šå¾Œå‡ºç¾å¤§é™°ç·šï¼Œä¸”é™°ç·šå®Œå…¨ã€Œåå™¬ã€äº†å‰ä¸€å¤©çš„é™½ç·šå¯¦é«”ï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡å¼·å‹ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„çœ‹è·Œä¿¡è™Ÿï¼Œç‰¹åˆ¥æ˜¯åœ¨ä¸Šæ¼²è¶¨å‹¢æœ«æœŸï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨åå™¬Kç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²æ¯å­ç·š\": {\n",
        "            \"explanation\": \"å¤§é™°ç·šå¾Œå‡ºç¾å°é™½ç·šï¼Œä¸”å°é™½ç·šå®Œå…¨åœ¨å‰ä¸€å¤©å¤§é™°ç·šå¯¦é«”ç¯„åœå…§ï¼Œè¡¨ç¤ºä¸‹è·Œå‹•èƒ½æ¸›å¼±ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½çš„åº•éƒ¨åè½‰ä¿¡è™Ÿï¼Œå»ºè­°ç­‰å¾…é€²ä¸€æ­¥ç¢ºèªå¾Œå†åšå¤šï¼Œæ­¢æè¨­åœ¨æ¯å­ç·šçµ„åˆçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œæ¯å­ç·š\": {\n",
        "            \"explanation\": \"å¤§é™½ç·šå¾Œå‡ºç¾å°é™°ç·šï¼Œä¸”å°é™°ç·šå®Œå…¨åœ¨å‰ä¸€å¤©å¤§é™½ç·šå¯¦é«”ç¯„åœå…§ï¼Œè¡¨ç¤ºä¸Šæ¼²å‹•èƒ½æ¸›å¼±ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½çš„é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œå»ºè­°ç­‰å¾…é€²ä¸€æ­¥ç¢ºèªå¾Œå†åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨æ¯å­ç·šçµ„åˆçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²æ™¨æ˜Ÿ\": {\n",
        "            \"explanation\": \"ç”±ä¸‰æ ¹Kç·šçµ„æˆï¼šå¤§é™°ç·šã€å°å¯¦é«”ç·šï¼ˆé€šå¸¸æ˜¯åå­—æ˜Ÿï¼‰å’Œå¤§é™½ç·šï¼Œè¡¨ç¤ºå¸‚å ´ç”±ç©ºé ­è½‰ç‚ºå¤šé ­ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„åº•éƒ¨åè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨æ™¨æ˜Ÿçµ„åˆçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œæš®æ˜Ÿ\": {\n",
        "            \"explanation\": \"ç”±ä¸‰æ ¹Kç·šçµ„æˆï¼šå¤§é™½ç·šã€å°å¯¦é«”ç·šï¼ˆé€šå¸¸æ˜¯åå­—æ˜Ÿï¼‰å’Œå¤§é™°ç·šï¼Œè¡¨ç¤ºå¸‚å ´ç”±å¤šé ­è½‰ç‚ºç©ºé ­ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨æš®æ˜Ÿçµ„åˆçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²ä¸‰ç™½å…µ\": {\n",
        "            \"explanation\": \"é€£çºŒä¸‰æ ¹ä¸Šæ¼²çš„é™½ç·šï¼Œæ¯æ ¹çš„æ”¶ç›¤åƒ¹éƒ½é«˜æ–¼å‰ä¸€æ ¹ï¼Œè¡¨ç¤ºè²·æ–¹æŒçºŒæ§åˆ¶å¸‚å ´ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„ä¸Šæ¼²è¶¨å‹¢ç¢ºèªä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨ç¬¬ä¸€æ ¹Kç·šçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œä¸‰é»‘é´‰\": {\n",
        "            \"explanation\": \"é€£çºŒä¸‰æ ¹ä¸‹è·Œçš„é™°ç·šï¼Œæ¯æ ¹çš„æ”¶ç›¤åƒ¹éƒ½ä½æ–¼å‰ä¸€æ ¹ï¼Œè¡¨ç¤ºè³£æ–¹æŒçºŒæ§åˆ¶å¸‚å ´ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„ä¸‹è·Œè¶¨å‹¢ç¢ºèªä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨ç¬¬ä¸€æ ¹Kç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²ç©¿åˆºç·š\": {\n",
        "            \"explanation\": \"å¤§é™°ç·šå¾Œå‡ºç¾å¤§é™½ç·šï¼Œä¸”é™½ç·šé–‹ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©æœ€ä½åƒ¹ï¼Œæ”¶ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©å¯¦é«”ä¸­é»ï¼Œè¡¨ç¤ºè²·æ–¹åŠ›é‡å¼·å‹ã€‚\",\n",
        "            \"suggestion\": \"çœ‹æ¼²åè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨ç©¿åˆºç·šçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œçƒé›²è“‹é ‚\": {\n",
        "            \"explanation\": \"å¤§é™½ç·šå¾Œå‡ºç¾å¤§é™°ç·šï¼Œä¸”é™°ç·šé–‹ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©æœ€é«˜åƒ¹ï¼Œæ”¶ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©å¯¦é«”ä¸­é»ï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡å¼·å‹ã€‚\",\n",
        "            \"suggestion\": \"çœ‹è·Œåè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨çƒé›²è“‹é ‚çš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"ä¸­æ€§é•·è…³åå­—ç·š\": {\n",
        "            \"explanation\": \"é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒï¼Œä½†æœ‰å¾ˆé•·çš„ä¸Šä¸‹å½±ç·šï¼Œè¡¨ç¤ºå¸‚å ´æ³¢å‹•åŠ‡çƒˆä½†æœªå½¢æˆæ˜ç¢ºæ–¹å‘ã€‚\",\n",
        "            \"suggestion\": \"å¸‚å ´çŒ¶è±«ä¸æ±ºçš„ä¿¡è™Ÿï¼Œå¯èƒ½é ç¤ºè‘—åŠ‡çƒˆæ³¢å‹•ï¼Œå»ºè­°ç­‰å¾…æ›´æ˜ç¢ºçš„æ–¹å‘ä¿¡è™Ÿã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œä¸ŠåŠç·š\": {\n",
        "            \"explanation\": \"åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­å‡ºç¾ï¼Œå½¢ç‹€é¡ä¼¼éŒ˜å­ç·šä½†å‡ºç¾åœ¨ä¸Šæ¼²è¶¨å‹¢é ‚éƒ¨ï¼Œå…·æœ‰è¼ƒé•·çš„ä¸‹å½±ç·šï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡æ­£åœ¨å¢å¼·ã€‚\",\n",
        "            \"suggestion\": \"é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨ä¸ŠåŠç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"ä¸­æ€§é™€èº\": {\n",
        "            \"explanation\": \"å°å¯¦é«”Kç·šï¼Œä¸Šä¸‹å½±ç·šé•·åº¦ç›¸è¿‘ï¼Œè¡¨ç¤ºå¸‚å ´çŒ¶è±«ä¸æ±ºï¼Œå¤šç©ºåŠ›é‡ç›¸ç•¶ã€‚\",\n",
        "            \"suggestion\": \"é€šå¸¸è¡¨ç¤ºå¸‚å ´ä¸ç¢ºå®šæ€§å¢åŠ ï¼Œå»ºè­°ç­‰å¾…æ›´æ˜ç¢ºçš„æ–¹å‘ä¿¡è™Ÿã€‚\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # å¾å®Œæ•´åç¨±ä¸­æå–åŸºæœ¬å‹æ…‹åç¨±\n",
        "    for key in pattern_dict.keys():\n",
        "        if key in pattern_name:\n",
        "            return pattern_dict[key]\n",
        "\n",
        "    return {\n",
        "        \"explanation\": \"é€™æ˜¯ä¸€ç¨®æŠ€è¡“å½¢æ…‹ï¼Œå¯èƒ½è¡¨ç¤ºå¸‚å ´è¶¨å‹¢çš„è®ŠåŒ–ã€‚\",\n",
        "        \"suggestion\": \"å»ºè­°çµåˆå…¶ä»–æŠ€è¡“æŒ‡æ¨™é€²è¡Œç¢ºèªã€‚\"\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def generate_pattern_report(df, periods=['daily']):\n",
        "    \"\"\"\n",
        "    ç”ŸæˆKç·šå‹æ…‹åˆ†æå ±å‘Šï¼ˆä¸ä¾è³´talibï¼‰\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): åŒ…å«OHLCæ•¸æ“šçš„DataFrame\n",
        "        periods (list): è¦åˆ†æçš„æ™‚é–“é€±æœŸåˆ—è¡¨ï¼Œå¯ä»¥æ˜¯ 'daily', 'weekly', 'monthly'\n",
        "\n",
        "    Returns:\n",
        "        str: æ ¼å¼åŒ–çš„Kç·šå‹æ…‹å ±å‘Š\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šæ•¸æ“šç‚ºç©º\"\n",
        "\n",
        "    # ç¢ºä¿å¿…è¦çš„åˆ—å­˜åœ¨\n",
        "    required_cols = ['open', 'high', 'low', 'close']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        missing = [col for col in required_cols if col not in df.columns]\n",
        "        return f\"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šç¼ºå°‘å¿…è¦åˆ— {', '.join(missing)}\"\n",
        "\n",
        "    # å®šç¾©ç°¡å–®çš„Kç·šå‹æ…‹æª¢æ¸¬å‡½æ•¸\n",
        "    def detect_patterns(ohlc_data):\n",
        "        \"\"\"ä½¿ç”¨ç°¡å–®è¦å‰‡æª¢æ¸¬å¸¸è¦‹Kç·šå‹æ…‹\"\"\"\n",
        "        patterns = {\n",
        "            \"çœ‹æ¼²\": [],\n",
        "            \"çœ‹è·Œ\": [],\n",
        "            \"ä¸­æ€§\": []\n",
        "        }\n",
        "\n",
        "        # ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“š\n",
        "        if len(ohlc_data) < 5:\n",
        "            return patterns\n",
        "\n",
        "        # å–æœ€è¿‘çš„Kç·šæ•¸æ“šé€²è¡Œåˆ†æ\n",
        "        recent = ohlc_data.tail(10).copy()\n",
        "\n",
        "        # è¨ˆç®—æ¯æ ¹Kç·šçš„å¯¦é«”å¤§å°å’Œå½±ç·šé•·åº¦\n",
        "        recent['body_size'] = abs(recent['close'] - recent['open'])\n",
        "        recent['upper_shadow'] = recent['high'] - recent[['open', 'close']].max(axis=1)\n",
        "        recent['lower_shadow'] = recent[['open', 'close']].min(axis=1) - recent['low']\n",
        "        recent['is_bullish'] = recent['close'] > recent['open']\n",
        "        recent['is_bearish'] = recent['close'] < recent['open']\n",
        "\n",
        "        # è¨ˆç®—ç§»å‹•å¹³å‡ç·š\n",
        "        recent['ma5'] = recent['close'].rolling(window=5).mean()\n",
        "        recent['ma10'] = recent['close'].rolling(window=10).mean()\n",
        "\n",
        "        # æœ€è¿‘3æ ¹Kç·š\n",
        "        last3 = recent.tail(3)\n",
        "\n",
        "        # æª¢æ¸¬çœ‹æ¼²å‹æ…‹\n",
        "\n",
        "        # ä¸‰ç™½å…µ: é€£çºŒä¸‰æ ¹ä¸Šæ¼²Kç·šï¼Œæ¯æ ¹æ”¶ç›¤åƒ¹éƒ½é«˜æ–¼å‰ä¸€æ ¹\n",
        "        if len(last3) == 3 and all(last3['is_bullish']) and \\\n",
        "           last3['close'].iloc[0] < last3['close'].iloc[1] < last3['close'].iloc[2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"ä¸‰ç™½å…µ\")\n",
        "\n",
        "        # å¤šé ­åå™¬: ä¸€æ ¹çœ‹è·ŒKç·šå¾Œè·Ÿä¸€æ ¹è¼ƒå¤§çš„çœ‹æ¼²Kç·šï¼Œå®Œå…¨åå™¬å‰ä¸€æ ¹\n",
        "        if len(last3) >= 2 and last3['is_bearish'].iloc[-2] and last3['is_bullish'].iloc[-1] and \\\n",
        "           last3['open'].iloc[-1] <= last3['close'].iloc[-2] and \\\n",
        "           last3['close'].iloc[-1] >= last3['open'].iloc[-2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"å¤šé ­åå™¬\")\n",
        "\n",
        "        # çœ‹æ¼²éŒ˜é ­: ä¸‹å½±ç·šé•·ï¼Œå¹¾ä¹æ²’æœ‰ä¸Šå½±ç·šï¼Œå°å¯¦é«”\n",
        "        if any(last3['lower_shadow'] > 2 * last3['body_size']) and \\\n",
        "           any(last3['upper_shadow'] < 0.2 * last3['body_size']) and \\\n",
        "           any(last3['is_bullish']):\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"çœ‹æ¼²éŒ˜é ­\")\n",
        "\n",
        "        # æª¢æ¸¬çœ‹è·Œå‹æ…‹\n",
        "\n",
        "        # ä¸‰é»‘é´‰: é€£çºŒä¸‰æ ¹ä¸‹è·ŒKç·šï¼Œæ¯æ ¹æ”¶ç›¤åƒ¹éƒ½ä½æ–¼å‰ä¸€æ ¹\n",
        "        if len(last3) == 3 and all(last3['is_bearish']) and \\\n",
        "           last3['close'].iloc[0] > last3['close'].iloc[1] > last3['close'].iloc[2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ä¸‰é»‘é´‰\")\n",
        "\n",
        "        # ç©ºé ­åå™¬: ä¸€æ ¹çœ‹æ¼²Kç·šå¾Œè·Ÿä¸€æ ¹è¼ƒå¤§çš„çœ‹è·ŒKç·šï¼Œå®Œå…¨åå™¬å‰ä¸€æ ¹\n",
        "        if len(last3) >= 2 and last3['is_bullish'].iloc[-2] and last3['is_bearish'].iloc[-1] and \\\n",
        "           last3['open'].iloc[-1] >= last3['close'].iloc[-2] and \\\n",
        "           last3['close'].iloc[-1] <= last3['open'].iloc[-2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ç©ºé ­åå™¬\")\n",
        "\n",
        "        # çœ‹è·ŒåŠéŒ˜: ä¸Šå½±ç·šé•·ï¼Œå¹¾ä¹æ²’æœ‰ä¸‹å½±ç·šï¼Œå°å¯¦é«”\n",
        "        if any(last3['upper_shadow'] > 2 * last3['body_size']) and \\\n",
        "           any(last3['lower_shadow'] < 0.2 * last3['body_size']) and \\\n",
        "           any(last3['is_bearish']):\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"çœ‹è·ŒåŠéŒ˜\")\n",
        "\n",
        "        # æª¢æ¸¬ä¸­æ€§å‹æ…‹\n",
        "\n",
        "        # åå­—æ˜Ÿ: é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒ\n",
        "        if any(last3['body_size'] < 0.1 * (last3['high'] - last3['low'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"åå­—æ˜Ÿ\")\n",
        "\n",
        "        # é•·è…¿åå­—: é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒï¼Œä¸Šä¸‹å½±ç·šéƒ½å¾ˆé•·\n",
        "        if any((last3['body_size'] < 0.1 * (last3['high'] - last3['low'])) &\n",
        "               (last3['upper_shadow'] > last3['body_size']) &\n",
        "               (last3['lower_shadow'] > last3['body_size'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"é•·è…¿åå­—\")\n",
        "\n",
        "        # ç´¡éŒ˜é ‚: å°å¯¦é«”ï¼Œä¸Šä¸‹å½±ç·šå·®ä¸å¤šé•·\n",
        "        if any((last3['body_size'] < 0.3 * (last3['high'] - last3['low'])) &\n",
        "               (abs(last3['upper_shadow'] - last3['lower_shadow']) < 0.2 * (last3['high'] - last3['low']))):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"ç´¡éŒ˜\")\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    report_parts = []\n",
        "\n",
        "    # ç‚ºæ¯å€‹æ™‚é–“é€±æœŸç”Ÿæˆå ±å‘Š\n",
        "    for period in periods:\n",
        "        period_df = df.copy()\n",
        "\n",
        "        # ç¢ºä¿æ—¥æœŸåˆ—æ˜¯æ—¥æœŸé¡å‹\n",
        "        date_col = None\n",
        "        if 'date' in period_df.columns:\n",
        "            date_col = 'date'\n",
        "        elif 'datetime' in period_df.columns:\n",
        "            date_col = 'datetime'\n",
        "        elif 'time' in period_df.columns:\n",
        "            date_col = 'time'\n",
        "\n",
        "        # å¦‚æœæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œè¨­ç½®ç‚ºç´¢å¼•\n",
        "        if date_col:\n",
        "            try:\n",
        "                # å˜—è©¦å°‡æ—¥æœŸåˆ—è½‰æ›ç‚ºdatetimeé¡å‹\n",
        "                period_df[date_col] = pd.to_datetime(period_df[date_col])\n",
        "                period_df.set_index(date_col, inplace=True)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"ç„¡æ³•å°‡ {date_col} è¨­ç½®ç‚ºç´¢å¼•: {str(e)}\")\n",
        "                # å¦‚æœç„¡æ³•è¨­ç½®æ—¥æœŸç´¢å¼•ï¼Œå°±ä½¿ç”¨åŸå§‹æ•¸æ“š\n",
        "\n",
        "        # æ ¹æ“šæ™‚é–“é€±æœŸé‡æ–°å–æ¨£æ•¸æ“š (åªæœ‰ç•¶ç´¢å¼•æ˜¯DatetimeIndexæ™‚æ‰åŸ·è¡Œ)\n",
        "        try:\n",
        "            if period != 'daily' and isinstance(period_df.index, pd.DatetimeIndex):\n",
        "                if period == 'weekly':\n",
        "                    period_df = period_df.resample('W').agg({\n",
        "                        'open': 'first',\n",
        "                        'high': 'max',\n",
        "                        'low': 'min',\n",
        "                        'close': 'last'\n",
        "                    })\n",
        "                elif period == 'monthly':\n",
        "                    period_df = period_df.resample('M').agg({\n",
        "                        'open': 'first',\n",
        "                        'high': 'max',\n",
        "                        'low': 'min',\n",
        "                        'close': 'last'\n",
        "                    })\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"é‡æ¡æ¨£åˆ° {period} æ™‚å‡ºéŒ¯: {str(e)}\")\n",
        "            # å¦‚æœé‡æ¡æ¨£å¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨åŸå§‹æ•¸æ“š\n",
        "\n",
        "        # ç§»é™¤NaNå€¼\n",
        "        period_df = period_df.dropna()\n",
        "\n",
        "        if period_df.empty:\n",
        "            continue\n",
        "\n",
        "        # ä¸­æ–‡æ™‚é–“é€±æœŸåç¨±\n",
        "        period_name = {\n",
        "            'daily': 'æ—¥ç·š',\n",
        "            'weekly': 'é€±ç·š',\n",
        "            'monthly': 'æœˆç·š'\n",
        "        }.get(period, period)\n",
        "\n",
        "        # æª¢æ¸¬Kç·šå‹æ…‹\n",
        "        try:\n",
        "            patterns = detect_patterns(period_df)\n",
        "\n",
        "            period_report = [f\"{period_name}åˆ†æ:\"]\n",
        "\n",
        "            # æ·»åŠ æª¢æ¸¬åˆ°çš„å‹æ…‹åˆ°å ±å‘Šä¸­\n",
        "            for pattern_type, detected_patterns in patterns.items():\n",
        "                if detected_patterns:\n",
        "                    pattern_str = \", \".join(detected_patterns)\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: {pattern_str}\")\n",
        "                else:\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: ç„¡\")\n",
        "\n",
        "            # æ·»åŠ è©²æ™‚é–“é€±æœŸçš„å ±å‘Š\n",
        "            report_parts.append(\"\\n\".join(period_report))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {period_name} å‹æ…‹æ™‚å‡ºéŒ¯: {str(e)}\")\n",
        "            report_parts.append(f\"{period_name}åˆ†æ:\\nåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "    # å¦‚æœæ²’æœ‰ç”Ÿæˆä»»ä½•å ±å‘Šéƒ¨åˆ†ï¼Œè¿”å›ä¸€å€‹é»˜èªæ¶ˆæ¯\n",
        "    if not report_parts:\n",
        "        return \"æœªæª¢æ¸¬åˆ°æ˜é¡¯Kç·šå‹æ…‹\"\n",
        "\n",
        "    # çµ„åˆæœ€çµ‚å ±å‘Š\n",
        "    return \"\\n\\n\".join(report_parts)\n",
        "\n",
        "\n",
        "def analyze_multi_timeframe(df):\n",
        "    \"\"\"\n",
        "    å¤šæ™‚é–“æ¡†æ¶åˆ†æã€‚\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return {'error': 'ç„¡æœ‰æ•ˆæ•¸æ“š'}\n",
        "\n",
        "    try:\n",
        "        result = {\n",
        "            'D': {'quadrant': 'Q1', 'description': 'çœ‹æ¼²' if 'MA20' in df.columns and df['Close'].iloc[-1] > df['MA20'].iloc[-1] else 'ä¸­æ€§'},\n",
        "            'W': {'quadrant': 'Q2', 'description': 'ä¸­æ€§'},\n",
        "            'M': {'quadrant': 'Q1', 'description': 'çœ‹æ¼²' if 'MA60' in df.columns and df['Close'].iloc[-1] > df['MA60'].iloc[-1] else 'ä¸­æ€§'},\n",
        "            'combined': {\n",
        "                'trend_consistency': 'çœ‹æ¼²' if 'MA20' in df.columns and df['Close'].iloc[-1] > df['MA20'].iloc[-1] else 'ä¸­æ€§',\n",
        "                'strength': 'å¼·å‹¢' if 'RSI' in df.columns and df['RSI'].iloc[-1] > 60 else 'ä¸€èˆ¬',\n",
        "                'suggestion': 'è²·å…¥' if 'MA20' in df.columns and df['Close'].iloc[-1] > df['MA20'].iloc[-1] else 'æŒæœ‰'\n",
        "            }\n",
        "        }\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¤šæ™‚é–“æ¡†æ¶åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return {'error': f'åˆ†æå¤±æ•—: {str(e)}'}\n",
        "\n",
        "def analyze_market_structure(df):\n",
        "    \"\"\"\n",
        "    å¸‚å ´çµæ§‹åˆ†æã€‚\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return {'error': 'ç„¡æœ‰æ•ˆæ•¸æ“š'}\n",
        "\n",
        "    try:\n",
        "        last_price = df['Close'].iloc[-1]\n",
        "        support_levels = df['Low'].rolling(window=20).min().tail(5).tolist()\n",
        "        resistance_levels = df['High'].rolling(window=20).max().tail(5).tolist()\n",
        "        recent_volatility = df['Close'].pct_change().tail(20).std() * 100\n",
        "        long_term_volatility = df['Close'].pct_change().std() * 100\n",
        "\n",
        "        return {\n",
        "            'price_levels': {\n",
        "                'position': 'é«˜æ–¼æ”¯æ’ä½' if last_price > max(support_levels) else 'ä½æ–¼é˜»åŠ›ä½',\n",
        "                'resistance_levels': resistance_levels,\n",
        "                'support_levels': support_levels\n",
        "            },\n",
        "            'trend': 'çœ‹æ¼²' if 'MA20' in df.columns and df['Close'].iloc[-1] > df['MA20'].iloc[-1] else 'çœ‹è·Œ',\n",
        "            'volatility': {\n",
        "                'status': 'é«˜' if recent_volatility > long_term_volatility else 'ä½',\n",
        "                'recent': round(recent_volatility, 2),\n",
        "                'long_term': round(long_term_volatility, 2)\n",
        "            },\n",
        "            'volume': {\n",
        "                'status': 'å¢åŠ ' if 'Volume' in df.columns and df['Volume'].iloc[-1] > df['Volume'].rolling(window=20).mean().iloc[-1] else 'æ¸›å°‘',\n",
        "                'recent_avg': int(df['Volume'].tail(20).mean()) if 'Volume' in df.columns else 0,\n",
        "                'long_term_avg': int(df['Volume'].mean()) if 'Volume' in df.columns else 0\n",
        "            },\n",
        "            'sentiment': {\n",
        "                'status': 'è¶…è²·' if 'RSI' in df.columns and df['RSI'].iloc[-1] > 70 else 'è¶…è³£' if 'RSI' in df.columns and df['RSI'].iloc[-1] < 30 else 'ä¸­æ€§',\n",
        "                'rsi': round(df['RSI'].iloc[-1], 2) if 'RSI' in df.columns else 50\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¸‚å ´çµæ§‹åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return {'error': f'åˆ†æå¤±æ•—: {str(e)}'}\n",
        "\n",
        "def generate_indicator_summary(status):\n",
        "    \"\"\"\n",
        "    ç”ŸæˆæŠ€è¡“æŒ‡æ¨™æ‘˜è¦ã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if isinstance(status, dict) and 'error' in status:\n",
        "            return \"ç„¡æœ‰æ•ˆæŠ€è¡“æŒ‡æ¨™\"\n",
        "\n",
        "        summary = []\n",
        "        df = status.get('data_df')\n",
        "        if df is None or df.empty:\n",
        "            return \"ç„¡æœ‰æ•ˆæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\"\n",
        "\n",
        "        if 'MA5' in df.columns and 'MA20' in df.columns:\n",
        "            summary.append(\"ç§»å‹•å¹³å‡ç·š: çœ‹æ¼²\" if df['MA5'].iloc[-1] > df['MA20'].iloc[-1] else \"ç§»å‹•å¹³å‡ç·š: ä¸­æ€§\")\n",
        "\n",
        "        if 'RSI' in df.columns:\n",
        "            rsi = df['RSI'].iloc[-1]\n",
        "            summary.append(f\"RSI: {'è¶…è²·' if rsi > 70 else 'è¶…è³£' if rsi < 30 else 'ä¸­æ€§'} ({round(rsi, 2)})\")\n",
        "\n",
        "        if 'MACD' in df.columns and 'Signal' in df.columns:\n",
        "            summary.append(\"MACD: æ­£å‘\" if df['MACD'].iloc[-1] > df['Signal'].iloc[-1] else \"MACD: è² å‘\")\n",
        "\n",
        "        if 'K' in df.columns and 'D' in df.columns:\n",
        "            summary.append(\"KD: çœ‹æ¼²\" if df['K'].iloc[-1] > df['D'].iloc[-1] else \"KD: çœ‹è·Œ\")\n",
        "\n",
        "        return \", \".join(summary) if summary else \"ç„¡å¯ç”¨æŠ€è¡“æŒ‡æ¨™\"\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”ŸæˆæŠ€è¡“æŒ‡æ¨™æ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return \"æŠ€è¡“æŒ‡æ¨™æ‘˜è¦ç”Ÿæˆå¤±æ•—\"\n",
        "\n",
        "\n",
        "def get_summary_report_html(data: dict):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆ HTML æ ¼å¼çš„çµ±è¨ˆå ±å‘Šã€‚\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for stock_id, stock_data in data.items():\n",
        "        try:\n",
        "            # æª¢æŸ¥æ­·å²è³‡æ–™æ¬„ä½\n",
        "            hist_data = stock_data.get(\"æ­·å²è³‡æ–™\")\n",
        "            if not hist_data:\n",
        "                hist_data = stock_data.get(\"data\", [])\n",
        "\n",
        "            if not hist_data:\n",
        "                raise ValueError(\"ç„¡æ­·å²è³‡æ–™\")\n",
        "\n",
        "            df = pd.DataFrame(hist_data)\n",
        "            if df.empty:\n",
        "                raise ValueError(\"æ­·å²è³‡æ–™ç‚ºç©º\")\n",
        "\n",
        "            # æª¢æŸ¥æ¬„ä½åç¨±ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡ï¼‰\n",
        "            close_col = None\n",
        "            volume_col = None\n",
        "\n",
        "            for col in ['æ”¶ç›¤', 'Close', 'close']:\n",
        "                if col in df.columns:\n",
        "                    close_col = col\n",
        "                    break\n",
        "\n",
        "            for col in ['æˆäº¤é‡', 'Volume', 'volume']:\n",
        "                if col in df.columns:\n",
        "                    volume_col = col\n",
        "                    break\n",
        "\n",
        "            if not close_col or not volume_col:\n",
        "                raise ValueError(\"ç¼ºå°‘å¿…è¦æ¬„ä½\")\n",
        "\n",
        "            summary = df[[close_col, volume_col]].describe().T\n",
        "\n",
        "            row = {\n",
        "                \"è‚¡ç¥¨ä»£ç¢¼\": stock_id,\n",
        "                \"æ”¶ç›¤å¹³å‡\": round(summary.loc[close_col, \"mean\"], 2),\n",
        "                \"æ”¶ç›¤æœ€ä½\": round(summary.loc[close_col, \"min\"], 2),\n",
        "                \"æ”¶ç›¤æœ€é«˜\": round(summary.loc[close_col, \"max\"], 2),\n",
        "                \"æˆäº¤é‡å¹³å‡\": round(summary.loc[volume_col, \"mean\"], 0),\n",
        "                \"æˆäº¤é‡æœ€ä½\": round(summary.loc[volume_col, \"min\"], 0),\n",
        "                \"æˆäº¤é‡æœ€é«˜\": round(summary.loc[volume_col, \"max\"], 0),\n",
        "            }\n",
        "            rows.append(row)\n",
        "        except Exception as e:\n",
        "            rows.append({\n",
        "                \"è‚¡ç¥¨ä»£ç¢¼\": stock_id,\n",
        "                \"æ”¶ç›¤å¹³å‡\": \"éŒ¯èª¤\",\n",
        "                \"æ”¶ç›¤æœ€ä½\": \"\",\n",
        "                \"æ”¶ç›¤æœ€é«˜\": \"\",\n",
        "                \"æˆäº¤é‡å¹³å‡\": str(e),\n",
        "                \"æˆäº¤é‡æœ€ä½\": \"\",\n",
        "                \"æˆäº¤é‡æœ€é«˜\": \"\"\n",
        "            })\n",
        "\n",
        "    result_df = pd.DataFrame(rows)\n",
        "    return result_df.to_html(index=False, border=1, justify=\"center\", escape=False)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸ (***é‡å¤§ä¿®æ­£å€***)\n",
        "# ==============================================================================\n",
        "def send_notifications(message: str, files: List[str] = None):\n",
        "    \"\"\"\n",
        "    ç°¡åŒ–ç‰ˆé€šçŸ¥å‡½æ•¸ - åƒ…è¼¸å‡ºåˆ°æ§åˆ¶å°ï¼Œä¸éœ€è¦å¤–éƒ¨é…ç½®\n",
        "    \"\"\"\n",
        "    print(\"\\n=== é€šçŸ¥è¨Šæ¯ ===\")\n",
        "    print(message)\n",
        "    if files:\n",
        "        print(f\"é™„åŠ æª”æ¡ˆ: {', '.join(files)}\")\n",
        "    print(\"===============\\n\")\n",
        "\n",
        "    # å¦‚æœæœ‰æ—¥èªŒè¨˜éŒ„å™¨ï¼Œä¹Ÿè¨˜éŒ„ä¸€ä¸‹\n",
        "    try:\n",
        "        logger.info(f\"é€šçŸ¥è¨Šæ¯å·²è¼¸å‡ºåˆ°æ§åˆ¶å° (å« {len(files) if files else 0} å€‹æª”æ¡ˆ)\")\n",
        "    except:\n",
        "        pass  # å¦‚æœæ²’æœ‰ logger æˆ–å‡ºéŒ¯ï¼Œå°±å¿½ç•¥\n",
        "\n",
        "    \"\"\"\n",
        "    ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord (åŒæ­¥ç‰ˆæœ¬)\n",
        "    \"\"\"\n",
        "    # --- Telegram ç™¼é€ ---\n",
        "    for chat_id in TELEGRAM_CHAT_ID:\n",
        "        try:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            requests.post(url_msg, json=payload, timeout=20)\n",
        "            logger.info(f\"Telegram æ‘˜è¦æˆåŠŸç™¼é€è‡³ chat_id: {chat_id}\")\n",
        "\n",
        "            # ç™¼é€åœ–ç‰‡æª”æ¡ˆ\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        with open(file_path, 'rb') as f:\n",
        "                            photo_files = {'photo': (os.path.basename(file_path), f)}\n",
        "                            data = {'chat_id': chat_id}\n",
        "                            requests.post(url_photo, data=data, files=photo_files, timeout=60)\n",
        "                logger.info(f\"Telegram åœ–æª”æˆåŠŸç™¼é€è‡³ chat_id: {chat_id} ({len(files)}å€‹)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Telegram é€šçŸ¥è‡³ {chat_id} æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # --- Discord ç™¼é€ ---\n",
        "    try:\n",
        "        # æ¸…ç†è¨Šæ¯ä¸­çš„ Markdown ç¬¦è™Ÿï¼Œä½¿å…¶åœ¨ Discord ä¸­æ­£å¸¸é¡¯ç¤º\n",
        "        discord_message = message.replace('*', '').replace('_', '')\n",
        "        webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{discord_message}\\n```\")\n",
        "        if files:\n",
        "            for file_path in files:\n",
        "                if os.path.exists(file_path):\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "        response = webhook.execute()\n",
        "        if response.ok:\n",
        "            logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "        else:\n",
        "            logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "def format_notification_message(\n",
        "    results_to_show: Dict,\n",
        "    successful_analysis: int,\n",
        "    failed_analysis: int,\n",
        "    total_after_volume_filter: int,\n",
        "    top_n=5\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯ (å‡ç´šç‰ˆ)ï¼ŒåŒ…å«åˆ†æçµ±è¨ˆæ•¸æ“šã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not results_to_show:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– *å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š*\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆé¡¯ç¤ºæ¢ä»¶çš„è‚¡ç¥¨ã€‚\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–ã€‚\n",
        "\"\"\"\n",
        "\n",
        "        # æŒ‰åˆ†æ•¸æ’åºï¼Œç¢ºä¿é¡¯ç¤ºçš„æ˜¯æœ€é«˜åˆ†çš„è‚¡ç¥¨\n",
        "        top_stocks = sorted(results_to_show.values(), key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– *å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š*\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "*ğŸ“ˆ åˆ†æçµ±è¨ˆ:*\n",
        "> â€¢ ç¬¦åˆæˆäº¤é‡æ¨™æº–: {total_after_volume_filter} æ”¯\n",
        "> â€¢ æˆåŠŸåˆ†æ: {successful_analysis} æ”¯\n",
        "> â€¢ åˆ†æå¤±æ•—: {failed_analysis} æ”¯\n",
        "\n",
        "ğŸ† *TOP {min(top_n, len(top_stocks))} æ¨è–¦è‚¡ç¥¨:*\n",
        "\"\"\"\n",
        "        for rank, result in enumerate(top_stocks[:top_n], 1):\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            message += f\"\"\"\n",
        "*{rank}. {result.get('stock_name', '')} ({result.get('stock_id', '')})*\n",
        "   ğŸ’° æœ€æ–°åƒ¹æ ¼: {result.get('last_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ ç¶œåˆè©•åˆ†: *{result.get('combined_score', 0):.1f} / 100*\n",
        "   ğŸ¯ æŠ•è³‡å»ºè­°: *{recommendation.get('action', 'è§€æœ›')}*\n",
        "\"\"\"\n",
        "\n",
        "        message += \"\"\"\n",
        "âš ï¸ *æŠ•è³‡æé†’:*\n",
        "â€¢ æœ¬åˆ†æåƒ…ç‚ºæŠ€è¡“æŒ‡æ¨™åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡å»ºè­°ã€‚\n",
        "â€¢ æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹çµåˆåŸºæœ¬é¢åˆ†æä¸¦åšå¥½é¢¨éšªæ§ç®¡ã€‚\n",
        "\"\"\"\n",
        "        return message.strip()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "\n",
        "# ç¼ºå°‘çš„å‡½æ•¸å®šç¾©\n",
        "def filter_by_volume(stocks_data, min_volume_shares=1000000):\n",
        "    \"\"\"\n",
        "    æ ¹æ“šæˆäº¤é‡éæ¿¾è‚¡ç¥¨\n",
        "    \"\"\"\n",
        "    filtered_data = {}\n",
        "\n",
        "    for stock_id, stock_data in stocks_data.items():\n",
        "        try:\n",
        "            if 'data' not in stock_data or not stock_data['data']:\n",
        "                continue\n",
        "\n",
        "            df = pd.DataFrame(stock_data['data'])\n",
        "            if 'Volume' not in df.columns:\n",
        "                continue\n",
        "\n",
        "            # è¨ˆç®—è¿‘30å¤©å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(30).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            avg_volume_lots = recent_volume / 1000\n",
        "\n",
        "            if avg_volume_lots >= (min_volume_shares / 1000):  # min_volume_shareså·²ç¶“æ˜¯è‚¡æ•¸\n",
        "                filtered_data[stock_id] = stock_data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"éæ¿¾è‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    logger.info(f\"æˆäº¤é‡éæ¿¾å®Œæˆ: {len(filtered_data)}/{len(stocks_data)} æ”¯è‚¡ç¥¨ç¬¦åˆæ¨™æº–\")\n",
        "    return filtered_data\n",
        "\n",
        "def top_percentile_filter(analysis_results, percentile=98):\n",
        "    \"\"\"\n",
        "    ç¯©é¸å‰ç™¾åˆ†ä½çš„è‚¡ç¥¨\n",
        "    \"\"\"\n",
        "    if not analysis_results:\n",
        "        return {}\n",
        "\n",
        "    scores = [result.get('combined_score', 0) for result in analysis_results.values()]\n",
        "    threshold = np.percentile(scores, percentile)\n",
        "\n",
        "    elite_results = {\n",
        "        stock_id: result for stock_id, result in analysis_results.items()\n",
        "        if result.get('combined_score', 0) >= threshold\n",
        "    }\n",
        "\n",
        "    logger.info(f\"å‰{100-percentile}%ç¯©é¸å®Œæˆ: {len(elite_results)}/{len(analysis_results)} æ”¯è‚¡ç¥¨\")\n",
        "    return elite_results\n",
        "\n",
        "def print_top_stocks(results, top_n=10):\n",
        "    \"\"\"\n",
        "    æ‰“å°æœ€ä½³è‚¡ç¥¨æ¸…å–®\n",
        "    \"\"\"\n",
        "    sorted_results = sorted(results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "    print(f\"\\nğŸ† å‰ {min(top_n, len(sorted_results))} åæ¨è–¦è‚¡ç¥¨:\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for i, result in enumerate(sorted_results[:top_n], 1):\n",
        "        stock_id = result.get('stock_id', 'N/A')\n",
        "        stock_name = result.get('stock_name', 'N/A')\n",
        "        score = result.get('combined_score', 0)\n",
        "        recommendation = result.get('recommendation', {})\n",
        "\n",
        "        print(f\"{i:2d}. {stock_id} {stock_name}\")\n",
        "        print(f\"    ç¶œåˆè©•åˆ†: {score}/100\")\n",
        "        print(f\"    æŠ•è³‡å»ºè­°: {recommendation.get('action', 'N/A')}\")\n",
        "        print(f\"    ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 0)}%\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "def export_html_report(analysis_results):\n",
        "    \"\"\"\n",
        "    åŒ¯å‡ºHTMLå ±å‘Š\n",
        "    \"\"\"\n",
        "    try:\n",
        "        html_content = f\"\"\"\n",
        "        <!DOCTYPE html>\n",
        "        <html>\n",
        "        <head>\n",
        "            <meta charset=\"UTF-8\">\n",
        "            <title>å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š</title>\n",
        "            <style>\n",
        "                body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
        "                table {{ border-collapse: collapse; width: 100%; }}\n",
        "                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
        "                th {{ background-color: #f2f2f2; }}\n",
        "                .high-score {{ background-color: #d4edda; }}\n",
        "                .medium-score {{ background-color: #fff3cd; }}\n",
        "                .low-score {{ background-color: #f8d7da; }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š</h1>\n",
        "            <p>ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "            <table>\n",
        "                <tr>\n",
        "                    <th>æ’å</th>\n",
        "                    <th>è‚¡ç¥¨ä»£è™Ÿ</th>\n",
        "                    <th>è‚¡ç¥¨åç¨±</th>\n",
        "                    <th>ç¶œåˆè©•åˆ†</th>\n",
        "                    <th>æŠ•è³‡å»ºè­°</th>\n",
        "                    <th>ä¿¡å¿ƒåº¦</th>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        sorted_results = sorted(analysis_results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        for i, result in enumerate(sorted_results[:50], 1):  # åªé¡¯ç¤ºå‰50å\n",
        "            score = result.get('combined_score', 0)\n",
        "            score_class = 'high-score' if score >= 70 else 'medium-score' if score >= 50 else 'low-score'\n",
        "\n",
        "            html_content += f\"\"\"\n",
        "                <tr class=\"{score_class}\">\n",
        "                    <td>{i}</td>\n",
        "                    <td>{result.get('stock_id', 'N/A')}</td>\n",
        "                    <td>{result.get('stock_name', 'N/A')}</td>\n",
        "                    <td>{score}</td>\n",
        "                    <td>{result.get('recommendation', {}).get('action', 'N/A')}</td>\n",
        "                    <td>{result.get('recommendation', {}).get('confidence', 0)}%</td>\n",
        "                </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        html_content += \"\"\"\n",
        "            </table>\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "        html_path = os.path.join(RESULTS_DIR, f\"stock_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\")\n",
        "        with open(html_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        logger.info(f\"âœ… HTMLå ±å‘Šå·²åŒ¯å‡º: {html_path}\")\n",
        "        return html_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"åŒ¯å‡ºHTMLå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# ä¿®æ­£çš„åœ–è¡¨ç”Ÿæˆå‡½æ•¸\n",
        "def generate_detailed_analysis_report(stock_id, analysis_result, output_dir='reports'):\n",
        "    \"\"\"\n",
        "    ç‚ºå–®ä¸€è‚¡ç¥¨ç”Ÿæˆè©³ç´°çš„æŠ€è¡“åˆ†æå ±å‘Šï¼ŒåŒ…å«åœ–è¡¨å’Œé—œéµæŒ‡æ¨™ã€‚\n",
        "\n",
        "    ä¿®æ­£äº† addplot åƒæ•¸çš„è™•ç†é‚è¼¯ï¼Œé¿å…å‚³é None å€¼ã€‚\n",
        "\n",
        "    åƒæ•¸:\n",
        "    stock_id (str): è‚¡ç¥¨ä»£è™Ÿ\n",
        "    analysis_result (dict): åŒ…å«åˆ†æçµæœçš„å­—å…¸\n",
        "    output_dir (str): è¼¸å‡ºç›®éŒ„è·¯å¾‘\n",
        "\n",
        "    è¿”å›:\n",
        "    str: å ±å‘Šæ–‡ä»¶çš„è·¯å¾‘ï¼Œå¦‚æœç”Ÿæˆå¤±æ•—å‰‡è¿”å› None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not analysis_result or not analysis_result.get('success'):\n",
        "            logger.warning(f\"ç„¡æ³•ç‚ºè‚¡ç¥¨ {stock_id} ç”Ÿæˆå ±å‘Šï¼šåˆ†æçµæœç„¡æ•ˆ\")\n",
        "            return None\n",
        "\n",
        "        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # ç²å–åˆ†ææ•¸æ“š\n",
        "        df = analysis_result['data_df'].copy()\n",
        "\n",
        "        # ç¢ºä¿ç´¢å¼•æ˜¯æ—¥æœŸæ™‚é–“é¡å‹\n",
        "        if not isinstance(df.index, pd.DatetimeIndex):\n",
        "            logger.warning(f\"è‚¡ç¥¨ {stock_id} çš„æ•¸æ“šç´¢å¼•ä¸æ˜¯æ—¥æœŸé¡å‹ï¼Œå˜—è©¦è½‰æ›\")\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "\n",
        "        # ç¢ºä¿æ•¸æ“šæŒ‰æ—¥æœŸæ’åº\n",
        "        df.sort_index(inplace=True)\n",
        "\n",
        "        # å°‡ DataFrame è½‰æ›ç‚º mplfinance å¯ç”¨çš„æ ¼å¼\n",
        "        df_mpf = df[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "\n",
        "        # å‰µå»ºé™„åŠ åœ–è¡¨\n",
        "        ap = []  # åˆå§‹åŒ–ç‚ºç©ºåˆ—è¡¨\n",
        "\n",
        "        # æ·»åŠ ç§»å‹•å¹³å‡ç·š\n",
        "        if 'ma20' in df.columns and 'ma60' in df.columns and 'ma120' in df.columns:\n",
        "            ap.append(mpf.make_addplot(df['ma20'], color='blue', width=0.7))\n",
        "            ap.append(mpf.make_addplot(df['ma60'], color='red', width=0.7))\n",
        "            ap.append(mpf.make_addplot(df['ma120'], color='green', width=0.7))\n",
        "\n",
        "        # æ·»åŠ  RSI æŒ‡æ¨™ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
        "        if 'rsi' in df.columns:\n",
        "            # å‰µå»ºä¸€å€‹æ–°çš„å­åœ–ç”¨æ–¼ RSI\n",
        "            ap.append(mpf.make_addplot(df['rsi'], panel=1, color='purple',\n",
        "                                       ylabel='RSI'))\n",
        "\n",
        "        # æ·»åŠ  MACD æŒ‡æ¨™ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
        "        if all(col in df.columns for col in ['macd', 'macdsignal']):\n",
        "            # å‰µå»ºä¸€å€‹æ–°çš„å­åœ–ç”¨æ–¼ MACD\n",
        "            ap.append(mpf.make_addplot(df['macd'], panel=2, color='blue',\n",
        "                                       ylabel='MACD'))\n",
        "            ap.append(mpf.make_addplot(df['macdsignal'], panel=2, color='red'))\n",
        "            ap.append(mpf.make_addplot(df['histogram'], panel=2, type='bar', color='dimgray'))\n",
        "\n",
        "        # è¨­ç½®åœ–è¡¨æ¨£å¼å’Œä½ˆå±€\n",
        "        style = mpf.make_mpf_style(base_mpf_style='charles', rc={'figure.figsize': (12, 10)})\n",
        "\n",
        "        # è¨­ç½®å­åœ–æ¯”ä¾‹\n",
        "        fig_kwargs = {\n",
        "            'figratio': (12, 8),\n",
        "            'panel_ratios': (6, 2, 2) if 'macd' in df.columns else (6, 2)\n",
        "        }\n",
        "\n",
        "        # è¨­ç½®åœ–è¡¨æ¨™é¡Œ\n",
        "        title = f\"{stock_id} {analysis_result.get('stock_name', '')} æŠ€è¡“åˆ†æ ({df.index[0].strftime('%Y-%m-%d')} è‡³ {df.index[-1].strftime('%Y-%m-%d')})\"\n",
        "\n",
        "        # ç”Ÿæˆåœ–è¡¨\n",
        "        plot_kwargs = {\n",
        "            'type': 'candle',\n",
        "            'style': style,\n",
        "            'volume': True,\n",
        "            'title': title,\n",
        "            'figscale': 1.5,\n",
        "            'tight_layout': True,\n",
        "            'savefig': f\"{output_dir}/{stock_id}_technical_analysis.png\",\n",
        "            'returnfig': True,\n",
        "            **fig_kwargs\n",
        "        }\n",
        "\n",
        "        # åªæœ‰åœ¨ ap åˆ—è¡¨éç©ºæ™‚æ‰æ·»åŠ  addplot åƒæ•¸\n",
        "        if ap:\n",
        "            plot_kwargs['addplot'] = ap\n",
        "\n",
        "        fig, axes = mpf.plot(df_mpf, **plot_kwargs)\n",
        "\n",
        "        # é—œé–‰åœ–è¡¨ä»¥é‡‹æ”¾è¨˜æ†¶é«”\n",
        "        plt.close(fig)\n",
        "\n",
        "        # è¿”å›å ±å‘Šæ–‡ä»¶è·¯å¾‘\n",
        "        return f\"{output_dir}/{stock_id}_technical_analysis.png\"\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”Ÿæˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ ({stock_id}): {str(e)}\")\n",
        "        logger.debug(traceback.format_exc())\n",
        "        return None\n",
        "\n",
        "\n",
        "# æ‚¨åŸæœ¬çš„å…¶ä»–å‡½æ•¸ï¼ˆset_chinese_font, get_taiwan_stocks, etc.ï¼‰ä¿æŒä¸è®Š\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            font_name = 'Microsoft YaHei'\n",
        "            plt.rcParams['font.sans-serif'] = [font_name]\n",
        "        elif system == 'Darwin':\n",
        "            font_name = 'PingFang HK'\n",
        "            plt.rcParams['font.sans-serif'] = [font_name]\n",
        "        else:\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "            ]\n",
        "            found_font_path = next((path for path in font_paths if os.path.exists(path)), None)\n",
        "\n",
        "            if found_font_path:\n",
        "                font_manager.fontManager.addfont(found_font_path)\n",
        "                font_name = font_manager.FontProperties(fname=found_font_path).get_name()\n",
        "                plt.rcParams['font.sans-serif'] = [font_name]\n",
        "            else:\n",
        "                print(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "        if font_name:\n",
        "            print(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. å‡ç´šï¼šæœ€çµ‚å ±å‘Šåˆ—å°å‡½æ•¸ (æ›¿æ›èˆŠçš„ print_top_stocks_with_patterns)\n",
        "# ==============================================================================\n",
        "def print_final_report(results):\n",
        "    \"\"\"\n",
        "    åˆ—å°æœ€çµ‚çš„é ‚å°–è‚¡ç¥¨åˆ†æå ±å‘Š (V3.0 æ™ºèƒ½ç‰ˆ)\n",
        "    - é¡¯ç¤ºä¸­æ–‡Kç·šè¶¨å‹¢æ‘˜è¦\n",
        "    - é¡¯ç¤ºæ™ºèƒ½äº¤æ˜“å»ºè­°\n",
        "    \"\"\"\n",
        "    report_lines = []\n",
        "    header = \"ğŸ†\" * 20\n",
        "    title = \" \" * 28 + \"æœ€çµ‚é ‚å°–å€‹è‚¡åˆ†æå ±å‘Š\"\n",
        "\n",
        "    report_lines.append(\"\\n\" + \"=\"*80)\n",
        "    report_lines.append(header)\n",
        "    report_lines.append(title)\n",
        "    report_lines.append(header)\n",
        "    report_lines.append(\"=\"*80)\n",
        "\n",
        "    if not results:\n",
        "        report_lines.append(\"\\nğŸ¤· æœªèƒ½ç¯©é¸å‡ºä»»ä½•ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ã€‚\")\n",
        "        final_report = \"\\n\".join(report_lines)\n",
        "        print(final_report)\n",
        "        return final_report\n",
        "\n",
        "    # æ ¹æ“šç¶œåˆè©•åˆ†å¾é«˜åˆ°ä½æ’åº\n",
        "    sorted_results = sorted(results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "    for i, result in enumerate(sorted_results):\n",
        "        report_lines.append(f\"\\n--- æ’å {i+1} -----------------------------------------------------------\")\n",
        "\n",
        "        stock_id = result.get('stock_id', 'N/A')\n",
        "        stock_name = result.get('stock_name', 'N/A')\n",
        "        industry = result.get('industry', 'N/A')\n",
        "        last_price = result.get('last_price', 0.0)\n",
        "        combined_score = result.get('combined_score', 0)\n",
        "\n",
        "        # ç²å–å·²ç”Ÿæˆçš„æ™ºèƒ½å»ºè­°\n",
        "        recommendation = result.get('recommendation', {})\n",
        "        action = recommendation.get('action', 'åˆ†æä¸å®Œæ•´')\n",
        "        reason = recommendation.get('reason', 'ç„¡æ³•ç”Ÿæˆå»ºè­°')\n",
        "\n",
        "        # ç²å–å·²ç”Ÿæˆçš„Kç·šç²¾è¯æ‘˜è¦\n",
        "        pattern_report = result.get('pattern_report', 'Kç·šå‹æ…‹å ±å‘Šæœªç”Ÿæˆã€‚')\n",
        "\n",
        "        report_lines.append(f\"ğŸ“ˆ è‚¡ç¥¨: {stock_id} {stock_name} ({industry})\")\n",
        "        report_lines.append(f\"ğŸ’° æœ€æ–°è‚¡åƒ¹: {last_price:.2f}\")\n",
        "        report_lines.append(f\"â­ ç¶œåˆè©•åˆ†: {combined_score}/100\")\n",
        "        report_lines.append(f\"ğŸ’¡ äº¤æ˜“å»ºè­°: {action} - {reason}\")\n",
        "        report_lines.append(pattern_report) # ç›´æ¥ä½¿ç”¨å·²ç”Ÿæˆçš„å ±å‘Š\n",
        "\n",
        "        report_lines.append(\"-\" * 70)\n",
        "\n",
        "    report_lines.append(\"\\n\" + \"=\"*80)\n",
        "    report_lines.append(\"åˆ†æå ±å‘ŠçµæŸã€‚ç¥æ‚¨æŠ•è³‡é †åˆ©ï¼\")\n",
        "\n",
        "    final_report = \"\\n\".join(report_lines)\n",
        "    print(final_report)\n",
        "    return final_report\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # (å¯é¸) åœ¨æ­¤è™•åŠ å…¥å°‡å ±å‘Šç™¼é€åˆ° Telegram çš„é‚è¼¯\n",
        "    final_report_str = print_final_report(results_to_show)\n",
        "\n",
        "    send_notifications(final_report_str)\n",
        "\n",
        "# ä¿®æ­£ä¸¦å„ªåŒ–å¾Œçš„ä¸»é¸å–®å‡½æ•¸\n",
        "def main_menu():\n",
        "    \"\"\"\n",
        "    ä¸»ç¨‹å¼åŸ·è¡Œæµç¨‹ (æœ€çµ‚å„ªåŒ–ç‰ˆ)\n",
        "    \"\"\"\n",
        "    print(\"=\"*40)\n",
        "    print(\"==== å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· ====\")\n",
        "    print(\"=\"*40)\n",
        "    print(\"ğŸš€ é–‹å§‹è‡ªå‹•åˆ†ææ‰€æœ‰è‚¡ç¥¨...\")\n",
        "\n",
        "    try:\n",
        "        # [éšæ®µ1/7] ç²å–è‚¡ç¥¨åŸºæœ¬è³‡æ–™\n",
        "        print(\"\\n[éšæ®µ1/7] ç²å–æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬è³‡æ–™...\")\n",
        "        stocks_info = get_stock_basic_info()\n",
        "        if not stocks_info:\n",
        "            error_msg = \"âŒ ç„¡æ³•ç²å–è‚¡ç¥¨åŸºæœ¬è³‡æ–™ï¼Œæµç¨‹ä¸­æ­¢ã€‚\"\n",
        "            print(error_msg)\n",
        "            send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æå¤±æ•—*\\n\\n{error_msg}\")\n",
        "            return\n",
        "        print(f\"âœ… æˆåŠŸç²å– {len(stocks_info)} æ”¯è‚¡ç¥¨è³‡æ–™\")\n",
        "\n",
        "        # [éšæ®µ2/7] æ‰¹æ¬¡ä¸‹è¼‰æ­·å²è³‡æ–™\n",
        "        print(\"\\n[éšæ®µ2/7] æ‰¹æ¬¡ä¸‹è¼‰æ­·å²è³‡æ–™...\")\n",
        "        all_stocks_data = fetch_multiple_stocks_data(stocks_info, period='1y')\n",
        "        if not all_stocks_data:\n",
        "            error_msg = \"âŒ ç„¡æ³•å–å¾—ä»»ä½•è‚¡ç¥¨æ­·å²è³‡æ–™ï¼Œæµç¨‹ä¸­æ­¢ã€‚\"\n",
        "            print(error_msg)\n",
        "            send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æå¤±æ•—*\\n\\n{error_msg}\")\n",
        "            return\n",
        "\n",
        "        # [éšæ®µ3/7] éæ¿¾ä½æˆäº¤é‡è‚¡ç¥¨\n",
        "        print(\"\\n[éšæ®µ3/7] éæ¿¾ä½æˆäº¤é‡è‚¡ç¥¨...\")\n",
        "        filtered_data = filter_by_volume(all_stocks_data, min_volume_shares=1000000)\n",
        "        if not filtered_data:\n",
        "            error_msg = \"âŒ æ²’æœ‰ä»»ä½•å€‹è‚¡ç¬¦åˆæˆäº¤é‡æ¨™æº– (è¿‘ä¸€å€‹æœˆæ¯æ—¥æˆäº¤é‡ > 1000å¼µ)ã€‚\"\n",
        "            print(error_msg)\n",
        "            send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æçµæœ*\\n\\n{error_msg}\")\n",
        "            return\n",
        "\n",
        "        progress_msg = f\"ğŸ“Š *è‚¡ç¥¨åˆ†æé€²åº¦å ±å‘Š*\\n\\nâœ… å·²ç²å– {len(stocks_info)} æ”¯è‚¡ç¥¨è³‡æ–™\\nâœ… ç¬¦åˆæˆäº¤é‡æ¨™æº–: {len(filtered_data)} æ”¯\\nğŸ”„ é–‹å§‹é€²è¡ŒæŠ€è¡“åˆ†æ...\"\n",
        "        send_notifications(progress_msg)\n",
        "\n",
        "        # [éšæ®µ4/7] æ ¸å¿ƒåˆ†æèˆ‡è©•åˆ†\n",
        "        print(f\"\\n[éšæ®µ4/7] é€²è¡Œæ ¸å¿ƒåˆ†æèˆ‡ç¶œåˆè©•åˆ† ({len(filtered_data)} æ”¯)...\")\n",
        "        all_analysis_results = {}\n",
        "        successful_analysis, failed_analysis = 0, 0\n",
        "\n",
        "        for i, (stock_id, stock_data) in enumerate(filtered_data.items()):\n",
        "            print(f\"  åˆ†æä¸­ ({i+1}/{len(filtered_data)}): {stock_id} {stock_data.get('stock_name', '')}\")\n",
        "            try:\n",
        "                analysis_result = analyze_stock(stock_id, stock_data)\n",
        "                if analysis_result.get('success'):\n",
        "                    scores, final_score = calculate_comprehensive_score(analysis_result)\n",
        "                    analysis_result.update({\n",
        "                        'scores': {k: int(round(v)) for k, v in scores.items()},\n",
        "                        'combined_score': int(round(final_score))\n",
        "                        # å»ºè­°å…ˆä¸åœ¨æ­¤ç”¢ç”Ÿï¼Œå¾…Kç·šåˆ†æå¾Œçµ±ä¸€ç”¢ç”Ÿ\n",
        "                    })\n",
        "                    all_analysis_results[stock_id] = analysis_result\n",
        "                    successful_analysis += 1\n",
        "                else:\n",
        "                    failed_analysis += 1\n",
        "                    logger.warning(f\"è·³éè‚¡ç¥¨ {stock_id}ï¼Œåˆ†æå¤±æ•—: {analysis_result.get('message', 'æœªçŸ¥éŒ¯èª¤')}\")\n",
        "            except Exception as e:\n",
        "                failed_analysis += 1\n",
        "                logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”Ÿç„¡æ³•é æœŸçš„ç•°å¸¸: {str(e)}\")\n",
        "\n",
        "        print(f\"\\nåˆ†æå®Œæˆ: æˆåŠŸ {successful_analysis} æ”¯ï¼Œå¤±æ•— {failed_analysis} æ”¯\")\n",
        "\n",
        "        if not all_analysis_results:\n",
        "            error_msg = \"âŒ åˆ†æå®Œæˆï¼Œä½†æ²’æœ‰ä»»ä½•æœ‰æ•ˆçš„åˆ†æçµæœã€‚\"\n",
        "            print(error_msg)\n",
        "            send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æçµæœ*\\n\\n{error_msg}\")\n",
        "            return\n",
        "\n",
        "        # [éšæ®µ5/7] ç¯©é¸é ‚å°–å€‹è‚¡ä¸¦ç”ŸæˆKç·šå ±å‘Šèˆ‡å»ºè­° (åˆä½µåŸ5, 7, 8éšæ®µ)\n",
        "        print(\"\\n[éšæ®µ5/7] ç¯©é¸é ‚å°–å€‹è‚¡ä¸¦ç”Ÿæˆå ±å‘Šèˆ‡å»ºè­°...\")\n",
        "\n",
        "        # ç›´æ¥å¾æ‰€æœ‰åˆ†æçµæœä¸­ï¼ŒæŒ‰åˆ†æ•¸æ’åºï¼Œå–å‰10åä½œç‚ºé ‚å°–å€‹è‚¡\n",
        "        top_10_stocks = sorted(\n",
        "            all_analysis_results.items(),\n",
        "            key=lambda item: item[1].get('combined_score', 0),\n",
        "            reverse=True\n",
        "        )[:10]\n",
        "        results_to_show = dict(top_10_stocks)\n",
        "\n",
        "        if not results_to_show:\n",
        "             print(\"ğŸ¤· æœªç¯©é¸å‡ºä»»ä½•é ‚å°–å€‹è‚¡ã€‚\")\n",
        "        else:\n",
        "            print(f\"âœ… å·²ç¯©é¸å‡ºåˆ†æ•¸æœ€é«˜çš„ {len(results_to_show)} æ”¯è‚¡ç¥¨é€²è¡Œæœ€çµ‚å ±å‘Šã€‚\")\n",
        "\n",
        "        success_count, error_count = 0, 0\n",
        "        for stock_id, result in results_to_show.items():\n",
        "            print(f\"  è™•ç†ä¸­ ({success_count + error_count + 1}/{len(results_to_show)}): {stock_id}\")\n",
        "            df_for_patterns = result.get('data_df')\n",
        "\n",
        "            if df_for_patterns is not None and not df_for_patterns.empty:\n",
        "                try:\n",
        "                    df_copy = df_for_patterns.copy()\n",
        "                    df_copy.columns = [col.lower() for col in df_copy.columns]\n",
        "\n",
        "                    date_col = next((col for col in ['date', 'datetime', 'time'] if col in df_copy.columns), None)\n",
        "\n",
        "                    if date_col:\n",
        "                        try:\n",
        "                            df_copy[date_col] = pd.to_datetime(df_copy[date_col])\n",
        "                            df_copy.set_index(date_col, inplace=True)\n",
        "                        except Exception as e:\n",
        "                            #print(f\"    è­¦å‘Š: ç„¡æ³•å°‡ {date_col} è¨­ç‚ºç´¢å¼•: {e}ã€‚å‰µå»ºè‡¨æ™‚ç´¢å¼•ã€‚\")\n",
        "                            df_copy.set_index(pd.date_range(start='2023-01-01', periods=len(df_copy)), inplace=True)\n",
        "                    else:\n",
        "                        #print(\"    è­¦å‘Š: æœªæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œå‰µå»ºè‡¨æ™‚æ—¥æœŸç´¢å¼•ã€‚\")\n",
        "                        df_copy.set_index(pd.date_range(start='2023-01-01', periods=len(df_copy)), inplace=True)\n",
        "\n",
        "                    required_cols = ['open', 'high', 'low', 'close']\n",
        "                    if all(col in df_copy.columns for col in required_cols):\n",
        "                        full_pattern_report = generate_pattern_report(df_copy, periods=['daily', 'weekly', 'monthly'])\n",
        "                        condensed_report, report_summary = generate_condensed_pattern_report_and_summary(full_pattern_report)\n",
        "\n",
        "                        # *** ä¿®æ­£é»ï¼šåŠ å…¥èª¿è©¦ä¿¡æ¯ ***\n",
        "                        result['pattern_report'] = condensed_report\n",
        "                        combined_score = result.get('combined_score', 0)\n",
        "\n",
        "                        # ğŸ” èª¿è©¦ä¿¡æ¯ï¼šåœ¨èª¿ç”¨å‰æª¢æŸ¥åƒæ•¸\n",
        "                        #print(f\"    ğŸ” èª¿ç”¨ generate_recommendation:\")\n",
        "                        #print(f\"        stock_id: {stock_id}\")\n",
        "                        #print(f\"        combined_score: {combined_score} (type: {type(combined_score)})\")\n",
        "                        #print(f\"        report_summary å­˜åœ¨: {report_summary is not None}\")\n",
        "                        #if report_summary:\n",
        "                            #print(f\"        report_summary keys: {list(report_summary.keys())}\")\n",
        "\n",
        "                        recommendation = generate_recommendation(combined_score, report_summary)\n",
        "                        result['recommendation'] = recommendation\n",
        "\n",
        "                        # ğŸ” èª¿è©¦ä¿¡æ¯ï¼šæª¢æŸ¥è¿”å›çµæœ\n",
        "                        #print(f\"    ğŸ” generate_recommendation è¿”å›:\")\n",
        "                        #print(f\"        action: {recommendation.get('action', 'N/A')}\")\n",
        "                        #print(f\"        confidence: {recommendation.get('confidence', 'N/A')}\")\n",
        "\n",
        "                        #print(f\"    å ±å‘Šå·²ç”Ÿæˆ: æ‘˜è¦é•·åº¦ {len(condensed_report)} å­—ç¬¦\")\n",
        "                        #success_count += 1\n",
        "                    else:\n",
        "                        missing_cols = [col for col in required_cols if col not in df_copy.columns]\n",
        "                        logger.warning(f\"ç„¡æ³•ç‚ºè‚¡ç¥¨ {stock_id} ç”Ÿæˆå ±å‘Šï¼Œç¼ºå°‘æ¬„ä½: {missing_cols}\")\n",
        "                        result['pattern_report'] = f\"Kç·šå ±å‘Šç”Ÿæˆå¤±æ•—ï¼šç¼ºå°‘æ¬„ä½ã€‚\"\n",
        "                        result['recommendation'] = {\"action\": \"éŒ¯èª¤\", \"reason\": \"æ•¸æ“šä¸å®Œæ•´\", \"confidence\": 0}\n",
        "                        error_count += 1\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"ç‚ºè‚¡ç¥¨ {stock_id} ç”ŸæˆKç·šå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    result['pattern_report'] = \"Kç·šå ±å‘Šç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚\"\n",
        "                    result['recommendation'] = {\"action\": \"éŒ¯èª¤\", \"reason\": \"åˆ†æéç¨‹ç•°å¸¸\", \"confidence\": 0}\n",
        "                    error_count += 1\n",
        "            else:\n",
        "                logger.warning(f\"è‚¡ç¥¨ {stock_id} çš„æ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆå ±å‘Šã€‚\")\n",
        "                result['pattern_report'] = \"æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•ç”ŸæˆKç·šå ±å‘Šã€‚\"\n",
        "                result['recommendation'] = {\"action\": \"éŒ¯èª¤\", \"reason\": \"æ•¸æ“šä¸è¶³\", \"confidence\": 0}\n",
        "                error_count += 1\n",
        "\n",
        "        print_top_stocks(results_to_show, top_n=10)\n",
        "        print(f\"\\nå ±å‘Šç”Ÿæˆçµæœ: æˆåŠŸ {success_count} æ”¯ï¼Œå¤±æ•— {error_count} æ”¯\")\n",
        "        print(\"âœ… æ‰€æœ‰é ‚å°–å€‹è‚¡å ±å‘Šèˆ‡å»ºè­°å·²ç”Ÿæˆã€‚\")\n",
        "\n",
        "        # [éšæ®µ6/7] ç”Ÿæˆå ±å‘Šèˆ‡ç™¼é€é€šçŸ¥\n",
        "        print(\"\\n[éšæ®µ6/7] ç”Ÿæˆå ±å‘Šã€åœ–è¡¨èˆ‡ç™¼é€é€šçŸ¥...\")\n",
        "\n",
        "        summary_msg = format_notification_message(\n",
        "            results_to_show,\n",
        "            successful_analysis,\n",
        "            failed_analysis,\n",
        "            len(filtered_data)\n",
        "        )\n",
        "\n",
        "        report_dir = 'reports'\n",
        "        os.makedirs(report_dir, exist_ok=True)\n",
        "        generated_images = []\n",
        "\n",
        "        # åªç‚ºåˆ†æ•¸æœ€é«˜çš„å‰5åç”Ÿæˆåœ–è¡¨\n",
        "        for stock_id, stock_info in list(results_to_show.items())[:5]:\n",
        "            print(f\"  ç”Ÿæˆåœ–è¡¨: {stock_id}\")\n",
        "            image_path = generate_detailed_analysis_report(\n",
        "                stock_id=stock_id,\n",
        "                analysis_result=stock_info,\n",
        "                output_dir=report_dir\n",
        "            )\n",
        "            if image_path and os.path.exists(image_path):\n",
        "                generated_images.append(image_path)\n",
        "\n",
        "        export_html_report(all_analysis_results)\n",
        "\n",
        "        final_message = summary_msg + f\"\\n\\nğŸ“Š å·²ç”Ÿæˆ {len(generated_images)} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\\nğŸ“‹ HTML è©³ç´°å ±å‘Šå·²åŒ¯å‡º\"\n",
        "        send_notifications(final_message, generated_images)\n",
        "\n",
        "        # [éšæ®µ7/7] æ‰“å°æœ€çµ‚å ±å‘Š\n",
        "        if results_to_show:\n",
        "            print(\"\\n\\n========== ğŸ† é ‚å°–å€‹è‚¡åˆ†æå ±å‘Š ğŸ† ==========\\n\")\n",
        "            for stock_id, result in results_to_show.items():\n",
        "                try:\n",
        "                    stock_name = result.get('stock_name', '') or get_stock_name(stock_id)\n",
        "                    print(f\"ã€{stock_id} {stock_name}ã€‘\")\n",
        "                    print(f\"ç¶œåˆè©•åˆ†: {result.get('combined_score', 0)}\")\n",
        "\n",
        "                    pattern_report = result.get('pattern_report', 'ç„¡Kç·šå‹æ…‹å ±å‘Š')\n",
        "                    print(f\"Kç·šåˆ†æ:\\n{pattern_report}\")\n",
        "\n",
        "                    recommendation = result.get('recommendation', {})\n",
        "                    action = recommendation.get('action', 'ç„¡å»ºè­°')\n",
        "                    reason = recommendation.get('reason', 'ç„¡ç†ç”±')\n",
        "                    confidence = recommendation.get('confidence', 0)\n",
        "                    print(f\"\\næŠ•è³‡å»ºè­°: {action}\")\n",
        "                    print(f\"å»ºè­°ç†ç”±: {reason}\")\n",
        "                    print(f\"ä¿¡å¿ƒåº¦: {confidence}%\")\n",
        "\n",
        "                    if 'pattern_details' in recommendation:\n",
        "                        print(\"å‹æ…‹è©³æƒ…:\")\n",
        "                        for detail in recommendation['pattern_details']:\n",
        "                            print(f\"  â€¢ {detail}\")\n",
        "\n",
        "                    print(\"\\né—œéµæŒ‡æ¨™:\")\n",
        "                    indicators = result.get('indicators', {})\n",
        "                    for key in ['rsi', 'macd', 'bb_width', 'atr']:\n",
        "                        if key in indicators:\n",
        "                            print(f\"  {key.upper()}: {indicators[key]:.2f}\")\n",
        "\n",
        "                    print(\"-\" * 50 + \"\\n\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ æ‰“å°è‚¡ç¥¨ {stock_id} çš„å ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        else:\n",
        "            print(\"\\nâš ï¸ æ²’æœ‰é ‚å°–å€‹è‚¡å¯ä¾›é¡¯ç¤ºã€‚\")\n",
        "\n",
        "        print(\"\\nğŸ‰ å…¨éƒ¨æµç¨‹åŸ·è¡Œå®Œç•¢ï¼\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ä¸»ç¨‹åºç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}\"\n",
        "        print(error_msg)\n",
        "        logger.error(error_msg)\n",
        "        logger.debug(traceback.format_exc())\n",
        "        send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æåš´é‡å¤±æ•—*\\n\\n{error_msg}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    check_environment()\n",
        "    set_chinese_font()\n",
        "    main_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7gqIWGS8w_s",
        "outputId": "766e7ad9-935e-4dc6-94a3-4ee82b97e390"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'split'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1986545859.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# ========= é€šè¨Šè¨­å®š (è«‹è‡ªè¡Œæ›´æ›) =========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mTELEGRAM_BOT_TOKEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TELEGRAM_BOT_TOKEN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mTELEGRAM_CHAT_IDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TELEGRAM_CHAT_IDS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m879781796\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8113868436\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mDISCORD_WEBHOOK_URL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DISCORD_WEBHOOK_URL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mTELEGRAM_TOKEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "å°è‚¡æŠ€è¡“ + æƒ…ç·’ + æ©Ÿå™¨å­¸ç¿’å¼·åŒ– è©•åˆ†ç³»çµ± (å®Œæ•´æ•´åˆç‰ˆ)\n",
        "=================================================\n",
        "åŠŸèƒ½åŒ…å«ï¼š\n",
        "1. å–å¾—å°è‚¡æ¸…å–®èˆ‡å‚™æ´\n",
        "2. yfinance æŠ“å–æ­·å²æ—¥ç·š\n",
        "3. æŠ€è¡“æŒ‡æ¨™ï¼šRSI / MACD / KD / å¸ƒæ—å¸¶ / å‡ç·š\n",
        "4. æ–°èæ¨™é¡Œæƒ…ç·’ + ç†±åº¦çµ±è¨ˆï¼ˆå¤šä¾†æºï¼›ç°¡æ˜“å­—å…¸æƒ…ç·’ï¼‰\n",
        "5. å°ç£å¸‚å ´ Fear & Greed æŒ‡æ•¸ï¼ˆåƒ¹å‹•èƒ½ã€æ³¢å‹•æ¯”ã€é›†ä¸­å¸‚å ´æˆäº¤é‡ã€é¸æ“‡æ¬Š Put/Call Ratioï¼‰\n",
        "6. ç¶œåˆè©•åˆ†ï¼šè¶¨å‹¢ / æˆäº¤é‡ / æŠ€è¡“ / æƒ…ç·’ / MLé æ¸¬ï¼ˆå¯é¸ï¼‰\n",
        "7. Telegram / Discord é€šçŸ¥\n",
        "8. çµ‚ç«¯/æ–‡å­—è¼¸å‡ºæ ¼å¼åŒ–\n",
        "9. (æ›´æ–°) ä½¿ç”¨ TWSE å…¬é–‹ API çœŸå¯¦å–å¾—ï¼šæœ¬ç›Šæ¯”(PE)ã€ä¸‰å¤§æ³•äººè²·è³£è¶…(ç±Œç¢¼)ï¼Œæ›¿æ›éå»éš¨æ©Ÿç‰¹å¾µ\n",
        "=================================================\n",
        "å®‰è£éœ€æ±‚ï¼š\n",
        "pip install pandas numpy yfinance requests beautifulsoup4 jieba aiohttp nest_asyncio scikit-learn discord-webhook\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import logging\n",
        "import traceback\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import jieba\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from collections import Counter\n",
        "from io import StringIO\n",
        "from functools import lru_cache\n",
        "\n",
        "# ML\n",
        "try:\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    SKLEARN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SKLEARN_AVAILABLE = False\n",
        "\n",
        "# Discord\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# nest_asyncioï¼ˆåœ¨ Jupyter ç­‰éœ€è¦ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ========= æ—¥èªŒè¨­å®š =========\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
        ")\n",
        "logger = logging.getLogger(\"StockSentimentSystem\")\n",
        "\n",
        "# ========= æ™‚å€ =========\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# ========= é€šè¨Šè¨­å®š (è«‹è‡ªè¡Œæ›´æ›) =========\n",
        "TELEGRAM_BOT_TOKEN = os.getenv(\"TELEGRAM_BOT_TOKEN\", \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\")\n",
        "TELEGRAM_CHAT_IDS = [int(x) for x in os.getenv(\"TELEGRAM_CHAT_IDS\", [879781796, 8113868436]).split(\",\")]\n",
        "DISCORD_WEBHOOK_URL = os.getenv(\"DISCORD_WEBHOOK_URL\", \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\")\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "\n",
        "# ========= æ©Ÿå™¨å­¸ç¿’ç›¸é—œï¼ˆå¯é¸ï¼‰ =========\n",
        "def adaptive_weights(market_condition: str) -> Dict[str, float]:\n",
        "    if market_condition == \"bull\":\n",
        "        return {\"pe\": 0.2, \"volume\": 0.3, \"ma\": 0.3, \"chips\": 0.2}\n",
        "    elif market_condition == \"bear\":\n",
        "        return {\"pe\": 0.4, \"volume\": 0.2, \"ma\": 0.2, \"chips\": 0.2}\n",
        "    else:\n",
        "        return {\"pe\": 0.3, \"volume\": 0.25, \"ma\": 0.25, \"chips\": 0.2}\n",
        "\n",
        "def build_ml_model(historical_data: pd.DataFrame) -> Optional[RandomForestRegressor]:\n",
        "    if not SKLEARN_AVAILABLE:\n",
        "        logger.warning(\"scikit-learn æœªå®‰è£ï¼Œè·³é ML æ¨¡å‹å»ºç«‹\")\n",
        "        return None\n",
        "    required_cols = ['pe_ratio', 'volume', 'ma_signal', 'chips_score', 'future_return']\n",
        "    for c in required_cols:\n",
        "        if c not in historical_data.columns:\n",
        "            logger.warning(f\"æ­·å²è³‡æ–™ç¼ºå°‘æ¬„ä½: {c}ï¼Œè·³é ML\")\n",
        "            return None\n",
        "    try:\n",
        "        model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "        model.fit(historical_data[['pe_ratio', 'volume', 'ma_signal', 'chips_score']], historical_data['future_return'])\n",
        "        logger.info(\"ML æ¨¡å‹è¨“ç·´å®Œæˆ\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ML æ¨¡å‹è¨“ç·´å¤±æ•—: {e}\")\n",
        "        return None\n",
        "\n",
        "def ml_predict_current(model: RandomForestRegressor,\n",
        "                       pe_ratio: float,\n",
        "                       volume: float,\n",
        "                       ma_signal: int,\n",
        "                       chips_score: int) -> float:\n",
        "    if model is None:\n",
        "        return 0.0\n",
        "    try:\n",
        "        df_feat = pd.DataFrame([{\n",
        "            'pe_ratio': pe_ratio,\n",
        "            'volume': volume,\n",
        "            'ma_signal': ma_signal,\n",
        "            'chips_score': chips_score\n",
        "        }])\n",
        "        pred = float(model.predict(df_feat)[0])\n",
        "        return pred\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ML é æ¸¬å¤±æ•—: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "# ========= çœŸå¯¦ç‰¹å¾µæŠ“å–å™¨ =========\n",
        "class RealFeatureFetcher:\n",
        "    \"\"\"\n",
        "    å¾å°ç£è­‰äº¤æ‰€å…¬é–‹ API å–å¾—ï¼š\n",
        "    1. æœ¬ç›Šæ¯”ã€æ®–åˆ©ç‡ã€è‚¡åƒ¹æ·¨å€¼æ¯” (BWIBBU_d)\n",
        "    2. ä¸‰å¤§æ³•äººè²·è³£è¶… (T86)\n",
        "    (å…·å‚™æ—¥æœŸå›é€€ã€å¿«å–ã€è½‰æ›/æ¸…ç†)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        self._fundamental_cache: Dict[str, Dict[str, Any]] = {}\n",
        "        self._chips_cache: Dict[str, Dict[str, Any]] = {}\n",
        "        self._last_date_used = None\n",
        "\n",
        "    @staticmethod\n",
        "    def _date_str_list(days_back=7) -> List[str]:\n",
        "        today = datetime.now(taipei_tz).date()\n",
        "        dates = []\n",
        "        for i in range(days_back):\n",
        "            d = today - timedelta(days=i)\n",
        "            dates.append(d.strftime(\"%Y%m%d\"))\n",
        "        return dates\n",
        "\n",
        "    def _fetch_json(self, url: str, params: Dict[str, Any] = None, retry=3) -> Optional[Dict[str, Any]]:\n",
        "        for attempt in range(retry):\n",
        "            try:\n",
        "                r = self.session.get(url, params=params, headers=self.headers, timeout=15)\n",
        "                if r.status_code == 200:\n",
        "                    return r.json()\n",
        "                else:\n",
        "                    logger.debug(f\"URL {url} ç‹€æ…‹ç¢¼ {r.status_code}\")\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"è«‹æ±‚å¤±æ•— {url}: {e}\")\n",
        "            time.sleep(1 + attempt)\n",
        "        return None\n",
        "\n",
        "    def _load_fundamental_for_date(self, date_str: str) -> bool:\n",
        "        \"\"\"\n",
        "        å–å¾—å–®ä¸€æ—¥æœŸæœ¬ç›Šæ¯”è³‡æ–™\n",
        "        API: https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d?date=YYYYMMDD&selectType=ALL\n",
        "        \"\"\"\n",
        "        url = \"https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d\"\n",
        "        params = {\"date\": date_str, \"selectType\": \"ALL\", \"response\": \"json\"}\n",
        "        js = self._fetch_json(url, params=params)\n",
        "        if not js or js.get(\"data\") is None:\n",
        "            return False\n",
        "        fields = js.get(\"fields\", [])\n",
        "        data = js.get(\"data\", [])\n",
        "        # å…¸å‹æ¬„ä½ï¼ˆå¯èƒ½è®Šå‹•ï¼‰ï¼š['è­‰åˆ¸ä»£è™Ÿ','è­‰åˆ¸åç¨±','æ®–åˆ©ç‡(%)','è‚¡åˆ©å¹´åº¦','æœ¬ç›Šæ¯”','è‚¡åƒ¹æ·¨å€¼æ¯”','è²¡å ±å¹´/å­£']\n",
        "        try:\n",
        "            col_index = {name: idx for idx, name in enumerate(fields)}\n",
        "            for row in data:\n",
        "                try:\n",
        "                    code = row[col_index['è­‰åˆ¸ä»£è™Ÿ']].strip()\n",
        "                    pe_raw = row[col_index.get('æœ¬ç›Šæ¯”', -1)]\n",
        "                    pb_raw = row[col_index.get('è‚¡åƒ¹æ·¨å€¼æ¯”', -1)]\n",
        "                    dy_raw = row[col_index.get('æ®–åˆ©ç‡(%)', -1)]\n",
        "                    # æ¸…ç†\n",
        "                    def to_float(v):\n",
        "                        try:\n",
        "                            v = str(v).replace(',', '').strip()\n",
        "                            if v in ['-', 'N/A', 'nan', '']:\n",
        "                                return float('nan')\n",
        "                            return float(v)\n",
        "                        except:\n",
        "                            return float('nan')\n",
        "                    pe = to_float(pe_raw)\n",
        "                    pb = to_float(pb_raw)\n",
        "                    dy = to_float(dy_raw)\n",
        "                    self._fundamental_cache[code] = {\n",
        "                        'pe_ratio': pe,\n",
        "                        'pb_ratio': pb,\n",
        "                        'div_yield': dy,\n",
        "                        'date': date_str\n",
        "                    }\n",
        "                except Exception:\n",
        "                    continue\n",
        "            logger.info(f\"å–å¾—æœ¬ç›Šæ¯”è³‡æ–™æ—¥æœŸ {date_str} å…± {len(self._fundamental_cache)} ç­† (ç´¯ç©)\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.debug(f\"è§£ææœ¬ç›Šæ¯”è³‡æ–™å¤±æ•— {date_str}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _load_chips_for_date(self, date_str: str) -> bool:\n",
        "        \"\"\"\n",
        "        å–å¾—ä¸‰å¤§æ³•äººè³‡æ–™\n",
        "        API: https://www.twse.com.tw/rwd/zh/fund/T86?date=YYYYMMDD&selectType=ALL\n",
        "        é‡é»æ¬„ä½ï¼š'è­‰åˆ¸ä»£è™Ÿ','è­‰åˆ¸åç¨±','ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸'\n",
        "        \"\"\"\n",
        "        url = \"https://www.twse.com.tw/rwd/zh/fund/T86\"\n",
        "        params = {\"date\": date_str, \"selectType\": \"ALL\", \"response\": \"json\"}\n",
        "        js = self._fetch_json(url, params=params)\n",
        "        if not js or js.get(\"data\") is None:\n",
        "            return False\n",
        "        fields = js.get(\"fields\", [])\n",
        "        data = js.get(\"data\", [])\n",
        "        try:\n",
        "            col_index = {name: idx for idx, name in enumerate(fields)}\n",
        "            if 'ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸' not in col_index:\n",
        "                # çµæ§‹è®Šå‹• fallback\n",
        "                return False\n",
        "            for row in data:\n",
        "                try:\n",
        "                    code = row[col_index['è­‰åˆ¸ä»£è™Ÿ']].strip()\n",
        "                    net_raw = row[col_index['ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸']]\n",
        "                    net_raw = str(net_raw).replace(',', '').strip()\n",
        "                    if net_raw in ['-', '']:\n",
        "                        net_val = 0\n",
        "                    else:\n",
        "                        net_val = int(net_raw)\n",
        "                    self._chips_cache[code] = {\n",
        "                        'chips_net': net_val,\n",
        "                        'date': date_str\n",
        "                    }\n",
        "                except Exception:\n",
        "                    continue\n",
        "            logger.info(f\"å–å¾—ä¸‰å¤§æ³•äººè³‡æ–™æ—¥æœŸ {date_str} å…± {len(self._chips_cache)} ç­† (ç´¯ç©)\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.debug(f\"è§£æä¸‰å¤§æ³•äººè³‡æ–™å¤±æ•— {date_str}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def prepare_latest(self, max_back_days: int = 7):\n",
        "        \"\"\"\n",
        "        ä¾åºå¾€å‰å›é€€æ—¥æœŸç›´åˆ°æŠ“åˆ°è³‡æ–™æˆ–é”ä¸Šé™\n",
        "        \"\"\"\n",
        "        if self._last_date_used is not None:\n",
        "            return  # å·²ç¶“æŠ“éç•¶æ—¥/æœ€è¿‘ä¸€æ¬¡\n",
        "        for d in self._date_str_list(max_back_days):\n",
        "            f_ok = self._load_fundamental_for_date(d)\n",
        "            c_ok = self._load_chips_for_date(d)\n",
        "            if f_ok or c_ok:\n",
        "                self._last_date_used = d\n",
        "                break\n",
        "        if self._last_date_used is None:\n",
        "            logger.warning(\"ç„¡æ³•å–å¾—æœ€è¿‘ 7 æ—¥å…§ä»»ä½•æœ¬ç›Šæ¯” / ç±Œç¢¼è³‡æ–™ï¼Œå°‡ä½¿ç”¨é è¨­å€¼\")\n",
        "\n",
        "    def get_features(self, stock_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        å›å‚³æŒ‡å®šè‚¡ç¥¨çš„ç‰¹å¾µï¼š\n",
        "        pe_ratio, pb_ratio, div_yield, chips_net, chips_score\n",
        "        chips_score è¨ˆç®—é‚è¼¯ï¼š\n",
        "            - ä¾æ‰€æœ‰æœ‰è³‡æ–™è‚¡ç¥¨çš„ chips_net æ’å (åˆ†ä½æ•¸)\n",
        "            - åˆ†ä½æ•¸ > 0.66 â‡’ 2\n",
        "            - 0.33 ~ 0.66 â‡’ 1\n",
        "            - <= 0.33 â‡’ 0\n",
        "            - è‹¥ç‚ºé¡¯è‘—è² å€¼ä¸”å°æ–¼ 20% åˆ†ä½å¯çµ¦ -1ï¼ˆä¾› ML ä½¿ç”¨ï¼Œä¸é€²å…¥åŸæœ¬çš„çµ„åˆè©•åˆ†ï¼‰\n",
        "        \"\"\"\n",
        "        # ç¢ºä¿è³‡æ–™å·²è¼‰å…¥\n",
        "        if self._last_date_used is None:\n",
        "            self.prepare_latest()\n",
        "\n",
        "        feat = {\n",
        "            'pe_ratio': float('nan'),\n",
        "            'pb_ratio': float('nan'),\n",
        "            'div_yield': float('nan'),\n",
        "            'chips_net': 0,\n",
        "            'chips_score': 0\n",
        "        }\n",
        "        if stock_id in self._fundamental_cache:\n",
        "            f = self._fundamental_cache[stock_id]\n",
        "            feat['pe_ratio'] = f.get('pe_ratio', float('nan'))\n",
        "            feat['pb_ratio'] = f.get('pb_ratio', float('nan'))\n",
        "            feat['div_yield'] = f.get('div_yield', float('nan'))\n",
        "        if stock_id in self._chips_cache:\n",
        "            feat['chips_net'] = self._chips_cache[stock_id]['chips_net']\n",
        "\n",
        "        # è¨ˆç®—ç±Œç¢¼åˆ†ä½æ•¸ï¼ˆåªåšä¸€æ¬¡å…¨åŸŸæ’åºï¼‰\n",
        "        if not hasattr(self, '_chips_rank_prepared'):\n",
        "            all_nets = [v['chips_net'] for v in self._chips_cache.values() if isinstance(v.get('chips_net'), int)]\n",
        "            if len(all_nets) > 10:\n",
        "                arr = np.array(all_nets)\n",
        "                self._chips_p33 = np.percentile(arr, 33)\n",
        "                self._chips_p66 = np.percentile(arr, 66)\n",
        "                self._chips_p20 = np.percentile(arr, 20)\n",
        "            else:\n",
        "                self._chips_p33 = self._chips_p66 = self._chips_p20 = 0\n",
        "            self._chips_rank_prepared = True\n",
        "\n",
        "        try:\n",
        "            cn = feat['chips_net']\n",
        "            if ' _chips_p33' in dir(self):\n",
        "                # ç›´æ¥ç”¨å±¬æ€§\n",
        "                pass\n",
        "            if cn <= self._chips_p20:\n",
        "                feat['chips_score'] = -1  # é¡¯è‘—åç©º\n",
        "            if cn > self._chips_p66:\n",
        "                feat['chips_score'] = 2\n",
        "            elif cn > self._chips_p33:\n",
        "                feat['chips_score'] = 1\n",
        "            # <= p33 ä¸”å°šæœªæ¨™è¨˜ -1 æ™‚ä¿æŒ 0\n",
        "        except Exception:\n",
        "            feat['chips_score'] = 0\n",
        "\n",
        "        # fallback: pe_ratio è‹¥ç‚º nan çµ¦å¹³å‡å€¼ 15~20\n",
        "        if math.isnan(feat['pe_ratio']):\n",
        "            feat['pe_ratio'] = 18.0\n",
        "        return feat\n",
        "\n",
        "# ========= å¸‚å ´æƒ…ç·’åˆ†æå™¨ =========\n",
        "class MarketSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.config = {\n",
        "            'news_weight': 0.4,\n",
        "            'fear_greed_weight': 0.6,\n",
        "            'news_sources': [\n",
        "                'https://news.cnyes.com/news/cat/tw_stock',\n",
        "                'https://www.moneydj.com/kmdj/news/newsreallist.aspx?a=5',\n",
        "                'https://www.cnbc.com/world/?region=world',\n",
        "            ],\n",
        "            'positive_keywords': ['ä¸Šæ¼²', 'çªç ´', 'åˆ©å¤š', 'æˆé•·', 'ç²åˆ©', 'çœ‹å¥½', 'å¼·å‹¢', 'æ¼²åœ', 'çªåœ', 'è²·é€²', 'å‰µé«˜', 'è¶…é æœŸ'],\n",
        "            'negative_keywords': ['ä¸‹è·Œ', 'è·Œç ´', 'åˆ©ç©º', 'è¡°é€€', 'è™§æ', 'çœ‹æ·¡', 'å¼±å‹¢', 'è·Œåœ', 'é‡æŒ«', 'è³£å‡º', 'èª¿é™', 'è£å“¡'],\n",
        "            'cache_duration': 1800\n",
        "        }\n",
        "        self.news_cache: Dict[str, Any] = {}\n",
        "        self.fear_greed_cache: Dict[str, Any] = {'timestamp': 0, 'value': 50, 'components': {}}\n",
        "\n",
        "    def get_stock_news_sentiment(self, stock_id: str, stock_name: str) -> Tuple[float, int]:\n",
        "        cache_key = f\"{stock_id}_{stock_name}\"\n",
        "        now_ts = time.time()\n",
        "        if cache_key in self.news_cache and (now_ts - self.news_cache[cache_key]['timestamp'] < self.config['cache_duration']):\n",
        "            return self.news_cache[cache_key]['sentiment_score'], self.news_cache[cache_key]['news_count']\n",
        "        search_terms = [stock_id, stock_name]\n",
        "        news_count = 0\n",
        "        sentiment_scores = []\n",
        "        for url in self.config['news_sources']:\n",
        "            try:\n",
        "                headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "                resp = requests.get(url, headers=headers, timeout=12)\n",
        "                soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "                candidates = soup.select('a, h2, h3, div')\n",
        "                for c in candidates:\n",
        "                    text = c.get_text(strip=True)\n",
        "                    if not text or len(text) > 60:\n",
        "                        continue\n",
        "                    if any(term in text for term in search_terms):\n",
        "                        news_count += 1\n",
        "                        words = jieba.lcut(text)\n",
        "                        pos = sum(1 for w in words if w in self.config['positive_keywords'])\n",
        "                        neg = sum(1 for w in words if w in self.config['negative_keywords'])\n",
        "                        if pos + neg > 0:\n",
        "                            s = (pos - neg) / (pos + neg)\n",
        "                            sentiment_scores.append(s)\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"æ–°èä¾†æºå¤±æ•— {url}: {e}\")\n",
        "        if sentiment_scores:\n",
        "            avg = float(np.mean(sentiment_scores))\n",
        "            score_0_100 = (avg + 1) * 50\n",
        "        else:\n",
        "            score_0_100 = 50.0\n",
        "        self.news_cache[cache_key] = {\n",
        "            'timestamp': now_ts,\n",
        "            'sentiment_score': score_0_100,\n",
        "            'news_count': news_count\n",
        "        }\n",
        "        return score_0_100, news_count\n",
        "\n",
        "    def get_fear_greed_index(self) -> Tuple[float, Dict[str, Any]]:\n",
        "        now_ts = time.time()\n",
        "        if now_ts - self.fear_greed_cache['timestamp'] < self.config['cache_duration']:\n",
        "            return self.fear_greed_cache['value'], self.fear_greed_cache['components']\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        components = {\n",
        "            'price_momentum': None,\n",
        "            'price_score': 50,\n",
        "            'volatility_ratio': None,\n",
        "            'volatility_score': 50,\n",
        "            'volume_change_pct': None,\n",
        "            'volume_score': 50,\n",
        "            'pc_ratio': None,\n",
        "            'pc_ratio_score': 50\n",
        "        }\n",
        "        try:\n",
        "            taiex_url = \"https://query1.finance.yahoo.com/v8/finance/chart/%5ETWII?interval=1d&range=60d\"\n",
        "            r = requests.get(taiex_url, headers=headers, timeout=12).json()\n",
        "            closes = r['chart']['result'][0]['indicators']['quote'][0]['close']\n",
        "            closes = [c for c in closes if c is not None]\n",
        "            if len(closes) >= 20:\n",
        "                ma10 = np.mean(closes[-10:])\n",
        "                last = closes[-1]\n",
        "                price_momentum = (last / ma10 - 1) * 100 if ma10 else 0\n",
        "                components['price_momentum'] = price_momentum\n",
        "                price_score = 50 + price_momentum * 5\n",
        "                components['price_score'] = max(0, min(100, price_score))\n",
        "                ret = np.diff(closes) / closes[:-1]\n",
        "                if len(ret) >= 21:\n",
        "                    vol_5 = np.std(ret[-5:]) * 100\n",
        "                    vol_20 = np.std(ret[-20:]) * 100\n",
        "                    vol_ratio = vol_5 / vol_20 if vol_20 else 1\n",
        "                    components['volatility_ratio'] = vol_ratio\n",
        "                    volatility_score = 100 - (vol_ratio - 0.5) * 100\n",
        "                    components['volatility_score'] = max(0, min(100, volatility_score))\n",
        "            volume_url = \"https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK?date=20230101&response=json\"\n",
        "            try:\n",
        "                rv = requests.get(volume_url, headers=headers, timeout=12).json()\n",
        "                vol_list = []\n",
        "                if 'data' in rv:\n",
        "                    for row in rv['data'][-8:]:\n",
        "                        try:\n",
        "                            val = row[1].replace(',', '')\n",
        "                            vol_list.append(float(val))\n",
        "                        except:\n",
        "                            pass\n",
        "                if len(vol_list) >= 5:\n",
        "                    recent = np.mean(vol_list[-5:])\n",
        "                    prev = np.mean(vol_list[-10:-5]) if len(vol_list) >= 10 else recent\n",
        "                    volume_change = (recent / prev - 1) * 100 if prev else 0\n",
        "                    components['volume_change_pct'] = volume_change\n",
        "                    components['volume_score'] = max(0, min(100, 50 + volume_change))\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"FearGreed æˆäº¤é‡æŠ“å–å¤±æ•—: {e}\")\n",
        "            try:\n",
        "                pc_url = \"https://www.taifex.com.tw/cht/3/pcRatio\"\n",
        "                pr = requests.get(pc_url, headers=headers, timeout=12)\n",
        "                soup = BeautifulSoup(pr.text, 'html.parser')\n",
        "                tables = soup.find_all('table')\n",
        "                pc_ratio = None\n",
        "                for tbl in tables:\n",
        "                    tds = tbl.find_all('td')\n",
        "                    for td in tds:\n",
        "                        txt = td.get_text(strip=True)\n",
        "                        if re.match(r'^\\d+(\\.\\d+)?$', txt):\n",
        "                            val = float(txt)\n",
        "                            if 0.3 < val < 5:\n",
        "                                pc_ratio = val\n",
        "                                break\n",
        "                    if pc_ratio:\n",
        "                        break\n",
        "                if pc_ratio:\n",
        "                    components['pc_ratio'] = pc_ratio\n",
        "                    pc_score = 50 + (pc_ratio - 1) * 40\n",
        "                    components['pc_ratio_score'] = max(0, min(100, pc_score))\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"FearGreed P/C å¤±æ•—: {e}\")\n",
        "            final_value = (\n",
        "                components['price_score'] * 0.5 +\n",
        "                components['volatility_score'] * 0.2 +\n",
        "                components['volume_score'] * 0.15 +\n",
        "                components['pc_ratio_score'] * 0.15\n",
        "            )\n",
        "            final_value = max(0, min(100, final_value))\n",
        "            market_mood = \"æ¥µåº¦ææ…Œ\" if final_value < 20 else \\\n",
        "                          \"ææ…Œ\" if final_value < 40 else \\\n",
        "                          \"ä¸­æ€§\" if final_value < 60 else \\\n",
        "                          \"è²ªå©ª\" if final_value < 80 else \"æ¥µåº¦è²ªå©ª\"\n",
        "            components['market_mood'] = market_mood\n",
        "            self.fear_greed_cache = {\n",
        "                'timestamp': now_ts,\n",
        "                'value': final_value,\n",
        "                'components': components\n",
        "            }\n",
        "            return final_value, components\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Fear & Greed è¨ˆç®—å¤±æ•—: {e}\")\n",
        "            return self.fear_greed_cache['value'], self.fear_greed_cache['components']\n",
        "\n",
        "    def calculate_sentiment_score(self, stock_id: str, stock_name: str) -> Dict[str, Any]:\n",
        "        news_sentiment, news_count = self.get_stock_news_sentiment(stock_id, stock_name)\n",
        "        fear_greed_value, fg_components = self.get_fear_greed_index()\n",
        "        if fear_greed_value < 20 or fear_greed_value > 80:\n",
        "            adj_fg_w = self.config['fear_greed_weight'] * 1.3\n",
        "        else:\n",
        "            adj_fg_w = self.config['fear_greed_weight']\n",
        "        adj_news_w = self.config['news_weight'] * min(1.0, news_count / 5)\n",
        "        total_w = adj_news_w + adj_fg_w\n",
        "        if total_w == 0:\n",
        "            total_w = 1\n",
        "        adj_news_w /= total_w\n",
        "        adj_fg_w /= total_w\n",
        "        sentiment_score = news_sentiment * adj_news_w + fear_greed_value * adj_fg_w\n",
        "        return {\n",
        "            'sentiment_score': sentiment_score,\n",
        "            'news_sentiment': news_sentiment,\n",
        "            'news_count': news_count,\n",
        "            'fear_greed_index': fear_greed_value,\n",
        "            'market_mood': fg_components.get('market_mood', ''),\n",
        "            'fear_greed_components': fg_components,\n",
        "            'weight_news': adj_news_w,\n",
        "            'weight_fear_greed': adj_fg_w\n",
        "        }\n",
        "\n",
        "# ========= è‚¡ç¥¨åˆ†æå™¨ =========\n",
        "class StockAnalyzer:\n",
        "    def __init__(self, ml_model: Optional[RandomForestRegressor] = None):\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,\n",
        "            'sentiment_weights': {\n",
        "                'trend': 0.25,\n",
        "                'volume': 0.10,\n",
        "                'technical': 0.35,\n",
        "                'sentiment': 0.20,\n",
        "                'ml': 0.10\n",
        "            }\n",
        "        }\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "        self.taiwan_stocks: Optional[pd.DataFrame] = None\n",
        "        self.sentiment_analyzer = MarketSentimentAnalyzer()\n",
        "        self.ml_model = ml_model\n",
        "        self.feature_fetcher = RealFeatureFetcher()  # æ–°å¢çœŸå¯¦ç‰¹å¾µæŠ“å–å™¨ï¼ˆæœ¬ç›Šæ¯” / ç±Œç¢¼ï¼‰\n",
        "\n",
        "    # --------- è‚¡ç¥¨åˆ—è¡¨å–å¾— ---------\n",
        "    def get_taiwan_stocks(self, force_update: bool = True) -> pd.DataFrame:\n",
        "        if (not force_update) and os.path.exists(self.stock_list_path):\n",
        "            if time.time() - os.path.getmtime(self.stock_list_path) < 86400:\n",
        "                try:\n",
        "                    return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "                except Exception:\n",
        "                    pass\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_dfs = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                resp = requests.get(url, headers=headers, timeout=30)\n",
        "                resp.encoding = 'big5'\n",
        "                tables = pd.read_html(StringIO(resp.text))\n",
        "                df = tables[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df['market'] = market_name\n",
        "                all_dfs.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"å–å¾— {market_name} æ¸…å–®å¤±æ•—: {e}\")\n",
        "        if not all_dfs:\n",
        "            return self._get_backup_stock_list()\n",
        "        try:\n",
        "            df = pd.concat(all_dfs, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)]\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)]\n",
        "            df['yahoo_symbol'] = df.apply(\n",
        "                lambda r: f\"{r['stock_id']}.TW\" if 'ä¸Šå¸‚' in r['market'] else f\"{r['stock_id']}.TWO\", axis=1\n",
        "            )\n",
        "            final = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final = final.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"å–å¾—è‚¡ç¥¨æ¸…å–® {len(final)} æ”¯\")\n",
        "            return final\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†æ¸…å–®éŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        data = [\n",
        "            {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "            {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "            {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "            {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "            {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "            {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "            {'stock_id': '3008', 'stock_name': 'å¤§ç«‹å…‰', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3008.TW', 'industry': 'å…‰å­¸'},\n",
        "            {'stock_id': '3711', 'stock_name': 'æ—¥æœˆå…‰æŠ•æ§', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3711.TW', 'industry': 'åŠå°é«”'},\n",
        "            {'stock_id': '2884', 'stock_name': 'ç‰å±±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2884.TW', 'industry': 'é‡‘è'},\n",
        "            {'stock_id': '2002', 'stock_name': 'ä¸­é‹¼', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2002.TW', 'industry': 'é‹¼éµ'}\n",
        "        ]\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    # --------- æ•¸æ“šå–å¾—èˆ‡æŒ‡æ¨™ ---------\n",
        "    def fetch_yfinance_data(self, symbol: str,\n",
        "                            period: str = \"1y\",\n",
        "                            interval: str = \"1d\",\n",
        "                            retries: int = 3) -> pd.DataFrame:\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(symbol, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"{symbol} ç„¡è³‡æ–™\")\n",
        "                    return pd.DataFrame()\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "                df = df[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "                df.reset_index(inplace=True)\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    wait = 0.5 * (2 ** attempt) + random.random()\n",
        "                    time.sleep(wait)\n",
        "                else:\n",
        "                    logger.error(f\"{symbol} æŠ“å–å¤±æ•—: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        delta = prices.diff()\n",
        "        gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(period).mean()\n",
        "        rs = gain / loss\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "        return rsi\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast=12, slow=26, signal=9):\n",
        "        ema_fast = prices.ewm(span=fast).mean()\n",
        "        ema_slow = prices.ewm(span=slow).mean()\n",
        "        macd_line = ema_fast - ema_slow\n",
        "        macd_signal = macd_line.ewm(span=signal).mean()\n",
        "        macd_hist = macd_line - macd_signal\n",
        "        return macd_line, macd_signal, macd_hist\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period=20, std_dev=2):\n",
        "        mid = prices.rolling(period).mean()\n",
        "        std = prices.rolling(period).std()\n",
        "        upper = mid + std_dev * std\n",
        "        lower = mid - std_dev * std\n",
        "        return upper, mid, lower\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period=14):\n",
        "        ll = low.rolling(period).min()\n",
        "        hh = high.rolling(period).max()\n",
        "        rsv = (close - ll) / (hh - ll) * 100\n",
        "        k = rsv.ewm(alpha=1/3).mean()\n",
        "        d = k.ewm(alpha=1/3).mean()\n",
        "        return k, d\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if df.empty:\n",
        "            return df\n",
        "        df = df.copy()\n",
        "        df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "        macd_line, macd_signal, macd_hist = self.calculate_macd(\n",
        "            df['Close'], self.config['macd_fast'], self.config['macd_slow'], self.config['macd_signal']\n",
        "        )\n",
        "        df['MACD'] = macd_line\n",
        "        df['MACD_Signal'] = macd_signal\n",
        "        df['MACD_Hist'] = macd_hist\n",
        "        upper, mid, lower = self.calculate_bollinger_bands(df['Close'], self.config['bb_period'], self.config['bb_std'])\n",
        "        df['BB_Upper'] = upper\n",
        "        df['BB_Middle'] = mid\n",
        "        df['BB_Lower'] = lower\n",
        "        k, d = self.calculate_kd(df['High'], df['Low'], df['Close'], self.config['kd_period'])\n",
        "        df['K_Percent'] = k\n",
        "        df['D_Percent'] = d\n",
        "        df['MA5'] = df['Close'].rolling(5).mean()\n",
        "        df['MA10'] = df['Close'].rolling(10).mean()\n",
        "        df['MA20'] = df['Close'].rolling(20).mean()\n",
        "        df['Volume_MA'] = df['Volume'].rolling(self.config['volume_ma_period']).mean()\n",
        "        return df\n",
        "\n",
        "    # --------- åŸºç¤åˆ†æ ---------\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        if df.empty:\n",
        "            return False\n",
        "        if 'Volume' not in df.columns:\n",
        "            return False\n",
        "        avg20 = df['Volume'].tail(20).mean()\n",
        "        lots = avg20 / 1000.0\n",
        "        return lots >= self.config['min_volume_lots']\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty or len(df) < 20:\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "        cp = float(df['Close'].iloc[-1])\n",
        "        p5 = float(df['Close'].iloc[-6]) if len(df) >= 6 else cp\n",
        "        p20 = float(df['Close'].iloc[-21]) if len(df) >= 21 else cp\n",
        "        ch5 = (cp / p5 - 1) * 100 if p5 else 0\n",
        "        ch20 = (cp / p20 - 1) * 100 if p20 else 0\n",
        "        ma5 = df['MA5'].iloc[-1]\n",
        "        ma20 = df['MA20'].iloc[-1]\n",
        "        trend = 'ç›¤æ•´'\n",
        "        strength = 0\n",
        "        if ch5 > 3 and ch20 > 5 and cp > ma5 > ma20:\n",
        "            trend = 'å¼·å‹¢ä¸Šæ¼²'; strength = 3\n",
        "        elif ch5 > 1 and ch20 > 2 and cp > ma5:\n",
        "            trend = 'ä¸Šæ¼²'; strength = 2\n",
        "        elif ch5 < -3 and ch20 < -5 and cp < ma5 < ma20:\n",
        "            trend = 'å¼·å‹¢ä¸‹è·Œ'; strength = -3\n",
        "        elif ch5 < -1 and ch20 < -2 and cp < ma5:\n",
        "            trend = 'ä¸‹è·Œ'; strength = -2\n",
        "        return {\n",
        "            'trend': trend,\n",
        "            'strength': strength,\n",
        "            'price_change_5d': ch5,\n",
        "            'price_change_20d': ch20,\n",
        "            'ma5_position': ma5,\n",
        "            'ma20_position': ma20\n",
        "        }\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty or len(df) < 20:\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "        curr_vol = df['Volume'].iloc[-1]\n",
        "        avg20 = df['Volume'].rolling(20).mean().iloc[-1]\n",
        "        ratio = curr_vol / avg20 if avg20 else 1.0\n",
        "        avg_lots = avg20 / 1000\n",
        "        if ratio > 2:\n",
        "            vt, vs = 'çˆ†é‡', 'å¼·çƒˆ'\n",
        "        elif ratio > 1.5:\n",
        "            vt, vs = 'æ”¾é‡', 'ç©æ¥µ'\n",
        "        elif ratio < 0.5:\n",
        "            vt, vs = 'ç¸®é‡', 'æ¶ˆæ¥µ'\n",
        "        else:\n",
        "            vt, vs = 'æ­£å¸¸', 'ä¸­æ€§'\n",
        "        return {\n",
        "            'volume_trend': vt,\n",
        "            'volume_ratio': ratio,\n",
        "            'volume_signal': vs,\n",
        "            'avg_volume_lots': avg_lots\n",
        "        }\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty:\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "        score = 50\n",
        "        out = {}\n",
        "        rsi_v = df['RSI'].iloc[-1]\n",
        "        if math.isnan(rsi_v):\n",
        "            rsi_v = 50\n",
        "        out['rsi_value'] = rsi_v\n",
        "        if rsi_v > 80:\n",
        "            out['rsi_signal'] = 'è¶…è²·'; score -= 15\n",
        "        elif rsi_v > 70:\n",
        "            out['rsi_signal'] = 'åé«˜'; score -= 5\n",
        "        elif rsi_v < 20:\n",
        "            out['rsi_signal'] = 'è¶…è³£'; score += 15\n",
        "        elif rsi_v < 30:\n",
        "            out['rsi_signal'] = 'åä½'; score += 5\n",
        "        else:\n",
        "            out['rsi_signal'] = 'ä¸­æ€§'\n",
        "        macd_c = df['MACD'].iloc[-1]; macd_s = df['MACD_Signal'].iloc[-1]\n",
        "        macd_p = df['MACD'].iloc[-2] if len(df) >= 2 else macd_c\n",
        "        macd_sp = df['MACD_Signal'].iloc[-2] if len(df) >= 2 else macd_s\n",
        "        out['macd_value'] = macd_c\n",
        "        if macd_p <= macd_sp and macd_c > macd_s:\n",
        "            out['macd_signal'] = 'é»ƒé‡‘äº¤å‰'; score += 20\n",
        "        elif macd_p >= macd_sp and macd_c < macd_s:\n",
        "            out['macd_signal'] = 'æ­»äº¡äº¤å‰'; score -= 20\n",
        "        elif macd_c > macd_s:\n",
        "            out['macd_signal'] = 'å¤šé ­'; score += 5\n",
        "        elif macd_c < macd_s:\n",
        "            out['macd_signal'] = 'ç©ºé ­'; score -= 5\n",
        "        else:\n",
        "            out['macd_signal'] = 'ä¸­æ€§'\n",
        "        k_v = df['K_Percent'].iloc[-1]; d_v = df['D_Percent'].iloc[-1]\n",
        "        if math.isnan(k_v): k_v = 50\n",
        "        if math.isnan(d_v): d_v = 50\n",
        "        out['k_value'] = k_v; out['d_value'] = d_v\n",
        "        if k_v > 80 and d_v > 80:\n",
        "            out['kd_signal'] = 'è¶…è²·'; score -= 10\n",
        "        elif k_v < 20 and d_v < 20:\n",
        "            out['kd_signal'] = 'è¶…è³£'; score += 10\n",
        "        elif k_v > d_v:\n",
        "            out['kd_signal'] = 'åå¤š'; score += 3\n",
        "        elif k_v < d_v:\n",
        "            out['kd_signal'] = 'åç©º'; score -= 3\n",
        "        else:\n",
        "            out['kd_signal'] = 'ä¸­æ€§'\n",
        "        upper = df['BB_Upper'].iloc[-1]; lower = df['BB_Lower'].iloc[-1]; cp = df['Close'].iloc[-1]\n",
        "        if not (math.isnan(upper) or math.isnan(lower)) and upper != lower:\n",
        "            pos = (cp - lower) / (upper - lower)\n",
        "            out['bb_position'] = pos\n",
        "            if pos > 0.8:\n",
        "                out['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'; score -= 5\n",
        "            elif pos < 0.2:\n",
        "                out['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'; score += 5\n",
        "            else:\n",
        "                out['bb_signal'] = 'ä¸­æ€§'\n",
        "        else:\n",
        "            out['bb_signal'] = 'ä¸­æ€§'; out['bb_position'] = 0.5\n",
        "        out['score'] = max(0, min(100, score))\n",
        "        return out\n",
        "\n",
        "    # --------- ç¶œåˆè©•åˆ†å«æƒ…ç·’ & ML ---------\n",
        "    def calculate_combined_score(self,\n",
        "                                 trend_analysis: Dict[str, Any],\n",
        "                                 volume_analysis: Dict[str, Any],\n",
        "                                 technical_analysis: Dict[str, Any],\n",
        "                                 sentiment_analysis: Optional[Dict[str, Any]] = None,\n",
        "                                 ml_pred: Optional[float] = None) -> Dict[str, Any]:\n",
        "        w = self.config['sentiment_weights']\n",
        "        base = 50\n",
        "        trend_strength = trend_analysis.get('strength', 0)\n",
        "        trend_component = max(-30, min(30, trend_strength * 10))\n",
        "        vr = volume_analysis.get('volume_ratio', 1.0)\n",
        "        if vr > 1.8:\n",
        "            vol_comp = 12\n",
        "        elif vr > 1.5:\n",
        "            vol_comp = 8\n",
        "        elif vr > 1.2:\n",
        "            vol_comp = 5\n",
        "        elif vr < 0.6:\n",
        "            vol_comp = -8\n",
        "        elif vr < 0.8:\n",
        "            vol_comp = -4\n",
        "        else:\n",
        "            vol_comp = 0\n",
        "        tech_score = technical_analysis.get('score', 50) - 50\n",
        "        tech_score = max(-50, min(50, tech_score))\n",
        "        sent_score = (sentiment_analysis.get('sentiment_score', 50) - 50) if sentiment_analysis else 0\n",
        "        if ml_pred is not None:\n",
        "            ml_scaled = max(-30, min(30, ml_pred))\n",
        "        else:\n",
        "            ml_scaled = 0\n",
        "        composite = (base +\n",
        "                     trend_component * w['trend'] +\n",
        "                     vol_comp * w['volume'] +\n",
        "                     tech_score * w['technical'] +\n",
        "                     sent_score * w['sentiment'] +\n",
        "                     ml_scaled * w['ml'])\n",
        "        composite = max(0, min(100, composite))\n",
        "        return {\n",
        "            'combined_score': composite,\n",
        "            'components': {\n",
        "                'trend_component': trend_component,\n",
        "                'volume_component': vol_comp,\n",
        "                'technical_component': tech_score,\n",
        "                'sentiment_component': sent_score,\n",
        "                'ml_component': ml_scaled\n",
        "            },\n",
        "            'weights': w\n",
        "        }\n",
        "\n",
        "    def generate_recommendation(self,\n",
        "                                combined_score: float,\n",
        "                                trend_analysis: Dict[str, Any],\n",
        "                                technical_analysis: Dict[str, Any],\n",
        "                                sentiment_analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        if combined_score >= 80:\n",
        "            rec, conf = \"å¼·åŠ›è²·é€²\", \"é«˜\"\n",
        "        elif combined_score >= 65:\n",
        "            rec, conf = \"è²·é€²\", \"ä¸­é«˜\"\n",
        "        elif combined_score >= 45:\n",
        "            rec, conf = \"æŒæœ‰\", \"ä¸­ç­‰\"\n",
        "        elif combined_score >= 30:\n",
        "            rec, conf = \"è³£å‡º\", \"ä¸­\"\n",
        "        else:\n",
        "            rec, conf = \"å¼·åŠ›è³£å‡º\", \"é«˜\"\n",
        "        reasons = []\n",
        "        trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "        if 'ä¸Šæ¼²' in trend:\n",
        "            reasons.append(f\"è¶¨å‹¢ï¼š{trend}\")\n",
        "        elif 'ä¸‹è·Œ' in trend:\n",
        "            reasons.append(f\"è¶¨å‹¢ï¼š{trend}\")\n",
        "        rsi_sig = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "        if rsi_sig in ['è¶…è³£', 'åä½']:\n",
        "            reasons.append(f\"RSI {rsi_sig}\")\n",
        "        elif rsi_sig in ['è¶…è²·', 'åé«˜']:\n",
        "            reasons.append(f\"RSI {rsi_sig}\")\n",
        "        macd_sig = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "        if macd_sig == 'é»ƒé‡‘äº¤å‰':\n",
        "            reasons.append(\"MACD é»ƒé‡‘äº¤å‰\")\n",
        "        elif macd_sig == 'æ­»äº¡äº¤å‰':\n",
        "            reasons.append(\"MACD æ­»äº¡äº¤å‰\")\n",
        "        if sentiment_analysis:\n",
        "            mood = sentiment_analysis.get('market_mood', '')\n",
        "            if mood:\n",
        "                reasons.append(f\"å¸‚å ´æƒ…ç·’ï¼š{mood}\")\n",
        "        return {\n",
        "            'recommendation': rec,\n",
        "            'confidence': conf,\n",
        "            'score': combined_score,\n",
        "            'reasons': reasons[:5]\n",
        "        }\n",
        "\n",
        "    # --------- å–®æ”¯è‚¡ç¥¨åˆ†æ (å«æƒ…ç·’ + çœŸå¯¦ç‰¹å¾µ + ML) ---------\n",
        "    async def analyze_stock_async(self,\n",
        "                                  session: aiohttp.ClientSession,\n",
        "                                  stock_info: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "        stock_id = stock_info['stock_id']\n",
        "        try:\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'stock_id': stock_id,\n",
        "                    'success': False,\n",
        "                    'error': 'æ•¸æ“šä¸è¶³'\n",
        "                }\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'stock_id': stock_id,\n",
        "                    'success': False,\n",
        "                    'error': 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶'\n",
        "                }\n",
        "            df_ind = self.calculate_technical_indicators(df)\n",
        "            trend_analysis = self.analyze_trend(df_ind)\n",
        "            volume_analysis = self.analyze_volume(df_ind)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_ind)\n",
        "            sentiment_analysis = self.sentiment_analyzer.calculate_sentiment_score(stock_id, stock_name)\n",
        "\n",
        "            # ====== (æ›´æ–°) çœŸå¯¦ç‰¹å¾µå–å¾— (å–ä»£åŸæ¨¡æ“¬éš¨æ©Ÿ) ======\n",
        "            real_feats = self.feature_fetcher.get_features(stock_id)\n",
        "            pe_ratio = real_feats['pe_ratio']\n",
        "            # ç•¶ä¸‹æˆäº¤é‡ä½¿ç”¨æœ€å¾Œä¸€æ ¹ Volumeï¼ˆèˆ‡ model åŒé‡ç´šï¼‰\n",
        "            volume_value = float(df_ind['Volume'].iloc[-1])\n",
        "            # ma_signalï¼šåˆ©ç”¨å‡ç·šå¤šç©ºçµæ§‹\n",
        "            cp = df_ind['Close'].iloc[-1]\n",
        "            ma5 = df_ind['MA5'].iloc[-1]\n",
        "            ma20 = df_ind['MA20'].iloc[-1]\n",
        "            if cp > ma5 > ma20:\n",
        "                ma_signal = 2\n",
        "            elif cp > ma5:\n",
        "                ma_signal = 1\n",
        "            else:\n",
        "                ma_signal = 0\n",
        "            chips_score = real_feats['chips_score']\n",
        "            # ====== ML é æ¸¬ ======\n",
        "            ml_pred = None\n",
        "            if self.ml_model:\n",
        "                ml_pred = ml_predict_current(self.ml_model, pe_ratio, volume_value, ma_signal, chips_score)\n",
        "\n",
        "            combined = self.calculate_combined_score(\n",
        "                trend_analysis, volume_analysis, technical_analysis, sentiment_analysis, ml_pred\n",
        "            )\n",
        "            combined_score = combined['combined_score']\n",
        "            recommendation = self.generate_recommendation(\n",
        "                combined_score, trend_analysis, technical_analysis, sentiment_analysis\n",
        "            )\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_id,\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': float(df_ind['Close'].iloc[-1]),\n",
        "                'price_change_5d': trend_analysis.get('price_change_5d', 0),\n",
        "                'combined_score': combined_score,\n",
        "                'combined_components': combined.get('components', {}),\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'sentiment_analysis': sentiment_analysis,\n",
        "                'ml_predicted_return': ml_pred,\n",
        "                'real_features': {\n",
        "                    'pe_ratio': pe_ratio,\n",
        "                    'chips_net': real_feats['chips_net'],\n",
        "                    'chips_score': chips_score,\n",
        "                    'pb_ratio': real_feats['pb_ratio'],\n",
        "                    'div_yield': real_feats['div_yield'],\n",
        "                    'ma_signal': ma_signal,\n",
        "                    'volume_feature': volume_value\n",
        "                },\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            logger.error(f\"{symbol} åˆ†æéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_id,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    # --------- æ‰¹é‡åˆ†æ ---------\n",
        "    async def analyze_all_stocks(self, limit: Optional[int] = None) -> Dict[str, Any]:\n",
        "        if self.taiwan_stocks is None:\n",
        "            self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "        df_list = self.taiwan_stocks\n",
        "        if df_list.empty:\n",
        "            logger.error(\"ç„¡è‚¡ç¥¨æ¸…å–®\")\n",
        "            return {}\n",
        "        if limit:\n",
        "            df_list = df_list.head(limit)\n",
        "\n",
        "        # é å…ˆè¼‰å…¥æœ€æ–°æœ¬ç›Šæ¯” / ç±Œç¢¼è³‡æ–™ï¼Œé¿å…æ¯æª”é‡è¤‡å›é€€\n",
        "        self.feature_fetcher.prepare_latest()\n",
        "\n",
        "        results = {}\n",
        "        tasks = []\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            for _, row in df_list.iterrows():\n",
        "                tasks.append(self.analyze_stock_async(session, row.to_dict()))\n",
        "            batch_size = 12\n",
        "            for i in range(0, len(tasks), batch_size):\n",
        "                batch = tasks[i:i+batch_size]\n",
        "                batch_results = await asyncio.gather(*batch, return_exceptions=True)\n",
        "                for r in batch_results:\n",
        "                    if isinstance(r, dict) and 'symbol' in r:\n",
        "                        results[r['symbol']] = r\n",
        "                await asyncio.sleep(1)\n",
        "        return results\n",
        "\n",
        "# ========= è¼¸å‡ºæ ¼å¼åŒ– =========\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    ok = [r for r in results.values() if r.get('success')]\n",
        "    ok.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "    lines = []\n",
        "    now_str = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "    lines.append(\"ğŸ† å°è‚¡ç¶œåˆæŠ€è¡“ + æƒ…ç·’ + ML (çœŸå¯¦ç‰¹å¾µ) åˆ†æ\")\n",
        "    lines.append(f\"ğŸ•’ åˆ†ææ™‚é–“: {now_str}\")\n",
        "    lines.append(f\"âœ… æˆåŠŸåˆ†æ: {len(ok)} æ”¯\")\n",
        "    lines.append(f\"ğŸ“Š è©•åˆ†çµ„æˆ: è¶¨å‹¢/æˆäº¤é‡/æŠ€è¡“/æƒ…ç·’/ML\")\n",
        "    lines.append(\"=\" * 60)\n",
        "    if not ok:\n",
        "        lines.append(\"âŒ ç„¡å¯ç”¨çµæœ\")\n",
        "        return \"\\n\".join(lines)\n",
        "    top = ok[:limit]\n",
        "    for idx, r in enumerate(top, 1):\n",
        "        sa = r.get('sentiment_analysis', {})\n",
        "        news_cnt = sa.get('news_count', 0)\n",
        "        fear_greed = sa.get('fear_greed_index', 50)\n",
        "        mood = sa.get('market_mood', '')\n",
        "        fg_emoji = \"ğŸ˜¨\" if fear_greed < 30 else \"ğŸ˜\" if fear_greed < 70 else \"ğŸ¤‘\"\n",
        "        rec = r.get('recommendation', {}).get('recommendation', '')\n",
        "        feats = r.get('real_features', {})\n",
        "        lines.append(f\"{idx}. {r.get('stock_name')} ({r.get('stock_id')})\")\n",
        "        lines.append(f\"   ğŸ’° åƒ¹æ ¼: {r.get('current_price', 0):.2f} | 5æ—¥: {r.get('price_change_5d', 0):+.2f}% | å»ºè­°: {rec}\")\n",
        "        lines.append(f\"   â­ ç¶œåˆè©•åˆ†: {r.get('combined_score', 0):.1f}  | PE:{feats.get('pe_ratio','-'):.2f} | ç±Œç¢¼åˆ†æ•¸:{feats.get('chips_score','-')}\")\n",
        "        lines.append(f\"   ğŸ“° æ–°èç†±åº¦: {news_cnt} | æ–°èæƒ…ç·’: {sa.get('news_sentiment',50):.1f}\")\n",
        "        lines.append(f\"   {fg_emoji} å¸‚å ´æƒ…ç·’(F&G): {fear_greed:.1f} ({mood})\")\n",
        "        tech = r.get('technical_analysis', {})\n",
        "        lines.append(f\"   ğŸ” RSI {tech.get('rsi_value',50):.1f}({tech.get('rsi_signal','ä¸­æ€§')}), MACD:{tech.get('macd_signal','ä¸­æ€§')}, KD:{tech.get('k_value',50):.1f}/{tech.get('d_value',50):.1f}\")\n",
        "        lines.append(\"-\" * 60)\n",
        "    avg_score = np.mean([x.get('combined_score', 0) for x in ok]) if ok else 0\n",
        "    high_cnt = sum(1 for x in ok if x.get('combined_score', 0) >= 70)\n",
        "    lines.append(f\"ğŸ“ˆ å¹³å‡åˆ†æ•¸: {avg_score:.1f} | é«˜åˆ†(>=70): {high_cnt}\")\n",
        "    lines.append(\"âš ï¸ é¢¨éšªè²æ˜ï¼šåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªã€‚\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    msg = format_analysis_message(results, limit)\n",
        "    print(msg)\n",
        "\n",
        "# ========= é€šçŸ¥ =========\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "    if not files:\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        if os.path.exists(chart_dir):\n",
        "            # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "            files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                    if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            if files:\n",
        "                logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "            else:\n",
        "                logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                if response.status == 200:\n",
        "                    logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                else:\n",
        "                    response_text = await response.text()\n",
        "                    logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                sent_count = 0\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            data = aiohttp.FormData()\n",
        "                            data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                            # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                            caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                            data.add_field('caption', caption)\n",
        "\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                    if response.status == 200:\n",
        "                                        sent_count += 1\n",
        "                                    else:\n",
        "                                        response_text = await response.text()\n",
        "                                        logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                            # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                            await asyncio.sleep(0.5)\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "        message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "        for chunk in message_chunks:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response and response.ok:\n",
        "                logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                content = response.content if response else \"æœªçŸ¥\"\n",
        "                logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "        # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "        if files:\n",
        "            batch_size = 10\n",
        "            for i in range(0, len(files), batch_size):\n",
        "                batch_files = files[i:i+batch_size]\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                for file_path in batch_files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        # ç²å–åœ–è¡¨æª”æ¡ˆæ•¸é‡\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        chart_count = 0\n",
        "        if os.path.exists(chart_dir):\n",
        "            chart_files = [f for f in os.listdir(chart_dir) if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            chart_count = len(chart_files)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ“Š ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ“ˆ TOP {min(5, len(filtered_results))} æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            # ç²å–æ›´å¤šæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\n",
        "            macd = tech.get('macd_value', 0)\n",
        "            signal = tech.get('signal_value', 0)\n",
        "            macd_status = \"å¤šé ­\" if macd > signal else \"ç©ºé ­\" if macd < signal else \"ä¸­æ€§\"\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_status', 'ä¸­æ€§')})\n",
        "   ğŸ“‰ MACD: {macd_status}\n",
        "\"\"\"\n",
        "\n",
        "        # æ·»åŠ åœ–è¡¨è³‡è¨Š\n",
        "        if chart_count > 0:\n",
        "            message += f\"\"\"\n",
        "ğŸ“Š è©³ç´°åˆ†æåœ–è¡¨:\n",
        "â€¢ å·²ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "â€¢ åœ–è¡¨åŒ…å«Kç·šã€å‡ç·šã€æˆäº¤é‡ã€MACDåŠRSIæŒ‡æ¨™\n",
        "â€¢ åœ–è¡¨å°‡åœ¨æ­¤è¨Šæ¯å¾Œç™¼é€\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "# ========= ä¸»ç¨‹å¼å…¥å£ =========\n",
        "async def main():\n",
        "    print(\"ğŸš€ å•Ÿå‹• å°è‚¡æŠ€è¡“ + æƒ…ç·’ + ML (çœŸå¯¦ç‰¹å¾µ) åˆ†æç³»çµ±\")\n",
        "    ml_model = None\n",
        "    # è‹¥è¦å•Ÿç”¨ MLï¼Œè«‹æä¾›çœŸå¯¦ historical_dataï¼š\n",
        "    # historical_data = pd.read_csv('historical_features.csv')  # éœ€åŒ…å« pe_ratio, volume, ma_signal, chips_score, future_return\n",
        "    # ml_model = build_ml_model(historical_data)\n",
        "\n",
        "    analyzer = StockAnalyzer(ml_model=ml_model)\n",
        "    print(\"ğŸ“Š æ­£åœ¨åˆ†æè‚¡ç¥¨ï¼ˆå¯èƒ½éœ€æ•¸åˆ†é˜ï¼‰...\")\n",
        "    results = await analyzer.analyze_all_stocks(limit=2000)  # å¯èª¿æ•´åˆ†ææ•¸é‡\n",
        "    if not results:\n",
        "        print(\"âŒ ç„¡åˆ†æçµæœ\")\n",
        "        return\n",
        "    display_terminal_results(results, limit=15)\n",
        "    message = format_analysis_message(results, limit=15)\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        await send_notification(session, message)\n",
        "\n",
        "    print(\"âœ… å®Œæˆã€‚\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        asyncio.run(main())\n",
        "    except RuntimeError:\n",
        "        loop = asyncio.get_event_loop()\n",
        "        loop.run_until_complete(main())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPWpoPDH7u9_"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "#  å°è‚¡ç¶œåˆåˆ†æç³»çµ± (èåˆç‰ˆ)\n",
        "#  åŠŸèƒ½ï¼š\n",
        "#   1. è‚¡ç¥¨æ¸…å–®æŠ“å– + å¿«å– (å«å‚™æ´)\n",
        "#   2. yfinance æŠ“ OHLCV\n",
        "#   3. æŠ€è¡“æŒ‡æ¨™ï¼šv1 (ç°¡ç‰ˆ) / v2 (å®Œæ•´æ“´å……)\n",
        "#   4. æ–°èæƒ…ç·’ + å°ç£ Fear & Greed æŒ‡æ•¸\n",
        "#   5. ç¶œåˆè©•åˆ† (è¶¨å‹¢ / æˆäº¤é‡ / æŠ€è¡“ / æƒ…ç·’)\n",
        "#   6. èƒŒé›¢åµæ¸¬ (RSI vs Price)ï¼šå¸¸è¦ / éš±è—\n",
        "#   7. æˆäº¤é‡æ¢ä»¶éæ¿¾ (æ—¥/é€±)\n",
        "#   8. åœ–è¡¨è¼¸å‡º (mplfinance)\n",
        "#   9. Telegram / Discord é€šçŸ¥ (å¤šæ®µè¨Šæ¯ + Retry/Backoff)\n",
        "#  ä½œè€…ï¼šæ•´åˆç‰ˆï¼ˆç’°å¢ƒè®Šæ•¸å¼·åŒ– + æ”¹è‰¯é‡æ§‹ï¼‰\n",
        "# ===============================\n",
        "\n",
        "# ===============================\n",
        "# (å¯é¸) å®‰è£éœ€æ±‚ (Jupyter æ¸¬è©¦)\n",
        "# ===============================\n",
        "# !pip install --upgrade pip\n",
        "# !pip install pandas numpy yfinance requests lxml html5lib seaborn matplotlib mplfinance chineseize-matplotlib -q\n",
        "# !pip install twstock shioaji aiohttp nest-asyncio discord-webhook python-dotenv jieba -q\n",
        "\n",
        "# ===============================\n",
        "# Imports\n",
        "# ===============================\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import gc\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import signal\n",
        "import warnings\n",
        "import logging\n",
        "import traceback\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import requests\n",
        "import platform\n",
        "import dateutil.parser\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import jieba\n",
        "\n",
        "from io import StringIO\n",
        "from functools import wraps\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, Any, List, Optional, Tuple, Union\n",
        "from collections import Counter\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError\n",
        "\n",
        "# åœ–è¡¨\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import mplfinance as mpf\n",
        "\n",
        "# BeautifulSoup\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# nest_asyncioï¼ˆåœ¨ Jupyter é‡å…¥ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Discord Webhook (å¯é¸)\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# dotenv (å¯é¸)\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ===============================\n",
        "# å…¨åŸŸè¨­å®š\n",
        "# ===============================\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.switch_backend('Agg')\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"stock_analysis.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(\"FusionAnalyzer\")\n",
        "\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# ===============================\n",
        "# ç’°å¢ƒè®Šæ•¸è¨­å®šï¼ˆç„¡å‰‡ç•™ç©º -> ä¸ç™¼é€ï¼‰\n",
        "# ===============================\n",
        "\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# ===============================\n",
        "# ç›®éŒ„çµæ§‹\n",
        "# ===============================\n",
        "for d in ['data', 'data/stocks', 'cache', 'analysis_charts', 'analysis_reports', 'stock_reports']:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# å­—é«”è¨­å®šï¼ˆé¿å…ä¸­æ–‡å­—äº‚ç¢¼ï¼‰\n",
        "# ===============================\n",
        "def set_chinese_font():\n",
        "    system = platform.system()\n",
        "    if system == 'Windows':\n",
        "        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
        "    elif system == 'Darwin':\n",
        "        plt.rcParams['font.sans-serif'] = ['PingFang TC', 'PingFang HK', 'Heiti TC']\n",
        "    else:\n",
        "        plt.rcParams['font.sans-serif'] = ['Noto Sans CJK TC', 'WenQuanYi Micro Hei', 'SimHei']\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "set_chinese_font()\n",
        "\n",
        "# ===============================\n",
        "# é€šç”¨å·¥å…·\n",
        "# ===============================\n",
        "def parse_date(date_str):\n",
        "    try:\n",
        "        return dateutil.parser.parse(date_str)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def ensure_date_column(df: pd.DataFrame):\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    date_candidates = ['Date', 'date', 'æ—¥æœŸ', 'TradeDate', 'time', 'datetime']\n",
        "    for c in date_candidates:\n",
        "        if c in df.columns:\n",
        "            df = df.rename(columns={c: 'Date'})\n",
        "            try:\n",
        "                df['Date'] = pd.to_datetime(df['Date'])\n",
        "            except:\n",
        "                return None\n",
        "            return df\n",
        "    return None\n",
        "\n",
        "# ===============================\n",
        "# Timeout æ©Ÿåˆ¶\n",
        "# ===============================\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "def timeout_handler(signum, frame):\n",
        "    raise TimeoutException(\"åŸ·è¡Œæ™‚é–“éé•·ï¼Œå·²ä¸­æ­¢\")\n",
        "\n",
        "def timeout(seconds):\n",
        "    def decorator(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            if platform.system() == \"Windows\":\n",
        "                with ThreadPoolExecutor(max_workers=1) as executor:\n",
        "                    future = executor.submit(func, *args, **kwargs)\n",
        "                    try:\n",
        "                        return future.result(timeout=seconds)\n",
        "                    except FuturesTimeoutError:\n",
        "                        raise TimeoutException(f\"æ“ä½œè¶…æ™‚ ({seconds} ç§’)\")\n",
        "            else:\n",
        "                try:\n",
        "                    signal.signal(signal.SIGALRM, timeout_handler)\n",
        "                    signal.alarm(seconds)\n",
        "                    try:\n",
        "                        return func(*args, **kwargs)\n",
        "                    finally:\n",
        "                        signal.alarm(0)\n",
        "                except Exception:\n",
        "                    with ThreadPoolExecutor(max_workers=1) as executor:\n",
        "                        future = executor.submit(func, *args, **kwargs)\n",
        "                        try:\n",
        "                            return future.result(timeout=seconds)\n",
        "                        except FuturesTimeoutError:\n",
        "                            raise TimeoutException(f\"æ“ä½œè¶…æ™‚ ({seconds} ç§’)\")\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# ===============================\n",
        "# å¿«å–å·¥å…·\n",
        "# ===============================\n",
        "def _save_cache(cache_file, data):\n",
        "    try:\n",
        "        os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n",
        "        with open(cache_file, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ä¿å­˜å¿«å–å¤±æ•—: {e}\")\n",
        "\n",
        "def _load_backup_cache(cache_file):\n",
        "    try:\n",
        "        if os.path.exists(cache_file):\n",
        "            with open(cache_file, 'rb') as f:\n",
        "                return pickle.load(f)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"è¼‰å…¥å‚™ä»½å¿«å–å¤±æ•—: {e}\")\n",
        "    return {}\n",
        "\n",
        "# ===============================\n",
        "# é©—è­‰è‚¡ç¥¨è³‡æ–™\n",
        "# ===============================\n",
        "def validate_stock_data(df: pd.DataFrame, min_points=20):\n",
        "    if df is None or df.empty:\n",
        "        return False\n",
        "    if 'Date' not in df.columns:\n",
        "        return False\n",
        "    close_col = 'Close' if 'Close' in df.columns else ('close' if 'close' in df.columns else None)\n",
        "    if close_col is None:\n",
        "        return False\n",
        "    if df[close_col].isnull().all():\n",
        "        return False\n",
        "    if len(df) < min_points:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# ===============================\n",
        "# å¸‚å ´æƒ…ç·’åˆ†æå™¨\n",
        "# ===============================\n",
        "class MarketSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.config = {\n",
        "            'news_weight': 0.4,\n",
        "            'fear_greed_weight': 0.6,\n",
        "            'news_sources': [\n",
        "                'https://news.cnyes.com/news/cat/tw_stock',\n",
        "                'https://www.moneydj.com/kmdj/news/newsreallist.aspx?a=5',\n",
        "                'https://www.cnbc.com/world/?region=world',\n",
        "            ],\n",
        "            'positive_keywords': ['ä¸Šæ¼²', 'çªç ´', 'åˆ©å¤š', 'æˆé•·', 'ç²åˆ©', 'çœ‹å¥½', 'å¼·å‹¢', 'æ¼²åœ', 'çªåœ', 'è²·é€²', 'å‰µé«˜', 'è¶…é æœŸ'],\n",
        "            'negative_keywords': ['ä¸‹è·Œ', 'è·Œç ´', 'åˆ©ç©º', 'è¡°é€€', 'è™§æ', 'çœ‹æ·¡', 'å¼±å‹¢', 'è·Œåœ', 'é‡æŒ«', 'è³£å‡º', 'èª¿é™', 'è£å“¡'],\n",
        "            'cache_duration': 1800\n",
        "        }\n",
        "        self.news_cache = {}\n",
        "        self.fear_greed_cache = {'timestamp': 0, 'value': 50, 'components': {}}\n",
        "\n",
        "    def get_stock_news_sentiment(self, stock_id: str, stock_name: str) -> Tuple[float, int]:\n",
        "        cache_key = f\"{stock_id}_{stock_name}\"\n",
        "        now_ts = time.time()\n",
        "        if cache_key in self.news_cache and (now_ts - self.news_cache[cache_key]['timestamp'] < self.config['cache_duration']):\n",
        "            return self.news_cache[cache_key]['sentiment_score'], self.news_cache[cache_key]['news_count']\n",
        "        search_terms = [stock_id, stock_name]\n",
        "        news_count = 0\n",
        "        sentiment_scores = []\n",
        "        for url in self.config['news_sources']:\n",
        "            try:\n",
        "                headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "                resp = requests.get(url, headers=headers, timeout=12)\n",
        "                soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "                candidates = soup.select('a, h2, h3, div')\n",
        "                for c in candidates:\n",
        "                    text = c.get_text(strip=True)\n",
        "                    if not text or len(text) > 60:\n",
        "                        continue\n",
        "                    if any(term in text for term in search_terms):\n",
        "                        news_count += 1\n",
        "                        words = jieba.lcut(text)\n",
        "                        pos = sum(1 for w in words if w in self.config['positive_keywords'])\n",
        "                        neg = sum(1 for w in words if w in self.config['negative_keywords'])\n",
        "                        if pos + neg > 0:\n",
        "                            s = (pos - neg) / (pos + neg)\n",
        "                            sentiment_scores.append(s)\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"æ–°èä¾†æºå¤±æ•— {url}: {e}\")\n",
        "        if sentiment_scores:\n",
        "            avg = float(np.mean(sentiment_scores))\n",
        "            score_0_100 = (avg + 1) * 50\n",
        "        else:\n",
        "            score_0_100 = 50.0\n",
        "        self.news_cache[cache_key] = {\n",
        "            'timestamp': now_ts,\n",
        "            'sentiment_score': score_0_100,\n",
        "            'news_count': news_count\n",
        "        }\n",
        "        return score_0_100, news_count\n",
        "\n",
        "    def get_fear_greed_index(self) -> Tuple[float, Dict[str, Any]]:\n",
        "        now_ts = time.time()\n",
        "        if now_ts - self.fear_greed_cache['timestamp'] < self.config['cache_duration']:\n",
        "            return self.fear_greed_cache['value'], self.fear_greed_cache['components']\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        components = {\n",
        "            'price_momentum': None,\n",
        "            'price_score': 50,\n",
        "            'volatility_ratio': None,\n",
        "            'volatility_score': 50,\n",
        "            'volume_change_pct': None,\n",
        "            'volume_score': 50,\n",
        "            'pc_ratio': None,\n",
        "            'pc_ratio_score': 50\n",
        "        }\n",
        "        try:\n",
        "            taiex_url = \"https://query1.finance.yahoo.com/v8/finance/chart/%5ETWII?interval=1d&range=60d\"\n",
        "            r = requests.get(taiex_url, headers=headers, timeout=12).json()\n",
        "            closes = r['chart']['result'][0]['indicators']['quote'][0]['close']\n",
        "            closes = [c for c in closes if c is not None]\n",
        "            if len(closes) >= 20:\n",
        "                ma10 = np.mean(closes[-10:])\n",
        "                last = closes[-1]\n",
        "                price_momentum = (last / ma10 - 1) * 100 if ma10 else 0\n",
        "                components['price_momentum'] = price_momentum\n",
        "                price_score = 50 + price_momentum * 5\n",
        "                components['price_score'] = max(0, min(100, price_score))\n",
        "                ret = np.diff(closes) / closes[:-1]\n",
        "                if len(ret) >= 21:\n",
        "                    vol_5 = np.std(ret[-5:]) * 100\n",
        "                    vol_20 = np.std(ret[-20:]) * 100\n",
        "                    vol_ratio = vol_5 / vol_20 if vol_20 else 1\n",
        "                    components['volatility_ratio'] = vol_ratio\n",
        "                    volatility_score = 100 - (vol_ratio - 0.5) * 100\n",
        "                    components['volatility_score'] = max(0, min(100, volatility_score))\n",
        "            volume_url = \"https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK?date=20230101&response=json\"\n",
        "            try:\n",
        "                rv = requests.get(volume_url, headers=headers, timeout=12).json()\n",
        "                vol_list = []\n",
        "                if 'data' in rv:\n",
        "                    for row in rv['data'][-8:]:\n",
        "                        try:\n",
        "                            val = row[1].replace(',', '')\n",
        "                            vol_list.append(float(val))\n",
        "                        except:\n",
        "                            pass\n",
        "                if len(vol_list) >= 5:\n",
        "                    recent = np.mean(vol_list[-5:])\n",
        "                    prev = np.mean(vol_list[-10:-5]) if len(vol_list) >= 10 else recent\n",
        "                    volume_change = (recent / prev - 1) * 100 if prev else 0\n",
        "                    components['volume_change_pct'] = volume_change\n",
        "                    components['volume_score'] = max(0, min(100, 50 + volume_change))\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"æˆäº¤é‡æŠ“å–å¤±æ•—: {e}\")\n",
        "            try:\n",
        "                pc_url = \"https://www.taifex.com.tw/cht/3/pcRatio\"\n",
        "                pr = requests.get(pc_url, headers=headers, timeout=12)\n",
        "                soup = BeautifulSoup(pr.text, 'html.parser')\n",
        "                tables = soup.find_all('table')\n",
        "                pc_ratio = None\n",
        "                for tbl in tables:\n",
        "                    tds = tbl.find_all('td')\n",
        "                    for td in tds:\n",
        "                        txt = td.get_text(strip=True)\n",
        "                        if re.match(r'^\\d+(\\.\\d+)?$', txt):\n",
        "                            val = float(txt)\n",
        "                            if 0.3 < val < 5:\n",
        "                                pc_ratio = val\n",
        "                                break\n",
        "                    if pc_ratio:\n",
        "                        break\n",
        "                if pc_ratio:\n",
        "                    components['pc_ratio'] = pc_ratio\n",
        "                    pc_score = 50 + (pc_ratio - 1) * 40\n",
        "                    components['pc_ratio_score'] = max(0, min(100, pc_score))\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"P/C æŠ“å–å¤±æ•—: {e}\")\n",
        "            final_value = (\n",
        "                components['price_score'] * 0.5 +\n",
        "                components['volatility_score'] * 0.2 +\n",
        "                components['volume_score'] * 0.15 +\n",
        "                components['pc_ratio_score'] * 0.15\n",
        "            )\n",
        "            final_value = max(0, min(100, final_value))\n",
        "            mood = \"æ¥µåº¦ææ…Œ\" if final_value < 20 else \\\n",
        "                   \"ææ…Œ\" if final_value < 40 else \\\n",
        "                   \"ä¸­æ€§\" if final_value < 60 else \\\n",
        "                   \"è²ªå©ª\" if final_value < 80 else \"æ¥µåº¦è²ªå©ª\"\n",
        "            components['market_mood'] = mood\n",
        "            self.fear_greed_cache = {\n",
        "                'timestamp': now_ts,\n",
        "                'value': final_value,\n",
        "                'components': components\n",
        "            }\n",
        "            return final_value, components\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Fear & Greed è¨ˆç®—å¤±æ•—: {e}\")\n",
        "            return self.fear_greed_cache['value'], self.fear_greed_cache['components']\n",
        "\n",
        "    def calculate_sentiment_score(self, stock_id: str, stock_name: str) -> Dict[str, Any]:\n",
        "        news_sentiment, news_count = self.get_stock_news_sentiment(stock_id, stock_name)\n",
        "        fg_value, fg_components = self.get_fear_greed_index()\n",
        "        if fg_value < 20 or fg_value > 80:\n",
        "            adj_fg_w = self.config['fear_greed_weight'] * 1.3\n",
        "        else:\n",
        "            adj_fg_w = self.config['fear_greed_weight']\n",
        "        adj_news_w = self.config['news_weight'] * min(1.0, news_count / 5)\n",
        "        total_w = adj_news_w + adj_fg_w\n",
        "        if total_w == 0:\n",
        "            total_w = 1\n",
        "        adj_news_w /= total_w\n",
        "        adj_fg_w /= total_w\n",
        "        sentiment_score = news_sentiment * adj_news_w + fg_value * adj_fg_w\n",
        "        return {\n",
        "            'sentiment_score': sentiment_score,\n",
        "            'news_sentiment': news_sentiment,\n",
        "            'news_count': news_count,\n",
        "            'fear_greed_index': fg_value,\n",
        "            'market_mood': fg_components.get('market_mood', ''),\n",
        "            'fear_greed_components': fg_components,\n",
        "            'weight_news': adj_news_w,\n",
        "            'weight_fear_greed': adj_fg_w\n",
        "        }\n",
        "\n",
        "# ===============================\n",
        "# æŠ€è¡“åˆ†æä¸»é¡åˆ¥\n",
        "# ===============================\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,\n",
        "            'sentiment_weights': {\n",
        "                'trend': 0.25,\n",
        "                'volume': 0.10,\n",
        "                'technical': 0.40,\n",
        "                'sentiment': 0.25\n",
        "            }\n",
        "        }\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "        self.taiwan_stocks: Optional[pd.DataFrame] = None\n",
        "        self.sentiment_analyzer = MarketSentimentAnalyzer()\n",
        "\n",
        "    # è‚¡ç¥¨æ¸…å–®\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if time.time() - os.path.getmtime(self.stock_list_path) < 86400:\n",
        "                try:\n",
        "                    return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "                except:\n",
        "                    pass\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df['market'] = market_name\n",
        "                all_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} æ¸…å–®å¤±æ•—: {e}\")\n",
        "        if not all_df:\n",
        "            return self._backup_list()\n",
        "        try:\n",
        "            df = pd.concat(all_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)]\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)]\n",
        "            df['yahoo_symbol'] = df.apply(\n",
        "                lambda r: f\"{r['stock_id']}.TW\" if r['market'] == 'ä¸Šå¸‚' else f\"{r['stock_id']}.TWO\",\n",
        "                axis=1\n",
        "            )\n",
        "            final = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final = final.drop_duplicates(subset=['stock_id'])\n",
        "            final.to_csv(self.stock_list_path, index=False)\n",
        "            return final\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®éŒ¯èª¤: {e}\")\n",
        "            return self._backup_list()\n",
        "\n",
        "    def _backup_list(self):\n",
        "        data = [\n",
        "            {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'industry': 'åŠå°é«”', 'yahoo_symbol': '2330.TW'},\n",
        "            {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'industry': 'é›»å­', 'yahoo_symbol': '2317.TW'},\n",
        "            {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'industry': 'åŠå°é«”', 'yahoo_symbol': '2454.TW'},\n",
        "            {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'industry': 'é‡‘è', 'yahoo_symbol': '2881.TW'},\n",
        "            {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'industry': 'é‡‘è', 'yahoo_symbol': '2882.TW'},\n",
        "        ]\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    # æŠ“è³‡æ–™\n",
        "    def fetch_yfinance_data(self, symbol: str, period=\"1y\", interval=\"1d\", retries=3):\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(symbol, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    return pd.DataFrame()\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "                df = df[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "                df.reset_index(inplace=True)\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(0.5 * (2 ** attempt))\n",
        "                else:\n",
        "                    logger.error(f\"{symbol} æ•¸æ“šæŠ“å–å¤±æ•—: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # ç°¡ç‰ˆæŒ‡æ¨™ v1\n",
        "    def calculate_technical_indicators_v1(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if df.empty:\n",
        "            return df\n",
        "        df = df.copy()\n",
        "        delta = df['Close'].diff()\n",
        "        gain = delta.where(delta > 0, 0)\n",
        "        loss = -delta.where(delta < 0, 0)\n",
        "        avg_gain = gain.rolling(self.config['rsi_period']).mean()\n",
        "        avg_loss = loss.rolling(self.config['rsi_period']).mean()\n",
        "        rs = avg_gain / avg_loss\n",
        "        df['RSI'] = 100 - (100 / (1 + rs))\n",
        "        ema_fast = df['Close'].ewm(span=self.config['macd_fast']).mean()\n",
        "        ema_slow = df['Close'].ewm(span=self.config['macd_slow']).mean()\n",
        "        macd_line = ema_fast - ema_slow\n",
        "        macd_signal = macd_line.ewm(span=self.config['macd_signal']).mean()\n",
        "        df['MACD'] = macd_line\n",
        "        df['MACD_Signal'] = macd_signal\n",
        "        df['MACD_Histogram'] = macd_line - macd_signal\n",
        "        mid = df['Close'].rolling(self.config['bb_period']).mean()\n",
        "        std = df['Close'].rolling(self.config['bb_period']).std()\n",
        "        df['BB_Upper'] = mid + self.config['bb_std'] * std\n",
        "        df['BB_Middle'] = mid\n",
        "        df['BB_Lower'] = mid - self.config['bb_std'] * std\n",
        "        ll = df['Low'].rolling(self.config['kd_period']).min()\n",
        "        hh = df['High'].rolling(self.config['kd_period']).max()\n",
        "        k = (df['Close'] - ll) / (hh - ll + 1e-9) * 100\n",
        "        k = k.rolling(3).mean()\n",
        "        d = k.rolling(3).mean()\n",
        "        df['K_Percent'] = k\n",
        "        df['D_Percent'] = d\n",
        "        df['MA5'] = df['Close'].rolling(5).mean()\n",
        "        df['MA10'] = df['Close'].rolling(10).mean()\n",
        "        df['MA20'] = df['Close'].rolling(20).mean()\n",
        "        df['Volume_MA'] = df['Volume'].rolling(self.config['volume_ma_period']).mean()\n",
        "        return df\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        if df.empty:\n",
        "            return False\n",
        "        avg20 = df['Volume'].tail(20).mean()\n",
        "        lots = avg20 / 1000\n",
        "        return lots >= self.config['min_volume_lots']\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty or len(df) < 20:\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "        cp = df['Close'].iloc[-1]\n",
        "        p5 = df['Close'].iloc[-6] if len(df) >= 6 else cp\n",
        "        p20 = df['Close'].iloc[-21] if len(df) >= 21 else cp\n",
        "        ch5 = (cp / p5 - 1) * 100 if p5 else 0\n",
        "        ch20 = (cp / p20 - 1) * 100 if p20 else 0\n",
        "        ma5 = df['MA5'].iloc[-1]\n",
        "        ma20 = df['MA20'].iloc[-1]\n",
        "        trend = 'ç›¤æ•´'\n",
        "        strength = 0\n",
        "        if ch5 > 3 and ch20 > 5 and cp > ma5 > ma20:\n",
        "            trend = 'å¼·å‹¢ä¸Šæ¼²'; strength = 3\n",
        "        elif ch5 > 1 and ch20 > 2 and cp > ma5:\n",
        "            trend = 'ä¸Šæ¼²'; strength = 2\n",
        "        elif ch5 < -3 and ch20 < -5 and cp < ma5 < ma20:\n",
        "            trend = 'å¼·å‹¢ä¸‹è·Œ'; strength = -3\n",
        "        elif ch5 < -1 and ch20 < -2 and cp < ma5:\n",
        "            trend = 'ä¸‹è·Œ'; strength = -2\n",
        "        return {\n",
        "            'trend': trend,\n",
        "            'strength': strength,\n",
        "            'price_change_5d': ch5,\n",
        "            'price_change_20d': ch20\n",
        "        }\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty or len(df) < 20:\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "        curr = df['Volume'].iloc[-1]\n",
        "        avg20 = df['Volume'].rolling(20).mean().iloc[-1]\n",
        "        ratio = curr / avg20 if avg20 else 1\n",
        "        lots = avg20 / 1000\n",
        "        if ratio > 2: vt, vs = 'çˆ†é‡', 'å¼·çƒˆ'\n",
        "        elif ratio > 1.5: vt, vs = 'æ”¾é‡', 'ç©æ¥µ'\n",
        "        elif ratio < 0.5: vt, vs = 'ç¸®é‡', 'æ¶ˆæ¥µ'\n",
        "        else: vt, vs = 'æ­£å¸¸', 'ä¸­æ€§'\n",
        "        return {\n",
        "            'volume_trend': vt, 'volume_ratio': ratio, 'volume_signal': vs, 'avg_volume_lots': lots\n",
        "        }\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty:\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "        score = 50\n",
        "        out = {}\n",
        "        rsi_v = df['RSI'].iloc[-1] if 'RSI' in df.columns else 50\n",
        "        if math.isnan(rsi_v): rsi_v = 50\n",
        "        out['rsi_value'] = rsi_v\n",
        "        if rsi_v > 80: out['rsi_signal'] = 'è¶…è²·'; score -= 15\n",
        "        elif rsi_v > 70: out['rsi_signal'] = 'åé«˜'; score -= 5\n",
        "        elif rsi_v < 20: out['rsi_signal'] = 'è¶…è³£'; score += 15\n",
        "        elif rsi_v < 30: out['rsi_signal'] = 'åä½'; score += 5\n",
        "        else: out['rsi_signal'] = 'ä¸­æ€§'\n",
        "        macd_c = df['MACD'].iloc[-1] if 'MACD' in df.columns else 0\n",
        "        macd_s = df['MACD_Signal'].iloc[-1] if 'MACD_Signal' in df.columns else 0\n",
        "        macd_p = df['MACD'].iloc[-2] if 'MACD' in df.columns and len(df) >= 2 else macd_c\n",
        "        macd_sp = df['MACD_Signal'].iloc[-2] if 'MACD_Signal' in df.columns and len(df) >= 2 else macd_s\n",
        "        out['macd_value'] = macd_c\n",
        "        if macd_p <= macd_sp and macd_c > macd_s:\n",
        "            out['macd_signal'] = 'é»ƒé‡‘äº¤å‰'; score += 20\n",
        "        elif macd_p >= macd_sp and macd_c < macd_s:\n",
        "            out['macd_signal'] = 'æ­»äº¡äº¤å‰'; score -= 20\n",
        "        elif macd_c > macd_s:\n",
        "            out['macd_signal'] = 'å¤šé ­'; score += 5\n",
        "        elif macd_c < macd_s:\n",
        "            out['macd_signal'] = 'ç©ºé ­'; score -= 5\n",
        "        else:\n",
        "            out['macd_signal'] = 'ä¸­æ€§'\n",
        "        k_col = 'K_Percent' if 'K_Percent' in df.columns else ('K' if 'K' in df.columns else None)\n",
        "        d_col = 'D_Percent' if 'D_Percent' in df.columns else ('D' if 'D' in df.columns else None)\n",
        "        k_v = df[k_col].iloc[-1] if k_col else 50\n",
        "        d_v = df[d_col].iloc[-1] if d_col else 50\n",
        "        if math.isnan(k_v): k_v = 50\n",
        "        if math.isnan(d_v): d_v = 50\n",
        "        out['k_value'] = k_v; out['d_value'] = d_v\n",
        "        if k_v > 80 and d_v > 80: out['kd_signal'] = 'è¶…è²·'; score -= 10\n",
        "        elif k_v < 20 and d_v < 20: out['kd_signal'] = 'è¶…è³£'; score += 10\n",
        "        elif k_v > d_v: out['kd_signal'] = 'åå¤š'; score += 3\n",
        "        elif k_v < d_v: out['kd_signal'] = 'åç©º'; score -= 3\n",
        "        else: out['kd_signal'] = 'ä¸­æ€§'\n",
        "        if 'BB_Upper' in df.columns and 'BB_Lower' in df.columns and 'Close' in df.columns:\n",
        "            bb_u = df['BB_Upper'].iloc[-1]; bb_l = df['BB_Lower'].iloc[-1]; cp = df['Close'].iloc[-1]\n",
        "            if not (math.isnan(bb_u) or math.isnan(bb_l)) and bb_u != bb_l:\n",
        "                pos = (cp - bb_l) / (bb_u - bb_l)\n",
        "                out['bb_position'] = pos\n",
        "                if pos > 0.8: out['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'; score -= 5\n",
        "                elif pos < 0.2: out['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'; score += 5\n",
        "                else: out['bb_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                out['bb_signal'] = 'ä¸­æ€§'; out['bb_position'] = 0.5\n",
        "        else:\n",
        "            out['bb_signal'] = 'ä¸­æ€§'; out['bb_position'] = 0.5\n",
        "        out['score'] = max(0, min(100, score))\n",
        "        return out\n",
        "\n",
        "    def calculate_combined_score(self,\n",
        "                                 trend_analysis: Dict[str, Any],\n",
        "                                 volume_analysis: Dict[str, Any],\n",
        "                                 technical_analysis: Dict[str, Any],\n",
        "                                 sentiment_analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        w = self.config['sentiment_weights']\n",
        "        base = 50\n",
        "        trend_strength = trend_analysis.get('strength', 0)\n",
        "        trend_component = max(-30, min(30, trend_strength * 10))\n",
        "        vr = volume_analysis.get('volume_ratio', 1.0)\n",
        "        if vr > 1.8: vol_comp = 12\n",
        "        elif vr > 1.5: vol_comp = 8\n",
        "        elif vr > 1.2: vol_comp = 5\n",
        "        elif vr < 0.6: vol_comp = -8\n",
        "        elif vr < 0.8: vol_comp = -4\n",
        "        else: vol_comp = 0\n",
        "        tech_score = max(-50, min(50, technical_analysis.get('score', 50) - 50))\n",
        "        sent_score = (sentiment_analysis.get('sentiment_score', 50) - 50) if sentiment_analysis else 0\n",
        "        composite = (base +\n",
        "                     trend_component * w['trend'] +\n",
        "                     vol_comp * w['volume'] +\n",
        "                     tech_score * w['technical'] +\n",
        "                     sent_score * w['sentiment'])\n",
        "        composite = max(0, min(100, composite))\n",
        "        return {\n",
        "            'combined_score': composite,\n",
        "            'components': {\n",
        "                'trend_component': trend_component,\n",
        "                'volume_component': vol_comp,\n",
        "                'technical_component': tech_score,\n",
        "                'sentiment_component': sent_score\n",
        "            },\n",
        "            'weights': w\n",
        "        }\n",
        "\n",
        "    def generate_recommendation(self,\n",
        "                                combined_score: float,\n",
        "                                trend_analysis: Dict[str, Any],\n",
        "                                technical_analysis: Dict[str, Any],\n",
        "                                sentiment_analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        if combined_score >= 80: rec, conf = \"å¼·åŠ›è²·é€²\", \"é«˜\"\n",
        "        elif combined_score >= 65: rec, conf = \"è²·é€²\", \"ä¸­é«˜\"\n",
        "        elif combined_score >= 45: rec, conf = \"æŒæœ‰\", \"ä¸­ç­‰\"\n",
        "        elif combined_score >= 30: rec, conf = \"è³£å‡º\", \"ä¸­\"\n",
        "        else: rec, conf = \"å¼·åŠ›è³£å‡º\", \"é«˜\"\n",
        "        reasons = []\n",
        "        trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "        if 'ä¸Šæ¼²' in trend or 'ä¸‹è·Œ' in trend:\n",
        "            reasons.append(f\"è¶¨å‹¢ï¼š{trend}\")\n",
        "        rsi_sig = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "        if rsi_sig in ['è¶…è³£', 'åä½', 'è¶…è²·', 'åé«˜']:\n",
        "            reasons.append(f\"RSI {rsi_sig}\")\n",
        "        macd_sig = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "        if macd_sig in ['é»ƒé‡‘äº¤å‰', 'æ­»äº¡äº¤å‰']:\n",
        "            reasons.append(f\"MACD {macd_sig}\")\n",
        "        if sentiment_analysis:\n",
        "            mood = sentiment_analysis.get('market_mood', '')\n",
        "            if mood:\n",
        "                reasons.append(f\"å¸‚å ´æƒ…ç·’ï¼š{mood}\")\n",
        "        return {\n",
        "            'recommendation': rec,\n",
        "            'confidence': conf,\n",
        "            'score': combined_score,\n",
        "            'reasons': reasons[:5]\n",
        "        }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "        stock_id = stock_info['stock_id']\n",
        "        try:\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df.empty or len(df) < 60:\n",
        "                return {'symbol': symbol, 'stock_name': stock_name, 'stock_id': stock_id, 'success': False, 'error': 'æ•¸æ“šä¸è¶³'}\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {'symbol': symbol, 'stock_name': stock_name, 'stock_id': stock_id, 'success': False, 'error': 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶'}\n",
        "            df_ind = self.calculate_technical_indicators_v1(df)\n",
        "            trend_analysis = self.analyze_trend(df_ind)\n",
        "            volume_analysis = self.analyze_volume(df_ind)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_ind)\n",
        "            sentiment_analysis = self.sentiment_analyzer.calculate_sentiment_score(stock_id, stock_name)\n",
        "            combined = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis, sentiment_analysis)\n",
        "            recommendation = self.generate_recommendation(combined['combined_score'], trend_analysis, technical_analysis, sentiment_analysis)\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_id,\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': float(df_ind['Close'].iloc[-1]),\n",
        "                'price_change_5d': trend_analysis.get('price_change_5d', 0),\n",
        "                'combined_score': combined['combined_score'],\n",
        "                'combined_components': combined.get('components', {}),\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'sentiment_analysis': sentiment_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"{symbol} åˆ†æéŒ¯èª¤: {e}\")\n",
        "            return {'symbol': symbol, 'stock_name': stock_name, 'stock_id': stock_id, 'success': False, 'error': str(e)}\n",
        "\n",
        "    async def analyze_all_stocks(self, limit: Optional[int] = None) -> Dict[str, Any]:\n",
        "        if self.taiwan_stocks is None:\n",
        "            self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "        if self.taiwan_stocks.empty:\n",
        "            return {}\n",
        "        df_list = self.taiwan_stocks if not limit else self.taiwan_stocks.head(limit)\n",
        "        tasks = []\n",
        "        results = {}\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            for _, row in df_list.iterrows():\n",
        "                tasks.append(self.analyze_stock_async(session, row.to_dict()))\n",
        "            batch_size = 12\n",
        "            for i in range(0, len(tasks), batch_size):\n",
        "                batch = tasks[i:i+batch_size]\n",
        "                batch_results = await asyncio.gather(*batch, return_exceptions=True)\n",
        "                for r in batch_results:\n",
        "                    if isinstance(r, dict) and 'symbol' in r:\n",
        "                        results[r['symbol']] = r\n",
        "                await asyncio.sleep(1)\n",
        "        return results\n",
        "\n",
        "# ===============================\n",
        "# æ ¼å¼åŒ–è¼¸å‡º\n",
        "# ===============================\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    ok = [r for r in results.values() if r.get('success')]\n",
        "    ok.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "    lines = []\n",
        "    now_str = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "    lines.append(\"ğŸ† å°è‚¡ç¶œåˆæŠ€è¡“ + æƒ…ç·’ åˆ†æ\")\n",
        "    lines.append(f\"ğŸ•’ åˆ†ææ™‚é–“: {now_str}\")\n",
        "    lines.append(f\"âœ… æˆåŠŸåˆ†æ: {len(ok)} æ”¯\")\n",
        "    lines.append(\"=\" * 50)\n",
        "    if not ok:\n",
        "        lines.append(\"âŒ ç„¡å¯ç”¨çµæœ\")\n",
        "        return \"\\n\".join(lines)\n",
        "    top = ok[:limit]\n",
        "    for idx, r in enumerate(top, 1):\n",
        "        sa = r.get('sentiment_analysis', {})\n",
        "        news_cnt = sa.get('news_count', 0)\n",
        "        fear_greed = sa.get('fear_greed_index', 50)\n",
        "        mood = sa.get('market_mood', '')\n",
        "        fg_emoji = \"ğŸ˜¨\" if fear_greed < 30 else \"ğŸ˜\" if fear_greed < 70 else \"ğŸ¤‘\"\n",
        "        rec = r.get('recommendation', {}).get('recommendation', '')\n",
        "        lines.append(f\"{idx}. {r.get('stock_name')} ({r.get('stock_id')})\")\n",
        "        lines.append(f\"   ğŸ’° åƒ¹æ ¼: {r.get('current_price', 0):.2f} | 5æ—¥: {r.get('price_change_5d', 0):+.2f}%\")\n",
        "        lines.append(f\"   â­ ç¶œåˆè©•åˆ†: {r.get('combined_score', 0):.1f} | å»ºè­°: {rec}\")\n",
        "        lines.append(f\"   ğŸ“° æ–°èç†±åº¦: {news_cnt} | æ–°èæƒ…ç·’: {sa.get('news_sentiment',50):.1f}\")\n",
        "        lines.append(f\"   {fg_emoji} å¸‚å ´æƒ…ç·’(F&G): {fear_greed:.1f} ({mood})\")\n",
        "        tech = r.get('technical_analysis', {})\n",
        "        lines.append(f\"   ğŸ” RSI {tech.get('rsi_value',50):.1f}({tech.get('rsi_signal','ä¸­æ€§')}), MACD:{tech.get('macd_signal','ä¸­æ€§')}, KD:{tech.get('k_value',50):.1f}/{tech.get('d_value',50):.1f}\")\n",
        "        lines.append(\"-\" * 50)\n",
        "    avg_score = np.mean([x.get('combined_score', 0) for x in ok]) if ok else 0\n",
        "    high_cnt = sum(1 for x in ok if x.get('combined_score', 0) >= 70)\n",
        "    lines.append(f\"ğŸ“ˆ å¹³å‡åˆ†æ•¸: {avg_score:.1f} | é«˜åˆ†(>=70): {high_cnt}\")\n",
        "    lines.append(\"âš ï¸ é¢¨éšªè²æ˜ï¼šåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªã€‚\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# ===============================\n",
        "# é€šçŸ¥ï¼ˆå« Retry / Backoffï¼‰\n",
        "# ===============================\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "    if not files:\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        if os.path.exists(chart_dir):\n",
        "            # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "            files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                    if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            if files:\n",
        "                logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "            else:\n",
        "                logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                if response.status == 200:\n",
        "                    logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                else:\n",
        "                    response_text = await response.text()\n",
        "                    logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                sent_count = 0\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            data = aiohttp.FormData()\n",
        "                            data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                            # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                            caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                            data.add_field('caption', caption)\n",
        "\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                    if response.status == 200:\n",
        "                                        sent_count += 1\n",
        "                                    else:\n",
        "                                        response_text = await response.text()\n",
        "                                        logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                            # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                            await asyncio.sleep(0.5)\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "        message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "        for chunk in message_chunks:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response and response.ok:\n",
        "                logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                content = response.content if response else \"æœªçŸ¥\"\n",
        "                logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "        # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "        if files:\n",
        "            batch_size = 10\n",
        "            for i in range(0, len(files), batch_size):\n",
        "                batch_files = files[i:i+batch_size]\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                for file_path in batch_files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        # ç²å–åœ–è¡¨æª”æ¡ˆæ•¸é‡\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        chart_count = 0\n",
        "        if os.path.exists(chart_dir):\n",
        "            chart_files = [f for f in os.listdir(chart_dir) if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            chart_count = len(chart_files)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ“Š ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ“ˆ TOP {min(5, len(filtered_results))} æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            # ç²å–æ›´å¤šæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\n",
        "            macd = tech.get('macd_value', 0)\n",
        "            signal = tech.get('signal_value', 0)\n",
        "            macd_status = \"å¤šé ­\" if macd > signal else \"ç©ºé ­\" if macd < signal else \"ä¸­æ€§\"\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_status', 'ä¸­æ€§')})\n",
        "   ğŸ“‰ MACD: {macd_status}\n",
        "\"\"\"\n",
        "\n",
        "        # æ·»åŠ åœ–è¡¨è³‡è¨Š\n",
        "        if chart_count > 0:\n",
        "            message += f\"\"\"\n",
        "ğŸ“Š è©³ç´°åˆ†æåœ–è¡¨:\n",
        "â€¢ å·²ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "â€¢ åœ–è¡¨åŒ…å«Kç·šã€å‡ç·šã€æˆäº¤é‡ã€MACDåŠRSIæŒ‡æ¨™\n",
        "â€¢ åœ–è¡¨å°‡åœ¨æ­¤è¨Šæ¯å¾Œç™¼é€\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def detect_divergence(df, rsi_threshold=30, rsi_overbought=70, window=20, min_divergence_points=2):\n",
        "    \"\"\"\n",
        "    æª¢æ¸¬ RSI èˆ‡åƒ¹æ ¼ä¹‹é–“çš„èƒŒé›¢\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): åŒ…å«åƒ¹æ ¼å’Œ RSI çš„ DataFrame\n",
        "        rsi_threshold (int): RSI è¶…è³£é–¾å€¼\n",
        "        rsi_overbought (int): RSI è¶…è²·é–¾å€¼\n",
        "        window (int): æª¢æ¸¬çª—å£å¤§å°\n",
        "        min_divergence_points (int): æœ€å°èƒŒé›¢é»æ•¸é‡\n",
        "\n",
        "    Returns:\n",
        "        dict: åŒ…å«èƒŒé›¢é¡å‹å’Œåˆ†æ•¸çš„å­—å…¸\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨\n",
        "        required_cols = ['Close', 'RSI']\n",
        "        for col in required_cols:\n",
        "            if col not in df.columns:\n",
        "                # å˜—è©¦æŸ¥æ‰¾å°å¯«ç‰ˆæœ¬\n",
        "                if col.lower() in df.columns:\n",
        "                    df[col] = df[col.lower()]\n",
        "                    logger.info(f\"å·²å°‡ {col.lower()} æ¬„ä½è¤‡è£½ç‚º {col}\")\n",
        "                else:\n",
        "                    logger.warning(f\"detect_divergence: ç¼ºå°‘å¿…è¦æ¬„ä½ {col}\")\n",
        "                    return {\n",
        "                        'type': 'ç„¡',                        'bullish_regular': 0,\n",
        "                        'bullish_hidden': 0,\n",
        "                        'bearish_regular': 0,\n",
        "                        'bearish_hidden': 0,\n",
        "                        'details': f\"ç¼ºå°‘å¿…è¦æ¬„ä½: {col}\"\n",
        "                        }\n",
        "\n",
        "        # åˆå§‹åŒ–è¿”å›çµæœ\n",
        "        result = {\n",
        "        'type': 'ç„¡',\n",
        "        'bullish_regular': 0,\n",
        "        'bullish_hidden': 0,\n",
        "        'bearish_regular': 0,\n",
        "        'bearish_hidden': 0,\n",
        "        'details': None\n",
        "        }\n",
        "\n",
        "        if df is None or df.empty:\n",
        "            return result\n",
        "        if 'Close' not in df.columns or 'RSI' not in df.columns:\n",
        "            return result\n",
        "        lookback = 30\n",
        "        if len(df) < lookback:\n",
        "            return result\n",
        "        recent = df.tail(lookback)\n",
        "        price_highs, price_lows, rsi_highs, rsi_lows = [], [], [], []\n",
        "        for i in range(1, len(recent)-1):\n",
        "            if recent['Close'].iloc[i] > recent['Close'].iloc[i-1] and recent['Close'].iloc[i] > recent['Close'].iloc[i+1]:\n",
        "                price_highs.append((i, recent['Close'].iloc[i]))\n",
        "            if recent['Close'].iloc[i] < recent['Close'].iloc[i-1] and recent['Close'].iloc[i] < recent['Close'].iloc[i+1]:\n",
        "                price_lows.append((i, recent['Close'].iloc[i]))\n",
        "            if recent['RSI'].iloc[i] > recent['RSI'].iloc[i-1] and recent['RSI'].iloc[i] > recent['RSI'].iloc[i+1]:\n",
        "                rsi_highs.append((i, recent['RSI'].iloc[i]))\n",
        "            if recent['RSI'].iloc[i] < recent['RSI'].iloc[i-1] and recent['RSI'].iloc[i] < recent['RSI'].iloc[i+1]:\n",
        "                rsi_lows.append((i, recent['RSI'].iloc[i]))\n",
        "        if len(price_highs) >= 2 and len(rsi_highs) >= 2:\n",
        "            lp = price_highs[-1]; pp = price_highs[-2]\n",
        "            lr = rsi_highs[-1]; pr = rsi_highs[-2]\n",
        "            if lp[1] > pp[1] and lr[1] < pr[1]:\n",
        "                result['bearish_regular'] += 1\n",
        "                result['type'] = 'é ‚èƒŒé›¢'\n",
        "                result['details'] = {'price_high1': pp[1], 'price_high2': lp[1], 'rsi_high1': pr[1], 'rsi_high2': lr[1]}\n",
        "            if lp[1] < pp[1] and lr[1] > pr[1]:\n",
        "                result['bearish_hidden'] += 1\n",
        "        if len(price_lows) >= 2 and len(rsi_lows) >= 2:\n",
        "            lp = price_lows[-1]; pp = price_lows[-2]\n",
        "            lr = rsi_lows[-1]; pr = rsi_lows[-2]\n",
        "            if lp[1] < pp[1] and lr[1] > pr[1]:\n",
        "                result['bullish_regular'] += 1\n",
        "                result['type'] = 'åº•èƒŒé›¢'\n",
        "                result['details'] = {'price_low1': pp[1], 'price_low2': lp[1], 'rsi_low1': pr[1], 'rsi_low2': lr[1]}\n",
        "            if lp[1] > pp[1] and lr[1] < pr[1]:\n",
        "                result['bullish_hidden'] += 1\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logger.error(f\"èƒŒé›¢æª¢æ¸¬éŒ¯èª¤: {e}\")\n",
        "        return result\n",
        "\n",
        "def check_volume_condition(df, min_volume=1000, weeks=3):\n",
        "    try:\n",
        "        if 'Volume' not in df.columns or df.empty:\n",
        "            return False\n",
        "        if not isinstance(df.index, pd.DatetimeIndex):\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "        if len(df) < weeks * 5:\n",
        "            return False\n",
        "        weekly_volume = df['Volume'].resample('W').mean() / 1000\n",
        "        if len(weekly_volume) < weeks:\n",
        "            return False\n",
        "        is_high_volume = weekly_volume.tail(weeks) > min_volume\n",
        "        return all(is_high_volume)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æª¢æŸ¥æˆäº¤é‡æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return False\n",
        "\n",
        "# ===============================\n",
        "# v2 æŠ€è¡“æŒ‡æ¨™ï¼ˆå®Œæ•´ï¼‰\n",
        "# ===============================\n",
        "def calculate_technical_indicators_v2(df: pd.DataFrame, debug: bool = False):\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    if debug:\n",
        "        print(\"=== DEBUG BEFORE INDICATOR ===\")\n",
        "        print(df.columns.tolist())\n",
        "        print(df.head(3))\n",
        "        print(df.dtypes)\n",
        "        for i, c in enumerate(df.columns):\n",
        "            print(i, repr(c), \"-> stripped:\", repr(str(c).strip()))\n",
        "    try:\n",
        "        df = df.copy()\n",
        "        if not isinstance(df.index, pd.DatetimeIndex):\n",
        "            if 'Date' in df.columns:\n",
        "                try:\n",
        "                    df['Date'] = pd.to_datetime(df['Date'])\n",
        "                    df.set_index('Date', inplace=True)\n",
        "                except:\n",
        "                    pass\n",
        "        cols = []\n",
        "        for c in df.columns:\n",
        "            if isinstance(c, tuple):\n",
        "                parts = [str(x) for x in c if x is not None and str(x) != \"\"]\n",
        "                cols.append(\"_\".join(parts))\n",
        "            else:\n",
        "                cols.append(str(c))\n",
        "        df.columns = cols\n",
        "        def normalize(col: str):\n",
        "            col2 = str(col).strip().replace('\\u3000', ' ')\n",
        "            col2 = re.sub(r'\\s+', '', col2)\n",
        "            return col2.lower()\n",
        "        norm_map = {}\n",
        "        for original in df.columns:\n",
        "            n = normalize(original)\n",
        "            if n not in norm_map:\n",
        "                norm_map[n] = original\n",
        "        if debug:\n",
        "            print(\"== Column Normalization Map ==\")\n",
        "            for k, v in norm_map.items():\n",
        "                print(f\"{k} -> {v}\")\n",
        "        def find_first_by_keywords(keywords):\n",
        "            for kw in keywords:\n",
        "                kw_n = normalize(kw)\n",
        "                if kw_n in norm_map:\n",
        "                    return norm_map[kw_n]\n",
        "            for norm_key, orig in norm_map.items():\n",
        "                if any(kw in norm_key for kw in keywords):\n",
        "                    return orig\n",
        "            return None\n",
        "        col_close = find_first_by_keywords(['close', 'adjclose', 'closeprice', 'price'])\n",
        "        col_high  = find_first_by_keywords(['high', 'max'])\n",
        "        col_low   = find_first_by_keywords(['low', 'min'])\n",
        "        col_open  = find_first_by_keywords(['open'])\n",
        "        col_vol   = find_first_by_keywords(['volume', 'vol'])\n",
        "        missing = [n for n, v in [('Close', col_close), ('High', col_high), ('Low', col_low)] if v is None]\n",
        "        if missing:\n",
        "            if debug:\n",
        "                print(\"åŸå§‹æ¬„ä½åˆ—è¡¨:\", df.columns.tolist())\n",
        "            return None\n",
        "        rename_map = {}\n",
        "        if col_close and col_close != 'Close': rename_map[col_close] = 'Close'\n",
        "        if col_high  and col_high  != 'High':  rename_map[col_high]  = 'High'\n",
        "        if col_low   and col_low   != 'Low':   rename_map[col_low]   = 'Low'\n",
        "        if col_open  and col_open  != 'Open':  rename_map[col_open]  = 'Open'\n",
        "        if col_vol   and col_vol   != 'Volume':rename_map[col_vol]   = 'Volume'\n",
        "        if rename_map:\n",
        "            df.rename(columns=rename_map, inplace=True)\n",
        "        def series_only(frame, col):\n",
        "            s = frame[col]\n",
        "            if isinstance(s, pd.DataFrame):\n",
        "                for sub in s.columns:\n",
        "                    if not s[sub].isna().all():\n",
        "                        return s[sub]\n",
        "                return s.iloc[:, 0]\n",
        "            return s\n",
        "        close = series_only(df, 'Close')\n",
        "        high  = series_only(df, 'High')\n",
        "        low   = series_only(df, 'Low')\n",
        "        volume = series_only(df, 'Volume') if 'Volume' in df.columns else pd.Series(0, index=df.index)\n",
        "        core = pd.concat([close, high, low], axis=1)\n",
        "        df = df.loc[~core.isna().all(axis=1)].copy()\n",
        "        for win in [5, 10, 20, 60, 120]:\n",
        "            df[f\"MA{win}\"] = close.rolling(win, min_periods=1).mean()\n",
        "        ema12 = close.ewm(span=12, adjust=False).mean()\n",
        "        ema26 = close.ewm(span=26, adjust=False).mean()\n",
        "        macd_line = ema12 - ema26\n",
        "        macd_signal = macd_line.ewm(span=9, adjust=False).mean()\n",
        "        df['MACD'] = macd_line\n",
        "        df['MACD_Signal'] = macd_signal\n",
        "        df['MACD_Hist'] = macd_line - macd_signal\n",
        "        delta = close.diff()\n",
        "        gain = delta.clip(lower=0)\n",
        "        loss = (-delta.clip(upper=0)).abs()\n",
        "        avg_gain = gain.rolling(14, min_periods=14).mean()\n",
        "        avg_loss = loss.rolling(14, min_periods=14).mean()\n",
        "        rs = avg_gain / (avg_loss.replace(0, np.nan))\n",
        "        df['RSI'] = 100 - (100 / (1 + rs))\n",
        "        mid = close.rolling(20, min_periods=15).mean()\n",
        "        std = close.rolling(20, min_periods=15).std()\n",
        "        df['BB_Middle'] = mid\n",
        "        df['BB_Upper'] = mid + 2 * std\n",
        "        df['BB_Lower'] = mid - 2 * std\n",
        "        n = 14\n",
        "        ll = low.rolling(n, min_periods=5).min()\n",
        "        hh = high.rolling(n, min_periods=5).max()\n",
        "        rng = (hh - ll).replace(0, np.nan)\n",
        "        k_raw = 100 * (close - ll) / (rng + 1e-9)\n",
        "        df['%K_raw'] = k_raw\n",
        "        df['K'] = k_raw.rolling(3, min_periods=1).mean()\n",
        "        df['D'] = df['K'].rolling(3, min_periods=1).mean()\n",
        "        pc = close.diff()\n",
        "        obv_step = np.where(pc > 0, volume,\n",
        "                            np.where(pc < 0, -volume, 0))\n",
        "        df['OBV'] = pd.Series(obv_step, index=df.index).cumsum()\n",
        "        tr1 = (high - low).abs()\n",
        "        tr2 = (high - close.shift()).abs()\n",
        "        tr3 = (low - close.shift()).abs()\n",
        "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "        df['ATR'] = tr.rolling(14, min_periods=5).mean()\n",
        "        plus_dm_raw = (high - high.shift())\n",
        "        minus_dm_raw = (low.shift() - low)\n",
        "        plus_dm = plus_dm_raw.where((plus_dm_raw > minus_dm_raw) & (plus_dm_raw > 0), 0.0)\n",
        "        minus_dm = minus_dm_raw.where((minus_dm_raw > plus_dm_raw) & (minus_dm_raw > 0), 0.0)\n",
        "        tr_14 = tr.rolling(14, min_periods=5).sum()\n",
        "        plus_di = 100 * (plus_dm.rolling(14, min_periods=5).sum() / (tr_14 + 1e-9))\n",
        "        minus_di = 100 * (minus_dm.rolling(14, min_periods=5).sum() / (tr_14 + 1e-9))\n",
        "        dx = 100 * ((plus_di - minus_di).abs() / (plus_di + minus_di + 1e-9))\n",
        "        df['Plus_DI'] = plus_di\n",
        "        df['Minus_DI'] = minus_di\n",
        "        df['ADX'] = dx.rolling(14, min_periods=5).mean()\n",
        "        tp = (high + low + close) / 3\n",
        "        tp_ma = tp.rolling(20, min_periods=15).mean()\n",
        "        mean_dev = (tp - tp_ma).abs().rolling(20, min_periods=15).mean()\n",
        "        df['CCI'] = (tp - tp_ma) / (0.015 * (mean_dev + 1e-9))\n",
        "        df['ROC'] = (close / close.shift(10) - 1) * 100\n",
        "        typical_price = tp\n",
        "        money_flow = typical_price * volume\n",
        "        pos_mf = money_flow.where(typical_price > typical_price.shift(), 0.0)\n",
        "        neg_mf = money_flow.where(typical_price < typical_price.shift(), 0.0)\n",
        "        pmf_sum = pos_mf.rolling(14, min_periods=5).sum()\n",
        "        nmf_sum = neg_mf.rolling(14, min_periods=5).sum()\n",
        "        mfr = pmf_sum / (nmf_sum + 1e-9)\n",
        "        df['MFI'] = 100 - (100 / (1 + mfr))\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"[calculate_technical_indicators_v2] ä¾‹å¤–: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "# ===============================\n",
        "# èƒŒé›¢åˆ†ææµç¨‹\n",
        "# ===============================\n",
        "async def run_divergence_analysis(\n",
        "        stocks: List[Dict[str, Any]],\n",
        "        min_score=3,\n",
        "        period='1y',\n",
        "        volume_weeks=3,\n",
        "        require_volume=1000,\n",
        "        include_sentiment=True):\n",
        "    results = []\n",
        "    total = len(stocks)\n",
        "    logger.info(f\"èƒŒé›¢åˆ†æé–‹å§‹: å…± {total} æ”¯è‚¡ç¥¨\")\n",
        "    sent_analyzer = MarketSentimentAnalyzer() if include_sentiment else None\n",
        "    for idx, s in enumerate(stocks, 1):\n",
        "        try:\n",
        "            stock_id = s.get('stock_id')\n",
        "            yahoo_symbol = s.get('yahoo_symbol', f\"{stock_id}.TW\")\n",
        "            raw = yf.download(yahoo_symbol, period=period, interval=\"1d\", auto_adjust=True, progress=False)\n",
        "            if raw.empty or len(raw) < 200:\n",
        "                continue\n",
        "            raw.reset_index(inplace=True)\n",
        "            if 'Date' not in raw.columns or 'Close' not in raw.columns:\n",
        "                continue\n",
        "            raw['Date'] = pd.to_datetime(raw['Date'])\n",
        "            raw.set_index('Date', inplace=True)\n",
        "            ind_df = calculate_technical_indicators_v2(raw)\n",
        "            if ind_df is None or ind_df.empty:\n",
        "                continue\n",
        "            div = detect_divergence(ind_df)\n",
        "            bull_score = div['bullish_regular'] + div['bullish_hidden']\n",
        "            bear_score = div['bearish_regular'] + div['bearish_hidden']\n",
        "            if bull_score == 0 and bear_score == 0:\n",
        "                continue\n",
        "            direction = None\n",
        "            final_score = 0\n",
        "            if bull_score > bear_score and bull_score >= min_score:\n",
        "                direction = 'bullish'; final_score = bull_score\n",
        "            elif bear_score > bull_score and bear_score >= min_score:\n",
        "                direction = 'bearish'; final_score = bear_score\n",
        "            else:\n",
        "                continue\n",
        "            if not check_volume_condition(ind_df[['Volume']].copy(), min_volume=require_volume, weeks=volume_weeks):\n",
        "                continue\n",
        "            sentiment_block = {}\n",
        "            if include_sentiment and sent_analyzer:\n",
        "                sentiment_block = sent_analyzer.calculate_sentiment_score(stock_id, s.get('stock_name', ''))\n",
        "            results.append({\n",
        "                'stock_id': stock_id,\n",
        "                'stock_name': s.get('stock_name', ''),\n",
        "                'type': div['type'],\n",
        "                'score': final_score,\n",
        "                'direction': direction,\n",
        "                'close': ind_df['Close'].iloc[-1],\n",
        "                'date': ind_df.index[-1].strftime('%Y-%m-%d'),\n",
        "                'rsi': ind_df['RSI'].iloc[-1] if 'RSI' in ind_df.columns else None,\n",
        "                'volume_condition': True,\n",
        "                'sentiment': sentiment_block,\n",
        "                'data': ind_df\n",
        "            })\n",
        "            logger.info(f\"[{idx}/{total}] {stock_id} èƒŒé›¢ç¬¦åˆ: {direction} åˆ†æ•¸={final_score}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"èƒŒé›¢åˆ†æéŒ¯èª¤ {s}: {e}\")\n",
        "    if results:\n",
        "        results.sort(key=lambda x: x['score'], reverse=True)\n",
        "    return results\n",
        "\n",
        "# ===============================\n",
        "# èƒŒé›¢åœ–è¡¨\n",
        "# ===============================\n",
        "def plot_divergence_chart(entry: Dict[str, Any], save_dir='analysis_charts'):\n",
        "    try:\n",
        "        df = entry.get('data')\n",
        "        if df is None or df.empty:\n",
        "            return None\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        title = f\"{entry['stock_id']} {entry['stock_name']} {entry['type']} åˆ†æ•¸:{entry['score']}\"\n",
        "        ap = []\n",
        "        if 'MA20' in df.columns:\n",
        "            ap.append(mpf.make_addplot(df['MA20'], color='blue', width=1))\n",
        "        if 'MA60' in df.columns:\n",
        "            ap.append(mpf.make_addplot(df['MA60'], color='red', width=1))\n",
        "        if 'RSI' in df.columns:\n",
        "            ap.append(mpf.make_addplot(df['RSI'], panel=1, color='purple', ylabel='RSI'))\n",
        "            ap.append(mpf.make_addplot([70]*len(df), panel=1, color='red', linestyle='--'))\n",
        "            ap.append(mpf.make_addplot([30]*len(df), panel=1, color='green', linestyle='--'))\n",
        "        path = os.path.join(save_dir, f\"{entry['stock_id']}_{datetime.now().strftime('%Y%m%d')}_div.png\")\n",
        "        mpf.plot(df, type='candle', title=title, addplot=ap, volume=True, figsize=(14,8),\n",
        "                 panel_ratios=(6,2), style='yahoo', savefig=path)\n",
        "        return path\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç¹ªè£½èƒŒé›¢åœ–éŒ¯èª¤: {e}\")\n",
        "        return None\n",
        "\n",
        "# ===============================\n",
        "# èƒŒé›¢é€šçŸ¥\n",
        "# ===============================\n",
        "async def notify_divergence_results(entries: List[Dict[str, Any]], limit=10):\n",
        "    if not entries:\n",
        "        await send_notification_text(\"ğŸ“‰ èƒŒé›¢åˆ†æï¼šæ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "        return\n",
        "    text_lines = []\n",
        "    text_lines.append(\"ğŸ” èƒŒé›¢åˆ†æçµæœ\")\n",
        "    text_lines.append(f\"ğŸ•’ {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    text_lines.append(\"=\"*40)\n",
        "    top = entries[:limit]\n",
        "    for i, e in enumerate(top, 1):\n",
        "        sent = e.get('sentiment', {})\n",
        "        fg = sent.get('fear_greed_index', 50)\n",
        "        mood = sent.get('market_mood', '')\n",
        "        text_lines.append(f\"{i}. {e['stock_id']} {e['stock_name']} {e['type']} åˆ†æ•¸:{e['score']} åƒ¹:{e['close']:.2f}\")\n",
        "        if sent:\n",
        "            text_lines.append(f\"   æƒ…ç·’:{sent.get('sentiment_score',50):.1f} F&G:{fg:.1f}({mood}) æ–°è:{sent.get('news_count',0)}\")\n",
        "    await send_notification_text(\"\\n\".join(text_lines))\n",
        "    for e in top:\n",
        "        try:\n",
        "            chart = plot_divergence_chart(e)\n",
        "            if chart:\n",
        "                logger.info(f\"èƒŒé›¢åœ–å·²ç”Ÿæˆ: {chart}\")\n",
        "        except Exception as ex:\n",
        "            logger.error(f\"ç”ŸæˆèƒŒé›¢åœ–å¤±æ•—: {ex}\")\n",
        "\n",
        "# ===============================\n",
        "# ä¸»æµç¨‹\n",
        "# ===============================\n",
        "async def main_all():\n",
        "    logger.info(\"===== ç¶œåˆåˆ†æå•Ÿå‹• (æŠ€è¡“+æƒ…ç·’ + èƒŒé›¢) =====\")\n",
        "    analyzer = StockAnalyzer()\n",
        "    results = await analyzer.analyze_all_stocks(limit=2000)\n",
        "    msg = format_analysis_message(results, limit=10)\n",
        "    print(msg)\n",
        "    await send_notification_text(msg)\n",
        "    if analyzer.taiwan_stocks is None or analyzer.taiwan_stocks.empty:\n",
        "        logger.warning(\"ç„¡æ³•å–å¾—è‚¡ç¥¨æ¸…å–®é€²è¡ŒèƒŒé›¢åˆ†æ\")\n",
        "        return\n",
        "    stocks_list = analyzer.taiwan_stocks.to_dict('records')\n",
        "    divergence_entries = await run_divergence_analysis(\n",
        "        stocks=stocks_list,\n",
        "        min_score=3,\n",
        "        period='1y',\n",
        "        volume_weeks=3,\n",
        "        require_volume=1000,\n",
        "        include_sentiment=True\n",
        "    )\n",
        "    await notify_divergence_results(divergence_entries, limit=10)\n",
        "    logger.info(\"===== ç¶œåˆåˆ†æå®Œæˆ =====\")\n",
        "\n",
        "# ===============================\n",
        "# Debug æ¸¬è©¦ï¼šæŒ‡æ¨™ v2\n",
        "# ===============================\n",
        "def debug_indicator_test(symbol=\"2330.TW\"):\n",
        "    t = yf.download(symbol, period=\"3mo\", interval=\"1d\", auto_adjust=True, progress=False)\n",
        "    if t.empty:\n",
        "        print(\"ä¸‹è¼‰æ¸¬è©¦è³‡æ–™å¤±æ•—\")\n",
        "        return\n",
        "    t.columns = [c + ' ' if c == 'Close' else c for c in t.columns]  # æ¨¡æ“¬ Close æœ‰ç©ºç™½\n",
        "    ind = calculate_technical_indicators_v2(t, debug=True)\n",
        "    if ind is None:\n",
        "        print(\"æŒ‡æ¨™è¨ˆç®—å¤±æ•—ï¼Œè«‹è²¼ debug è¼¸å‡ºã€‚\")\n",
        "        return\n",
        "    cols_show = [c for c in ['Close', 'K', 'D', 'RSI', 'MACD', 'MFI'] if c in ind.columns]\n",
        "    print(ind.tail()[cols_show])\n",
        "\n",
        "# ===============================\n",
        "# åŸ·è¡Œå…¥å£\n",
        "# ===============================\n",
        "if __name__ == \"__main__\":\n",
        "    RUN_MAIN = True\n",
        "    RUN_DEBUG_INDICATOR = False\n",
        "    if RUN_MAIN:\n",
        "        try:\n",
        "            asyncio.run(main_all())\n",
        "        except RuntimeError:\n",
        "            loop = asyncio.get_event_loop()\n",
        "            loop.run_until_complete(main_all())\n",
        "    if RUN_DEBUG_INDICATOR:\n",
        "        debug_indicator_test(\"2330.TW\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUm-I-mRgO7R"
      },
      "outputs": [],
      "source": [
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "class StrongMomentumStockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–å¼·å‹¢è‚¡åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 500,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'price_change_threshold': 5.0,  # åƒ¹æ ¼è®ŠåŒ–é–¾å€¼(%)\n",
        "            'volume_ratio_threshold': 1.5,  # æˆäº¤é‡æ¯”ç‡é–¾å€¼\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.5,\n",
        "                'volume_trend': 0.3,\n",
        "                'technical_score': 0.2\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df.loc[:, 'market'] = market_name\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)].copy()\n",
        "\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨è‚¡ç¥¨æ¸…å–®\")\n",
        "\n",
        "            # å¾åœ–ç‰‡ä¸­è­˜åˆ¥çš„è‚¡ç¥¨åŠ å…¥å‚™ç”¨åˆ—è¡¨\n",
        "            image_stocks = [\n",
        "                {'stock_id': '6134', 'stock_name': 'è¬æ—­', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '6134.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '6133', 'stock_name': 'é‡‘æ©‹', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '6133.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '3163', 'stock_name': 'æ³¢è‹¥å¨', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3163.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '5475', 'stock_name': 'å¾·å®', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '5475.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '3605', 'stock_name': 'å®è‡´', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3605.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '1815', 'stock_name': 'å¯Œé¦™', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1815.TW', 'industry': 'é£Ÿå“'},\n",
        "                {'stock_id': '1802', 'stock_name': 'å°ç»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1802.TW', 'industry': 'ç»ç’ƒ'},\n",
        "                {'stock_id': '3297', 'stock_name': 'æ­ç‰¹', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3297.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '6895', 'stock_name': 'å®ç¢©ç³»çµ±', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '6895.TW', 'industry': 'è³‡è¨Šæœå‹™'},\n",
        "                {'stock_id': '4989', 'stock_name': 'æ¦®ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '4989.TW', 'industry': 'ç”ŸæŠ€é†«ç™‚'},\n",
        "                {'stock_id': '3332', 'stock_name': 'åœ­åº·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3332.TW', 'industry': 'ç”ŸæŠ€é†«ç™‚'},\n",
        "                {'stock_id': '6197', 'stock_name': 'ä½³å¿…çª', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '6197.TW', 'industry': 'é›»å­'},\n",
        "            ]\n",
        "\n",
        "            # æ·»åŠ å…¶ä»–çŸ¥åè‚¡ç¥¨\n",
        "            famous_stocks = [\n",
        "                {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2412', 'stock_name': 'ä¸­è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2412.TW', 'industry': 'é€šä¿¡'},\n",
        "                {'stock_id': '1301', 'stock_name': 'å°å¡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1301.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "            ]\n",
        "\n",
        "            # åˆä½µå…©å€‹åˆ—è¡¨\n",
        "            all_stocks = image_stocks + famous_stocks\n",
        "\n",
        "            df = pd.DataFrame(all_stocks)\n",
        "            logger.info(f\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1mo\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“š\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "                # è¨ˆç®—æˆäº¤é‡æ¯”ç‡ (ç•¶æ—¥æˆäº¤é‡/20æ—¥å¹³å‡)\n",
        "                df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']\n",
        "\n",
        "            # è¨ˆç®—æ—¥æ¼²å¹…\n",
        "            df['Daily_Return'] = df['Close'].pct_change() * 100\n",
        "\n",
        "            # è¨ˆç®—5æ—¥æ¼²å¹…\n",
        "            df['5D_Return'] = df['Close'].pct_change(5) * 100\n",
        "\n",
        "            # è¨ˆç®—10æ—¥æ¼²å¹…\n",
        "            df['10D_Return'] = df['Close'].pct_change(10) * 100\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def check_volume_surge(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡çªå¢\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or 'Volume_Ratio' not in df.columns:\n",
        "                return {'volume_surge': False, 'volume_ratio': 1.0}\n",
        "\n",
        "            # ç²å–æœ€è¿‘ä¸€æ—¥çš„æˆäº¤é‡æ¯”ç‡\n",
        "            latest_volume_ratio = df['Volume_Ratio'].iloc[-1]\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦æœ‰æˆäº¤é‡çªå¢\n",
        "            volume_surge = latest_volume_ratio >= self.config['volume_ratio_threshold']\n",
        "\n",
        "            return {\n",
        "                'volume_surge': volume_surge,\n",
        "                'volume_ratio': latest_volume_ratio\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡çªå¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_surge': False, 'volume_ratio': 1.0}\n",
        "\n",
        "    def check_price_momentum(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æª¢æŸ¥åƒ¹æ ¼å‹•èƒ½\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Daily_Return' not in df.columns:\n",
        "                return {'strong_momentum': False, 'daily_return': 0, '5d_return': 0}\n",
        "\n",
        "            # ç²å–æœ€è¿‘ä¸€æ—¥çš„æ¼²å¹…\n",
        "            daily_return = df['Daily_Return'].iloc[-1]\n",
        "\n",
        "            # ç²å–5æ—¥æ¼²å¹…\n",
        "            five_day_return = df['5D_Return'].iloc[-1] if '5D_Return' in df.columns else 0\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦æœ‰å¼·å‹¢å‹•èƒ½ (æ—¥æ¼²å¹…è¶…éé–¾å€¼)\n",
        "            strong_momentum = daily_return >= self.config['price_change_threshold']\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦æ¥è¿‘æ¼²åœ (å°ç£è‚¡å¸‚æ¼²åœé€šå¸¸ç‚º10%)\n",
        "            near_limit_up = daily_return >= 8.0\n",
        "\n",
        "            return {\n",
        "                'strong_momentum': strong_momentum,\n",
        "                'near_limit_up': near_limit_up,\n",
        "                'daily_return': daily_return,\n",
        "                '5d_return': five_day_return\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥åƒ¹æ ¼å‹•èƒ½æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'strong_momentum': False, 'daily_return': 0, '5d_return': 0}\n",
        "\n",
        "    def check_ma_crossover(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æª¢æŸ¥å‡ç·šäº¤å‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'MA5' not in df.columns or 'MA20' not in df.columns or len(df) < 2:\n",
        "                return {'ma_crossover': False, 'ma_support': False}\n",
        "\n",
        "            # æª¢æŸ¥5æ—¥å‡ç·šæ˜¯å¦ä¸Šç©¿20æ—¥å‡ç·š\n",
        "            prev_ma5 = df['MA5'].iloc[-2]\n",
        "            prev_ma20 = df['MA20'].iloc[-2]\n",
        "            curr_ma5 = df['MA5'].iloc[-1]\n",
        "            curr_ma20 = df['MA20'].iloc[-1]\n",
        "\n",
        "            ma_crossover = (prev_ma5 <= prev_ma20) and (curr_ma5 > curr_ma20)\n",
        "\n",
        "            # æª¢æŸ¥åƒ¹æ ¼æ˜¯å¦ç«™ä¸Šå‡ç·š (åƒ¹æ ¼ > 5æ—¥å‡ç·š > 20æ—¥å‡ç·š)\n",
        "            current_price = df['Close'].iloc[-1]\n",
        "            ma_support = (current_price > curr_ma5) and (curr_ma5 > curr_ma20)\n",
        "\n",
        "            return {\n",
        "                'ma_crossover': ma_crossover,\n",
        "                'ma_support': ma_support,\n",
        "                'price_above_ma5': current_price > curr_ma5,\n",
        "                'price_above_ma20': current_price > curr_ma20\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥å‡ç·šäº¤å‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'ma_crossover': False, 'ma_support': False}\n",
        "\n",
        "    def calculate_strong_momentum_score(self, price_momentum: Dict, volume_surge: Dict, ma_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—å¼·å‹¢å‹•èƒ½åˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # åƒ¹æ ¼å‹•èƒ½åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            price_score = 0\n",
        "            if price_momentum.get('near_limit_up', False):\n",
        "                price_score = 30  # æ¥è¿‘æ¼²åœçµ¦äºˆé«˜åˆ†\n",
        "            elif price_momentum.get('strong_momentum', False):\n",
        "                price_score = 20  # å¼·å‹¢å‹•èƒ½çµ¦äºˆä¸­é«˜åˆ†\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_surge.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 2.5:\n",
        "                volume_score = 20  # çˆ†é‡\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_score = 15  # æ”¾é‡\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 10  # å°å¹…æ”¾é‡\n",
        "\n",
        "            # å‡ç·šåˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            ma_score = 0\n",
        "            if ma_analysis.get('ma_crossover', False):\n",
        "                ma_score = 15  # å‡ç·šäº¤å‰\n",
        "            elif ma_analysis.get('ma_support', False):\n",
        "                ma_score = 10  # å‡ç·šæ”¯æ’\n",
        "            elif ma_analysis.get('price_above_ma5', False):\n",
        "                ma_score = 5   # åƒ¹æ ¼ç«™ä¸Š5æ—¥å‡ç·š\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            weights = self.config['trend_weights']\n",
        "            total_score = base_score + (price_score * weights['price_trend']) + (volume_score * weights['volume_trend']) + (ma_score * weights['technical_score'])\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¼·å‹¢å‹•èƒ½åˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_momentum_label(self, price_momentum: Dict, volume_surge: Dict, ma_analysis: Dict, score: float) -> str:\n",
        "        \"\"\"ç”Ÿæˆå‹•èƒ½æ¨™ç±¤\"\"\"\n",
        "        try:\n",
        "            # æ ¹æ“šå„é …æŒ‡æ¨™ç”Ÿæˆæ¨™ç±¤\n",
        "            labels = []\n",
        "\n",
        "            # åƒ¹æ ¼å‹•èƒ½æ¨™ç±¤\n",
        "            if price_momentum.get('near_limit_up', False):\n",
        "                labels.append(\"æ¼²åœè‚¡\")\n",
        "            elif price_momentum.get('daily_return', 0) >= 7.0:\n",
        "                labels.append(\"å¼·æ¼²è‚¡\")\n",
        "            elif price_momentum.get('strong_momentum', False):\n",
        "                labels.append(\"æ¼²å‹¢è‚¡\")\n",
        "\n",
        "            # æˆäº¤é‡æ¨™ç±¤\n",
        "            if volume_surge.get('volume_ratio', 1.0) > 2.5:\n",
        "                labels.append(\"çˆ†é‡\")\n",
        "            elif volume_surge.get('volume_ratio', 1.0) > 1.5:\n",
        "                labels.append(\"æ”¾é‡\")\n",
        "\n",
        "            # å‡ç·šæ¨™ç±¤\n",
        "            if ma_analysis.get('ma_crossover', False):\n",
        "                labels.append(\"å‡ç·šäº¤å‰\")\n",
        "            elif ma_analysis.get('ma_support', False):\n",
        "                labels.append(\"å‡ç·šå¤šé ­\")\n",
        "\n",
        "            # å¦‚æœæ²’æœ‰ç‰¹å®šæ¨™ç±¤ï¼Œæ ¹æ“šåˆ†æ•¸çµ¦äºˆä¸€èˆ¬æ¨™ç±¤\n",
        "            if not labels:\n",
        "                if score >= 80:\n",
        "                    labels.append(\"å¼·å‹¢è‚¡\")\n",
        "                elif score >= 65:\n",
        "                    labels.append(\"ç†±é–€è‚¡\")\n",
        "                elif score >= 50:\n",
        "                    labels.append(\"æ´»èºè‚¡\")\n",
        "\n",
        "            # è¿”å›æœ€å¤šå…©å€‹æ¨™ç±¤\n",
        "            return \" + \".join(labels[:2]) if labels else \"ä¸€èˆ¬è‚¡\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‹•èƒ½æ¨™ç±¤æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return \"ä¸€èˆ¬è‚¡\"\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "        stock_id = stock_info['stock_id']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol, period=\"1mo\")\n",
        "            if df is None or df.empty or len(df) < 5:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_id': stock_id,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡çªå¢\n",
        "            volume_surge = self.check_volume_surge(df_with_indicators)\n",
        "\n",
        "            # æª¢æŸ¥åƒ¹æ ¼å‹•èƒ½\n",
        "            price_momentum = self.check_price_momentum(df_with_indicators)\n",
        "\n",
        "            # æª¢æŸ¥å‡ç·šäº¤å‰\n",
        "            ma_analysis = self.check_ma_crossover(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—å¼·å‹¢å‹•èƒ½åˆ†æ•¸\n",
        "            momentum_score = self.calculate_strong_momentum_score(price_momentum, volume_surge, ma_analysis)\n",
        "\n",
        "            # ç”Ÿæˆå‹•èƒ½æ¨™ç±¤\n",
        "            momentum_label = self.generate_momentum_label(price_momentum, volume_surge, ma_analysis, momentum_score)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            daily_return = price_momentum.get('daily_return', 0)\n",
        "            five_day_return = price_momentum.get('5d_return', 0)\n",
        "\n",
        "            # ç²å–æˆäº¤é‡è³‡è¨Š (è½‰æ›ç‚ºå¼µæ•¸)\n",
        "            current_volume = float(df['Volume'].iloc[-1]) if 'Volume' in df.columns else 0\n",
        "            volume_lots = current_volume / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_id': stock_id,\n",
        "                'stock_name': stock_name,\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'daily_return': daily_return,\n",
        "                '5d_return': five_day_return,\n",
        "                'volume_lots': volume_lots,\n",
        "                'volume_ratio': volume_surge.get('volume_ratio', 1.0),\n",
        "                'momentum_score': momentum_score,\n",
        "                'momentum_label': momentum_label,\n",
        "                'price_momentum': price_momentum,\n",
        "                'volume_surge': volume_surge,\n",
        "                'ma_analysis': ma_analysis,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {momentum_score:.1f} - æ¨™ç±¤: {momentum_label} - æ—¥æ¼²å¹…: {daily_return:.2f}%\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_id': stock_id,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_momentum_stocks_message(results: Dict[str, Any], limit: int = 15) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–å¼·å‹¢è‚¡åˆ†æçµæœç‚ºè¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰å‹•èƒ½åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('momentum_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        # å…ˆæŒ‰æ—¥æ¼²å¹…æ’åº\n",
        "        successful_results.sort(key=lambda x: x.get('daily_return', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸš€ å°è‚¡å¼·å‹¢è‚¡åˆ†æ\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢è‚¡\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºæ¼²å¹…å‰Nåçš„å¼·å‹¢è‚¡\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ”¥ ä»Šæ—¥å¼·å‹¢è‚¡ TOP {len(top_stocks)}:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            daily_return = result.get('daily_return', 0)\n",
        "            five_day_return = result.get('5d_return', 0)\n",
        "            momentum_score = result.get('momentum_score', 0)\n",
        "            momentum_label = result.get('momentum_label', 'ä¸€èˆ¬è‚¡')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            volume_lots = result.get('volume_lots', 0)\n",
        "            volume_ratio = result.get('volume_ratio', 1.0)\n",
        "\n",
        "            # æ¼²å¹…ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ”´\" if daily_return > 0 else \"ğŸ”µ\" if daily_return < 0 else \"âšª\"\n",
        "\n",
        "            # æˆäº¤é‡ç¬¦è™Ÿ\n",
        "            volume_symbol = \"ğŸ’¥\" if volume_ratio > 2.5 else \"ğŸ“ˆ\" if volume_ratio > 1.5 else \"ğŸ“Š\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {stock_name} ({stock_id}) - {momentum_label}\")\n",
        "            message_parts.append(f\"   {change_symbol} æ¼²å¹…: {daily_return:+.2f}% | 5æ—¥: {five_day_return:+.2f}%\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f} | {volume_symbol} æˆäº¤é‡: {volume_lots:.0f}å¼µ (x{volume_ratio:.1f})\")\n",
        "            message_parts.append(f\"   â­ å‹•èƒ½è©•åˆ†: {momentum_score:.1f}/100\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ æ¼²åœè‚¡çµ±è¨ˆ\n",
        "        limit_up_stocks = [r for r in successful_results if r.get('daily_return', 0) >= 9.5]\n",
        "        strong_up_stocks = [r for r in successful_results if 7.0 <= r.get('daily_return', 0) < 9.5]\n",
        "\n",
        "        message_parts.append(\"ğŸ“Š å¸‚å ´å¼·å‹¢è‚¡çµ±è¨ˆ:\")\n",
        "        message_parts.append(f\"   ğŸ”¥ æ¼²åœè‚¡æ•¸: {len(limit_up_stocks)} æ”¯\")\n",
        "        message_parts.append(f\"   ğŸ“ˆ å¼·æ¼²è‚¡æ•¸ (7-9.5%): {len(strong_up_stocks)} æ”¯\")\n",
        "\n",
        "        # æ·»åŠ ç”¢æ¥­åˆ†å¸ƒ\n",
        "        industry_counts = {}\n",
        "        for result in limit_up_stocks + strong_up_stocks:\n",
        "            industry = result.get('industry', 'å…¶ä»–')\n",
        "            industry_counts[industry] = industry_counts.get(industry, 0) + 1\n",
        "\n",
        "        if industry_counts:\n",
        "            message_parts.append(\"   ğŸ­ å¼·å‹¢ç”¢æ¥­åˆ†å¸ƒ:\")\n",
        "            for industry, count in sorted(industry_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "                message_parts.append(f\"      {industry}: {count} æ”¯\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å¼·å‹¢è‚¡å¸¸æœ‰å¤§å¹…æ³¢å‹•ï¼Œè«‹è¬¹æ…äº¤æ˜“\")\n",
        "        message_parts.append(\"â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 15):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰å‹•èƒ½åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('momentum_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        # å…ˆæŒ‰æ—¥æ¼²å¹…æ’åº\n",
        "        successful_results.sort(key=lambda x: x.get('daily_return', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸš€ å°è‚¡å¼·å‹¢è‚¡åˆ†æçµæœ\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢è‚¡\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'æ¼²å¹…%':<8}{'5æ—¥%':<8}{'åƒ¹æ ¼':<10}{'æˆäº¤é‡(å¼µ)':<12}{'é‡æ¯”':<6}{'å‹•èƒ½è©•åˆ†':<8}{'æ¨™ç±¤':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰Nå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            daily_return = result.get('daily_return', 0)\n",
        "            five_day_return = result.get('5d_return', 0)\n",
        "            momentum_score = result.get('momentum_score', 0)\n",
        "            momentum_label = result.get('momentum_label', 'ä¸€èˆ¬è‚¡')[:10]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            volume_lots = result.get('volume_lots', 0)\n",
        "            volume_ratio = result.get('volume_ratio', 1.0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{daily_return:<+8.2f}{five_day_return:<+8.2f}{current_price:<10.2f}{volume_lots:<12.0f}{volume_ratio:<6.1f}{momentum_score:<8.1f}{momentum_label:<12}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        limit_up_stocks = [r for r in successful_results if r.get('daily_return', 0) >= 9.5]\n",
        "        strong_up_stocks = [r for r in successful_results if 7.0 <= r.get('daily_return', 0) < 9.5]\n",
        "\n",
        "        print(f\"\\nğŸ“Š å¸‚å ´å¼·å‹¢è‚¡çµ±è¨ˆ:\")\n",
        "        print(f\"   ğŸ”¥ æ¼²åœè‚¡æ•¸: {len(limit_up_stocks)} æ”¯\")\n",
        "        print(f\"   ğŸ“ˆ å¼·æ¼²è‚¡æ•¸ (7-9.5%): {len(strong_up_stocks)} æ”¯\")\n",
        "\n",
        "        # ç”¢æ¥­åˆ†å¸ƒ\n",
        "        industry_counts = {}\n",
        "        for result in limit_up_stocks + strong_up_stocks:\n",
        "            industry = result.get('industry', 'å…¶ä»–')\n",
        "            industry_counts[industry] = industry_counts.get(industry, 0) + 1\n",
        "\n",
        "        if industry_counts:\n",
        "            print(\"   ğŸ­ å¼·å‹¢ç”¢æ¥­åˆ†å¸ƒ:\")\n",
        "            for industry, count in sorted(industry_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "                print(f\"      {industry}: {count} æ”¯\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å¼·å‹¢è‚¡å¸¸æœ‰å¤§å¹…æ³¢å‹•ï¼Œè«‹è¬¹æ…äº¤æ˜“\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "    if not files:\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        if os.path.exists(chart_dir):\n",
        "            # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "            files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                    if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            if files:\n",
        "                logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "            else:\n",
        "                logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                if response.status == 200:\n",
        "                    logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                else:\n",
        "                    response_text = await response.text()\n",
        "                    logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                sent_count = 0\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            data = aiohttp.FormData()\n",
        "                            data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                            # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                            caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                            data.add_field('caption', caption)\n",
        "\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                    if response.status == 200:\n",
        "                                        sent_count += 1\n",
        "                                    else:\n",
        "                                        response_text = await response.text()\n",
        "                                        logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                            # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                            await asyncio.sleep(0.5)\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "        message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "        for chunk in message_chunks:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response and response.ok:\n",
        "                logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                content = response.content if response else \"æœªçŸ¥\"\n",
        "                logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "        # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "        if files:\n",
        "            batch_size = 10\n",
        "            for i in range(0, len(files), batch_size):\n",
        "                batch_files = files[i:i+batch_size]\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                for file_path in batch_files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        # ç²å–åœ–è¡¨æª”æ¡ˆæ•¸é‡\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        chart_count = 0\n",
        "        if os.path.exists(chart_dir):\n",
        "            chart_files = [f for f in os.listdir(chart_dir) if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            chart_count = len(chart_files)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ“Š ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ“ˆ TOP {min(5, len(filtered_results))} æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            # ç²å–æ›´å¤šæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\n",
        "            macd = tech.get('macd_value', 0)\n",
        "            signal = tech.get('signal_value', 0)\n",
        "            macd_status = \"å¤šé ­\" if macd > signal else \"ç©ºé ­\" if macd < signal else \"ä¸­æ€§\"\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_status', 'ä¸­æ€§')})\n",
        "   ğŸ“‰ MACD: {macd_status}\n",
        "\"\"\"\n",
        "\n",
        "        # æ·»åŠ åœ–è¡¨è³‡è¨Š\n",
        "        if chart_count > 0:\n",
        "            message += f\"\"\"\n",
        "ğŸ“Š è©³ç´°åˆ†æåœ–è¡¨:\n",
        "â€¢ å·²ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "â€¢ åœ–è¡¨åŒ…å«Kç·šã€å‡ç·šã€æˆäº¤é‡ã€MACDåŠRSIæŒ‡æ¨™\n",
        "â€¢ åœ–è¡¨å°‡åœ¨æ­¤è¨Šæ¯å¾Œç™¼é€\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ å°è‚¡å¼·å‹¢è‚¡åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†æç›®æ¨™: å°‹æ‰¾å¸‚å ´å¼·å‹¢è‚¡\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StrongMomentumStockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=15)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_momentum_stocks_message(results, limit=15)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆ\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCbUcnP8rm87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ar0GtM0XrsGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLyj04YtrwNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aGW55prbShh"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "# è™•ç†ä¸­æ–‡å­—é«”å’Œè­¦å‘Š\n",
        "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Jupyter Notebook æ”¯æ´\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "# é€šçŸ¥è¨­å®š (è«‹æ ¹æ“šéœ€è¦ä¿®æ”¹)\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]  # æ”¯æ´å¤šç”¨æˆ¶é€šçŸ¥\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "# å˜—è©¦å°å…¥é€šçŸ¥ç›¸é—œæ¨¡çµ„\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'screen_conditions': {\n",
        "                'min_price_change': 5.0,      # æœ€å°æ¼²å¹…5%\n",
        "                'min_volume_lots': 5000,      # æœ€å°æˆäº¤é‡5000å¼µ\n",
        "                'max_volume_ratio': 3.0,      # æœ€å¤§æˆäº¤é‡æ¯”ç‡3å€\n",
        "                'macd_diff_min': 0.0,         # MACDå·®å€¼æœ€å°å€¼\n",
        "                'macd_diff_max': 1.5,         # MACDå·®å€¼æœ€å¤§å€¼\n",
        "            },\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df.loc[:, 'market'] = market_name\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)].copy()\n",
        "\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨è‚¡ç¥¨æ¸…å–®\")\n",
        "            famous_stocks = [\n",
        "                {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2412', 'stock_name': 'ä¸­è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2412.TW', 'industry': 'é€šä¿¡'},\n",
        "                {'stock_id': '1301', 'stock_name': 'å°å¡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1301.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '1303', 'stock_name': 'å—äº', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1303.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '2308', 'stock_name': 'å°é”é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2308.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2002', 'stock_name': 'ä¸­é‹¼', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2002.TW', 'industry': 'é‹¼éµ'},\n",
        "                {'stock_id': '2886', 'stock_name': 'å…†è±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2886.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2891.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '3008', 'stock_name': 'å¤§ç«‹å…‰', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3008.TW', 'industry': 'å…‰å­¸'},\n",
        "                {'stock_id': '2357', 'stock_name': 'è¯ç¢©', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2357.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2382', 'stock_name': 'å»£é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2382.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2395', 'stock_name': 'ç ”è¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2395.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '3711', 'stock_name': 'æ—¥æœˆå…‰æŠ•æ§', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3711.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2409', 'stock_name': 'å‹é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2409.TW', 'industry': 'é¢æ¿'},\n",
        "                {'stock_id': '2884', 'stock_name': 'ç‰å±±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2884.TW', 'industry': 'é‡‘è'},\n",
        "            ]\n",
        "            df = pd.DataFrame(famous_stocks)\n",
        "            logger.info(f\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "            volume_lots = recent_volume / 1000\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "            return meets_volume\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # åŸºç¤æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å‡½æ•¸\n",
        "    def calculate_sma(self, data, period):\n",
        "        \"\"\"è¨ˆç®—SMA (ç°¡å–®ç§»å‹•å¹³å‡ç·š)\"\"\"\n",
        "        return data.rolling(window=period).mean()\n",
        "\n",
        "    def calculate_ema(self, data, period):\n",
        "        \"\"\"è¨ˆç®—EMA (æŒ‡æ•¸ç§»å‹•å¹³å‡ç·š)\"\"\"\n",
        "        return data.ewm(span=period, adjust=False).mean()\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = None) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            if period is None:\n",
        "                period = self.config['rsi_period']\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = None, slow: int = None, signal: int = None):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            if fast is None:\n",
        "                fast = self.config['macd_fast']\n",
        "            if slow is None:\n",
        "                slow = self.config['macd_slow']\n",
        "            if signal is None:\n",
        "                signal = self.config['macd_signal']\n",
        "\n",
        "            ema_fast = self.calculate_ema(prices, fast)\n",
        "            ema_slow = self.calculate_ema(prices, slow)\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = self.calculate_ema(macd_line, signal)\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_stoch(self, high, low, close, k_period=None, d_period=3):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if k_period is None:\n",
        "                k_period = self.config['kd_period']\n",
        "\n",
        "            # è¨ˆç®—%K\n",
        "            lowest_low = low.rolling(window=k_period).min()\n",
        "            highest_high = high.rolling(window=k_period).max()\n",
        "\n",
        "            # é˜²æ­¢é™¤ä»¥é›¶\n",
        "            denom = highest_high - lowest_low\n",
        "            denom = denom.replace(0, 0.000001)\n",
        "\n",
        "            k = 100 * ((close - lowest_low) / denom)\n",
        "            # è¨ˆç®—%D (Kçš„ç§»å‹•å¹³å‡)\n",
        "            d = k.rolling(window=d_period).mean()\n",
        "            return k, d\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = None, std_dev: int = None):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            if period is None:\n",
        "                period = self.config['bb_period']\n",
        "            if std_dev is None:\n",
        "                std_dev = self.config['bb_std']\n",
        "\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_indicators(self, data):\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ï¼ˆæ•´åˆç‰ˆï¼‰\"\"\"\n",
        "        if data is None or len(data) < 30:\n",
        "            return None\n",
        "\n",
        "        # è¤‡è£½æ•¸æ“šä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š\n",
        "        df = data.copy()\n",
        "\n",
        "        try:\n",
        "            # è¨ˆç®—MACD\n",
        "            df['MACD'], df['MACD_Signal'], df['MACD_Hist'] = self.calculate_macd(df['Close'])\n",
        "\n",
        "            # è¨ˆç®—å‡ç·š\n",
        "            df['MA5'] = self.calculate_sma(df['Close'], 5)\n",
        "            df['MA10'] = self.calculate_sma(df['Close'], 10)\n",
        "            df['MA20'] = self.calculate_sma(df['Close'], 20)\n",
        "            df['MA30'] = self.calculate_sma(df['Close'], 30)\n",
        "\n",
        "            # è¨ˆç®—RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'])\n",
        "\n",
        "            # è¨ˆç®—KD\n",
        "            df['K'], df['D'] = self.calculate_stoch(df['High'], df['Low'], df['Close'])\n",
        "            df['K_Percent'] = df['K']  # ä¿æŒä¸€è‡´æ€§\n",
        "            df['D_Percent'] = df['D']  # ä¿æŒä¸€è‡´æ€§\n",
        "\n",
        "            # è¨ˆç®—å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(df['Close'])\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # è¨ˆç®—æ¼²å¹…\n",
        "            df['Change'] = df['Close'].pct_change() * 100\n",
        "\n",
        "            # è¨ˆç®—æˆäº¤é‡å‡ç·š\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "                df['Volume_MA30'] = self.calculate_sma(df['Volume'], 30)\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ï¼ˆèˆ‡calculate_indicatorsä¿æŒä¸€è‡´ï¼‰\"\"\"\n",
        "        return self.calculate_indicators(df)\n",
        "\n",
        "    def perform_quadrant_analysis(self, data):\n",
        "        \"\"\"å››è±¡é™åˆ†æ\"\"\"\n",
        "        if data is None or len(data) < 30:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # ç²å–æœ€æ–°æ•¸æ“š\n",
        "            latest = data.iloc[-1]\n",
        "\n",
        "            # å››è±¡é™åˆ¤æ–·\n",
        "            macd_above_signal = latest['MACD'] > latest['MACD_Signal']\n",
        "            macd_rising = data['MACD'].iloc[-1] > data['MACD'].iloc[-2] if len(data) >= 2 else False\n",
        "\n",
        "            rsi_above_50 = latest['RSI'] > 50\n",
        "            rsi_rising = data['RSI'].iloc[-1] > data['RSI'].iloc[-2] if len(data) >= 2 else False\n",
        "\n",
        "            # åˆ¤æ–·è±¡é™\n",
        "            if macd_above_signal and rsi_above_50:\n",
        "                quadrant = 1  # å¼·å‹¢å¤šé ­\n",
        "            elif not macd_above_signal and rsi_above_50:\n",
        "                quadrant = 2  # å¤šé ­è­¦æˆ’\n",
        "            elif not macd_above_signal and not rsi_above_50:\n",
        "                quadrant = 3  # å¼·å‹¢ç©ºé ­\n",
        "            else:  # macd_above_signal and not rsi_above_50\n",
        "                quadrant = 4  # ç©ºé ­åè½‰\n",
        "\n",
        "            # è¶¨å‹¢æ–¹å‘\n",
        "            if macd_rising and rsi_rising:\n",
        "                trend = \"ä¸Šå‡\"\n",
        "            elif not macd_rising and not rsi_rising:\n",
        "                trend = \"ä¸‹é™\"\n",
        "            else:\n",
        "                trend = \"ç›¤æ•´\"\n",
        "\n",
        "            # è¿”å›åˆ†æçµæœ\n",
        "            return {\n",
        "                'quadrant': quadrant,\n",
        "                'trend': trend,\n",
        "                'macd_above_signal': macd_above_signal,\n",
        "                'macd_rising': macd_rising,\n",
        "                'rsi_above_50': rsi_above_50,\n",
        "                'rsi_rising': rsi_rising,\n",
        "                'macd': latest['MACD'],\n",
        "                'macd_signal': latest['MACD_Signal'],\n",
        "                'macd_hist': latest['MACD_Hist'],\n",
        "                'rsi': latest['RSI'],\n",
        "                'k': latest['K'],\n",
        "                'd': latest['D']\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å››è±¡é™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_resample_frequency(self, freq_type: str) -> str:\n",
        "        \"\"\"ç²å–é©ç•¶çš„é‡æ¡æ¨£é »ç‡å­—ç¬¦ä¸²\"\"\"\n",
        "        try:\n",
        "            import pandas as pd\n",
        "\n",
        "            # æª¢æŸ¥ pandas ç‰ˆæœ¬\n",
        "            pd_version = pd.__version__\n",
        "            major_version = int(pd_version.split('.')[0])\n",
        "            minor_version = int(pd_version.split('.')[1])\n",
        "\n",
        "            # pandas 2.2.0+ ä½¿ç”¨æ–°çš„é »ç‡å­—ç¬¦ä¸²\n",
        "            if major_version > 2 or (major_version == 2 and minor_version >= 2):\n",
        "                freq_mapping = {\n",
        "                    'M': 'ME',  # Month End\n",
        "                    'Q': 'QE',  # Quarter End\n",
        "                    'Y': 'YE',  # Year End\n",
        "                    'W': 'W',   # Week (unchanged)\n",
        "                    'D': 'D',   # Day (unchanged)\n",
        "                }\n",
        "                return freq_mapping.get(freq_type, freq_type)\n",
        "            else:\n",
        "                return freq_type\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"æª¢æŸ¥ pandas ç‰ˆæœ¬æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return freq_type\n",
        "\n",
        "    def perform_multi_timeframe_analysis(self, stock_id, start_date=None, end_date=None):\n",
        "        \"\"\"å¤šæ™‚é–“é€±æœŸåˆ†æï¼ˆä¿®æ­£ç‰ˆï¼‰\"\"\"\n",
        "        try:\n",
        "            if start_date is None:\n",
        "                start_date = (datetime.now() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "            if end_date is None:\n",
        "                end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            # ç²å–è¼ƒé•·æ™‚é–“çš„æ•¸æ“šä»¥ä¾¿é‡æ¡æ¨£\n",
        "            extended_start = (datetime.strptime(start_date, \"%Y-%m-%d\") - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            # å¦‚æœæ˜¯yahoo symbolæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦å‰‡è½‰æ›\n",
        "            if not stock_id.endswith(('.TW', '.TWO')):\n",
        "                yahoo_symbol = f\"{stock_id}.TW\"\n",
        "            else:\n",
        "                yahoo_symbol = stock_id\n",
        "\n",
        "            data = self.fetch_yfinance_data(yahoo_symbol, period=\"2y\")\n",
        "\n",
        "            if data is None or data.empty:\n",
        "                return None\n",
        "\n",
        "            # è¨­å®šæ—¥æœŸç‚ºç´¢å¼•\n",
        "            if 'Date' in data.columns:\n",
        "                data.set_index('Date', inplace=True)\n",
        "            elif data.index.name != 'Date':\n",
        "                data.index = pd.to_datetime(data.index)\n",
        "\n",
        "            # ä¸åŒæ™‚é–“é€±æœŸçš„æ•¸æ“š\n",
        "            daily_data = self.calculate_indicators(data)\n",
        "\n",
        "            # é€±ç·šæ•¸æ“š\n",
        "            try:\n",
        "                weekly_freq = self.get_resample_frequency('W')\n",
        "                weekly_data = data.resample(weekly_freq).agg({\n",
        "                    'Open': 'first',\n",
        "                    'High': 'max',\n",
        "                    'Low': 'min',\n",
        "                    'Close': 'last',\n",
        "                    'Volume': 'sum'\n",
        "                }).dropna()\n",
        "                weekly_data = self.calculate_indicators(weekly_data)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"é€±ç·šæ•¸æ“šé‡æ¡æ¨£å¤±æ•—: {e}\")\n",
        "                weekly_data = None\n",
        "\n",
        "            # æœˆç·šæ•¸æ“š\n",
        "            try:\n",
        "                monthly_freq = self.get_resample_frequency('M')\n",
        "\n",
        "                # ä½¿ç”¨è­¦å‘ŠæŠ‘åˆ¶ä¾†è™•ç†èˆŠç‰ˆæœ¬çš„æ£„ç”¨è­¦å‘Š\n",
        "                import warnings\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*'M' is deprecated.*\")\n",
        "\n",
        "                    monthly_data = data.resample(monthly_freq).agg({\n",
        "                        'Open': 'first',\n",
        "                        'High': 'max',\n",
        "                        'Low': 'min',\n",
        "                        'Close': 'last',\n",
        "                        'Volume': 'sum'\n",
        "                    }).dropna()\n",
        "\n",
        "                monthly_data = self.calculate_indicators(monthly_data)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"æœˆç·šæ•¸æ“šé‡æ¡æ¨£å¤±æ•—: {e}\")\n",
        "                monthly_data = None\n",
        "\n",
        "            # é€²è¡Œå››è±¡é™åˆ†æ\n",
        "            daily_analysis = self.perform_quadrant_analysis(daily_data) if daily_data is not None else None\n",
        "            weekly_analysis = self.perform_quadrant_analysis(weekly_data) if weekly_data is not None else None\n",
        "            monthly_analysis = self.perform_quadrant_analysis(monthly_data) if monthly_data is not None else None\n",
        "\n",
        "            result = {\n",
        "                'daily': {\n",
        "                    'data': daily_data,\n",
        "                    'analysis': daily_analysis\n",
        "                }\n",
        "            }\n",
        "\n",
        "            if weekly_data is not None:\n",
        "                result['weekly'] = {\n",
        "                    'data': weekly_data,\n",
        "                    'analysis': weekly_analysis\n",
        "                }\n",
        "\n",
        "            if monthly_data is not None:\n",
        "                result['monthly'] = {\n",
        "                    'data': monthly_data,\n",
        "                    'analysis': monthly_analysis\n",
        "                }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å¤šæ™‚é–“é€±æœŸåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_multi_timeframe_summary(self, results, stock_id):\n",
        "        \"\"\"ç”Ÿæˆå¤šæ™‚é–“é€±æœŸåˆ†æå ±å‘Š\"\"\"\n",
        "        if not results:\n",
        "            print(\"ç„¡åˆ†æçµæœå¯é¡¯ç¤º\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(f\"è‚¡ç¥¨ä»£ç¢¼: {stock_id} å¤šæ™‚é–“é€±æœŸå››è±¡é™åˆ†æçµæœ\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        timeframes = {\n",
        "            'daily': 'æ—¥ç·š',\n",
        "            'weekly': 'é€±ç·š',\n",
        "            'monthly': 'æœˆç·š'\n",
        "        }\n",
        "\n",
        "        quadrant_names = {\n",
        "            1: \"å¼·å‹¢å¤šé ­ (ç¬¬ä¸€è±¡é™)\",\n",
        "            2: \"å¤šé ­è­¦æˆ’ (ç¬¬äºŒè±¡é™)\",\n",
        "            3: \"å¼·å‹¢ç©ºé ­ (ç¬¬ä¸‰è±¡é™)\",\n",
        "            4: \"ç©ºé ­åè½‰ (ç¬¬å››è±¡é™)\"\n",
        "        }\n",
        "\n",
        "        for tf, tf_name in timeframes.items():\n",
        "            if tf in results and results[tf]['analysis']:\n",
        "                analysis = results[tf]['analysis']\n",
        "                data = results[tf]['data']\n",
        "                latest = data.iloc[-1]\n",
        "\n",
        "                print(f\"\\nã€{tf_name}åˆ†æã€‘\")\n",
        "                print(f\"è±¡é™: {quadrant_names[analysis['quadrant']]}\")\n",
        "                print(f\"è¶¨å‹¢: {analysis['trend']}\")\n",
        "                print(f\"MACD: {analysis['macd']:.4f}, è¨Šè™Ÿç·š: {analysis['macd_signal']:.4f}, æŸ±ç‹€: {analysis['macd_hist']:.4f}\")\n",
        "                print(f\"RSI: {analysis['rsi']:.2f}\")\n",
        "                print(f\"KDæŒ‡æ¨™: K={analysis['k']:.2f}, D={analysis['d']:.2f}\")\n",
        "                print(f\"æ”¶ç›¤åƒ¹: {latest['Close']:.2f}, 10æ—¥å‡ç·š: {latest['MA10']:.2f}, 30æ—¥å‡ç·š: {latest['MA30']:.2f}\")\n",
        "\n",
        "                # é¡¯ç¤ºç›¸å°ä½ç½®\n",
        "                print(\"æŠ€è¡“æŒ‡æ¨™ç›¸å°ä½ç½®:\")\n",
        "                if latest['Close'] > latest['MA10']:\n",
        "                    print(\"- åƒ¹æ ¼ä½æ–¼10æ—¥å‡ç·šä¹‹ä¸Š\")\n",
        "                else:\n",
        "                    print(\"- åƒ¹æ ¼ä½æ–¼10æ—¥å‡ç·šä¹‹ä¸‹\")\n",
        "\n",
        "                if latest['Close'] > latest['MA30']:\n",
        "                    print(\"- åƒ¹æ ¼ä½æ–¼30æ—¥å‡ç·šä¹‹ä¸Š\")\n",
        "                else:\n",
        "                    print(\"- åƒ¹æ ¼ä½æ–¼30æ—¥å‡ç·šä¹‹ä¸‹\")\n",
        "\n",
        "                if analysis['macd'] > analysis['macd_signal']:\n",
        "                    print(\"- MACDä½æ–¼è¨Šè™Ÿç·šä¹‹ä¸Š (å¤šé ­)\")\n",
        "                else:\n",
        "                    print(\"- MACDä½æ–¼è¨Šè™Ÿç·šä¹‹ä¸‹ (ç©ºé ­)\")\n",
        "\n",
        "                if analysis['k'] > analysis['d']:\n",
        "                    print(\"- Kç·šä½æ–¼Dç·šä¹‹ä¸Š (å¤šé ­)\")\n",
        "                else:\n",
        "                    print(\"- Kç·šä½æ–¼Dç·šä¹‹ä¸‹ (ç©ºé ­)\")\n",
        "\n",
        "                print(f\"\\nã€{tf_name}åˆ†æã€‘: æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•åˆ†æ\")\n",
        "\n",
        "        # ç¶œåˆå»ºè­°\n",
        "        print(\"\\nã€ç¶œåˆåˆ†æã€‘\")\n",
        "\n",
        "        # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰æ™‚é–“é€±æœŸéƒ½æœ‰åˆ†æçµæœ\n",
        "        if all(tf in results and results[tf]['analysis'] for tf in timeframes):\n",
        "            daily_q = results['daily']['analysis']['quadrant']\n",
        "            weekly_q = results['weekly']['analysis']['quadrant']\n",
        "            monthly_q = results['monthly']['analysis']['quadrant']\n",
        "\n",
        "            # å¤šé ­æ’åˆ—\n",
        "            if monthly_q in [1, 4] and weekly_q in [1, 4] and daily_q in [1, 4]:\n",
        "                print(\"å¤šé ­æ’åˆ—: æœˆç·šã€é€±ç·šå’Œæ—¥ç·šå‡å‘ˆç¾å¤šé ­è¶¨å‹¢ï¼Œå¯è€ƒæ…®é€¢ä½è²·å…¥\")\n",
        "            # ç©ºé ­æ’åˆ—\n",
        "            elif monthly_q in [2, 3] and weekly_q in [2, 3] and daily_q in [2, 3]:\n",
        "                print(\"ç©ºé ­æ’åˆ—: æœˆç·šã€é€±ç·šå’Œæ—¥ç·šå‡å‘ˆç¾ç©ºé ­è¶¨å‹¢ï¼Œå»ºè­°è§€æœ›æˆ–æ¸›å€‰\")\n",
        "            # å¤šç©ºè½‰æ›\n",
        "            else:\n",
        "                if daily_q in [1, 4] and (weekly_q in [2, 3] or monthly_q in [2, 3]):\n",
        "                    print(\"çŸ­ç·šåå½ˆ: æ—¥ç·šå‘ˆç¾å¤šé ­ï¼Œä½†ä¸­é•·æœŸä»åœ¨ç©ºé ­ï¼Œå¯èƒ½æ˜¯åå½ˆè¡Œæƒ…\")\n",
        "                elif daily_q in [2, 3] and (weekly_q in [1, 4] or monthly_q in [1, 4]):\n",
        "                    print(\"çŸ­ç·šå›èª¿: æ—¥ç·šå‘ˆç¾ç©ºé ­ï¼Œä½†ä¸­é•·æœŸä»åœ¨å¤šé ­ï¼Œå¯èƒ½æ˜¯å›èª¿è¡Œæƒ…\")\n",
        "                else:\n",
        "                    print(\"å¤šç©ºäº¤éŒ¯: å„æ™‚é–“é€±æœŸèµ°å‹¢ä¸ä¸€è‡´ï¼Œå»ºè­°è§€æœ›æˆ–ä¾ä¸»è¦æ™‚é–“é€±æœŸæ“ä½œ\")\n",
        "        else:\n",
        "            print(\"éƒ¨åˆ†æ™‚é–“é€±æœŸæ•¸æ“šä¸è¶³ï¼Œç„¡æ³•æä¾›å®Œæ•´ç¶œåˆåˆ†æ\")\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    def screen_stocks(self, start_date=None, end_date=None) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        è‚¡ç¥¨ç¯©é¸åŠŸèƒ½\n",
        "        ç¯©é¸æ¢ä»¶ï¼š\n",
        "        1. æŠ€è¡“é¢\n",
        "           - MACD: 0 < D-M < 1.5\n",
        "           - æœ¬æ—¥æ”¶ç›¤åƒ¹é«˜æ–¼10æ—¥å‡åƒ¹ä¸”é«˜æ–¼30æ—¥å‡åƒ¹\n",
        "           - æœ¬æ—¥è‚¡åƒ¹æ¼²å¹…5%ä»¥ä¸Š\n",
        "        2. ç±Œç¢¼é¢\n",
        "           - æœ¬æ—¥æˆäº¤é‡5000å¼µä»¥ä¸Šä½†ä¸è¶…é30æ—¥å‡é‡çš„3å€\n",
        "           - ç”±ç¬¦åˆç¯©é¸æ¢ä»¶ä¸­å–æˆäº¤é‡å‰ä¸‰å¤§ç‚ºæ¨™çš„\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"é–‹å§‹è‚¡ç¥¨ç¯©é¸...\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if start_date is None:\n",
        "            start_date = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
        "        if end_date is None:\n",
        "            end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        # å»¶é•·é–‹å§‹æ—¥æœŸä»¥ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“šè¨ˆç®—æŒ‡æ¨™\n",
        "        extended_start = (datetime.strptime(start_date, \"%Y-%m-%d\") - timedelta(days=60)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        # ç²å–è‚¡ç¥¨æ¸…å–®\n",
        "        if self.taiwan_stocks is None:\n",
        "            self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "        if self.taiwan_stocks.empty:\n",
        "            print(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "            return []\n",
        "\n",
        "        results = []\n",
        "        stock_list = [(row['stock_id'], row['stock_name'], row['yahoo_symbol']) for _, row in self.taiwan_stocks.iterrows()]\n",
        "\n",
        "        # éæ­·è‚¡ç¥¨åˆ—è¡¨\n",
        "        for i, (stock_id, stock_name, yahoo_symbol) in enumerate(stock_list):\n",
        "            print(f\"è™•ç† {i+1}/{len(stock_list)}: {stock_id} - {stock_name}\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            data = self.fetch_yfinance_data(yahoo_symbol, period=\"3mo\")\n",
        "            if data is None or len(data) < 30:\n",
        "                continue\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df = self.calculate_indicators(data)\n",
        "            if df is None:\n",
        "                continue\n",
        "\n",
        "            # ç²å–æœ€æ–°ä¸€å¤©çš„æ•¸æ“š\n",
        "            latest = df.iloc[-1]\n",
        "\n",
        "            try:\n",
        "                # ç¯©é¸æ¢ä»¶æª¢æŸ¥\n",
        "                # 1. MACD: 0 < D-M < 1.5\n",
        "                macd_diff = latest['MACD_Signal'] - latest['MACD']\n",
        "                macd_condition = (self.config['screen_conditions']['macd_diff_min'] <\n",
        "                                macd_diff < self.config['screen_conditions']['macd_diff_max'])\n",
        "\n",
        "                # 2. æœ¬æ—¥æ”¶ç›¤åƒ¹é«˜æ–¼10æ—¥å‡åƒ¹ä¸”é«˜æ–¼30æ—¥å‡åƒ¹\n",
        "                price_above_ma = (latest['Close'] > latest['MA10']) and (latest['Close'] > latest['MA30'])\n",
        "\n",
        "                # 3. æœ¬æ—¥è‚¡åƒ¹æ¼²å¹…5%ä»¥ä¸Š\n",
        "                price_change = latest['Change']\n",
        "                price_change_condition = price_change >= self.config['screen_conditions']['min_price_change']\n",
        "\n",
        "                # 4. æœ¬æ—¥æˆäº¤é‡5000å¼µä»¥ä¸Šä½†ä¸è¶…é30æ—¥å‡é‡çš„3å€\n",
        "                # å°è‚¡ä¸€å¼µæ˜¯1000è‚¡ï¼Œæ‰€ä»¥5000å¼µæ˜¯5,000,000è‚¡\n",
        "                min_volume = self.config['screen_conditions']['min_volume_lots'] * 1000\n",
        "                max_volume_ratio = self.config['screen_conditions']['max_volume_ratio']\n",
        "                volume_condition = (latest['Volume'] >= min_volume and\n",
        "                                  latest['Volume'] <= latest['Volume_MA30'] * max_volume_ratio)\n",
        "\n",
        "                # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæ‰€æœ‰æ¢ä»¶\n",
        "                if macd_condition and price_above_ma and price_change_condition and volume_condition:\n",
        "                    # é€²è¡Œå››è±¡é™åˆ†æ\n",
        "                    quadrant_analysis = self.perform_quadrant_analysis(df)\n",
        "\n",
        "                    results.append({\n",
        "                        'stock_id': stock_id,\n",
        "                        'stock_name': stock_name,\n",
        "                        'yahoo_symbol': yahoo_symbol,\n",
        "                        'close': latest['Close'],\n",
        "                        'change': price_change,\n",
        "                        'volume': latest['Volume'],\n",
        "                        'volume_lots': latest['Volume'] / 1000,\n",
        "                        'macd_diff': macd_diff,\n",
        "                        'quadrant_analysis': quadrant_analysis,\n",
        "                        'data': df\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ç¯©é¸ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                continue\n",
        "\n",
        "        # æŒ‰æˆäº¤é‡æ’åº\n",
        "        if results:\n",
        "            results.sort(key=lambda x: x['volume'], reverse=True)\n",
        "\n",
        "            # å–å‰ä¸‰å¤§æˆäº¤é‡\n",
        "            top_results = results[:min(3, len(results))]\n",
        "\n",
        "            print(\"\\n\" + \"=\" * 80)\n",
        "            print(f\"ç¯©é¸çµæœ: ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨æœ‰ {len(results)} æª”ï¼Œå–æˆäº¤é‡å‰ {len(top_results)} å¤§\")\n",
        "            print(\"=\" * 80)\n",
        "\n",
        "            for i, result in enumerate(top_results):\n",
        "                print(f\"\\næ’å {i+1}: {result['stock_id']} - {result['stock_name']}\")\n",
        "                print(f\"æ”¶ç›¤åƒ¹: {result['close']:.2f}, æ¼²å¹…: {result['change']:.2f}%\")\n",
        "                print(f\"æˆäº¤é‡: {result['volume']:,.0f} è‚¡ (ç´„ {result['volume_lots']:.0f} å¼µ)\")\n",
        "                print(f\"MACDå·®å€¼ (D-M): {result['macd_diff']:.4f}\")\n",
        "\n",
        "                # å››è±¡é™åˆ†æ\n",
        "                if result['quadrant_analysis']:\n",
        "                    analysis = result['quadrant_analysis']\n",
        "                    print(f\"å››è±¡é™åˆ†æ: ç¬¬ {analysis['quadrant']} è±¡é™ ({analysis['trend']}è¶¨å‹¢)\")\n",
        "\n",
        "            return top_results\n",
        "        else:\n",
        "            print(\"\\næ²’æœ‰ç¬¦åˆç¯©é¸æ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "            return []\n",
        "\n",
        "    def create_stock_chart(self, stock_data: Dict[str, Any], save_path: str = None) -> str:\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨æŠ€è¡“åˆ†æåœ–è¡¨\"\"\"\n",
        "        try:\n",
        "            df = stock_data.get('data')\n",
        "            if df is None or df.empty:\n",
        "                return None\n",
        "\n",
        "            stock_name = stock_data.get('stock_name', 'Unknown')\n",
        "            stock_id = stock_data.get('stock_id', 'Unknown')\n",
        "\n",
        "            # å‰µå»ºåœ–è¡¨\n",
        "            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "            fig.suptitle(f'{stock_name} ({stock_id}) æŠ€è¡“åˆ†æåœ–è¡¨', fontsize=16, fontweight='bold')\n",
        "\n",
        "            # ç¢ºä¿æ—¥æœŸæ ¼å¼æ­£ç¢º\n",
        "            if 'Date' not in df.columns:\n",
        "                df = df.reset_index()\n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "            # å–æœ€è¿‘60å¤©çš„æ•¸æ“šç”¨æ–¼ç¹ªåœ–\n",
        "            plot_df = df.tail(60).copy()\n",
        "\n",
        "            # åœ–1: åƒ¹æ ¼å’Œç§»å‹•å¹³å‡ç·š\n",
        "            ax1.plot(plot_df['Date'], plot_df['Close'], label='æ”¶ç›¤åƒ¹', linewidth=2, color='black')\n",
        "            ax1.plot(plot_df['Date'], plot_df['MA5'], label='MA5', color='red', alpha=0.7)\n",
        "            ax1.plot(plot_df['Date'], plot_df['MA10'], label='MA10', color='blue', alpha=0.7)\n",
        "            ax1.plot(plot_df['Date'], plot_df['MA20'], label='MA20', color='green', alpha=0.7)\n",
        "            ax1.plot(plot_df['Date'], plot_df['MA30'], label='MA30', color='purple', alpha=0.7)\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            ax1.fill_between(plot_df['Date'], plot_df['BB_Upper'], plot_df['BB_Lower'],\n",
        "                           alpha=0.1, color='gray', label='å¸ƒæ—å¸¶')\n",
        "\n",
        "            ax1.set_title('åƒ¹æ ¼èµ°å‹¢èˆ‡ç§»å‹•å¹³å‡ç·š')\n",
        "            ax1.legend()\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "\n",
        "            # åœ–2: MACD\n",
        "            ax2.plot(plot_df['Date'], plot_df['MACD'], label='MACD', color='blue')\n",
        "            ax2.plot(plot_df['Date'], plot_df['MACD_Signal'], label='Signal', color='red')\n",
        "            ax2.bar(plot_df['Date'], plot_df['MACD_Hist'], label='Histogram', alpha=0.3, color='green')\n",
        "            ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
        "            ax2.set_title('MACDæŒ‡æ¨™')\n",
        "            ax2.legend()\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "\n",
        "            # åœ–3: RSIå’ŒKD\n",
        "            ax3_twin = ax3.twinx()\n",
        "            ax3.plot(plot_df['Date'], plot_df['RSI'], label='RSI', color='purple', linewidth=2)\n",
        "            ax3.axhline(y=70, color='red', linestyle='--', alpha=0.5, label='è¶…è²·ç·š')\n",
        "            ax3.axhline(y=30, color='green', linestyle='--', alpha=0.5, label='è¶…è³£ç·š')\n",
        "            ax3.set_ylim(0, 100)\n",
        "            ax3.set_ylabel('RSI', color='purple')\n",
        "\n",
        "            ax3_twin.plot(plot_df['Date'], plot_df['K'], label='K', color='orange')\n",
        "            ax3_twin.plot(plot_df['Date'], plot_df['D'], label='D', color='brown')\n",
        "            ax3_twin.set_ylim(0, 100)\n",
        "            ax3_twin.set_ylabel('KD', color='orange')\n",
        "\n",
        "            ax3.set_title('RSIèˆ‡KDæŒ‡æ¨™')\n",
        "            ax3.legend(loc='upper left')\n",
        "            ax3_twin.legend(loc='upper right')\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "            ax3.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "\n",
        "            # åœ–4: æˆäº¤é‡\n",
        "            ax4.bar(plot_df['Date'], plot_df['Volume']/1000, alpha=0.6, color='skyblue', label='æˆäº¤é‡(åƒè‚¡)')\n",
        "            ax4.plot(plot_df['Date'], plot_df['Volume_MA']/1000, color='red', label='20æ—¥å‡é‡', linewidth=2)\n",
        "            ax4.set_title('æˆäº¤é‡åˆ†æ')\n",
        "            ax4.legend()\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "\n",
        "            # èª¿æ•´æ—¥æœŸæ¨™ç±¤\n",
        "            for ax in [ax1, ax2, ax3, ax4]:\n",
        "                ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # ä¿å­˜åœ–è¡¨\n",
        "            if save_path is None:\n",
        "                save_path = f\"charts/{stock_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "\n",
        "            # ç¢ºä¿ç›®éŒ„å­˜åœ¨\n",
        "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "            logger.info(f\"åœ–è¡¨å·²ä¿å­˜: {save_path}\")\n",
        "            return save_path\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å‰µå»ºåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return None\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "                        # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # å››è±¡é™åˆ†æ\n",
        "            quadrant_analysis = self.perform_quadrant_analysis(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_info.get('stock_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'quadrant_analysis': quadrant_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'data': df_with_indicators,  # æ·»åŠ æ•¸æ“šç”¨æ–¼åœ–è¡¨ç”Ÿæˆ\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - è±¡é™: {quadrant_analysis.get('quadrant', 'N/A') if quadrant_analysis else 'N/A'}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def analyze_single_stock_with_multi_timeframe(self, stock_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†æå–®æ”¯è‚¡ç¥¨ä¸¦åŒ…å«å¤šæ™‚é–“é€±æœŸåˆ†æ\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_id}\")\n",
        "\n",
        "            # å¦‚æœä¸æ˜¯yahoo symbolæ ¼å¼ï¼Œè½‰æ›ç‚ºyahoo symbol\n",
        "            if not stock_id.endswith(('.TW', '.TWO')):\n",
        "                yahoo_symbol = f\"{stock_id}.TW\"\n",
        "            else:\n",
        "                yahoo_symbol = stock_id\n",
        "                stock_id = stock_id.split('.')[0]\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(yahoo_symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': yahoo_symbol,\n",
        "                    'stock_id': stock_id,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': yahoo_symbol,\n",
        "                    'stock_id': stock_id,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # å››è±¡é™åˆ†æ\n",
        "            quadrant_analysis = self.perform_quadrant_analysis(df_with_indicators)\n",
        "\n",
        "            # å¤šæ™‚é–“é€±æœŸåˆ†æ\n",
        "            multi_timeframe_analysis = self.perform_multi_timeframe_analysis(yahoo_symbol)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': yahoo_symbol,\n",
        "                'stock_id': stock_id,\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'quadrant_analysis': quadrant_analysis,\n",
        "                'multi_timeframe_analysis': multi_timeframe_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'data': df_with_indicators,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_id} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': yahoo_symbol if 'yahoo_symbol' in locals() else stock_id,\n",
        "                'stock_id': stock_id,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "# é¡¯ç¤ºå’Œé€šçŸ¥åŠŸèƒ½\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{score:<8.1f}{current_price:<10.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {stock_name} ({stock_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºé€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        if not successful_results:\n",
        "            return \"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\"\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message = f\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\\n\"\n",
        "        message += f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "        message += f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\\n\"\n",
        "        message += f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\\n\\n\"\n",
        "\n",
        "        message += \"ğŸ… å‰ååå„ªè³ªè‚¡ç¥¨:\\n\"\n",
        "        message += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            recommendation = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "\n",
        "            message += f\"{i:2d}. {stock_name} ({stock_id})\\n\"\n",
        "            message += f\"    ğŸ’° åƒ¹æ ¼: {current_price:.2f} ({price_change:+.1f}%)\\n\"\n",
        "            message += f\"    ğŸ“Š è©•åˆ†: {score:.1f} | ğŸ¯ {recommendation}\\n\\n\"\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰ä¸‰å\n",
        "        message += \"\\nğŸ“Š è©³ç´°åˆ†æ (å‰ä¸‰å):\\n\"\n",
        "        message += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:3], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            quadrant_analysis = result.get('quadrant_analysis', {})\n",
        "\n",
        "            message += f\"\\n{i}. {stock_name} ({stock_id})\\n\"\n",
        "            message += f\"ğŸ” RSI: {technical_analysis.get('rsi_value', 50):.1f}\\n\"\n",
        "            message += f\"ğŸ“ˆ MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\\n\"\n",
        "            if quadrant_analysis:\n",
        "                message += f\"ğŸ¯ å››è±¡é™: ç¬¬{quadrant_analysis.get('quadrant', 'N/A')}è±¡é™\\n\"\n",
        "\n",
        "        message += \"\\nâš ï¸ æŠ•è³‡æé†’:\\n\"\n",
        "        message += \"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\\n\"\n",
        "        message += \"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæ±ºç­–\\n\"\n",
        "        message += \"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\"\n",
        "\n",
        "        return message\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, chart_files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† å°è‚¡åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "                # ç™¼é€åœ–è¡¨æ–‡ä»¶\n",
        "                if chart_files:\n",
        "                    telegram_photo_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto\"\n",
        "                    for chart_file in chart_files:\n",
        "                        if os.path.exists(chart_file):\n",
        "                            try:\n",
        "                                with open(chart_file, 'rb') as photo:\n",
        "                                    files = {'photo': photo}\n",
        "                                    data = {'chat_id': chat_id}\n",
        "\n",
        "                                    # ä½¿ç”¨ requests åŒæ­¥ç™¼é€åœ–ç‰‡ï¼ˆå› ç‚º aiohttp è™•ç†æ–‡ä»¶ä¸Šå‚³è¼ƒè¤‡é›œï¼‰\n",
        "                                    import requests\n",
        "                                    response = requests.post(telegram_photo_url, files=files, data=data, timeout=30)\n",
        "\n",
        "                                    if response.status_code == 200:\n",
        "                                        logger.info(f\"æˆåŠŸç™¼é€åœ–è¡¨åˆ° Telegram: {chart_file}\")\n",
        "                                    else:\n",
        "                                        logger.error(f\"ç™¼é€åœ–è¡¨å¤±æ•—: {response.status_code} - {response.text}\")\n",
        "                            except Exception as e:\n",
        "                                logger.error(f\"ç™¼é€åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "\n",
        "            # æ·»åŠ åœ–è¡¨æ–‡ä»¶\n",
        "            if chart_files:\n",
        "                for chart_file in chart_files:\n",
        "                    if os.path.exists(chart_file):\n",
        "                        with open(chart_file, \"rb\") as f:\n",
        "                            webhook.add_file(file=f.read(), filename=os.path.basename(chart_file))\n",
        "\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "def run_stock_screening():\n",
        "    \"\"\"åŸ·è¡Œè‚¡ç¥¨ç¯©é¸åŠŸèƒ½\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"å°è‚¡ç¯©é¸ç³»çµ±\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nç¯©é¸æ¢ä»¶:\")\n",
        "    print(\"1. æŠ€è¡“é¢\")\n",
        "    print(\"   - MACD: 0 < D-M < 1.5\")\n",
        "    print(\"   - æœ¬æ—¥æ”¶ç›¤åƒ¹é«˜æ–¼10æ—¥å‡åƒ¹ä¸”é«˜æ–¼30æ—¥å‡åƒ¹\")\n",
        "    print(\"   - æœ¬æ—¥è‚¡åƒ¹æ¼²å¹…5%ä»¥ä¸Š\")\n",
        "    print(\"2. ç±Œç¢¼é¢\")\n",
        "    print(\"   - æœ¬æ—¥æˆäº¤é‡5000å¼µä»¥ä¸Šä½†ä¸è¶…é30æ—¥å‡é‡çš„3å€\")\n",
        "    print(\"   - ç”±ç¬¦åˆç¯©é¸æ¢ä»¶ä¸­å–æˆäº¤é‡å‰ä¸‰å¤§ç‚ºæ¨™çš„\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    analyzer = StockAnalyzer()\n",
        "\n",
        "    # åŸ·è¡Œç¯©é¸\n",
        "    screened_stocks = analyzer.screen_stocks()\n",
        "\n",
        "    if screened_stocks:\n",
        "        print(f\"\\nğŸ¯ ç¯©é¸å®Œæˆï¼Œå…±æ‰¾åˆ° {len(screened_stocks)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "\n",
        "        # ç‚ºç¯©é¸å‡ºçš„è‚¡ç¥¨ç”Ÿæˆåœ–è¡¨\n",
        "        chart_files = []\n",
        "        for stock_data in screened_stocks:\n",
        "            chart_path = analyzer.create_stock_chart(stock_data)\n",
        "            if chart_path:\n",
        "                chart_files.append(chart_path)\n",
        "\n",
        "        return screened_stocks, chart_files\n",
        "    else:\n",
        "        print(\"\\nâŒ æœªæ‰¾åˆ°ç¬¦åˆç¯©é¸æ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "        return [], []\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ å°è‚¡æŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # ç‚ºå‰ä¸‰åè‚¡ç¥¨ç”Ÿæˆåœ–è¡¨\n",
        "        print(\"\\nğŸ“Š æ­£åœ¨ç‚ºå‰ä¸‰åè‚¡ç¥¨ç”ŸæˆæŠ€è¡“åˆ†æåœ–è¡¨...\")\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        chart_files = []\n",
        "        for i, result in enumerate(successful_results[:3]):\n",
        "            print(f\"ç”Ÿæˆåœ–è¡¨ {i+1}/3: {result.get('stock_name', 'Unknown')}\")\n",
        "            chart_path = analyzer.create_stock_chart(result)\n",
        "            if chart_path:\n",
        "                chart_files.append(chart_path)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message, chart_files)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "        print(\"ğŸ“Š æŠ€è¡“åˆ†æåœ–è¡¨å·²ç”Ÿæˆä¸¦ç™¼é€\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "# ä½¿ç”¨ç¯„ä¾‹\n",
        "def example_usage():\n",
        "    \"\"\"ä½¿ç”¨ç¯„ä¾‹\"\"\"\n",
        "    analyzer = StockAnalyzer()\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"å°è‚¡æŠ€è¡“åˆ†æç³»çµ± - ä½¿ç”¨ç¯„ä¾‹\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # ç¯„ä¾‹1: åˆ†æå–®æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«å¤šæ™‚é–“é€±æœŸåˆ†æï¼‰\n",
        "    print(\"\\n=== ç¯„ä¾‹1: å–®æ”¯è‚¡ç¥¨å®Œæ•´åˆ†æ ===\")\n",
        "    result = analyzer.analyze_single_stock_with_multi_timeframe(\"2330\")\n",
        "    if result['success']:\n",
        "        print(f\"è‚¡ç¥¨: {result['stock_id']} - {result.get('stock_name', 'Unknown')}\")\n",
        "        print(f\"ç•¶å‰åƒ¹æ ¼: {result['current_price']:.2f}\")\n",
        "        print(f\"ç¶œåˆåˆ†æ•¸: {result['combined_score']:.1f}\")\n",
        "        print(f\"æŠ•è³‡å»ºè­°: {result['recommendation']['recommendation']}\")\n",
        "\n",
        "        # é¡¯ç¤ºå››è±¡é™åˆ†æ\n",
        "        if result['quadrant_analysis']:\n",
        "            quad = result['quadrant_analysis']\n",
        "            print(f\"å››è±¡é™: ç¬¬{quad['quadrant']}è±¡é™ ({quad['trend']})\")\n",
        "\n",
        "        # é¡¯ç¤ºå¤šæ™‚é–“é€±æœŸåˆ†æ\n",
        "        if result['multi_timeframe_analysis']:\n",
        "            analyzer.generate_multi_timeframe_summary(result['multi_timeframe_analysis'], result['stock_id'])\n",
        "\n",
        "                # ç”Ÿæˆåœ–è¡¨\n",
        "        chart_path = analyzer.create_stock_chart(result)\n",
        "        if chart_path:\n",
        "            print(f\"æŠ€è¡“åˆ†æåœ–è¡¨å·²ç”Ÿæˆ: {chart_path}\")\n",
        "    else:\n",
        "        print(f\"åˆ†æå¤±æ•—: {result['error']}\")\n",
        "\n",
        "    # ç¯„ä¾‹2: è‚¡ç¥¨ç¯©é¸åŠŸèƒ½\n",
        "    print(\"\\n=== ç¯„ä¾‹2: è‚¡ç¥¨ç¯©é¸åŠŸèƒ½ ===\")\n",
        "    screened_stocks, chart_files = run_stock_screening()\n",
        "\n",
        "    # ç¯„ä¾‹3: æ‰¹é‡åˆ†æï¼ˆæ³¨æ„ï¼šé€™æœƒåˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼Œå¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“ï¼‰\n",
        "    print(\"\\n=== ç¯„ä¾‹3: æ‰¹é‡åˆ†æ ===\")\n",
        "    print(\"æ³¨æ„ï¼šæ‰¹é‡åˆ†ææœƒåˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼Œå¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“\")\n",
        "    user_input = input(\"æ˜¯å¦åŸ·è¡Œæ‰¹é‡åˆ†æï¼Ÿ(y/N): \")\n",
        "    if user_input.lower() == 'y':\n",
        "        results = asyncio.run(analyzer.analyze_all_stocks())\n",
        "        print(f\"æˆåŠŸåˆ†æ {len(results)} æ”¯è‚¡ç¥¨\")\n",
        "        display_terminal_results(results, limit=5)\n",
        "    else:\n",
        "        print(\"è·³éæ‰¹é‡åˆ†æ\")\n",
        "\n",
        "# å®šæ™‚åŸ·è¡ŒåŠŸèƒ½\n",
        "def schedule_analysis():\n",
        "    \"\"\"å®šæ™‚åŸ·è¡Œåˆ†æ\"\"\"\n",
        "    import schedule\n",
        "    import time\n",
        "\n",
        "    def job():\n",
        "        \"\"\"å®šæ™‚ä»»å‹™\"\"\"\n",
        "        print(f\"\\nğŸ• å®šæ™‚åˆ†æé–‹å§‹: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        asyncio.run(main())\n",
        "        print(f\"ğŸ• å®šæ™‚åˆ†æå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "    # è¨­å®šæ’ç¨‹ï¼šæ¯å¤©æ—©ä¸Š9é»å’Œä¸‹åˆ2é»åŸ·è¡Œ\n",
        "    schedule.every().day.at(\"09:00\").do(job)\n",
        "    schedule.every().day.at(\"14:00\").do(job)\n",
        "\n",
        "    print(\"ğŸ“… å®šæ™‚åˆ†æå·²å•Ÿå‹•\")\n",
        "    print(\"â° åŸ·è¡Œæ™‚é–“: æ¯å¤© 09:00 å’Œ 14:00\")\n",
        "    print(\"æŒ‰ Ctrl+C åœæ­¢å®šæ™‚åŸ·è¡Œ\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            schedule.run_pending()\n",
        "            time.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nğŸ“… å®šæ™‚åˆ†æå·²åœæ­¢\")\n",
        "\n",
        "# äº’å‹•å¼é¸å–®\n",
        "def interactive_menu():\n",
        "    \"\"\"äº’å‹•å¼é¸å–®\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æç³»çµ±\".center(60))\n",
        "        print(\"=\" * 60)\n",
        "        print(\"1. ğŸ“Š åˆ†æå–®æ”¯è‚¡ç¥¨ï¼ˆå«å¤šæ™‚é–“é€±æœŸï¼‰\")\n",
        "        print(\"2. ğŸ” è‚¡ç¥¨ç¯©é¸åŠŸèƒ½\")\n",
        "        print(\"3. ğŸ“ˆ æ‰¹é‡åˆ†ææ‰€æœ‰è‚¡ç¥¨\")\n",
        "        print(\"4. ğŸ“± ç™¼é€æ¸¬è©¦é€šçŸ¥\")\n",
        "        print(\"5. ğŸ“… å•Ÿå‹•å®šæ™‚åˆ†æ\")\n",
        "        print(\"6. ğŸ”§ è¨­å®šç®¡ç†\")\n",
        "        print(\"7. â“ ä½¿ç”¨èªªæ˜\")\n",
        "        print(\"0. ğŸšª é€€å‡ºç¨‹å¼\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        choice = input(\"è«‹é¸æ“‡åŠŸèƒ½ (0-7): \").strip()\n",
        "\n",
        "        if choice == \"1\":\n",
        "            stock_id = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ (ä¾‹: 2330): \").strip()\n",
        "            if stock_id:\n",
        "                analyzer = StockAnalyzer()\n",
        "                result = analyzer.analyze_single_stock_with_multi_timeframe(stock_id)\n",
        "                if result['success']:\n",
        "                    print(f\"\\nâœ… åˆ†æå®Œæˆ: {result.get('stock_name', 'Unknown')} ({result['stock_id']})\")\n",
        "                    print(f\"ğŸ“Š ç¶œåˆè©•åˆ†: {result['combined_score']:.1f}\")\n",
        "                    print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {result['recommendation']['recommendation']}\")\n",
        "\n",
        "                    # ç”Ÿæˆåœ–è¡¨\n",
        "                    chart_path = analyzer.create_stock_chart(result)\n",
        "                    if chart_path:\n",
        "                        print(f\"ğŸ“Š åœ–è¡¨å·²ç”Ÿæˆ: {chart_path}\")\n",
        "\n",
        "                    # é¡¯ç¤ºå¤šæ™‚é–“é€±æœŸåˆ†æ\n",
        "                    if result.get('multi_timeframe_analysis'):\n",
        "                        show_detail = input(\"æ˜¯å¦é¡¯ç¤ºè©³ç´°å¤šæ™‚é–“é€±æœŸåˆ†æï¼Ÿ(y/N): \")\n",
        "                        if show_detail.lower() == 'y':\n",
        "                            analyzer.generate_multi_timeframe_summary(\n",
        "                                result['multi_timeframe_analysis'], result['stock_id'])\n",
        "                else:\n",
        "                    print(f\"âŒ åˆ†æå¤±æ•—: {result['error']}\")\n",
        "            else:\n",
        "                print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            screened_stocks, chart_files = run_stock_screening()\n",
        "            if chart_files:\n",
        "                print(f\"ğŸ“Š å·²ç”Ÿæˆ {len(chart_files)} å€‹æŠ€è¡“åˆ†æåœ–è¡¨\")\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            confirm = input(\"âš ï¸  æ‰¹é‡åˆ†æéœ€è¦è¼ƒé•·æ™‚é–“ï¼Œç¢ºå®šåŸ·è¡Œï¼Ÿ(y/N): \")\n",
        "            if confirm.lower() == 'y':\n",
        "                asyncio.run(main())\n",
        "            else:\n",
        "                print(\"âŒ å·²å–æ¶ˆæ‰¹é‡åˆ†æ\")\n",
        "\n",
        "        elif choice == \"4\":\n",
        "            test_message = f\"ğŸ§ª æ¸¬è©¦é€šçŸ¥\\nâ° æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\\nâœ… é€šçŸ¥ç³»çµ±é‹ä½œæ­£å¸¸\"\n",
        "            asyncio.run(send_test_notification(test_message))\n",
        "\n",
        "        elif choice == \"5\":\n",
        "            confirm = input(\"âš ï¸  é€™å°‡å•Ÿå‹•å®šæ™‚åˆ†æï¼ˆæ¯å¤©09:00å’Œ14:00åŸ·è¡Œï¼‰ï¼Œç¢ºå®šå•Ÿå‹•ï¼Ÿ(y/N): \")\n",
        "            if confirm.lower() == 'y':\n",
        "                schedule_analysis()\n",
        "            else:\n",
        "                print(\"âŒ å·²å–æ¶ˆå®šæ™‚åˆ†æ\")\n",
        "\n",
        "        elif choice == \"6\":\n",
        "            settings_menu()\n",
        "\n",
        "        elif choice == \"7\":\n",
        "            show_help()\n",
        "\n",
        "        elif choice == \"0\":\n",
        "            print(\"ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨å°è‚¡æŠ€è¡“åˆ†æç³»çµ±ï¼\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥\")\n",
        "\n",
        "async def send_test_notification(message: str):\n",
        "    \"\"\"ç™¼é€æ¸¬è©¦é€šçŸ¥\"\"\"\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        await send_notification(session, message)\n",
        "    print(\"ğŸ“± æ¸¬è©¦é€šçŸ¥å·²ç™¼é€\")\n",
        "\n",
        "def settings_menu():\n",
        "    \"\"\"è¨­å®šé¸å–®\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"ğŸ”§ è¨­å®šç®¡ç†\".center(50))\n",
        "    print(\"=\" * 50)\n",
        "    print(\"1. ğŸ“± Telegram é€šçŸ¥è¨­å®š\")\n",
        "    print(\"2. ğŸ’¬ Discord é€šçŸ¥è¨­å®š\")\n",
        "    print(\"3. ğŸ“Š åˆ†æåƒæ•¸è¨­å®š\")\n",
        "    print(\"4. ğŸ” ç¯©é¸æ¢ä»¶è¨­å®š\")\n",
        "    print(\"0. ğŸ”™ è¿”å›ä¸»é¸å–®\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    choice = input(\"è«‹é¸æ“‡è¨­å®šé …ç›® (0-4): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        print(f\"\\nğŸ“± ç•¶å‰ Telegram è¨­å®š:\")\n",
        "        print(f\"Bot Token: {'å·²è¨­å®š' if TELEGRAM_BOT_TOKEN != 'YOUR_BOT_TOKEN_HERE' else 'æœªè¨­å®š'}\")\n",
        "        print(f\"Chat IDs: {TELEGRAM_CHAT_IDS if TELEGRAM_CHAT_IDS != ['YOUR_CHAT_ID_HERE'] else 'æœªè¨­å®š'}\")\n",
        "        print(\"\\nğŸ’¡ è«‹åœ¨ç¨‹å¼ç¢¼ä¸­ä¿®æ”¹ TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS è®Šæ•¸\")\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        print(f\"\\nğŸ’¬ ç•¶å‰ Discord è¨­å®š:\")\n",
        "        print(f\"Webhook URL: {'å·²è¨­å®š' if DISCORD_WEBHOOK_URL != 'YOUR_DISCORD_WEBHOOK_URL' else 'æœªè¨­å®š'}\")\n",
        "        print(f\"Discord æ¨¡çµ„: {'å·²å®‰è£' if MESSAGING_AVAILABLE else 'æœªå®‰è£'}\")\n",
        "        print(\"\\nğŸ’¡ è«‹åœ¨ç¨‹å¼ç¢¼ä¸­ä¿®æ”¹ DISCORD_WEBHOOK_URL è®Šæ•¸\")\n",
        "\n",
        "    elif choice == \"3\":\n",
        "        analyzer = StockAnalyzer()\n",
        "        print(f\"\\nğŸ“Š ç•¶å‰åˆ†æåƒæ•¸:\")\n",
        "        print(f\"RSI é€±æœŸ: {analyzer.config['rsi_period']}\")\n",
        "        print(f\"MACD å¿«ç·š: {analyzer.config['macd_fast']}\")\n",
        "        print(f\"MACD æ…¢ç·š: {analyzer.config['macd_slow']}\")\n",
        "        print(f\"MACD ä¿¡è™Ÿç·š: {analyzer.config['macd_signal']}\")\n",
        "        print(f\"æœ€å°æˆäº¤é‡: {analyzer.config['min_volume_lots']} å¼µ/æ—¥\")\n",
        "        print(\"\\nğŸ’¡ å¦‚éœ€ä¿®æ”¹è«‹ç·¨è¼¯ StockAnalyzer.__init__ ä¸­çš„ config\")\n",
        "\n",
        "    elif choice == \"4\":\n",
        "        analyzer = StockAnalyzer()\n",
        "        print(f\"\\nğŸ” ç•¶å‰ç¯©é¸æ¢ä»¶:\")\n",
        "        conditions = analyzer.config['screen_conditions']\n",
        "        print(f\"æœ€å°æ¼²å¹…: {conditions['min_price_change']}%\")\n",
        "        print(f\"æœ€å°æˆäº¤é‡: {conditions['min_volume_lots']} å¼µ\")\n",
        "        print(f\"æœ€å¤§æˆäº¤é‡å€æ•¸: {conditions['max_volume_ratio']} å€\")\n",
        "        print(f\"MACDå·®å€¼ç¯„åœ: {conditions['macd_diff_min']} ~ {conditions['macd_diff_max']}\")\n",
        "        print(\"\\nğŸ’¡ å¦‚éœ€ä¿®æ”¹è«‹ç·¨è¼¯ StockAnalyzer.__init__ ä¸­çš„ screen_conditions\")\n",
        "\n",
        "def show_help():\n",
        "    \"\"\"é¡¯ç¤ºä½¿ç”¨èªªæ˜\"\"\"\n",
        "    help_text = \"\"\"\n",
        "ğŸ“– å°è‚¡æŠ€è¡“åˆ†æç³»çµ± - ä½¿ç”¨èªªæ˜\n",
        "\n",
        "ğŸ¯ ç³»çµ±åŠŸèƒ½:\n",
        "1. ğŸ“Š å–®è‚¡åˆ†æ: æä¾›å®Œæ•´æŠ€è¡“æŒ‡æ¨™åˆ†æï¼ŒåŒ…å«å¤šæ™‚é–“é€±æœŸåˆ†æ\n",
        "2. ğŸ” è‚¡ç¥¨ç¯©é¸: æ ¹æ“šæŠ€è¡“é¢å’Œç±Œç¢¼é¢æ¢ä»¶ç¯©é¸å„ªè³ªè‚¡ç¥¨\n",
        "3. ğŸ“ˆ æ‰¹é‡åˆ†æ: åˆ†ææ‰€æœ‰å°è‚¡ï¼Œæ‰¾å‡ºè©•åˆ†æœ€é«˜çš„å‰åå\n",
        "4. ğŸ“± é€šçŸ¥åŠŸèƒ½: è‡ªå‹•ç™¼é€åˆ†æçµæœåˆ° Telegram å’Œ Discord\n",
        "5. ğŸ“Š åœ–è¡¨ç”Ÿæˆ: è‡ªå‹•ç”ŸæˆæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ”§ æŠ€è¡“æŒ‡æ¨™:\n",
        "â€¢ RSI: ç›¸å°å¼·å¼±æŒ‡æ¨™ï¼Œåˆ¤æ–·è¶…è²·è¶…è³£\n",
        "â€¢ MACD: æŒ‡æ•¸å¹³æ»‘ç§»å‹•å¹³å‡ç·šï¼Œåˆ¤æ–·è¶¨å‹¢è½‰æŠ˜\n",
        "â€¢ KD: éš¨æ©ŸæŒ‡æ¨™ï¼ŒçŸ­æœŸè²·è³£æ™‚æ©Ÿ\n",
        "â€¢ å¸ƒæ—å¸¶: åƒ¹æ ¼é€šé“ï¼Œåˆ¤æ–·åƒ¹æ ¼ç›¸å°ä½ç½®\n",
        "â€¢ ç§»å‹•å¹³å‡ç·š: MA5, MA10, MA20, MA30\n",
        "\n",
        "ğŸ¯ å››è±¡é™åˆ†æ:\n",
        "â€¢ ç¬¬ä¸€è±¡é™: å¼·å‹¢å¤šé ­ (MACD>Signal, RSI>50)\n",
        "â€¢ ç¬¬äºŒè±¡é™: å¤šé ­è­¦æˆ’ (MACD<Signal, RSI>50)\n",
        "â€¢ ç¬¬ä¸‰è±¡é™: å¼·å‹¢ç©ºé ­ (MACD<Signal, RSI<50)\n",
        "â€¢ ç¬¬å››è±¡é™: ç©ºé ­åè½‰ (MACD>Signal, RSI<50)\n",
        "\n",
        "ğŸ” ç¯©é¸æ¢ä»¶:\n",
        "â€¢ æŠ€è¡“é¢: MACDå·®å€¼0-1.5, åƒ¹æ ¼é«˜æ–¼å‡ç·š, æ¼²å¹…â‰¥5%\n",
        "â€¢ ç±Œç¢¼é¢: æˆäº¤é‡â‰¥5000å¼µä¸”â‰¤30æ—¥å‡é‡3å€\n",
        "\n",
        "ğŸ“± é€šçŸ¥è¨­å®š:\n",
        "1. ç”³è«‹ Telegram Bot Token\n",
        "2. ç²å– Chat ID\n",
        "3. åœ¨ç¨‹å¼ç¢¼ä¸­è¨­å®šç›¸é—œè®Šæ•¸\n",
        "4. å¯é¸: è¨­å®š Discord Webhook\n",
        "\n",
        "âš ï¸  é¢¨éšªæé†’:\n",
        "â€¢ æœ¬ç³»çµ±åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°\n",
        "â€¢ æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶å’Œè³‡é‡‘ç®¡ç†\n",
        "\n",
        "ğŸ’¡ æŠ€è¡“æ”¯æ´:\n",
        "â€¢ ç¢ºä¿ç¶²è·¯é€£ç·šæ­£å¸¸\n",
        "â€¢ è‚¡ç¥¨æ•¸æ“šä¾†æº: Yahoo Finance\n",
        "â€¢ å»ºè­°åœ¨äº¤æ˜“æ™‚é–“å¤–åŸ·è¡Œæ‰¹é‡åˆ†æ\n",
        "â€¢ å¦‚é‡å•é¡Œè«‹æª¢æŸ¥æ—¥èªŒè¼¸å‡º\n",
        "\"\"\"\n",
        "    print(help_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸš€ å°è‚¡æŠ€è¡“åˆ†æç³»çµ±\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"é¸æ“‡åŸ·è¡Œæ¨¡å¼:\")\n",
        "    print(\"1. ğŸ–¥ï¸  äº’å‹•å¼é¸å–®\")\n",
        "    print(\"2. ğŸ”„ ç›´æ¥åŸ·è¡Œä¸»ç¨‹å¼\")\n",
        "    print(\"3. ğŸ“š æŸ¥çœ‹ä½¿ç”¨ç¯„ä¾‹\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    mode = input(\"è«‹é¸æ“‡æ¨¡å¼ (1-3): \").strip()\n",
        "\n",
        "    if mode == \"1\":\n",
        "        interactive_menu()\n",
        "    elif mode == \"2\":\n",
        "        asyncio.run(main())\n",
        "    elif mode == \"3\":\n",
        "        example_usage()\n",
        "    else:\n",
        "        print(\"âŒ ç„¡æ•ˆé¸æ“‡ï¼Œå•Ÿå‹•äº’å‹•å¼é¸å–®\")\n",
        "        interactive_menu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import seaborn as sns\n",
        "from io import StringIO\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import json\n",
        "import pickle\n",
        "from typing import Dict, List, Any, Optional\n",
        "import random\n",
        "\n",
        "# æ©Ÿå™¨å­¸ç¿’ç›¸é—œ\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# é€šçŸ¥ç›¸é—œ\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# Jupyter Notebook æ”¯æ´\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "    import ipywidgets as widgets\n",
        "    from ipywidgets import Layout, HTML, Button, HBox, VBox, Output\n",
        "    from IPython.display import display, clear_output\n",
        "    JUPYTER_AVAILABLE = True\n",
        "except ImportError:\n",
        "    JUPYTER_AVAILABLE = False\n",
        "\n",
        "# Shioaji æ”¯æ´\n",
        "try:\n",
        "    import shioaji as sj\n",
        "    SHIOAJI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SHIOAJI_AVAILABLE = False\n",
        "\n",
        "# =============================================================================\n",
        "# å…¨åŸŸè¨­å®š\n",
        "# =============================================================================\n",
        "\n",
        "# ç¦æ­¢ä¸­æ–‡éŒ¯èª¤è­¦å‘Š\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ä¸­æ–‡å­—é«”è¨­å®š\n",
        "plt.rcParams['font.sans-serif'] = [\n",
        "    'Microsoft JhengHei',  # ç¹é«”ä¸­æ–‡\n",
        "    'SimHei',              # ç°¡é«”ä¸­æ–‡\n",
        "    'Arial Unicode MS',    # Unicode å­—é«”\n",
        "    'DejaVu Sans'         # åŸºç¤å­—é«”\n",
        "]\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# é€šçŸ¥è¨­å®š\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# åœ–è¡¨å„²å­˜ç›®éŒ„\n",
        "CHARTS_DIR = 'charts'\n",
        "if not os.path.exists(CHARTS_DIR):\n",
        "    os.makedirs(CHARTS_DIR)\n",
        "\n",
        "print(\"ğŸš€ ç’°å¢ƒè¨­å®šå®Œæˆï¼Œé–‹å§‹å»ºç«‹åˆ†æç³»çµ±...\")\n",
        "\n",
        "# =============================================================================\n",
        "# 1. æ•¸æ“šç²å–æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def fetch_from_cnn():\n",
        "    \"\"\"å¾CNNç¶²ç«™ç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\"\"\"\n",
        "    url = \"https://money.cnn.com/data/fear-and-greed/\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for element in soup.find_all(['div', 'span']):\n",
        "            if \"Fear & Greed Now:\" in element.get_text():\n",
        "                number_match = re.search(r'(\\d+)', element.get_text())\n",
        "                if number_match:\n",
        "                    value = int(number_match.group(1))\n",
        "                    logger.info(f\"æˆåŠŸå¾CNNç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸: {value}\")\n",
        "                    return value\n",
        "        logger.warning(\"ç„¡æ³•å¾CNNæå–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾CNNç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_from_alternative_me(limit=1):\n",
        "    \"\"\"å¾alternative.me APIç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\"\"\"\n",
        "    try:\n",
        "        url = f\"https://api.alternative.me/fng/?limit={limit}&format=json\"\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if 'data' in data and len(data['data']) > 0:\n",
        "            if limit == 1:\n",
        "                value = int(data['data'][0]['value'])\n",
        "                logger.info(f\"æˆåŠŸå¾Alternative.me APIç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸: {value}\")\n",
        "                return value\n",
        "            else:\n",
        "                df = pd.DataFrame(data['data'])\n",
        "                df['value'] = pd.to_numeric(df['value'])\n",
        "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
        "                df = df.rename(columns={'timestamp': 'Date', 'value': 'FearGreedIndex'})\n",
        "                df['Date'] = pd.to_datetime(df['Date'])\n",
        "                logger.info(f\"æˆåŠŸç²å– {len(df)} å¤©çš„æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“š\")\n",
        "                return df[['Date', 'FearGreedIndex']]\n",
        "        else:\n",
        "            logger.warning(\"Alternative.me APIè¿”å›çš„æ•¸æ“šæ ¼å¼ä¸æ­£ç¢º\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾Alternative.meç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_fear_and_greed_data(days):\n",
        "    \"\"\"ç²å–å³æ™‚èˆ‡æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“š\"\"\"\n",
        "    logger.info(\"æ­£åœ¨ç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸...\")\n",
        "\n",
        "    current_value = fetch_from_cnn()\n",
        "    if current_value is None:\n",
        "        current_value = fetch_from_alternative_me(limit=1)\n",
        "\n",
        "    historical_df = fetch_from_alternative_me(limit=days)\n",
        "\n",
        "    if historical_df is not None:\n",
        "        logger.info(\"å·²æˆåŠŸç²å–çœŸå¯¦æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“šã€‚\")\n",
        "        if current_value is not None:\n",
        "            today = pd.to_datetime(datetime.now().date())\n",
        "            if today not in historical_df['Date'].values:\n",
        "                new_row = pd.DataFrame([{'Date': today, 'FearGreedIndex': current_value}])\n",
        "                historical_df = pd.concat([historical_df, new_row], ignore_index=True)\n",
        "        return historical_df.drop_duplicates(subset=['Date'], keep='last')\n",
        "\n",
        "    logger.warning(\"ç„¡æ³•ç²å–çœŸå¯¦æ­·å²æ•¸æ“šï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šä½œç‚ºå‚™æ¡ˆã€‚\")\n",
        "    if current_value is None:\n",
        "        current_value = 50\n",
        "        logger.warning(f\"æ‰€æœ‰å³æ™‚ä¾†æºå‡å¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼ {current_value}\")\n",
        "\n",
        "    dates = pd.to_datetime([datetime.now() - timedelta(days=i) for i in range(days)]).sort_values()\n",
        "    scores = [current_value]\n",
        "    np.random.seed(42)\n",
        "    for _ in range(1, days):\n",
        "        mean_reversion = 0.1 * (50 - scores[-1])\n",
        "        random_change = np.random.normal(0, 3)\n",
        "        new_score = scores[-1] + mean_reversion + random_change\n",
        "        scores.append(max(0, min(100, new_score)))\n",
        "\n",
        "    return pd.DataFrame({'Date': dates, 'FearGreedIndex': scores})\n",
        "\n",
        "def fetch_stock_data(symbol, period='1y'):\n",
        "    \"\"\"å¾Yahoo Financeç²å–è‚¡ç¥¨æ•¸æ“šï¼Œè‡ªå‹•åˆ¤æ–·å°è‚¡/ç¾è‚¡\"\"\"\n",
        "    original_symbol = symbol\n",
        "\n",
        "    # å¦‚æœè¼¸å…¥çš„æ˜¯ç´”æ•¸å­—ï¼Œåˆ¤æ–·ç‚ºå°è‚¡ä»£ç¢¼\n",
        "    if re.match(r'^\\d{4,5}$', symbol):\n",
        "        symbol += \".TW\"\n",
        "        logger.info(f\"æª¢æ¸¬åˆ°å°è‚¡ä»£ç¢¼ï¼Œè½‰æ›ç‚º {symbol}\")\n",
        "\n",
        "    logger.info(f\"æ­£åœ¨å¾Yahoo Financeç²å– {symbol} ({period}) çš„æ•¸æ“š...\")\n",
        "    try:\n",
        "        stock = yf.Ticker(symbol)\n",
        "        df = stock.history(period=period, interval='1d')\n",
        "        if df.empty:\n",
        "            logger.error(f\"ç„¡æ³•ç²å– {symbol} çš„æ•¸æ“šï¼Œè«‹æª¢æŸ¥ä»£ç¢¼æ˜¯å¦æ­£ç¢ºã€‚\")\n",
        "            return None\n",
        "\n",
        "        df.reset_index(inplace=True)\n",
        "        df['Date'] = pd.to_datetime(df['Date'].dt.date)\n",
        "\n",
        "        logger.info(f\"æˆåŠŸç²å– {original_symbol} çš„ {len(df)} ç­†æ•¸æ“š\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾Yahoo Financeç²å– {symbol} çš„æ•¸æ“šæ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================\n",
        "# 2. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"è¨ˆç®—å®Œæ•´çš„æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "    # ç§»å‹•å¹³å‡ç·š\n",
        "    df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "    df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "    df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "    df['MA60'] = df['Close'].rolling(window=60).mean()\n",
        "\n",
        "    # EMA\n",
        "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "\n",
        "    # MACD\n",
        "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']\n",
        "\n",
        "    # RSI\n",
        "    delta = df['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean()\n",
        "    avg_loss = loss.rolling(window=14).mean().replace(0, np.nan)\n",
        "    rs = avg_gain / avg_loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # å¸ƒæ—å¸¶\n",
        "    df['BB_Middle'] = df['MA20']\n",
        "    std_dev = df['Close'].rolling(window=20).std()\n",
        "    df['BB_Upper'] = df['BB_Middle'] + (std_dev * 2)\n",
        "    df['BB_Lower'] = df['BB_Middle'] - (std_dev * 2)\n",
        "\n",
        "    # KDæŒ‡æ¨™\n",
        "    low_min = df['Low'].rolling(window=9).min()\n",
        "    high_max = df['High'].rolling(window=9).max()\n",
        "    rsv = (df['Close'] - low_min) / (high_max - low_min) * 100\n",
        "    df['K'] = rsv.ewm(com=2).mean()\n",
        "    df['D'] = df['K'].ewm(com=2).mean()\n",
        "\n",
        "    # å¨å»‰æŒ‡æ¨™\n",
        "    df['Williams_R'] = -100 * (high_max - df['Close']) / (high_max - low_min)\n",
        "\n",
        "    # æˆäº¤é‡æŒ‡æ¨™\n",
        "    df['Volume_MA'] = df['Volume'].rolling(window=20).mean()\n",
        "    df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']\n",
        "\n",
        "    # OBV\n",
        "    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()\n",
        "\n",
        "    # ADX (ç°¡åŒ–ç‰ˆ)\n",
        "    high_diff = df['High'].diff()\n",
        "    low_diff = df['Low'].diff()\n",
        "    plus_dm = np.where((high_diff > low_diff) & (high_diff > 0), high_diff, 0)\n",
        "    minus_dm = np.where((low_diff > high_diff) & (low_diff > 0), low_diff, 0)\n",
        "    tr1 = df['High'] - df['Low']\n",
        "    tr2 = abs(df['High'] - df['Close'].shift(1))\n",
        "    tr3 = abs(df['Low'] - df['Close'].shift(1))\n",
        "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "    atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
        "    plus_di = 100 * (pd.Series(plus_dm).ewm(alpha=1/14, adjust=False).mean() / atr)\n",
        "    minus_di = 100 * (pd.Series(minus_dm).ewm(alpha=1/14, adjust=False).mean() / atr)\n",
        "    dx = 100 * (abs(plus_di - minus_di) / (plus_di + minus_di).replace(0, np.nan))\n",
        "    df['ADX'] = dx.ewm(alpha=1/14, adjust=False).mean()\n",
        "\n",
        "    # CCI\n",
        "    typical_price = (df['High'] + df['Low'] + df['Close']) / 3\n",
        "    sma_tp = typical_price.rolling(window=20).mean()\n",
        "    mad = typical_price.rolling(window=20).apply(lambda x: np.mean(np.abs(x - np.mean(x))))\n",
        "    df['CCI'] = (typical_price - sma_tp) / (0.015 * mad)\n",
        "\n",
        "    # MFI\n",
        "    typical_price = (df['High'] + df['Low'] + df['Close']) / 3\n",
        "    money_flow = typical_price * df['Volume']\n",
        "    mf_sign = np.where(typical_price.diff() > 0, 1, -1)\n",
        "    signed_mf = money_flow * mf_sign\n",
        "    positive_mf = np.where(signed_mf > 0, signed_mf, 0)\n",
        "    negative_mf = np.where(signed_mf < 0, -signed_mf, 0)\n",
        "    mfr = pd.Series(positive_mf).rolling(14).sum() / pd.Series(negative_mf).rolling(14).sum().replace(0, np.nan)\n",
        "    df['MFI'] = 100 - (100 / (1 + mfr))\n",
        "\n",
        "    return df\n",
        "\n",
        "def feature_engineering(df):\n",
        "    \"\"\"å‰µå»ºè¡ç”Ÿç‰¹å¾µ\"\"\"\n",
        "    # åƒ¹æ ¼è®ŠåŒ–\n",
        "    df['Price_Change_1d'] = df['Close'].pct_change(1)\n",
        "    df['Price_Change_5d'] = df['Close'].pct_change(5)\n",
        "    df['Price_Change_20d'] = df['Close'].pct_change(20)\n",
        "\n",
        "    # æ³¢å‹•ç‡\n",
        "    df['Volatility_5d'] = df['Close'].rolling(5).std()\n",
        "    df['Volatility_20d'] = df['Close'].rolling(20).std()\n",
        "\n",
        "    # å¸ƒæ—å¸¶ç›¸é—œ\n",
        "    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']\n",
        "    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower']).replace(0, np.nan)\n",
        "\n",
        "    # å‹•é‡æŒ‡æ¨™\n",
        "    df['Momentum_14'] = df['Close'] - df['Close'].shift(14)\n",
        "\n",
        "    # ç›¸å°å¼·åº¦\n",
        "    df['Relative_Volume'] = df['Volume'] / df['Volume_MA']\n",
        "\n",
        "    # å¡«å……NaNå€¼\n",
        "    df.bfill(inplace=True)\n",
        "    df.ffill(inplace=True)\n",
        "    df.fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# =============================================================================\n",
        "# 3. Kç·šå‹æ…‹è­˜åˆ¥æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def identify_candlestick_patterns(df):\n",
        "    \"\"\"è­˜åˆ¥å¸¸è¦‹çš„Kç·šå‹æ…‹\"\"\"\n",
        "    result_df = df.copy()\n",
        "\n",
        "    # åŸºæœ¬è¨ˆç®—\n",
        "    result_df['body_size'] = abs(result_df['Close'] - result_df['Open'])\n",
        "    result_df['upper_shadow'] = result_df['High'] - result_df[['Open', 'Close']].max(axis=1)\n",
        "    result_df['lower_shadow'] = result_df[['Open', 'Close']].min(axis=1) - result_df['Low']\n",
        "    result_df['total_range'] = result_df['High'] - result_df['Low']\n",
        "\n",
        "    # å‰å¹¾å¤©æ•¸æ“š\n",
        "    for i in range(1, 4):\n",
        "        result_df[f'prev{i}_open'] = result_df['Open'].shift(i)\n",
        "        result_df[f'prev{i}_high'] = result_df['High'].shift(i)\n",
        "        result_df[f'prev{i}_low'] = result_df['Low'].shift(i)\n",
        "        result_df[f'prev{i}_close'] = result_df['Close'].shift(i)\n",
        "        result_df[f'prev{i}_body_size'] = result_df['body_size'].shift(i)\n",
        "\n",
        "    # Kç·šè¶¨å‹¢\n",
        "    result_df['is_bullish'] = result_df['Close'] > result_df['Open']\n",
        "    result_df['is_bearish'] = result_df['Close'] < result_df['Open']\n",
        "\n",
        "    for i in range(1, 4):\n",
        "        result_df[f'prev{i}_is_bullish'] = result_df[f'prev{i}_close'] > result_df[f'prev{i}_open']\n",
        "        result_df[f'prev{i}_is_bearish'] = result_df[f'prev{i}_close'] < result_df[f'prev{i}_open']\n",
        "\n",
        "    # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢åˆ¤æ–·\n",
        "    result_df['uptrend'] = (result_df['MA5'] > result_df['MA20']) & (result_df['Close'] > result_df['MA20'])\n",
        "    result_df['downtrend'] = (result_df['MA5'] < result_df['MA20']) & (result_df['Close'] < result_df['MA20'])\n",
        "\n",
        "    # åˆå§‹åŒ–å‹æ…‹æ¬„ä½\n",
        "    pattern_columns = [\n",
        "        'åå­—æ˜Ÿ_ä¸­æ€§', 'éŒ˜å­ç·š_çœ‹æ¼²', 'éŒ˜å­ç·š_çœ‹è·Œ', 'æµæ˜Ÿç·š_çœ‹è·Œ',\n",
        "        'åå™¬_çœ‹æ¼²', 'åå™¬_çœ‹è·Œ', 'æ¯å­ç·š_çœ‹æ¼²', 'æ¯å­ç·š_çœ‹è·Œ',\n",
        "        'æ™¨æ˜Ÿ_çœ‹æ¼²', 'æš®æ˜Ÿ_çœ‹è·Œ', 'ä¸‰ç™½å…µ_çœ‹æ¼²', 'ä¸‰é»‘é´‰_çœ‹è·Œ',\n",
        "        'ç©¿åˆºç·š_çœ‹æ¼²', 'çƒé›²è“‹é ‚_çœ‹è·Œ', 'é•·è…¿åå­—ç·š_ä¸­æ€§', 'ä¸ŠåŠç·š_çœ‹è·Œ',\n",
        "        'ç´¡éŒ˜_ä¸­æ€§', 'åè½‰_çœ‹æ¼²', 'åè½‰_çœ‹è·Œ'\n",
        "    ]\n",
        "\n",
        "    for col in pattern_columns:\n",
        "        result_df[col] = 0\n",
        "\n",
        "    # åå­—æ˜Ÿ\n",
        "    doji_condition = result_df['body_size'] <= 0.1 * result_df['total_range']\n",
        "    result_df.loc[doji_condition, 'åå­—æ˜Ÿ_ä¸­æ€§'] = 1\n",
        "\n",
        "    # éŒ˜å­ç·š\n",
        "    hammer_condition = (\n",
        "        (result_df['lower_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['upper_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "    result_df.loc[hammer_condition & result_df['downtrend'], 'éŒ˜å­ç·š_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[hammer_condition & result_df['uptrend'], 'éŒ˜å­ç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # æµæ˜Ÿç·š\n",
        "    shooting_star_condition = (\n",
        "        (result_df['upper_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['lower_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "    result_df.loc[shooting_star_condition & result_df['uptrend'], 'æµæ˜Ÿç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # çœ‹æ¼²åå™¬\n",
        "    bullish_engulfing = (\n",
        "        (~result_df['prev1_is_bullish']) &\n",
        "        result_df['is_bullish'] &\n",
        "        (result_df['Open'] < result_df['prev1_close']) &\n",
        "        (result_df['Close'] > result_df['prev1_open'])\n",
        "    )\n",
        "    result_df.loc[bullish_engulfing & result_df['downtrend'], 'åå™¬_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # çœ‹è·Œåå™¬\n",
        "    bearish_engulfing = (\n",
        "        result_df['prev1_is_bullish'] &\n",
        "        (~result_df['is_bullish']) &\n",
        "        (result_df['Open'] > result_df['prev1_close']) &\n",
        "        (result_df['Close'] < result_df['prev1_open'])\n",
        "    )\n",
        "    result_df.loc[bearish_engulfing & result_df['uptrend'], 'åå™¬_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # çœ‹æ¼²æ¯å­ç·š\n",
        "    bullish_harami = (\n",
        "        (~result_df['prev1_is_bullish']) &\n",
        "        result_df['is_bullish'] &\n",
        "        (result_df['High'] < result_df['prev1_high']) &\n",
        "        (result_df['Low'] > result_df['prev1_low']) &\n",
        "        (result_df['body_size'] < result_df['prev1_body_size'])\n",
        "    )\n",
        "    result_df.loc[bullish_harami & result_df['downtrend'], 'æ¯å­ç·š_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # çœ‹è·Œæ¯å­ç·š\n",
        "    bearish_harami = (\n",
        "        result_df['prev1_is_bullish'] &\n",
        "        (~result_df['is_bullish']) &\n",
        "        (result_df['High'] < result_df['prev1_high']) &\n",
        "        (result_df['Low'] > result_df['prev1_low']) &\n",
        "        (result_df['body_size'] < result_df['prev1_body_size'])\n",
        "    )\n",
        "    result_df.loc[bearish_harami & result_df['uptrend'], 'æ¯å­ç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # æ™¨æ˜Ÿ\n",
        "    morning_star = (\n",
        "        (~result_df['prev2_is_bullish']) &\n",
        "        (result_df['prev1_body_size'] <= 0.3 * result_df['prev1_total_range']) &\n",
        "        result_df['is_bullish'] &\n",
        "        (result_df['Close'] > (result_df['prev2_open'] + result_df['prev2_close']) / 2)\n",
        "    )\n",
        "    result_df.loc[morning_star & result_df['downtrend'], 'æ™¨æ˜Ÿ_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # æš®æ˜Ÿ\n",
        "    evening_star = (\n",
        "        result_df['prev2_is_bullish'] &\n",
        "        (result_df['prev1_body_size'] <= 0.3 * result_df['prev1_total_range']) &\n",
        "        (~result_df['is_bullish']) &\n",
        "        (result_df['Close'] < (result_df['prev2_open'] + result_df['prev2_close']) / 2)\n",
        "    )\n",
        "    result_df.loc[evening_star & result_df['uptrend'], 'æš®æ˜Ÿ_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # ä¸‰ç™½å…µ\n",
        "    three_white_soldiers = (\n",
        "        result_df['is_bullish'] &\n",
        "        result_df['prev1_is_bullish'] &\n",
        "        result_df['prev2_is_bullish'] &\n",
        "        (result_df['Close'] > result_df['prev1_close']) &\n",
        "        (result_df['prev1_close'] > result_df['prev2_close']) &\n",
        "        (result_df['Open'] > result_df['prev1_open']) &\n",
        "        (result_df['prev1_open'] > result_df['prev2_open'])\n",
        "    )\n",
        "    result_df.loc[three_white_soldiers, 'ä¸‰ç™½å…µ_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # ä¸‰é»‘é´‰\n",
        "    three_black_crows = (\n",
        "        (~result_df['is_bullish']) &\n",
        "        (~result_df['prev1_is_bullish']) &\n",
        "        (~result_df['prev2_is_bullish']) &\n",
        "        (result_df['Close'] < result_df['prev1_close']) &\n",
        "        (result_df['prev1_close'] < result_df['prev2_close']) &\n",
        "        (result_df['Open'] < result_df['prev1_open']) &\n",
        "        (result_df['prev1_open'] < result_df['prev2_open'])\n",
        "    )\n",
        "    result_df.loc[three_black_crows, 'ä¸‰é»‘é´‰_çœ‹è·Œ'] = -1\n",
        "\n",
        "    return result_df\n",
        "\n",
        "def generate_pattern_report(df, periods=['daily']):\n",
        "    \"\"\"ç”ŸæˆKç·šå‹æ…‹åˆ†æå ±å‘Š\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šæ•¸æ“šç‚ºç©º\"\n",
        "\n",
        "    required_cols = ['Open', 'High', 'Low', 'Close']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šç¼ºå°‘å¿…è¦æ¬„ä½\"\n",
        "\n",
        "    def detect_patterns(ohlc_data):\n",
        "        patterns = {\"çœ‹æ¼²\": [], \"çœ‹è·Œ\": [], \"ä¸­æ€§\": []}\n",
        "\n",
        "        if len(ohlc_data) < 5:\n",
        "            return patterns\n",
        "\n",
        "        recent = ohlc_data.tail(10).copy()\n",
        "        recent['body_size'] = abs(recent['Close'] - recent['Open'])\n",
        "        recent['upper_shadow'] = recent['High'] - recent[['Open', 'Close']].max(axis=1)\n",
        "        recent['lower_shadow'] = recent[['Open', 'Close']].min(axis=1) - recent['Low']\n",
        "        recent['total_range'] = recent['High'] - recent['Low']\n",
        "        recent['is_bullish'] = recent['Close'] > recent['Open']\n",
        "        recent['is_bearish'] = recent['Close'] < recent['Open']\n",
        "\n",
        "        # è¨ˆç®—ç§»å‹•å¹³å‡ç·š\n",
        "        recent['ma5'] = recent['Close'].rolling(window=5).mean()\n",
        "        recent['ma10'] = recent['Close'].rolling(window=10).mean()\n",
        "\n",
        "        last3 = recent.tail(3)\n",
        "\n",
        "        # ä¸‰ç™½å…µ\n",
        "        if len(last3) == 3 and all(last3['is_bullish']) and \\\n",
        "           last3['Close'].iloc[0] < last3['Close'].iloc[1] < last3['Close'].iloc[2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"ä¸‰ç™½å…µ\")\n",
        "\n",
        "        # ä¸‰é»‘é´‰\n",
        "        if len(last3) == 3 and all(last3['is_bearish']) and \\\n",
        "           last3['Close'].iloc[0] > last3['Close'].iloc[1] > last3['Close'].iloc[2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ä¸‰é»‘é´‰\")\n",
        "\n",
        "        # å¤šé ­åå™¬\n",
        "        if len(last3) >= 2 and last3['is_bearish'].iloc[-2] and last3['is_bullish'].iloc[-1] and \\\n",
        "           last3['Open'].iloc[-1] <= last3['Close'].iloc[-2] and \\\n",
        "           last3['Close'].iloc[-1] >= last3['Open'].iloc[-2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"å¤šé ­åå™¬\")\n",
        "\n",
        "        # ç©ºé ­åå™¬\n",
        "        if len(last3) >= 2 and last3['is_bullish'].iloc[-2] and last3['is_bearish'].iloc[-1] and \\\n",
        "           last3['Open'].iloc[-1] >= last3['Close'].iloc[-2] and \\\n",
        "           last3['Close'].iloc[-1] <= last3['Open'].iloc[-2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ç©ºé ­åå™¬\")\n",
        "\n",
        "        # çœ‹æ¼²éŒ˜é ­\n",
        "        if any(last3['lower_shadow'] > 2 * last3['body_size']) and \\\n",
        "           any(last3['upper_shadow'] < 0.2 * last3['body_size']) and \\\n",
        "           any(last3['is_bullish']):\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"çœ‹æ¼²éŒ˜é ­\")\n",
        "\n",
        "        # çœ‹è·ŒåŠéŒ˜\n",
        "        if any(last3['upper_shadow'] > 2 * last3['body_size']) and \\\n",
        "           any(last3['lower_shadow'] < 0.2 * last3['body_size']) and \\\n",
        "           any(last3['is_bearish']):\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"çœ‹è·ŒåŠéŒ˜\")\n",
        "\n",
        "        # åå­—æ˜Ÿ\n",
        "        if any(last3['body_size'] < 0.1 * last3['total_range']):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"åå­—æ˜Ÿ\")\n",
        "\n",
        "        # é•·è…¿åå­—\n",
        "        if any((last3['body_size'] < 0.1 * last3['total_range']) &\n",
        "               (last3['upper_shadow'] > last3['body_size']) &\n",
        "               (last3['lower_shadow'] > last3['body_size'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"é•·è…¿åå­—\")\n",
        "\n",
        "        # ç´¡éŒ˜\n",
        "        if any((last3['body_size'] < 0.3 * last3['total_range']) &\n",
        "               (abs(last3['upper_shadow'] - last3['lower_shadow']) < 0.2 * last3['total_range'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"ç´¡éŒ˜\")\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    report_parts = []\n",
        "\n",
        "    for period in periods:\n",
        "        period_name = {'daily': 'æ—¥ç·š', 'weekly': 'é€±ç·š', 'monthly': 'æœˆç·š'}.get(period, period)\n",
        "\n",
        "        try:\n",
        "            patterns = detect_patterns(df)\n",
        "            period_report = [f\"{period_name}åˆ†æ:\"]\n",
        "\n",
        "            for pattern_type, detected_patterns in patterns.items():\n",
        "                if detected_patterns:\n",
        "                    pattern_str = \", \".join(detected_patterns)\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: {pattern_str}\")\n",
        "                else:\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: ç„¡\")\n",
        "\n",
        "            report_parts.append(\"\\n\".join(period_report))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {period_name} å‹æ…‹æ™‚å‡ºéŒ¯: {e}\")\n",
        "            report_parts.append(f\"{period_name}åˆ†æ:\\nåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤\")\n",
        "\n",
        "    return \"\\n\\n\".join(report_parts) if report_parts else \"æœªæª¢æ¸¬åˆ°æ˜é¡¯Kç·šå‹æ…‹\"\n",
        "\n",
        "# =============================================================================\n",
        "# 4. æ³¢æµªç†è«–åˆ†ææ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def wave_theory_analysis(df, stock_id):\n",
        "    \"\"\"å®Œæ•´çš„æ³¢æµªç†è«–åˆ†æ\"\"\"\n",
        "    close = df['Close'].values\n",
        "    high = df['High'].values\n",
        "    low = df['Low'].values\n",
        "\n",
        "    if len(close) < 30:\n",
        "        return False, \"æ•¸æ“šä¸è¶³\", None\n",
        "\n",
        "    # å°‹æ‰¾æœ€è¿‘çš„é¡¯è‘—é«˜é»ä½œç‚ºå¯èƒ½çš„3æµªé ‚é»\n",
        "    window = min(20, len(high) - 1)\n",
        "    peaks = []\n",
        "    troughs = []\n",
        "\n",
        "    # æ‰¾å‡ºæ‰€æœ‰å±€éƒ¨é«˜é»å’Œä½é»\n",
        "    for i in range(window, len(high) - window):\n",
        "        # æª¢æŸ¥æ˜¯å¦ç‚ºå±€éƒ¨é«˜é»\n",
        "        if high[i] == max(high[i-window:i+window+1]):\n",
        "            peaks.append((i, high[i]))\n",
        "        # æª¢æŸ¥æ˜¯å¦ç‚ºå±€éƒ¨ä½é»\n",
        "        if low[i] == min(low[i-window:i+window+1]):\n",
        "            troughs.append((i, low[i]))\n",
        "\n",
        "    # å¦‚æœæ²’æœ‰æ‰¾åˆ°è¶³å¤ çš„æ³¢å³°æ³¢è°·\n",
        "    if len(peaks) < 2 or len(troughs) < 2:\n",
        "        return False, \"ç„¡æ³•è­˜åˆ¥è¶³å¤ çš„æ³¢å³°æ³¢è°·\", None\n",
        "\n",
        "    # æŒ‰æ™‚é–“æ’åº\n",
        "    peaks.sort(key=lambda x: x[0])\n",
        "    troughs.sort(key=lambda x: x[0])\n",
        "\n",
        "    # å°‹æ‰¾å¯èƒ½çš„3æµªé«˜é»ï¼ˆæœ€å¾Œæˆ–å€’æ•¸ç¬¬äºŒå€‹é«˜é»ï¼‰\n",
        "    potential_wave3_peaks = []\n",
        "\n",
        "    # æª¢æŸ¥æœ€å¾Œä¸€å€‹é«˜é»\n",
        "    if peaks[-1][0] > troughs[-1][0]:  # æœ€å¾Œä¸€å€‹é«˜é»åœ¨æœ€å¾Œä¸€å€‹ä½é»ä¹‹å¾Œ\n",
        "        wave3_peak_idx, wave3_peak = peaks[-1]\n",
        "\n",
        "        # å°‹æ‰¾3æµªèµ·é»ï¼ˆå‰ä¸€å€‹ä½é»ï¼‰\n",
        "        for i in range(len(troughs) - 1, -1, -1):\n",
        "            if troughs[i][0] < wave3_peak_idx:\n",
        "                wave3_start_idx, wave3_start = troughs[i]\n",
        "                break\n",
        "        else:\n",
        "            wave3_start_idx, wave3_start = 0, low[0]\n",
        "\n",
        "        wave3_rise = wave3_peak - wave3_start\n",
        "        current_price = close[-1]\n",
        "        retracement = (wave3_peak - current_price) / wave3_rise if wave3_rise > 0 else 0\n",
        "\n",
        "        if 0.10 <= retracement <= 0.618:  # å›æ’¤æ¯”ä¾‹\n",
        "            potential_wave3_peaks.append((wave3_peak_idx, wave3_peak, wave3_start_idx, wave3_start, retracement))\n",
        "\n",
        "    # æª¢æŸ¥å€’æ•¸ç¬¬äºŒå€‹é«˜é»\n",
        "    if len(peaks) >= 2:\n",
        "        wave3_peak_idx, wave3_peak = peaks[-2]\n",
        "\n",
        "        # å°‹æ‰¾3æµªèµ·é»ï¼ˆå‰ä¸€å€‹ä½é»ï¼‰\n",
        "        for i in range(len(troughs) - 1, -1, -1):\n",
        "            if troughs[i][0] < wave3_peak_idx:\n",
        "                wave3_start_idx, wave3_start = troughs[i]\n",
        "                break\n",
        "        else:\n",
        "            wave3_start_idx, wave3_start = 0, low[0]\n",
        "\n",
        "        wave3_rise = wave3_peak - wave3_start\n",
        "        current_price = close[-1]\n",
        "        retracement = (wave3_peak - current_price) / wave3_rise if wave3_rise > 0 else 0\n",
        "\n",
        "        if 0.10 <= retracement <= 0.618:\n",
        "            potential_wave3_peaks.append((wave3_peak_idx, wave3_peak, wave3_start_idx, wave3_start, retracement))\n",
        "\n",
        "    # å¦‚æœæ²’æœ‰æ‰¾åˆ°å¯èƒ½çš„3æµªé«˜é»\n",
        "    if not potential_wave3_peaks:\n",
        "        return False, \"ç„¡æ³•è­˜åˆ¥ç¬¦åˆå›æ’¤æ¯”ä¾‹çš„3æµªé«˜é»\", None\n",
        "\n",
        "    # é¸æ“‡æœ€ä½³çš„3æµªé«˜é»ï¼ˆé¸æ“‡å›æ’¤æ¯”ä¾‹æœ€æ¥è¿‘0.382çš„ï¼‰\n",
        "    best_match = min(potential_wave3_peaks, key=lambda x: abs(x[4] - 0.382))\n",
        "    wave3_peak_idx, wave3_peak, wave3_start_idx, wave3_start, retracement = best_match\n",
        "\n",
        "    # æª¢æŸ¥æ˜¯å¦æœ‰1æµªé«˜é»\n",
        "    if wave3_start_idx > window:\n",
        "        # å°‹æ‰¾1æµªé«˜é»ï¼ˆåœ¨3æµªèµ·é»ä¹‹å‰çš„é«˜é»ï¼‰\n",
        "        wave1_candidates = [(i, h) for i, h in peaks if i < wave3_start_idx]\n",
        "        if wave1_candidates:\n",
        "            wave1_peak_idx, wave1_peak = max(wave1_candidates, key=lambda x: x[1])\n",
        "\n",
        "            # æª¢æŸ¥4æµªæ˜¯å¦èˆ‡1æµªé‡ç–Š\n",
        "            if close[-1] > wave1_peak:\n",
        "                wave_data = {\n",
        "                    'wave3_peak': wave3_peak,\n",
        "                    'wave3_start': wave3_start,\n",
        "                    'retracement': retracement,\n",
        "                    'current_price': close[-1],\n",
        "                    'wave1_peak': wave1_peak\n",
        "                }\n",
        "                return True, f\"4æµªå›æ’¤æ¯”ä¾‹: {retracement:.2%}, æœªèˆ‡1æµªé‡ç–Š\", wave_data\n",
        "            else:\n",
        "                return False, f\"4æµªèˆ‡1æµªé‡ç–Šï¼Œå›æ’¤æ¯”ä¾‹: {retracement:.2%}\", None\n",
        "        else:\n",
        "            # å¦‚æœæ‰¾ä¸åˆ°1æµªé«˜é»ï¼Œåƒ…ä¾æ“šå›æ’¤æ¯”ä¾‹åˆ¤æ–·\n",
        "            wave_data = {\n",
        "                'wave3_peak': wave3_peak,\n",
        "                'wave3_start': wave3_start,\n",
        "                'retracement': retracement,\n",
        "                'current_price': close[-1]\n",
        "            }\n",
        "            return True, f\"4æµªå›æ’¤æ¯”ä¾‹: {retracement:.2%}ï¼ˆç„¡æ³•ç¢ºèªèˆ‡1æµªé—œä¿‚ï¼‰\", wave_data\n",
        "    else:\n",
        "        wave_data = {\n",
        "            'wave3_peak': wave3_peak,\n",
        "            'wave3_start': wave3_start,\n",
        "            'retracement': retracement,\n",
        "            'current_price': close[-1]\n",
        "        }\n",
        "        return True, f\"4æµªå›æ’¤æ¯”ä¾‹: {retracement:.2%}ï¼ˆç„¡æ³•ç¢ºèªèˆ‡1æµªé—œä¿‚ï¼‰\", wave_data\n",
        "\n",
        "# =============================================================================\n",
        "# 5. æ©Ÿå™¨å­¸ç¿’é æ¸¬æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "class StockPredictor:\n",
        "    def __init__(self, target_days=7):\n",
        "        self.models = {\n",
        "            'ç·šæ€§è¿´æ­¸': LinearRegression(),\n",
        "            'éš¨æ©Ÿæ£®æ—': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "            'XGBoost': XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0),\n",
        "            'LightGBM': LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1)\n",
        "        }\n",
        "        self.scalers = {}\n",
        "        self.feature_names = None\n",
        "        self.target_days = target_days\n",
        "        self.backtest_results = {}\n",
        "        self.future_predictions = {}\n",
        "        self.feature_importances = None\n",
        "\n",
        "    def _prepare_data(self, df, predict_day):\n",
        "        \"\"\"æº–å‚™ç‰¹å¾µå’Œç›®æ¨™è®Šé‡\"\"\"\n",
        "        feature_columns = [\n",
        "            'MA5', 'MA10', 'MA20', 'MA60', 'MACD', 'MACD_Signal', 'RSI',\n",
        "            'BB_Width', 'BB_Position', 'K', 'D', 'Williams_R', 'ADX', 'CCI', 'MFI',\n",
        "            'Price_Change_1d', 'Price_Change_5d', 'Price_Change_20d',\n",
        "            'Volatility_5d', 'Volatility_20d', 'Momentum_14', 'Relative_Volume',\n",
        "            'FearGreedIndex'\n",
        "        ]\n",
        "        self.feature_names = [col for col in feature_columns if col in df.columns]\n",
        "\n",
        "        X = df[self.feature_names].copy()\n",
        "        y = df['Close'].shift(-predict_day)\n",
        "\n",
        "        valid_idx = ~y.isnull()\n",
        "        X = X[valid_idx]\n",
        "        y = y[valid_idx]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def run_backtest(self, df):\n",
        "        \"\"\"åŸ·è¡Œå›æ¸¬\"\"\"\n",
        "        logger.info(\"åŸ·è¡Œå›æ¸¬...\")\n",
        "        X, y = self._prepare_data(df, predict_day=1)\n",
        "\n",
        "        if len(X) < 50:\n",
        "            logger.warning(\"æ•¸æ“šé‡ä¸è¶³ï¼Œè·³éå›æ¸¬\")\n",
        "            return\n",
        "\n",
        "        split_index = int(len(X) * 0.8)\n",
        "        X_train, X_test = X[:split_index], X[split_index:]\n",
        "        y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            try:\n",
        "                model.fit(X_train_scaled, y_train)\n",
        "                y_pred = model.predict(X_test_scaled)\n",
        "                mse = mean_squared_error(y_test, y_pred)\n",
        "                r2 = r2_score(y_test, y_pred)\n",
        "                self.backtest_results[name] = {\n",
        "                    'y_test': y_test, 'y_pred': y_pred, 'mse': mse, 'r2': r2\n",
        "                }\n",
        "                logger.info(f\"[å›æ¸¬] {name} - RÂ²: {r2:.4f}, MSE: {mse:.4f}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"æ¨¡å‹ {name} è¨“ç·´å¤±æ•—: {e}\")\n",
        "\n",
        "        # ç‰¹å¾µé‡è¦æ€§\n",
        "        if 'éš¨æ©Ÿæ£®æ—' in self.models and hasattr(self.models['éš¨æ©Ÿæ£®æ—'], 'feature_importances_'):\n",
        "            self.feature_importances = pd.DataFrame({\n",
        "                'ç‰¹å¾µ': self.feature_names,\n",
        "                'é‡è¦æ€§': self.models['éš¨æ©Ÿæ£®æ—'].feature_importances_\n",
        "            }).sort_values('é‡è¦æ€§', ascending=False)\n",
        "\n",
        "    def predict_future(self, df):\n",
        "        \"\"\"é æ¸¬æœªä¾†åƒ¹æ ¼\"\"\"\n",
        "        logger.info(\"è¨“ç·´å®Œæ•´æ•¸æ“šé›†ä¸¦é æ¸¬æœªä¾†åƒ¹æ ¼...\")\n",
        "\n",
        "        for day in range(1, self.target_days + 1):\n",
        "            X, y = self._prepare_data(df, predict_day=day)\n",
        "\n",
        "            if X.empty or len(X) < 20:\n",
        "                logger.warning(f\"ç„¡æ³•ç‚ºé æ¸¬ç¬¬ {day} å¤©æº–å‚™æ•¸æ“šï¼Œè·³éã€‚\")\n",
        "                continue\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_scaled = scaler.fit_transform(X)\n",
        "            X_last = df[self.feature_names].iloc[-1:].copy()\n",
        "            X_last_scaled = scaler.transform(X_last)\n",
        "\n",
        "            daily_predictions = {}\n",
        "            for name, model in self.models.items():\n",
        "                try:\n",
        "                    model.fit(X_scaled, y)\n",
        "                    prediction = model.predict(X_last_scaled)[0]\n",
        "                    daily_predictions[name] = prediction\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"æ¨¡å‹ {name} é æ¸¬ç¬¬ {day} å¤©å¤±æ•—: {e}\")\n",
        "\n",
        "            if daily_predictions:\n",
        "                self.future_predictions[day] = daily_predictions\n",
        "\n",
        "# =============================================================================\n",
        "# 6. ç¶œåˆè©•åˆ†ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_combined_score(df):\n",
        "    \"\"\"è¨ˆç®—ç¶œåˆè©•åˆ†\"\"\"\n",
        "    if df.empty:\n",
        "        return 50\n",
        "\n",
        "    scores = []\n",
        "    latest = df.iloc[-1]\n",
        "\n",
        "    # æŠ€è¡“æŒ‡æ¨™è©•åˆ†\n",
        "    if 'RSI' in df.columns and not pd.isna(latest['RSI']):\n",
        "        rsi = latest['RSI']\n",
        "        if 30 <= rsi <= 50:\n",
        "            scores.append(70)  # æ½›åœ¨åå½ˆå€\n",
        "        elif 50 < rsi <= 70:\n",
        "            scores.append(60)  # å¼·å‹¢å€\n",
        "        elif rsi > 70:\n",
        "            scores.append(30)  # è¶…è²·\n",
        "        elif rsi < 30:\n",
        "            scores.append(80)  # è¶…è³£åå½ˆ\n",
        "        else:\n",
        "            scores.append(50)\n",
        "\n",
        "    # ç§»å‹•å¹³å‡ç·šè©•åˆ†\n",
        "    if all(col in df.columns for col in ['MA5', 'MA20', 'MA60']):\n",
        "        ma5, ma20, ma60 = latest['MA5'], latest['MA20'], latest['MA60']\n",
        "        if not any(pd.isna([ma5, ma20, ma60])):\n",
        "            if ma5 > ma20 > ma60:\n",
        "                scores.append(80)  # å¤šé ­æ’åˆ—\n",
        "            elif ma5 > ma20:\n",
        "                scores.append(65)  # çŸ­æœŸå¤šé ­\n",
        "            elif ma5 < ma20 < ma60:\n",
        "                scores.append(20)  # ç©ºé ­æ’åˆ—\n",
        "            else:\n",
        "                scores.append(45)\n",
        "\n",
        "    # MACDè©•åˆ†\n",
        "    if all(col in df.columns for col in ['MACD', 'MACD_Signal', 'MACD_Hist']):\n",
        "        macd, signal, hist = latest['MACD'], latest['MACD_Signal'], latest['MACD_Hist']\n",
        "        if not any(pd.isna([macd, signal, hist])):\n",
        "            if macd > signal and hist > 0:\n",
        "                scores.append(75)  # å¤šé ­ä¿¡è™Ÿ\n",
        "            elif macd > signal:\n",
        "                scores.append(60)  # æ½›åœ¨å¤šé ­\n",
        "            elif macd < signal and hist < 0:\n",
        "                scores.append(25)  # ç©ºé ­ä¿¡è™Ÿ\n",
        "            else:\n",
        "                scores.append(45)\n",
        "\n",
        "    # KDæŒ‡æ¨™è©•åˆ†\n",
        "    if all(col in df.columns for col in ['K', 'D']):\n",
        "        k, d = latest['K'], latest['D']\n",
        "        if not any(pd.isna([k, d])):\n",
        "            if k < 20 and d < 20:\n",
        "                scores.append(75)  # è¶…è³£\n",
        "            elif k > 80 and d > 80:\n",
        "                scores.append(25)  # è¶…è²·\n",
        "            elif k > d:\n",
        "                scores.append(60)  # é»ƒé‡‘äº¤å‰\n",
        "            else:\n",
        "                scores.append(40)  # æ­»äº¡äº¤å‰\n",
        "\n",
        "    # å¸ƒæ—å¸¶è©•åˆ†\n",
        "    if 'BB_Position' in df.columns and not pd.isna(latest['BB_Position']):\n",
        "        bb_pos = latest['BB_Position']\n",
        "        if bb_pos < 0.2:\n",
        "            scores.append(75)  # æ¥è¿‘ä¸‹è»Œ\n",
        "        elif bb_pos > 0.8:\n",
        "            scores.append(25)  # æ¥è¿‘ä¸Šè»Œ\n",
        "        else:\n",
        "            scores.append(50)\n",
        "\n",
        "    # åƒ¹æ ¼è¶¨å‹¢è©•åˆ†\n",
        "    if 'Price_Change_5d' in df.columns and not pd.isna(latest['Price_Change_5d']):\n",
        "        change = latest['Price_Change_5d']\n",
        "        if change > 0.1:\n",
        "            scores.append(80)  # å¼·å‹¢ä¸Šæ¼²\n",
        "        elif change > 0.05:\n",
        "            scores.append(65)  # æº«å’Œä¸Šæ¼²\n",
        "        elif change > 0:\n",
        "            scores.append(55)  # å¾®å¹…ä¸Šæ¼²\n",
        "        elif change > -0.05:\n",
        "            scores.append(45)  # å¾®å¹…ä¸‹è·Œ\n",
        "        elif change > -0.1:\n",
        "            scores.append(35)  # æº«å’Œä¸‹è·Œ\n",
        "        else:\n",
        "            scores.append(20)  # å¤§å¹…ä¸‹è·Œ\n",
        "\n",
        "    # æˆäº¤é‡è©•åˆ†\n",
        "    if 'Relative_Volume' in df.columns and not pd.isna(latest['Relative_Volume']):\n",
        "        vol_ratio = latest['Relative_Volume']\n",
        "        if vol_ratio > 2:\n",
        "            scores.append(70)  # çˆ†é‡\n",
        "        elif vol_ratio > 1.5:\n",
        "            scores.append(60)  # æ”¾é‡\n",
        "        elif vol_ratio < 0.5:\n",
        "            scores.append(40)  # ç¸®é‡\n",
        "        else:\n",
        "            scores.append(50)\n",
        "\n",
        "    # ææ‡¼è²ªå©ªæŒ‡æ•¸è©•åˆ†\n",
        "    if 'FearGreedIndex' in df.columns and not pd.isna(latest['FearGreedIndex']):\n",
        "        fgi = latest['FearGreedIndex']\n",
        "        if fgi < 25:\n",
        "            scores.append(75)  # æ¥µåº¦ææ‡¼ï¼Œåå½ˆæ©Ÿæœƒ\n",
        "        elif fgi < 45:\n",
        "            scores.append(65)  # ææ‡¼ï¼Œæ½›åœ¨æ©Ÿæœƒ\n",
        "        elif fgi > 75:\n",
        "            scores.append(30)  # æ¥µåº¦è²ªå©ªï¼Œé¢¨éšªé«˜\n",
        "        elif fgi > 55:\n",
        "            scores.append(40)  # è²ªå©ªï¼Œè¬¹æ…\n",
        "        else:\n",
        "            scores.append(50)  # ä¸­æ€§\n",
        "\n",
        "    return np.mean(scores) if scores else 50\n",
        "\n",
        "# =============================================================================\n",
        "# 7. æ™ºèƒ½å»ºè­°ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "def generate_recommendation(combined_score, pattern_report=None, wave_analysis=None):\n",
        "    \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "    try:\n",
        "        combined_score = float(combined_score)\n",
        "    except (ValueError, TypeError):\n",
        "        combined_score = 50.0\n",
        "\n",
        "    recommendation = {\n",
        "        \"action\": \"ä¸­ç«‹è§€å¯Ÿ\",\n",
        "        \"reason\": f\"ç¶œåˆè©•åˆ†ä¸­æ€§ ({combined_score:.2f})ã€‚\",\n",
        "        \"pattern_details\": [],\n",
        "        \"confidence\": 50,\n",
        "        \"risk_level\": \"ä¸­ç­‰\"\n",
        "    }\n",
        "\n",
        "    # åŸºæ–¼è©•åˆ†çš„å»ºè­°\n",
        "    if combined_score >= 80:\n",
        "        recommendation[\"action\"] = \"å¼·çƒˆè²·å…¥\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†æ¥µä½³ ({combined_score:.2f})ï¼Œå¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹¢ã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä½\"\n",
        "    elif combined_score >= 70:\n",
        "        recommendation[\"action\"] = \"è²·å…¥\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†è‰¯å¥½ ({combined_score:.2f})ï¼ŒæŠ€è¡“é¢åå¤šã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä½-ä¸­ç­‰\"\n",
        "    elif combined_score >= 60:\n",
        "        recommendation[\"action\"] = \"è²·å…¥è§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼· ({combined_score:.2f})ï¼Œå¯è€ƒæ…®åˆ†æ‰¹é€²å ´ã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä¸­ç­‰\"\n",
        "    elif combined_score <= 20:\n",
        "        recommendation[\"action\"] = \"å¼·çƒˆè³£å‡º\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†æ¥µå·® ({combined_score:.2f})ï¼Œå¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼±å‹¢ã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"é«˜\"\n",
        "    elif combined_score <= 30:\n",
        "        recommendation[\"action\"] = \"è³£å‡º\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†ç–²å¼± ({combined_score:.2f})ï¼ŒæŠ€è¡“é¢åç©ºã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä¸­ç­‰-é«˜\"\n",
        "    elif combined_score <= 40:\n",
        "        recommendation[\"action\"] = \"è³£å‡ºè§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼± ({combined_score:.2f})ï¼Œå»ºè­°æ¸›å€‰ã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä¸­ç­‰\"\n",
        "\n",
        "    # æ•´åˆKç·šå‹æ…‹åˆ†æ\n",
        "    if pattern_report and \"çœ‹æ¼²\" in pattern_report:\n",
        "        if combined_score >= 60:\n",
        "            recommendation[\"pattern_details\"].append(\"Kç·šå‹æ…‹æ”¯æŒçœ‹æ¼²è§€é»\")\n",
        "        else:\n",
        "            recommendation[\"pattern_details\"].append(\"Kç·šå‹æ…‹çœ‹æ¼²ä½†å…¶ä»–æŒ‡æ¨™åå¼±\")\n",
        "\n",
        "    if pattern_report and \"çœ‹è·Œ\" in pattern_report:\n",
        "        if combined_score <= 40:\n",
        "            recommendation[\"pattern_details\"].append(\"Kç·šå‹æ…‹æ”¯æŒçœ‹è·Œè§€é»\")\n",
        "        else:\n",
        "            recommendation[\"pattern_details\"].append(\"Kç·šå‹æ…‹çœ‹è·Œä½†å…¶ä»–æŒ‡æ¨™åå¼·\")\n",
        "\n",
        "    # æ•´åˆæ³¢æµªç†è«–åˆ†æ\n",
        "    if wave_analysis and wave_analysis[0]:  # å¦‚æœæ³¢æµªåˆ†æç‚ºTrue\n",
        "        recommendation[\"pattern_details\"].append(f\"æ³¢æµªç†è«–: {wave_analysis[1]}\")\n",
        "        if \"4æµªå›æ’¤\" in wave_analysis[1]:\n",
        "            if combined_score >= 60:\n",
        "                recommendation[\"action\"] = \"è²·å…¥\"\n",
        "                recommendation[\"reason\"] += \" æ³¢æµªç†è«–æ”¯æŒ5æµªä¸Šæ¼²ã€‚\"\n",
        "\n",
        "    # è¨ˆç®—ä¿¡å¿ƒåº¦\n",
        "    distance_from_center = abs(combined_score - 50)\n",
        "    base_confidence = min(distance_from_center * 2, 100)\n",
        "\n",
        "    # æ ¹æ“šå‹æ…‹åˆ†æèª¿æ•´ä¿¡å¿ƒåº¦\n",
        "    if recommendation[\"pattern_details\"]:\n",
        "        base_confidence = min(base_confidence + 10, 100)\n",
        "\n",
        "    recommendation['confidence'] = int(base_confidence)\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "# =============================================================================\n",
        "# 8. å¯è¦–åŒ–æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "class StockVisualizer:\n",
        "    def __init__(self, symbol):\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def plot_stock_analysis(self, df):\n",
        "        \"\"\"ç¹ªè£½è‚¡ç¥¨æŠ€è¡“åˆ†æåœ–\"\"\"\n",
        "        fig, axes = plt.subplots(4, 1, figsize=(16, 16), sharex=True)\n",
        "        fig.suptitle(f'{self.symbol} å®Œæ•´æŠ€è¡“åˆ†æç¸½è¦½', fontsize=20, fontweight='bold')\n",
        "\n",
        "        # åƒ¹æ ¼èˆ‡ç§»å‹•å¹³å‡ç·šã€å¸ƒæ—å¸¶\n",
        "        axes[0].plot(df['Date'], df['Close'], label='æ”¶ç›¤åƒ¹', linewidth=2, color='black')\n",
        "        if 'MA5' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['MA5'], label='MA5', alpha=0.8, color='blue')\n",
        "        if 'MA20' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['MA20'], label='MA20', alpha=0.8, color='red')\n",
        "        if 'MA60' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['MA60'], label='MA60', alpha=0.8, color='green')\n",
        "        if 'BB_Upper' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['BB_Upper'], label='å¸ƒæ—ä¸Šè»Œ', linestyle='--', alpha=0.7, color='gray')\n",
        "            axes[0].plot(df['Date'], df['BB_Lower'], label='å¸ƒæ—ä¸‹è»Œ', linestyle='--', alpha=0.7, color='gray')\n",
        "            axes[0].fill_between(df['Date'], df['BB_Lower'], df['BB_Upper'], alpha=0.1, color='gray')\n",
        "        axes[0].set_title('åƒ¹æ ¼èµ°å‹¢èˆ‡ç§»å‹•å¹³å‡ç·š')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # MACD\n",
        "        if 'MACD' in df.columns:\n",
        "            axes[1].plot(df['Date'], df['MACD'], label='MACD', color='blue')\n",
        "            axes[1].plot(df['Date'], df['MACD_Signal'], label='è¨Šè™Ÿç·š', color='red', linestyle='--')\n",
        "            if 'MACD_Hist' in df.columns:\n",
        "                colors = ['green' if x >= 0 else 'red' for x in df['MACD_Hist']]\n",
        "                axes[1].bar(df['Date'], df['MACD_Hist'], label='MACDæŸ±ç‹€åœ–', color=colors, alpha=0.6)\n",
        "        axes[1].set_title('MACD')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        axes[1].axhline(0, color='black', linestyle='-', alpha=0.3)\n",
        "\n",
        "        # RSI å’Œ KD\n",
        "        if 'RSI' in df.columns:\n",
        "            axes[2].plot(df['Date'], df['RSI'], label='RSI', color='purple', linewidth=2)\n",
        "            axes[2].axhline(70, color='red', linestyle='--', alpha=0.7, label='è¶…è²·å€ (70)')\n",
        "            axes[2].axhline(30, color='green', linestyle='--', alpha=0.7, label='è¶…è³£å€ (30)')\n",
        "            axes[2].axhline(50, color='black', linestyle='-', alpha=0.3)\n",
        "        if 'K' in df.columns and 'D' in df.columns:\n",
        "            axes[2].plot(df['Date'], df['K'], label='Kå€¼', color='orange', alpha=0.8)\n",
        "            axes[2].plot(df['Date'], df['D'], label='Då€¼', color='brown', alpha=0.8)\n",
        "        axes[2].set_title('RSI èˆ‡ KD æŒ‡æ¨™')\n",
        "        axes[2].legend()\n",
        "        axes[2].grid(True, alpha=0.3)\n",
        "        axes[2].set_ylim(0, 100)\n",
        "\n",
        "        # æˆäº¤é‡\n",
        "        volume_colors = ['green' if df['Close'].iloc[i] >= df['Open'].iloc[i] else 'red'\n",
        "                        for i in range(len(df))]\n",
        "        axes[3].bar(df['Date'], df['Volume'], color=volume_colors, alpha=0.6, label='æˆäº¤é‡')\n",
        "        if 'Volume_MA' in df.columns:\n",
        "            axes[3].plot(df['Date'], df['Volume_MA'], label='æˆäº¤é‡å‡ç·š', color='blue', linewidth=2)\n",
        "        axes[3].set_title('æˆäº¤é‡')\n",
        "        axes[3].legend()\n",
        "        axes[3].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "        return fig\n",
        "\n",
        "    def plot_future_prediction(self, last_price, last_date, predictions):\n",
        "        \"\"\"ç¹ªè£½æœªä¾†é æ¸¬åœ–\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        pred_dates, pred_prices_avg, pred_prices_std = [], [], []\n",
        "\n",
        "        current_date = last_date\n",
        "        for day, preds in predictions.items():\n",
        "            while True:\n",
        "                current_date += timedelta(days=1)\n",
        "                if current_date.weekday() < 5:  # å·¥ä½œæ—¥\n",
        "                    break\n",
        "\n",
        "            pred_dates.append(current_date)\n",
        "            prices = list(preds.values())\n",
        "            avg_price = np.mean(prices)\n",
        "            std_price = np.std(prices)\n",
        "            pred_prices_avg.append(avg_price)\n",
        "            pred_prices_std.append(std_price)\n",
        "\n",
        "        # ç¹ªè£½å¹³å‡é æ¸¬åƒ¹æ ¼\n",
        "        ax.plot(pred_dates, pred_prices_avg, 'ro-', label='å¹³å‡é æ¸¬åƒ¹æ ¼', linewidth=2, markersize=8)\n",
        "\n",
        "       # ç¹ªè£½ä¿¡å¿ƒå€é–“\n",
        "        upper_bound = np.array(pred_prices_avg) + np.array(pred_prices_std)\n",
        "        lower_bound = np.array(pred_prices_avg) - np.array(pred_prices_std)\n",
        "        ax.fill_between(pred_dates, lower_bound, upper_bound, alpha=0.3, color='blue', label='é æ¸¬å€é–“')\n",
        "\n",
        "        # ç•¶å‰åƒ¹æ ¼ç·š\n",
        "        ax.axhline(last_price, color='gray', linestyle='--', label=f'ç•¶å‰åƒ¹æ ¼ ({last_price:.2f})', linewidth=2)\n",
        "\n",
        "        # æ¨™è¨»é æ¸¬åƒ¹æ ¼\n",
        "        for date, price, std in zip(pred_dates, pred_prices_avg, pred_prices_std):\n",
        "            change_pct = (price / last_price - 1) * 100\n",
        "            ax.text(date, price, f'{price:.2f}\\n({change_pct:+.1f}%)',\n",
        "                   ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "        ax.set_title(f'{self.symbol} æœªä¾†ä¸€é€±è‚¡åƒ¹é æ¸¬', fontsize=16, fontweight='bold')\n",
        "        ax.set_xlabel('æ—¥æœŸ')\n",
        "        ax.set_ylabel('é æ¸¬åƒ¹æ ¼')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # æ ¼å¼åŒ–æ—¥æœŸè»¸\n",
        "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_feature_importance(self, importances):\n",
        "        \"\"\"ç¹ªè£½ç‰¹å¾µé‡è¦æ€§åœ–\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "        top_15 = importances.head(15)\n",
        "\n",
        "        bars = ax.barh(top_15['ç‰¹å¾µ'], top_15['é‡è¦æ€§'], color='skyblue', edgecolor='navy', alpha=0.7)\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_title('ç‰¹å¾µé‡è¦æ€§æ’å (éš¨æ©Ÿæ£®æ—)', fontsize=16, fontweight='bold')\n",
        "        ax.set_xlabel('é‡è¦æ€§')\n",
        "\n",
        "        # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
        "        for bar, value in zip(bars, top_15['é‡è¦æ€§']):\n",
        "            ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2,\n",
        "                   f'{value:.3f}', ha='left', va='center', fontweight='bold')\n",
        "\n",
        "        ax.grid(True, alpha=0.3, axis='x')\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "# =============================================================================\n",
        "# 9. é€šçŸ¥ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, chart_files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        if TELEGRAM_TOKEN and TELEGRAM_CHAT_ID:\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_ID:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† è‚¡ç¥¨åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {'chat_id': chat_id, 'text': part}\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id}\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—: {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤: {e}\")\n",
        "\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "                # ç™¼é€åœ–è¡¨æ–‡ä»¶\n",
        "                if chart_files:\n",
        "                    telegram_photo_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                    for chart_file in chart_files:\n",
        "                        if os.path.exists(chart_file):\n",
        "                            try:\n",
        "                                with open(chart_file, 'rb') as photo:\n",
        "                                    files = {'photo': photo}\n",
        "                                    data = {'chat_id': chat_id}\n",
        "\n",
        "                                    import requests\n",
        "                                    response = requests.post(telegram_photo_url, files=files, data=data, timeout=30)\n",
        "\n",
        "                                    if response.status_code == 200:\n",
        "                                        logger.info(f\"æˆåŠŸç™¼é€åœ–è¡¨åˆ° Telegram: {chart_file}\")\n",
        "                                    else:\n",
        "                                        logger.error(f\"ç™¼é€åœ–è¡¨å¤±æ•—: {response.status_code}\")\n",
        "                            except Exception as e:\n",
        "                                logger.error(f\"ç™¼é€åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL:\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "\n",
        "            if chart_files:\n",
        "                for chart_file in chart_files:\n",
        "                    if os.path.exists(chart_file):\n",
        "                        with open(chart_file, \"rb\") as f:\n",
        "                            webhook.add_file(file=f.read(), filename=os.path.basename(chart_file))\n",
        "\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºé€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        if not successful_results:\n",
        "            return \"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\"\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message = f\"ğŸ† å¤šè‚¡ç¥¨æŠ€è¡“åˆ†æå ±å‘Š\\n\"\n",
        "        message += f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "        message += f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\\n\\n\"\n",
        "\n",
        "        message += \"ğŸ… å‰ååå„ªè³ªè‚¡ç¥¨:\\n\"\n",
        "        message += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            symbol = result.get('symbol', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            current_price = result.get('last_price', 0)\n",
        "            recommendation = result.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "\n",
        "            message += f\"{i:2d}. {symbol}\\n\"\n",
        "            message += f\"    ğŸ’° åƒ¹æ ¼: {current_price:.2f}\\n\"\n",
        "            message += f\"    ğŸ“Š è©•åˆ†: {score:.1f} | ğŸ¯ {recommendation}\\n\\n\"\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰ä¸‰å\n",
        "        message += \"\\nğŸ“Š è©³ç´°åˆ†æ (å‰ä¸‰å):\\n\"\n",
        "        message += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:3], 1):\n",
        "            symbol = result.get('symbol', 'Unknown')\n",
        "\n",
        "            message += f\"\\n{i}. {symbol}\\n\"\n",
        "            if 'data_df' in result and not result['data_df'].empty:\n",
        "                latest = result['data_df'].iloc[-1]\n",
        "                if 'RSI' in result['data_df'].columns:\n",
        "                    message += f\"ğŸ” RSI: {latest['RSI']:.1f}\\n\"\n",
        "                if 'MACD' in result['data_df'].columns:\n",
        "                    macd_signal = \"å¤šé ­\" if latest['MACD'] > latest.get('MACD_Signal', 0) else \"ç©ºé ­\"\n",
        "                    message += f\"ğŸ“ˆ MACD: {macd_signal}\\n\"\n",
        "\n",
        "        message += \"\\nâš ï¸ æŠ•è³‡æé†’:\\n\"\n",
        "        message += \"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\\n\"\n",
        "        message += \"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæ±ºç­–\\n\"\n",
        "        message += \"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\"\n",
        "\n",
        "        return message\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "# =============================================================================\n",
        "# 10. è‚¡ç¥¨ç¯©é¸å™¨\n",
        "# =============================================================================\n",
        "\n",
        "def screen_stocks(stock_list, days_back, condition):\n",
        "    \"\"\"ç¯©é¸ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\"\"\"\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=days_back * 2)\n",
        "    results = pd.DataFrame(columns=['ticker', 'close', 'volume', 'change_pct'])\n",
        "\n",
        "    for ticker in stock_list:\n",
        "        try:\n",
        "            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "            if data.empty or len(data) < 20:\n",
        "                continue\n",
        "\n",
        "            data = data.tail(days_back)\n",
        "            data['change_pct'] = data['Close'].pct_change() * 100\n",
        "\n",
        "            if condition == \"çªç ´æ•´ç†å€é–“\":\n",
        "                high_20d = data['High'].rolling(window=20).max().shift(1)\n",
        "                if data['Close'].iloc[-1] > high_20d.iloc[-1]:\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"çˆ†é‡é•·ç´…\":\n",
        "                vol_5d_avg = data['Volume'].rolling(window=5).mean().shift(1)\n",
        "                if (data['Volume'].iloc[-1] > vol_5d_avg.iloc[-1] * 2 and\n",
        "                    data['change_pct'].iloc[-1] > 3):\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"çªç ´å­£ç·š\":\n",
        "                ma60 = data['Close'].rolling(window=60).mean()\n",
        "                if (data['Close'].iloc[-1] > ma60.iloc[-1] and\n",
        "                    data['Close'].iloc[-2] <= ma60.iloc[-2]):\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"å¤šé ­åå™¬\":\n",
        "                if len(data) >= 2:\n",
        "                    prev_candle = data.iloc[-2]\n",
        "                    curr_candle = data.iloc[-1]\n",
        "                    if (prev_candle['Close'] < prev_candle['Open'] and  # å‰ä¸€æ ¹ç‚ºé™°ç·š\n",
        "                        curr_candle['Close'] > curr_candle['Open'] and  # ç•¶å‰ç‚ºé™½ç·š\n",
        "                        curr_candle['Open'] < prev_candle['Close'] and  # ä½é–‹\n",
        "                        curr_candle['Close'] > prev_candle['Open']):    # é«˜æ”¶\n",
        "                        results = pd.concat([results, pd.DataFrame({\n",
        "                            'ticker': [ticker],\n",
        "                            'close': [data['Close'].iloc[-1]],\n",
        "                            'volume': [data['Volume'].iloc[-1]],\n",
        "                            'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                        })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰\":\n",
        "                ma5 = data['Close'].rolling(window=5).mean()\n",
        "                ma20 = data['Close'].rolling(window=20).mean()\n",
        "                if (ma5.iloc[-1] > ma20.iloc[-1] and\n",
        "                    ma5.iloc[-2] <= ma20.iloc[-2]):\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return results\n",
        "\n",
        "# =============================================================================\n",
        "# 11. ä¸»è¦åˆ†æç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "class MultiStockAnalysisSystem:\n",
        "    def __init__(self, symbols, period='1y'):\n",
        "        self.symbols = symbols if isinstance(symbols, list) else [symbols]\n",
        "        self.period = period\n",
        "        self.results = {}\n",
        "\n",
        "    async def analyze_stock(self, symbol):\n",
        "        \"\"\"åˆ†æå–®ä¸€è‚¡ç¥¨\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æ {symbol}...\")\n",
        "\n",
        "            # 1. ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            stock_df = fetch_stock_data(symbol, self.period)\n",
        "            if stock_df is None:\n",
        "                return None\n",
        "\n",
        "            # 2. ç²å–ææ‡¼è²ªå©ªæŒ‡æ•¸\n",
        "            days_needed = len(stock_df)\n",
        "            sentiment_df = get_fear_and_greed_data(days=days_needed + 60)\n",
        "\n",
        "            # 3. åˆä½µæ•¸æ“š\n",
        "            df = pd.merge(stock_df, sentiment_df, on='Date', how='left')\n",
        "\n",
        "            # 4. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—\n",
        "            df = calculate_technical_indicators(df)\n",
        "            df = feature_engineering(df)\n",
        "\n",
        "            # 5. Kç·šå‹æ…‹åˆ†æ\n",
        "            pattern_report = generate_pattern_report(df)\n",
        "\n",
        "            # 6. æ³¢æµªç†è«–åˆ†æ\n",
        "            wave_analysis = wave_theory_analysis(df, symbol)\n",
        "\n",
        "            # 7. ç¶œåˆè©•åˆ†\n",
        "            combined_score = calculate_combined_score(df)\n",
        "\n",
        "            # 8. æ©Ÿå™¨å­¸ç¿’é æ¸¬\n",
        "            predictor = StockPredictor()\n",
        "            predictor.run_backtest(df)\n",
        "            predictor.predict_future(df)\n",
        "\n",
        "            # 9. ç”Ÿæˆå»ºè­°\n",
        "            recommendation = generate_recommendation(combined_score, pattern_report, wave_analysis)\n",
        "\n",
        "            # 10. ç”Ÿæˆåœ–è¡¨\n",
        "            visualizer = StockVisualizer(symbol)\n",
        "\n",
        "            # ä¿å­˜åœ–è¡¨\n",
        "            chart_files = []\n",
        "\n",
        "            # æŠ€è¡“åˆ†æåœ–\n",
        "            fig1 = visualizer.plot_stock_analysis(df)\n",
        "            chart_path1 = os.path.join(CHARTS_DIR, f\"{symbol}_technical.png\")\n",
        "            fig1.savefig(chart_path1, dpi=150, bbox_inches='tight')\n",
        "            chart_files.append(chart_path1)\n",
        "            plt.close(fig1)\n",
        "\n",
        "            # é æ¸¬åœ–\n",
        "            if predictor.future_predictions:\n",
        "                fig2 = visualizer.plot_future_prediction(\n",
        "                    df['Close'].iloc[-1], df['Date'].iloc[-1], predictor.future_predictions\n",
        "                )\n",
        "                chart_path2 = os.path.join(CHARTS_DIR, f\"{symbol}_prediction.png\")\n",
        "                fig2.savefig(chart_path2, dpi=150, bbox_inches='tight')\n",
        "                chart_files.append(chart_path2)\n",
        "                plt.close(fig2)\n",
        "\n",
        "            # ç‰¹å¾µé‡è¦æ€§åœ–\n",
        "            if predictor.feature_importances is not None:\n",
        "                fig3 = visualizer.plot_feature_importance(predictor.feature_importances)\n",
        "                chart_path3 = os.path.join(CHARTS_DIR, f\"{symbol}_features.png\")\n",
        "                fig3.savefig(chart_path3, dpi=150, bbox_inches='tight')\n",
        "                chart_files.append(chart_path3)\n",
        "                plt.close(fig3)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'data_df': df,\n",
        "                'combined_score': combined_score,\n",
        "                'pattern_report': pattern_report,\n",
        "                'wave_analysis': wave_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'predictor': predictor,\n",
        "                'chart_files': chart_files,\n",
        "                'last_price': df['Close'].iloc[-1],\n",
        "                'last_date': df['Date'].iloc[-1],\n",
        "                'success': True\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ {symbol}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'symbol': symbol, 'success': False, 'error': str(e)}\n",
        "\n",
        "    async def run_analysis(self):\n",
        "        \"\"\"åŸ·è¡Œå¤šè‚¡ç¥¨åˆ†æ\"\"\"\n",
        "        logger.info(f\"é–‹å§‹åˆ†æ {len(self.symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "        # ä¸¦è¡Œåˆ†ææ‰€æœ‰è‚¡ç¥¨\n",
        "        tasks = [self.analyze_stock(symbol) for symbol in self.symbols]\n",
        "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "        # æ•´ç†çµæœ\n",
        "        for i, result in enumerate(results):\n",
        "            if isinstance(result, Exception):\n",
        "                logger.error(f\"åˆ†æ {self.symbols[i]} æ™‚ç™¼ç”Ÿç•°å¸¸: {result}\")\n",
        "            elif result is not None:\n",
        "                self.results[self.symbols[i]] = result\n",
        "\n",
        "        # ç”Ÿæˆç¸½çµå ±å‘Š\n",
        "        await self.generate_summary_report()\n",
        "\n",
        "    async def generate_summary_report(self):\n",
        "        \"\"\"ç”Ÿæˆç¸½çµå ±å‘Šä¸¦ç™¼é€é€šçŸ¥\"\"\"\n",
        "        if not self.results:\n",
        "            logger.warning(\"æ²’æœ‰æˆåŠŸåˆ†æçš„è‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # ç”Ÿæˆå ±å‘Šæ–‡æœ¬\n",
        "        report_text = format_analysis_message(self.results, limit=10)\n",
        "\n",
        "        # æ”¶é›†æ‰€æœ‰åœ–è¡¨æ–‡ä»¶\n",
        "        all_chart_files = []\n",
        "        for result in self.results.values():\n",
        "            if result.get('success', False):\n",
        "                all_chart_files.extend(result.get('chart_files', []))\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, report_text, all_chart_files)\n",
        "\n",
        "        # çµ‚ç«¯é¡¯ç¤º\n",
        "        print(\"\\n\" + report_text)\n",
        "\n",
        "# =============================================================================\n",
        "# 12. Shioaji æ•´åˆæ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "if SHIOAJI_AVAILABLE:\n",
        "    class ShioajiStockScanner:\n",
        "        def __init__(self, api_key, secret_key, max_retries=3):\n",
        "            self.api_key = api_key\n",
        "            self.secret_key = secret_key\n",
        "            self.max_retries = max_retries\n",
        "            self.api = None\n",
        "            self.connect()\n",
        "\n",
        "        def connect(self):\n",
        "            \"\"\"å»ºç«‹é€£æ¥ä¸¦è™•ç†é‡è©¦é‚è¼¯\"\"\"\n",
        "            retries = 0\n",
        "            while retries < self.max_retries:\n",
        "                try:\n",
        "                    if self.api is not None:\n",
        "                        try:\n",
        "                            self.api.logout()\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                    self.api = sj.Shioaji()\n",
        "                    self.api.login(self.api_key, self.secret_key)\n",
        "                    logger.info(\"Shioaji ç™»å…¥æˆåŠŸ\")\n",
        "                    return True\n",
        "                except Exception as e:\n",
        "                    retries += 1\n",
        "                    logger.error(f\"Shioaji ç™»å…¥å˜—è©¦ {retries} å¤±æ•—: {str(e)}\")\n",
        "                    if \"Too Many Connections\" in str(e):\n",
        "                        logger.info(\"ç­‰å¾…é€£æ¥é‡‹æ”¾...\")\n",
        "                        time.sleep(10 + random.randint(1, 5))\n",
        "                    else:\n",
        "                        time.sleep(2)\n",
        "\n",
        "            logger.error(\"è¶…éæœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œç„¡æ³•å»ºç«‹é€£æ¥\")\n",
        "            return False\n",
        "\n",
        "        def get_stock_list(self, max_stocks=50):\n",
        "            \"\"\"ç²å–å°è‚¡æ¸…å–®\"\"\"\n",
        "            if not self.api:\n",
        "                if not self.connect():\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "            tse_stocks = self.api.Contracts.Stocks.TSE\n",
        "            otc_stocks = self.api.Contracts.Stocks.OTC\n",
        "\n",
        "            stock_list = []\n",
        "            count = 0\n",
        "\n",
        "            # å…ˆå–ä¸Šå¸‚è‚¡ç¥¨\n",
        "            for stock in tse_stocks:\n",
        "                try:\n",
        "                    stock_code = stock.code\n",
        "                    if len(stock_code) == 4 and stock_code.isdigit():\n",
        "                        stock_list.append({\n",
        "                            'code': stock_code,\n",
        "                            'name': stock.name,\n",
        "                            'exchange': stock.exchange\n",
        "                        })\n",
        "                        count += 1\n",
        "                        if count >= max_stocks:\n",
        "                            break\n",
        "                except AttributeError:\n",
        "                    continue\n",
        "\n",
        "            # å¦‚æœä¸Šå¸‚è‚¡ç¥¨ä¸è¶³ï¼Œå†å–ä¸Šæ«ƒè‚¡ç¥¨\n",
        "            if count < max_stocks:\n",
        "                for stock in otc_stocks:\n",
        "                    try:\n",
        "                        stock_code = stock.code\n",
        "                        if len(stock_code) == 4 and stock_code.isdigit():\n",
        "                            stock_list.append({\n",
        "                                'code': stock_code,\n",
        "                                'name': stock.name,\n",
        "                                'exchange': stock.exchange\n",
        "                            })\n",
        "                            count += 1\n",
        "                            if count >= max_stocks:\n",
        "                                break\n",
        "                    except AttributeError:\n",
        "                        continue\n",
        "\n",
        "            df = pd.DataFrame(stock_list)\n",
        "            logger.info(f\"ç²å–åˆ° {len(df)} æ”¯å°è‚¡è³‡æ–™\")\n",
        "            return df\n",
        "\n",
        "        def __del__(self):\n",
        "            \"\"\"æ¸…ç†è³‡æº\"\"\"\n",
        "            if hasattr(self, 'api') and self.api:\n",
        "                try:\n",
        "                    self.api.logout()\n",
        "                    logger.info(\"Shioaji æˆåŠŸç™»å‡º\")\n",
        "                except:\n",
        "                    logger.error(\"Shioaji ç™»å‡ºæ™‚ç™¼ç”ŸéŒ¯èª¤\")\n",
        "\n",
        "# =============================================================================\n",
        "# 13. UI ä»‹é¢ (Jupyter Notebook)\n",
        "# =============================================================================\n",
        "\n",
        "if JUPYTER_AVAILABLE:\n",
        "    def create_stock_analysis_ui():\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨åˆ†æUIä»‹é¢\"\"\"\n",
        "        style = {'description_width': '120px'}\n",
        "        layout = Layout(width='300px')\n",
        "\n",
        "        # æ§åˆ¶å…ƒä»¶\n",
        "        symbol_input = widgets.Text(\n",
        "            value='AAPL,TSLA,2330,2454',\n",
        "            placeholder='è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼Œç”¨é€—è™Ÿåˆ†éš”',\n",
        "            description='è‚¡ç¥¨ä»£ç¢¼:',\n",
        "            style=style,\n",
        "            layout=Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        period_dropdown = widgets.Dropdown(\n",
        "            options=[('1å¹´', '1y'), ('2å¹´', '2y'), ('5å¹´', '5y'), ('æœ€å¤§', 'max')],\n",
        "            value='1y',\n",
        "            description='æ™‚é–“ç¯„åœ:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        analyze_button = widgets.Button(\n",
        "            description='é–‹å§‹åˆ†æ',\n",
        "            button_style='primary',\n",
        "            layout=Layout(width='150px', height='40px')\n",
        "        )\n",
        "\n",
        "        output_area = widgets.Output()\n",
        "\n",
        "        def on_analyze_click(b):\n",
        "            with output_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"ğŸš€ é–‹å§‹åˆ†æ...\")\n",
        "\n",
        "                symbols = [s.strip().upper() for s in symbol_input.value.split(',') if s.strip()]\n",
        "                if not symbols:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    return\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem(symbols, period_dropdown.value)\n",
        "\n",
        "                    # åœ¨ Jupyter ä¸­é‹è¡Œç•°æ­¥ä»£ç¢¼\n",
        "                    loop = asyncio.get_event_loop()\n",
        "                    loop.run_until_complete(system.run_analysis())\n",
        "\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼è«‹æŸ¥çœ‹ç”Ÿæˆçš„åœ–è¡¨å’Œé€šçŸ¥ã€‚\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        analyze_button.on_click(on_analyze_click)\n",
        "\n",
        "        # çµ„åˆUI\n",
        "        ui = VBox([\n",
        "            HTML('<h2>ğŸ“ˆ å¤šè‚¡ç¥¨åˆ†æç³»çµ±</h2>'),\n",
        "            HTML('<p>æ”¯æ´å°è‚¡(è¼¸å…¥æ•¸å­—ä»£ç¢¼å¦‚2330)å’Œç¾è‚¡(è¼¸å…¥å­—æ¯ä»£ç¢¼å¦‚AAPL)</p>'),\n",
        "            symbol_input,\n",
        "            period_dropdown,\n",
        "            analyze_button,\n",
        "            output_area\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "    def create_stock_screener_ui():\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨ç¯©é¸å™¨UI\"\"\"\n",
        "        tw_stocks = [\n",
        "            '2330', '2317', '2454', '2881', '2882', '2883', '2884', '2885',\n",
        "            '2886', '2887', '2888', '2889', '2890', '2891', '2892', '2912'\n",
        "        ]\n",
        "\n",
        "        us_stocks = [\n",
        "            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX',\n",
        "            'JPM', 'JNJ', 'V', 'PG', 'UNH', 'HD', 'MA', 'DIS'\n",
        "        ]\n",
        "\n",
        "        style = {'description_width': '120px'}\n",
        "        layout = Layout(width='300px')\n",
        "\n",
        "        market_dropdown = widgets.Dropdown(\n",
        "            options=[('å°è‚¡', 'tw'), ('ç¾è‚¡', 'us')],\n",
        "            value='tw',\n",
        "            description='å¸‚å ´:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        condition_dropdown = widgets.Dropdown(\n",
        "            options=[\n",
        "                ('çªç ´æ•´ç†å€é–“', 'çªç ´æ•´ç†å€é–“'),\n",
        "                ('çˆ†é‡é•·ç´…', 'çˆ†é‡é•·ç´…'),\n",
        "                ('çªç ´å­£ç·š', 'çªç ´å­£ç·š'),\n",
        "                ('å¤šé ­åå™¬', 'å¤šé ­åå™¬'),\n",
        "                ('5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰', '5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰')\n",
        "            ],\n",
        "            value='çªç ´æ•´ç†å€é–“',\n",
        "            description='ç¯©é¸æ¢ä»¶:',\n",
        "            style=style,\n",
        "            layout=Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        days_slider = widgets.IntSlider(\n",
        "            value=30,\n",
        "            min=10,\n",
        "            max=100,\n",
        "            step=10,\n",
        "            description='å›çœ‹å¤©æ•¸:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        screen_button = widgets.Button(\n",
        "            description='é–‹å§‹ç¯©é¸',\n",
        "            button_style='success',\n",
        "            layout=Layout(width='150px', height='40px')\n",
        "        )\n",
        "\n",
        "        output_area = widgets.Output()\n",
        "\n",
        "        def on_screen_click(b):\n",
        "            with output_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"ğŸ” é–‹å§‹ç¯©é¸è‚¡ç¥¨...\")\n",
        "\n",
        "                stock_list = tw_stocks if market_dropdown.value == 'tw' else us_stocks\n",
        "\n",
        "                try:\n",
        "                    results = screen_stocks(stock_list, days_slider.value, condition_dropdown.value)\n",
        "\n",
        "                    if results.empty:\n",
        "                        print(\"âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "                    else:\n",
        "                        print(f\"âœ… æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨:\")\n",
        "                        print(\"\\n\" + \"=\"*60)\n",
        "                        for _, row in results.iterrows():\n",
        "                            print(f\"è‚¡ç¥¨: {row['ticker']}\")\n",
        "                            print(f\"æ”¶ç›¤åƒ¹: {row['close']:.2f}\")\n",
        "                            print(f\"æˆäº¤é‡: {row['volume']:,.0f}\")\n",
        "                            print(f\"æ¼²è·Œå¹…: {row['change_pct']:.2f}%\")\n",
        "                            print(\"-\" * 30)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ ç¯©é¸éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        screen_button.on_click(on_screen_click)\n",
        "\n",
        "        ui = VBox([\n",
        "            HTML('<h2>ğŸ” è‚¡ç¥¨ç¯©é¸å™¨</h2>'),\n",
        "            market_dropdown,\n",
        "            condition_dropdown,\n",
        "            days_slider,\n",
        "            screen_button,\n",
        "            output_area\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "# =============================================================================\n",
        "# 14. å‘½ä»¤è¡Œä»‹é¢\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"ä¸»å‡½æ•¸ï¼Œé‹è¡Œäº’å‹•å¼ç•Œé¢\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\\nğŸš€ æ­¡è¿ä½¿ç”¨å¤šè‚¡ç¥¨åˆ†æé æ¸¬ç³»çµ±\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"1. å¤šè‚¡ç¥¨åˆ†æèˆ‡é æ¸¬\")\n",
        "        print(\"2. è‚¡ç¥¨ç¯©é¸å™¨\")\n",
        "        print(\"3. å–®è‚¡ç¥¨è©³ç´°åˆ†æ\")\n",
        "        if SHIOAJI_AVAILABLE:\n",
        "            print(\"4. Shioaji å°è‚¡æƒæ\")\n",
        "        if JUPYTER_AVAILABLE:\n",
        "            print(\"5. å•Ÿå‹• Jupyter UI ä»‹é¢\")\n",
        "        print(\"0. é€€å‡ºç¨‹åº\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        try:\n",
        "            choice = input(\"è«‹é¸æ“‡åŠŸèƒ½ (0-5): \").strip()\n",
        "\n",
        "            if choice == '0':\n",
        "                print(\"æ„Ÿè¬ä½¿ç”¨ï¼Œç¨‹åºé€€å‡ºã€‚\")\n",
        "                break\n",
        "\n",
        "            elif choice == '1':\n",
        "                symbols_input = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ (ç”¨é€—è™Ÿåˆ†éš”ï¼Œå¦‚: AAPL,TSLA,2330,2454): \").strip()\n",
        "                if not symbols_input:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    continue\n",
        "\n",
        "                symbols = [s.strip().upper() for s in symbols_input.split(',') if s.strip()]\n",
        "                period = input(\"è«‹è¼¸å…¥æ­·å²æ•¸æ“šå€é–“ (1y, 2y, 5y, max) [é è¨­: 1y]: \").strip().lower()\n",
        "                if not period:\n",
        "                    period = '1y'\n",
        "\n",
        "                print(f\"ğŸš€ é–‹å§‹åˆ†æ {len(symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem(symbols, period)\n",
        "                    asyncio.run(system.run_analysis())\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '2':\n",
        "                print(\"\\nè‚¡ç¥¨ç¯©é¸å™¨\")\n",
        "                print(\"1. å°è‚¡ç¯©é¸\")\n",
        "                print(\"2. ç¾è‚¡ç¯©é¸\")\n",
        "\n",
        "                market_choice = input(\"è«‹é¸æ“‡å¸‚å ´ (1-2): \").strip()\n",
        "                if market_choice not in ['1', '2']:\n",
        "                    print(\"âŒ ç„¡æ•ˆé¸æ“‡\")\n",
        "                    continue\n",
        "\n",
        "                conditions = [\n",
        "                    \"çªç ´æ•´ç†å€é–“\", \"çˆ†é‡é•·ç´…\", \"çªç ´å­£ç·š\", \"å¤šé ­åå™¬\", \"5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰\"\n",
        "                ]\n",
        "\n",
        "                print(\"\\nç¯©é¸æ¢ä»¶:\")\n",
        "                for i, condition in enumerate(conditions, 1):\n",
        "                    print(f\"{i}. {condition}\")\n",
        "\n",
        "                condition_choice = input(\"è«‹é¸æ“‡ç¯©é¸æ¢ä»¶ (1-5): \").strip()\n",
        "                try:\n",
        "                    condition_idx = int(condition_choice) - 1\n",
        "                    if condition_idx < 0 or condition_idx >= len(conditions):\n",
        "                        print(\"âŒ ç„¡æ•ˆé¸æ“‡\")\n",
        "                        continue\n",
        "                    condition = conditions[condition_idx]\n",
        "                except ValueError:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æ•¸å­—\")\n",
        "                    continue\n",
        "\n",
        "                days_input = input(\"è«‹è¼¸å…¥å›çœ‹å¤©æ•¸ [é è¨­: 30]: \").strip()\n",
        "                try:\n",
        "                    days_back = int(days_input) if days_input else 30\n",
        "                except ValueError:\n",
        "                    days_back = 30\n",
        "\n",
        "                # è‚¡ç¥¨æ¸…å–®\n",
        "                tw_stocks = [\n",
        "                    '2330.TW', '2317.TW', '2454.TW', '2881.TW', '2882.TW', '2883.TW',\n",
        "                    '2884.TW', '2885.TW', '2886.TW', '2887.TW', '2888.TW', '2889.TW',\n",
        "                    '2890.TW', '2891.TW', '2892.TW', '2912.TW', '2002.TW', '1303.TW',\n",
        "                    '3711.TW', '1301.TW', '2207.TW', '2357.TW', '2382.TW', '5871.TW'\n",
        "                ]\n",
        "\n",
        "                us_stocks = [\n",
        "                    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX',\n",
        "                    'JPM', 'JNJ', 'V', 'PG', 'UNH', 'HD', 'MA', 'DIS', 'PYPL', 'ADBE',\n",
        "                    'CRM', 'INTC', 'CSCO', 'PFE', 'KO', 'PEP', 'WMT', 'MRK'\n",
        "                ]\n",
        "\n",
        "                stock_list = tw_stocks if market_choice == '1' else us_stocks\n",
        "                market_name = \"å°è‚¡\" if market_choice == '1' else \"ç¾è‚¡\"\n",
        "\n",
        "                print(f\"ğŸ” é–‹å§‹ç¯©é¸ {market_name}ï¼Œæ¢ä»¶: {condition}ï¼Œå›çœ‹: {days_back} å¤©...\")\n",
        "\n",
        "                try:\n",
        "                    results = screen_stocks(stock_list, days_back, condition)\n",
        "\n",
        "                    if results.empty:\n",
        "                        print(\"âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "                    else:\n",
        "                        print(f\"âœ… æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨:\")\n",
        "                        print(\"\\n\" + \"=\"*70)\n",
        "                        for _, row in results.iterrows():\n",
        "                            print(f\"è‚¡ç¥¨: {row['ticker']:<10} | æ”¶ç›¤åƒ¹: {row['close']:>8.2f} | \"\n",
        "                                  f\"æˆäº¤é‡: {row['volume']:>12,.0f} | æ¼²è·Œå¹…: {row['change_pct']:>6.2f}%\")\n",
        "                        print(\"=\"*70)\n",
        "\n",
        "                        # è©¢å•æ˜¯å¦å°ç¯©é¸çµæœé€²è¡Œè©³ç´°åˆ†æ\n",
        "                        analyze_choice = input(\"\\næ˜¯å¦å°ç¯©é¸çµæœé€²è¡Œè©³ç´°åˆ†æï¼Ÿ(y/n): \").strip().lower()\n",
        "                        if analyze_choice == 'y':\n",
        "                            selected_symbols = results['ticker'].tolist()\n",
        "                            print(f\"ğŸš€ é–‹å§‹è©³ç´°åˆ†æ {len(selected_symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "                            system = MultiStockAnalysisSystem(selected_symbols, '1y')\n",
        "                            asyncio.run(system.run_analysis())\n",
        "                            print(\"âœ… è©³ç´°åˆ†æå®Œæˆï¼\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ ç¯©é¸éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '3':\n",
        "                symbol = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ (å¦‚: AAPL æˆ– 2330): \").strip().upper()\n",
        "                if not symbol:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    continue\n",
        "\n",
        "                period = input(\"è«‹è¼¸å…¥æ­·å²æ•¸æ“šå€é–“ (1y, 2y, 5y, max) [é è¨­: 1y]: \").strip().lower()\n",
        "                if not period:\n",
        "                    period = '1y'\n",
        "\n",
        "                print(f\"ğŸš€ é–‹å§‹è©³ç´°åˆ†æ {symbol}...\")\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem([symbol], period)\n",
        "                    asyncio.run(system.run_analysis())\n",
        "\n",
        "                    # é¡¯ç¤ºè©³ç´°çµæœ\n",
        "                    if symbol in system.results:\n",
        "                        result = system.results[symbol]\n",
        "                        if result.get('success', False):\n",
        "                            print(\"\\nğŸ“Š è©³ç´°åˆ†æçµæœ:\")\n",
        "                            print(\"=\"*50)\n",
        "                            print(f\"è‚¡ç¥¨ä»£ç¢¼: {symbol}\")\n",
        "                            print(f\"æœ€æ–°åƒ¹æ ¼: {result['last_price']:.2f}\")\n",
        "                            print(f\"ç¶œåˆè©•åˆ†: {result['combined_score']:.2f}\")\n",
        "                            print(f\"æŠ•è³‡å»ºè­°: {result['recommendation']['action']}\")\n",
        "                            print(f\"å»ºè­°ç†ç”±: {result['recommendation']['reason']}\")\n",
        "                            print(f\"ä¿¡å¿ƒåº¦: {result['recommendation']['confidence']}%\")\n",
        "                            print(f\"é¢¨éšªç­‰ç´š: {result['recommendation']['risk_level']}\")\n",
        "\n",
        "                            print(\"\\nKç·šå‹æ…‹åˆ†æ:\")\n",
        "                            print(result['pattern_report'])\n",
        "\n",
        "                            if result['wave_analysis'][0]:\n",
        "                                print(f\"\\næ³¢æµªç†è«–åˆ†æ: {result['wave_analysis'][1]}\")\n",
        "\n",
        "                            if result['predictor'].future_predictions:\n",
        "                                print(\"\\næœªä¾†ä¸€é€±é æ¸¬:\")\n",
        "                                for day, preds in result['predictor'].future_predictions.items():\n",
        "                                    avg_pred = np.mean(list(preds.values()))\n",
        "                                    change_pct = (avg_pred / result['last_price'] - 1) * 100\n",
        "                                    print(f\"ç¬¬ {day} å¤©: {avg_pred:.2f} ({change_pct:+.1f}%)\")\n",
        "\n",
        "                            print(f\"\\nğŸ“ˆ åœ–è¡¨å·²ä¿å­˜åˆ°: {', '.join(result['chart_files'])}\")\n",
        "                        else:\n",
        "                            print(f\"âŒ åˆ†æ {symbol} å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}\")\n",
        "\n",
        "                    print(\"âœ… è©³ç´°åˆ†æå®Œæˆï¼\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '4' and SHIOAJI_AVAILABLE:\n",
        "                api_key = input(\"è«‹è¼¸å…¥ Shioaji API Key: \").strip()\n",
        "                secret_key = input(\"è«‹è¼¸å…¥ Shioaji Secret Key: \").strip()\n",
        "\n",
        "                if not api_key or not secret_key:\n",
        "                    print(\"âŒ API Key å’Œ Secret Key ä¸èƒ½ç‚ºç©º\")\n",
        "                    continue\n",
        "\n",
        "                max_stocks = input(\"è«‹è¼¸å…¥è¦æƒæçš„è‚¡ç¥¨æ•¸é‡ [é è¨­: 20]: \").strip()\n",
        "                try:\n",
        "                    max_stocks = int(max_stocks) if max_stocks else 20\n",
        "                except ValueError:\n",
        "                    max_stocks = 20\n",
        "\n",
        "                print(f\"ğŸš€ é–‹å§‹æƒæå°è‚¡ï¼Œæ•¸é‡: {max_stocks}...\")\n",
        "\n",
        "                try:\n",
        "                    scanner = ShioajiStockScanner(api_key, secret_key)\n",
        "                    stock_list_df = scanner.get_stock_list(max_stocks)\n",
        "\n",
        "                    if stock_list_df.empty:\n",
        "                        print(\"âŒ ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                        continue\n",
        "\n",
        "                    # è½‰æ›ç‚ºåˆ†æç³»çµ±å¯ç”¨çš„æ ¼å¼\n",
        "                    symbols = [f\"{code}.TW\" for code in stock_list_df['code'].tolist()]\n",
        "\n",
        "                    print(f\"ğŸ“Š ç²å–åˆ° {len(symbols)} æ”¯å°è‚¡ï¼Œé–‹å§‹æŠ€è¡“åˆ†æ...\")\n",
        "\n",
        "                    system = MultiStockAnalysisSystem(symbols, '1y')\n",
        "                    asyncio.run(system.run_analysis())\n",
        "\n",
        "                    print(\"âœ… Shioaji å°è‚¡æƒæå®Œæˆï¼\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ Shioaji æƒæéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '5' and JUPYTER_AVAILABLE:\n",
        "                print(\"ğŸ¯ å•Ÿå‹• Jupyter UI ä»‹é¢...\")\n",
        "                print(\"è«‹åœ¨ Jupyter Notebook ä¸­åŸ·è¡Œä»¥ä¸‹ä»£ç¢¼:\")\n",
        "                print(\"-\"*50)\n",
        "                print(\"# è‚¡ç¥¨åˆ†æUI\")\n",
        "                print(\"analysis_ui = create_stock_analysis_ui()\")\n",
        "                print(\"display(analysis_ui)\")\n",
        "                print()\n",
        "                print(\"# è‚¡ç¥¨ç¯©é¸UI\")\n",
        "                print(\"screener_ui = create_stock_screener_ui()\")\n",
        "                print(\"display(screener_ui)\")\n",
        "                print(\"-\"*50)\n",
        "\n",
        "                # å¦‚æœåœ¨ Jupyter ç’°å¢ƒä¸­ï¼Œç›´æ¥é¡¯ç¤º UI\n",
        "                try:\n",
        "                    from IPython.display import display\n",
        "                    print(\"æª¢æ¸¬åˆ° Jupyter ç’°å¢ƒï¼Œæ­£åœ¨é¡¯ç¤º UI...\")\n",
        "                    analysis_ui = create_stock_analysis_ui()\n",
        "                    screener_ui = create_stock_screener_ui()\n",
        "                    display(analysis_ui)\n",
        "                    display(screener_ui)\n",
        "                except:\n",
        "                    print(\"è«‹åœ¨ Jupyter Notebook ä¸­æ‰‹å‹•åŸ·è¡Œä¸Šè¿°ä»£ç¢¼\")\n",
        "\n",
        "            else:\n",
        "                print(\"âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "# =============================================================================\n",
        "# 15. ç¤ºä¾‹å’Œæ¸¬è©¦\n",
        "# =============================================================================\n",
        "\n",
        "def run_example():\n",
        "    \"\"\"é‹è¡Œç¤ºä¾‹åˆ†æ\"\"\"\n",
        "    print(\"ğŸš€ é‹è¡Œç¤ºä¾‹åˆ†æ...\")\n",
        "\n",
        "    # ç¤ºä¾‹è‚¡ç¥¨çµ„åˆ\n",
        "    example_symbols = ['AAPL', 'TSLA', '2330.TW', '2454.TW']\n",
        "\n",
        "    try:\n",
        "        system = MultiStockAnalysisSystem(example_symbols, '1y')\n",
        "        asyncio.run(system.run_analysis())\n",
        "        print(\"âœ… ç¤ºä¾‹åˆ†æå®Œæˆï¼\")\n",
        "\n",
        "        # é¡¯ç¤ºç°¡è¦çµæœ\n",
        "        print(\"\\nğŸ“Š ç¤ºä¾‹åˆ†æçµæœæ‘˜è¦:\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        successful_results = [\n",
        "            result for result in system.results.values()\n",
        "            if result.get('success', False)\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        for i, result in enumerate(successful_results, 1):\n",
        "            symbol = result.get('symbol', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "\n",
        "            print(f\"{i}. {symbol:<8} | è©•åˆ†: {score:>5.1f} | å»ºè­°: {recommendation}\")\n",
        "\n",
        "        print(\"=\"*50)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ç¤ºä¾‹åˆ†æå¤±æ•—: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def test_individual_components():\n",
        "    \"\"\"æ¸¬è©¦å„å€‹çµ„ä»¶\"\"\"\n",
        "    print(\"ğŸ§ª æ¸¬è©¦ç³»çµ±çµ„ä»¶...\")\n",
        "\n",
        "    # æ¸¬è©¦æ•¸æ“šç²å–\n",
        "    print(\"1. æ¸¬è©¦è‚¡ç¥¨æ•¸æ“šç²å–...\")\n",
        "    test_df = fetch_stock_data('AAPL', '3mo')\n",
        "    if test_df is not None:\n",
        "        print(f\"âœ… æˆåŠŸç²å– AAPL æ•¸æ“šï¼Œå…± {len(test_df)} ç­†\")\n",
        "    else:\n",
        "        print(\"âŒ è‚¡ç¥¨æ•¸æ“šç²å–å¤±æ•—\")\n",
        "\n",
        "    # æ¸¬è©¦ææ‡¼è²ªå©ªæŒ‡æ•¸\n",
        "    print(\"2. æ¸¬è©¦ææ‡¼è²ªå©ªæŒ‡æ•¸ç²å–...\")\n",
        "    sentiment_df = get_fear_and_greed_data(30)\n",
        "    if sentiment_df is not None:\n",
        "        print(f\"âœ… æˆåŠŸç²å–ææ‡¼è²ªå©ªæŒ‡æ•¸ï¼Œå…± {len(sentiment_df)} ç­†\")\n",
        "    else:\n",
        "        print(\"âŒ ææ‡¼è²ªå©ªæŒ‡æ•¸ç²å–å¤±æ•—\")\n",
        "\n",
        "    # æ¸¬è©¦æŠ€è¡“æŒ‡æ¨™è¨ˆç®—\n",
        "    if test_df is not None:\n",
        "        print(\"3. æ¸¬è©¦æŠ€è¡“æŒ‡æ¨™è¨ˆç®—...\")\n",
        "        try:\n",
        "            test_df = calculate_technical_indicators(test_df)\n",
        "            test_df = feature_engineering(test_df)\n",
        "            print(\"âœ… æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æˆåŠŸ\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—: {e}\")\n",
        "\n",
        "    # æ¸¬è©¦Kç·šå‹æ…‹è­˜åˆ¥\n",
        "    if test_df is not None:\n",
        "        print(\"4. æ¸¬è©¦Kç·šå‹æ…‹è­˜åˆ¥...\")\n",
        "        try:\n",
        "            pattern_report = generate_pattern_report(test_df)\n",
        "            print(\"âœ… Kç·šå‹æ…‹è­˜åˆ¥æˆåŠŸ\")\n",
        "            print(f\"å‹æ…‹å ±å‘Š: {pattern_report[:100]}...\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Kç·šå‹æ…‹è­˜åˆ¥å¤±æ•—: {e}\")\n",
        "\n",
        "    # æ¸¬è©¦è©•åˆ†ç³»çµ±\n",
        "    if test_df is not None:\n",
        "        print(\"5. æ¸¬è©¦è©•åˆ†ç³»çµ±...\")\n",
        "        try:\n",
        "            score = calculate_combined_score(test_df)\n",
        "            print(f\"âœ… è©•åˆ†ç³»çµ±æˆåŠŸï¼Œç¶œåˆè©•åˆ†: {score:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ è©•åˆ†ç³»çµ±å¤±æ•—: {e}\")\n",
        "\n",
        "    print(\"ğŸ§ª çµ„ä»¶æ¸¬è©¦å®Œæˆ\")\n",
        "\n",
        "# =============================================================================\n",
        "# 16. ç¨‹åºå…¥å£é»\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸ¯ å¤šè‚¡ç¥¨åˆ†æé æ¸¬ç³»çµ± v2.0\")\n",
        "    print(\"æ”¯æ´å°è‚¡ã€ç¾è‚¡æŠ€è¡“åˆ†æã€æ©Ÿå™¨å­¸ç¿’é æ¸¬ã€å‹æ…‹è­˜åˆ¥\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # æª¢æŸ¥ç’°å¢ƒ\n",
        "    print(\"ğŸ” æª¢æŸ¥ç³»çµ±ç’°å¢ƒ...\")\n",
        "    print(f\"Jupyter æ”¯æ´: {'âœ…' if JUPYTER_AVAILABLE else 'âŒ'}\")\n",
        "    print(f\"Shioaji æ”¯æ´: {'âœ…' if SHIOAJI_AVAILABLE else 'âŒ'}\")\n",
        "    print(f\"é€šçŸ¥åŠŸèƒ½: {'âœ…' if MESSAGING_AVAILABLE else 'âŒ'}\")\n",
        "\n",
        "    # è©¢å•é‹è¡Œæ¨¡å¼\n",
        "    print(\"\\né¸æ“‡é‹è¡Œæ¨¡å¼:\")\n",
        "    print(\"1. äº’å‹•å¼å‘½ä»¤è¡Œä»‹é¢\")\n",
        "    print(\"2. é‹è¡Œç¤ºä¾‹åˆ†æ\")\n",
        "    print(\"3. æ¸¬è©¦ç³»çµ±çµ„ä»¶\")\n",
        "    print(\"0. é€€å‡º\")\n",
        "\n",
        "    try:\n",
        "        mode = input(\"è«‹é¸æ“‡ (0-3): \").strip()\n",
        "\n",
        "        if mode == '0':\n",
        "            print(\"ç¨‹åºé€€å‡º\")\n",
        "        elif mode == '1':\n",
        "            main()\n",
        "        elif mode == '2':\n",
        "            run_example()\n",
        "        elif mode == '3':\n",
        "            test_individual_components()\n",
        "        else:\n",
        "            print(\"ç„¡æ•ˆé¸æ“‡ï¼Œå•Ÿå‹•äº’å‹•å¼ä»‹é¢...\")\n",
        "            main()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·\")\n",
        "    except Exception as e:\n",
        "        print(f\"ç¨‹åºé‹è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\næ„Ÿè¬ä½¿ç”¨å¤šè‚¡ç¥¨åˆ†æé æ¸¬ç³»çµ±ï¼\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "YwMw7d5jsBap",
        "outputId": "9d80d750-5a0d-4701-e13a-9ac5ab079ca1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2792634832.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFontProperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/seaborn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpalettes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrelational\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/seaborn/relational.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_compat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgroupby_apply_include_groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_statistics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEstimateAggregator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWeightedAggregator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maxisgrid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFacetGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_facet_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_docstrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocstringComponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_core_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/seaborn/_statistics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0m_no_scipy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    624\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    625\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 626\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_importlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'scipy.{name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_importlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from ._sputils import (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[0m\u001b[1;32m      9\u001b[0m                        \u001b[0mget_sum_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_todata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        matrix, validateaxis, getdtype, is_pydata_spmatrix)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_sputils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_ulong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m from scipy._lib._array_api import (Array, array_namespace, is_lazy_array,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                    \u001b[0mis_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp_result_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                    xp_size, xp_result_type)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_api_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m from scipy._lib.array_api_compat import (\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mis_array_api_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mis_lazy_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403  # pyright: ignore[reportWildcardImportFromLibrary]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# from numpy import * doesn't overwrite these builtin names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmatlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"f2py\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf2py\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf2py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf2py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"typing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf2py2e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiagnose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/f2py2e.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrackfortran\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcb_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauxfuncs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcapi_maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfuncs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcommon_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/capi_maps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcrackfortran\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmarkoutercomma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcb_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_isocbind\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miso_c_binding_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misoc_c2pycode_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miso_c2py_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/cb_rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    346\u001b[0m                                            l_and(hasnote, isintent_nothide): '--- See above.'}]},\n\u001b[1;32m    347\u001b[0m         \u001b[0;34m'docsign'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ml_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misrequired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misintent_nothide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'#varname#,'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;34m'docsignopt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ml_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misoptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misintent_nothide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'#varname#,'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;34m'depend'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     },\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/auxfuncs.py\u001b[0m in \u001b[0;36ml_and\u001b[0;34m(*f)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s,f%d=f[%d]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0ml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f%d(v)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s:%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' and '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/auxfuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFJhJswdyCNr"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import seaborn as sns\n",
        "from io import StringIO\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import json\n",
        "import pickle\n",
        "from typing import Dict, List, Any, Optional\n",
        "import random\n",
        "\n",
        "# æ©Ÿå™¨å­¸ç¿’ç›¸é—œ\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# é€šçŸ¥ç›¸é—œ\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# Jupyter Notebook æ”¯æ´\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "    import ipywidgets as widgets\n",
        "    from ipywidgets import Layout, HTML, Button, HBox, VBox, Output\n",
        "    from IPython.display import display, clear_output\n",
        "    JUPYTER_AVAILABLE = True\n",
        "except ImportError:\n",
        "    JUPYTER_AVAILABLE = False\n",
        "\n",
        "# =============================================================================\n",
        "# å…¨åŸŸè¨­å®š\n",
        "# =============================================================================\n",
        "\n",
        "# ç¦æ­¢ä¸­æ–‡éŒ¯èª¤è­¦å‘Š\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ä¸­æ–‡å­—é«”è¨­å®š\n",
        "plt.rcParams['font.sans-serif'] = [\n",
        "    'Microsoft JhengHei',  # ç¹é«”ä¸­æ–‡\n",
        "    'SimHei',              # ç°¡é«”ä¸­æ–‡\n",
        "    'Arial Unicode MS',    # Unicode å­—é«”\n",
        "    'DejaVu Sans'         # åŸºç¤å­—é«”\n",
        "]\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# é€šçŸ¥è¨­å®š\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# åœ–è¡¨å„²å­˜ç›®éŒ„\n",
        "CHARTS_DIR = 'charts'\n",
        "if not os.path.exists(CHARTS_DIR):\n",
        "    os.makedirs(CHARTS_DIR)\n",
        "\n",
        "print(\"ğŸš€ ç’°å¢ƒè¨­å®šå®Œæˆï¼Œé–‹å§‹å»ºç«‹åˆ†æç³»çµ±...\")\n",
        "\n",
        "# =============================================================================\n",
        "# 1. æ•¸æ“šç²å–æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def fetch_from_cnn():\n",
        "    \"\"\"å¾CNNç¶²ç«™ç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\"\"\"\n",
        "    url = \"https://money.cnn.com/data/fear-and-greed/\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for element in soup.find_all(['div', 'span']):\n",
        "            if \"Fear & Greed Now:\" in element.get_text():\n",
        "                number_match = re.search(r'(\\d+)', element.get_text())\n",
        "                if number_match:\n",
        "                    value = int(number_match.group(1))\n",
        "                    logger.info(f\"æˆåŠŸå¾CNNç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸: {value}\")\n",
        "                    return value\n",
        "        logger.warning(\"ç„¡æ³•å¾CNNæå–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾CNNç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_from_alternative_me(limit=1):\n",
        "    \"\"\"å¾alternative.me APIç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\"\"\"\n",
        "    try:\n",
        "        url = f\"https://api.alternative.me/fng/?limit={limit}&format=json\"\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if 'data' in data and len(data['data']) > 0:\n",
        "            if limit == 1:\n",
        "                value = int(data['data'][0]['value'])\n",
        "                logger.info(f\"æˆåŠŸå¾Alternative.me APIç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸: {value}\")\n",
        "                return value\n",
        "            else:\n",
        "                df = pd.DataFrame(data['data'])\n",
        "                df['value'] = pd.to_numeric(df['value'])\n",
        "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
        "                df = df.rename(columns={'timestamp': 'Date', 'value': 'FearGreedIndex'})\n",
        "                df['Date'] = pd.to_datetime(df['Date'])\n",
        "                logger.info(f\"æˆåŠŸç²å– {len(df)} å¤©çš„æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“š\")\n",
        "                return df[['Date', 'FearGreedIndex']]\n",
        "        else:\n",
        "            logger.warning(\"Alternative.me APIè¿”å›çš„æ•¸æ“šæ ¼å¼ä¸æ­£ç¢º\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾Alternative.meç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_fear_and_greed_data(days):\n",
        "    \"\"\"ç²å–å³æ™‚èˆ‡æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“š\"\"\"\n",
        "    logger.info(\"æ­£åœ¨ç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸...\")\n",
        "\n",
        "    current_value = fetch_from_cnn()\n",
        "    if current_value is None:\n",
        "        current_value = fetch_from_alternative_me(limit=1)\n",
        "\n",
        "    historical_df = fetch_from_alternative_me(limit=days)\n",
        "\n",
        "    if historical_df is not None:\n",
        "        logger.info(\"å·²æˆåŠŸç²å–çœŸå¯¦æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“šã€‚\")\n",
        "        if current_value is not None:\n",
        "            today = pd.to_datetime(datetime.now().date())\n",
        "            if today not in historical_df['Date'].values:\n",
        "                new_row = pd.DataFrame([{'Date': today, 'FearGreedIndex': current_value}])\n",
        "                historical_df = pd.concat([historical_df, new_row], ignore_index=True)\n",
        "        return historical_df.drop_duplicates(subset=['Date'], keep='last')\n",
        "\n",
        "    logger.warning(\"ç„¡æ³•ç²å–çœŸå¯¦æ­·å²æ•¸æ“šï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šä½œç‚ºå‚™æ¡ˆã€‚\")\n",
        "    if current_value is None:\n",
        "        current_value = 50\n",
        "        logger.warning(f\"æ‰€æœ‰å³æ™‚ä¾†æºå‡å¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼ {current_value}\")\n",
        "\n",
        "    dates = pd.to_datetime([datetime.now() - timedelta(days=i) for i in range(days)]).sort_values()\n",
        "    scores = [current_value]\n",
        "    np.random.seed(42)\n",
        "    for _ in range(1, days):\n",
        "        mean_reversion = 0.1 * (50 - scores[-1])\n",
        "        random_change = np.random.normal(0, 3)\n",
        "        new_score = scores[-1] + mean_reversion + random_change\n",
        "        scores.append(max(0, min(100, new_score)))\n",
        "\n",
        "    return pd.DataFrame({'Date': dates, 'FearGreedIndex': scores})\n",
        "\n",
        "def fetch_stock_data(symbol, period='1y'):\n",
        "    \"\"\"å¾Yahoo Financeç²å–è‚¡ç¥¨æ•¸æ“šï¼Œè‡ªå‹•åˆ¤æ–·å°è‚¡/ç¾è‚¡\"\"\"\n",
        "    original_symbol = symbol\n",
        "\n",
        "    # å¦‚æœè¼¸å…¥çš„æ˜¯ç´”æ•¸å­—ï¼Œåˆ¤æ–·ç‚ºå°è‚¡ä»£ç¢¼\n",
        "    if re.match(r'^\\d{4,5}$', symbol):\n",
        "        symbol += \".TW\"\n",
        "        logger.info(f\"æª¢æ¸¬åˆ°å°è‚¡ä»£ç¢¼ï¼Œè½‰æ›ç‚º {symbol}\")\n",
        "\n",
        "    logger.info(f\"æ­£åœ¨å¾Yahoo Financeç²å– {symbol} ({period}) çš„æ•¸æ“š...\")\n",
        "    try:\n",
        "        stock = yf.Ticker(symbol)\n",
        "        df = stock.history(period=period, interval='1d')\n",
        "        if df.empty:\n",
        "            logger.error(f\"ç„¡æ³•ç²å– {symbol} çš„æ•¸æ“šï¼Œè«‹æª¢æŸ¥ä»£ç¢¼æ˜¯å¦æ­£ç¢ºã€‚\")\n",
        "            return None\n",
        "\n",
        "        df.reset_index(inplace=True)\n",
        "        df['Date'] = pd.to_datetime(df['Date'].dt.date)\n",
        "\n",
        "        logger.info(f\"æˆåŠŸç²å– {original_symbol} çš„ {len(df)} ç­†æ•¸æ“š\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾Yahoo Financeç²å– {symbol} çš„æ•¸æ“šæ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================\n",
        "# 2. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"è¨ˆç®—æ‰€æœ‰éœ€è¦çš„æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "    # ç§»å‹•å¹³å‡ç·š\n",
        "    df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "    df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "    df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "    df['MA60'] = df['Close'].rolling(window=60).mean()\n",
        "\n",
        "    # MACD\n",
        "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "\n",
        "    # RSI\n",
        "    delta = df['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean()\n",
        "    avg_loss = loss.rolling(window=14).mean().replace(0, np.nan)\n",
        "    rs = avg_gain / avg_loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # å¸ƒæ—å¸¶\n",
        "    df['BB_Middle'] = df['MA20']\n",
        "    std_dev = df['Close'].rolling(window=20).std()\n",
        "    df['BB_Upper'] = df['BB_Middle'] + (std_dev * 2)\n",
        "    df['BB_Lower'] = df['BB_Middle'] - (std_dev * 2)\n",
        "\n",
        "    # KDæŒ‡æ¨™\n",
        "    low_min = df['Low'].rolling(window=9).min()\n",
        "    high_max = df['High'].rolling(window=9).max()\n",
        "    rsv = (df['Close'] - low_min) / (high_max - low_min) * 100\n",
        "    df['K'] = rsv.ewm(com=2).mean()\n",
        "    df['D'] = df['K'].ewm(com=2).mean()\n",
        "\n",
        "    # æˆäº¤é‡æŒ‡æ¨™\n",
        "    df['Volume_MA'] = df['Volume'].rolling(window=20).mean()\n",
        "\n",
        "    return df\n",
        "\n",
        "def feature_engineering(df):\n",
        "    \"\"\"å‰µå»ºè¡ç”Ÿç‰¹å¾µ\"\"\"\n",
        "    df['Price_Change_1d'] = df['Close'].pct_change(1)\n",
        "    df['Price_Change_5d'] = df['Close'].pct_change(5)\n",
        "    df['Volatility_5d'] = df['Close'].rolling(5).std()\n",
        "    df['Volatility_20d'] = df['Close'].rolling(20).std()\n",
        "    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']\n",
        "    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower']).replace(0, np.nan)\n",
        "\n",
        "    # å¡«å……NaNå€¼\n",
        "    df.bfill(inplace=True)\n",
        "    df.ffill(inplace=True)\n",
        "    df.fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# =============================================================================\n",
        "# 3. Kç·šå‹æ…‹è­˜åˆ¥æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def identify_candlestick_patterns(df):\n",
        "    \"\"\"è­˜åˆ¥å¸¸è¦‹çš„Kç·šå‹æ…‹\"\"\"\n",
        "    result_df = df.copy()\n",
        "\n",
        "    # åŸºæœ¬è¨ˆç®—\n",
        "    result_df['body_size'] = abs(result_df['Close'] - result_df['Open'])\n",
        "    result_df['upper_shadow'] = result_df['High'] - result_df[['Open', 'Close']].max(axis=1)\n",
        "    result_df['lower_shadow'] = result_df[['Open', 'Close']].min(axis=1) - result_df['Low']\n",
        "    result_df['total_range'] = result_df['High'] - result_df['Low']\n",
        "\n",
        "    # å‰ä¸€å¤©æ•¸æ“š\n",
        "    result_df['prev_open'] = result_df['Open'].shift(1)\n",
        "    result_df['prev_high'] = result_df['High'].shift(1)\n",
        "    result_df['prev_low'] = result_df['Low'].shift(1)\n",
        "    result_df['prev_close'] = result_df['Close'].shift(1)\n",
        "\n",
        "    # Kç·šè¶¨å‹¢\n",
        "    result_df['is_bullish'] = result_df['Close'] > result_df['Open']\n",
        "    result_df['prev_is_bullish'] = result_df['prev_close'] > result_df['prev_open']\n",
        "\n",
        "    # åˆå§‹åŒ–å‹æ…‹æ¬„ä½\n",
        "    pattern_columns = [\n",
        "        'åå­—æ˜Ÿ_ä¸­æ€§', 'éŒ˜å­ç·š_çœ‹æ¼²', 'éŒ˜å­ç·š_çœ‹è·Œ', 'æµæ˜Ÿç·š_çœ‹è·Œ',\n",
        "        'åå™¬_çœ‹æ¼²', 'åå™¬_çœ‹è·Œ', 'æ¯å­ç·š_çœ‹æ¼²', 'æ¯å­ç·š_çœ‹è·Œ'\n",
        "    ]\n",
        "\n",
        "    for col in pattern_columns:\n",
        "        result_df[col] = 0\n",
        "\n",
        "    # åå­—æ˜Ÿ\n",
        "    doji_condition = result_df['body_size'] <= 0.1 * result_df['total_range']\n",
        "    result_df.loc[doji_condition, 'åå­—æ˜Ÿ_ä¸­æ€§'] = 1\n",
        "\n",
        "    # éŒ˜å­ç·š\n",
        "    hammer_condition = (\n",
        "        (result_df['lower_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['upper_shadow'] <= 0.1 * result_df['total_range'])\n",
        "    )\n",
        "    result_df.loc[hammer_condition, 'éŒ˜å­ç·š_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # æµæ˜Ÿç·š\n",
        "    shooting_star_condition = (\n",
        "        (result_df['upper_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['lower_shadow'] <= 0.1 * result_df['total_range'])\n",
        "    )\n",
        "    result_df.loc[shooting_star_condition, 'æµæ˜Ÿç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # çœ‹æ¼²åå™¬\n",
        "    bullish_engulfing = (\n",
        "        (~result_df['prev_is_bullish']) &\n",
        "        result_df['is_bullish'] &\n",
        "        (result_df['Open'] < result_df['prev_close']) &\n",
        "        (result_df['Close'] > result_df['prev_open'])\n",
        "    )\n",
        "    result_df.loc[bullish_engulfing, 'åå™¬_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # çœ‹è·Œåå™¬\n",
        "    bearish_engulfing = (\n",
        "        result_df['prev_is_bullish'] &\n",
        "        (~result_df['is_bullish']) &\n",
        "        (result_df['Open'] > result_df['prev_close']) &\n",
        "        (result_df['Close'] < result_df['prev_open'])\n",
        "    )\n",
        "    result_df.loc[bearish_engulfing, 'åå™¬_çœ‹è·Œ'] = -1\n",
        "\n",
        "    return result_df\n",
        "\n",
        "def generate_pattern_report(df, periods=['daily']):\n",
        "    \"\"\"ç”ŸæˆKç·šå‹æ…‹åˆ†æå ±å‘Š\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šæ•¸æ“šç‚ºç©º\"\n",
        "\n",
        "    required_cols = ['Open', 'High', 'Low', 'Close']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šç¼ºå°‘å¿…è¦æ¬„ä½\"\n",
        "\n",
        "    def detect_patterns(ohlc_data):\n",
        "        patterns = {\"çœ‹æ¼²\": [], \"çœ‹è·Œ\": [], \"ä¸­æ€§\": []}\n",
        "\n",
        "        if len(ohlc_data) < 5:\n",
        "            return patterns\n",
        "\n",
        "        recent = ohlc_data.tail(10).copy()\n",
        "        recent['body_size'] = abs(recent['Close'] - recent['Open'])\n",
        "        recent['is_bullish'] = recent['Close'] > recent['Open']\n",
        "        recent['is_bearish'] = recent['Close'] < recent['Open']\n",
        "\n",
        "        last3 = recent.tail(3)\n",
        "\n",
        "        # ä¸‰ç™½å…µ\n",
        "        if len(last3) == 3 and all(last3['is_bullish']) and \\\n",
        "           last3['Close'].iloc[0] < last3['Close'].iloc[1] < last3['Close'].iloc[2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"ä¸‰ç™½å…µ\")\n",
        "\n",
        "        # ä¸‰é»‘é´‰\n",
        "        if len(last3) == 3 and all(last3['is_bearish']) and \\\n",
        "           last3['Close'].iloc[0] > last3['Close'].iloc[1] > last3['Close'].iloc[2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ä¸‰é»‘é´‰\")\n",
        "\n",
        "        # åå­—æ˜Ÿ\n",
        "        if any(last3['body_size'] < 0.1 * (last3['High'] - last3['Low'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"åå­—æ˜Ÿ\")\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    report_parts = []\n",
        "\n",
        "    for period in periods:\n",
        "        period_name = {'daily': 'æ—¥ç·š', 'weekly': 'é€±ç·š', 'monthly': 'æœˆç·š'}.get(period, period)\n",
        "\n",
        "        try:\n",
        "            patterns = detect_patterns(df)\n",
        "            period_report = [f\"{period_name}åˆ†æ:\"]\n",
        "\n",
        "            for pattern_type, detected_patterns in patterns.items():\n",
        "                if detected_patterns:\n",
        "                    pattern_str = \", \".join(detected_patterns)\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: {pattern_str}\")\n",
        "                else:\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: ç„¡\")\n",
        "\n",
        "            report_parts.append(\"\\n\".join(period_report))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {period_name} å‹æ…‹æ™‚å‡ºéŒ¯: {e}\")\n",
        "            report_parts.append(f\"{period_name}åˆ†æ:\\nåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤\")\n",
        "\n",
        "    return \"\\n\\n\".join(report_parts) if report_parts else \"æœªæª¢æ¸¬åˆ°æ˜é¡¯Kç·šå‹æ…‹\"\n",
        "\n",
        "# =============================================================================\n",
        "# 4. æ©Ÿå™¨å­¸ç¿’é æ¸¬æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "class StockPredictor:\n",
        "    def __init__(self, target_days=7):\n",
        "        self.models = {\n",
        "            'ç·šæ€§è¿´æ­¸': LinearRegression(),\n",
        "            'éš¨æ©Ÿæ£®æ—': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "            'XGBoost': XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "            'LightGBM': LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "        }\n",
        "        self.scalers = {}\n",
        "        self.feature_names = None\n",
        "        self.target_days = target_days\n",
        "        self.backtest_results = {}\n",
        "        self.future_predictions = {}\n",
        "        self.feature_importances = None\n",
        "\n",
        "    def _prepare_data(self, df, predict_day):\n",
        "        \"\"\"æº–å‚™ç‰¹å¾µå’Œç›®æ¨™è®Šé‡\"\"\"\n",
        "        feature_columns = [\n",
        "            'MA5', 'MA10', 'MA20', 'MACD', 'MACD_Signal', 'RSI', 'BB_Width', 'BB_Position',\n",
        "            'Price_Change_1d', 'Price_Change_5d', 'Volatility_5d', 'Volatility_20d',\n",
        "            'FearGreedIndex'\n",
        "        ]\n",
        "        self.feature_names = [col for col in feature_columns if col in df.columns]\n",
        "\n",
        "        X = df[self.feature_names].copy()\n",
        "        y = df['Close'].shift(-predict_day)\n",
        "\n",
        "        valid_idx = ~y.isnull()\n",
        "        X = X[valid_idx]\n",
        "        y = y[valid_idx]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def run_backtest(self, df):\n",
        "        \"\"\"åŸ·è¡Œå›æ¸¬\"\"\"\n",
        "        logger.info(\"åŸ·è¡Œå›æ¸¬...\")\n",
        "        X, y = self._prepare_data(df, predict_day=1)\n",
        "\n",
        "        split_index = int(len(X) * 0.8)\n",
        "        X_train, X_test = X[:split_index], X[split_index:]\n",
        "        y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            y_pred = model.predict(X_test_scaled)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            self.backtest_results[name] = {\n",
        "                'y_test': y_test, 'y_pred': y_pred, 'mse': mse, 'r2': r2\n",
        "            }\n",
        "            logger.info(f\"[å›æ¸¬] {name} - RÂ²: {r2:.4f}, MSE: {mse:.4f}\")\n",
        "\n",
        "        if 'éš¨æ©Ÿæ£®æ—' in self.models:\n",
        "            self.feature_importances = pd.DataFrame({\n",
        "                'ç‰¹å¾µ': self.feature_names,\n",
        "                'é‡è¦æ€§': self.models['éš¨æ©Ÿæ£®æ—'].feature_importances_\n",
        "            }).sort_values('é‡è¦æ€§', ascending=False)\n",
        "\n",
        "    def predict_future(self, df):\n",
        "        \"\"\"é æ¸¬æœªä¾†åƒ¹æ ¼\"\"\"\n",
        "        logger.info(\"è¨“ç·´å®Œæ•´æ•¸æ“šé›†ä¸¦é æ¸¬æœªä¾†åƒ¹æ ¼...\")\n",
        "\n",
        "        for day in range(1, self.target_days + 1):\n",
        "            X, y = self._prepare_data(df, predict_day=day)\n",
        "\n",
        "            if X.empty:\n",
        "                logger.warning(f\"ç„¡æ³•ç‚ºé æ¸¬ç¬¬ {day} å¤©æº–å‚™æ•¸æ“šï¼Œè·³éã€‚\")\n",
        "                continue\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_scaled = scaler.fit_transform(X)\n",
        "            X_last = df[self.feature_names].iloc[-1:].copy()\n",
        "            X_last_scaled = scaler.transform(X_last)\n",
        "\n",
        "            daily_predictions = {}\n",
        "            for name, model in self.models.items():\n",
        "                model.fit(X_scaled, y)\n",
        "                prediction = model.predict(X_last_scaled)[0]\n",
        "                daily_predictions[name] = prediction\n",
        "\n",
        "            self.future_predictions[day] = daily_predictions\n",
        "\n",
        "# =============================================================================\n",
        "# 5. ç¶œåˆè©•åˆ†ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_combined_score(df):\n",
        "    \"\"\"è¨ˆç®—ç¶œåˆè©•åˆ†\"\"\"\n",
        "    if df.empty:\n",
        "        return 50\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    # æŠ€è¡“æŒ‡æ¨™è©•åˆ†\n",
        "    if 'RSI' in df.columns:\n",
        "        rsi = df['RSI'].iloc[-1]\n",
        "        if 30 <= rsi <= 70:\n",
        "            scores.append(60 + (rsi - 50) * 0.8)\n",
        "        elif rsi > 70:\n",
        "            scores.append(80)\n",
        "        else:\n",
        "            scores.append(30)\n",
        "\n",
        "    # ç§»å‹•å¹³å‡ç·šè©•åˆ†\n",
        "    if all(col in df.columns for col in ['MA5', 'MA20']):\n",
        "        if df['MA5'].iloc[-1] > df['MA20'].iloc[-1]:\n",
        "            scores.append(70)\n",
        "        else:\n",
        "            scores.append(40)\n",
        "\n",
        "    # MACDè©•åˆ†\n",
        "    if all(col in df.columns for col in ['MACD', 'MACD_Signal']):\n",
        "        if df['MACD'].iloc[-1] > df['MACD_Signal'].iloc[-1]:\n",
        "            scores.append(65)\n",
        "        else:\n",
        "            scores.append(45)\n",
        "\n",
        "    # åƒ¹æ ¼è¶¨å‹¢è©•åˆ†\n",
        "    if 'Price_Change_5d' in df.columns:\n",
        "        change = df['Price_Change_5d'].iloc[-1]\n",
        "        if change > 0.05:\n",
        "            scores.append(75)\n",
        "        elif change > 0:\n",
        "            scores.append(60)\n",
        "        elif change > -0.05:\n",
        "            scores.append(40)\n",
        "        else:\n",
        "            scores.append(25)\n",
        "\n",
        "    return np.mean(scores) if scores else 50\n",
        "\n",
        "# =============================================================================\n",
        "# 6. æ™ºèƒ½å»ºè­°ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "def generate_recommendation(combined_score, report_summary=None):\n",
        "    \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "    try:\n",
        "        combined_score = float(combined_score)\n",
        "    except (ValueError, TypeError):\n",
        "        combined_score = 50.0\n",
        "\n",
        "    recommendation = {\n",
        "        \"action\": \"ä¸­ç«‹è§€å¯Ÿ\",\n",
        "        \"reason\": f\"ç¶œåˆè©•åˆ†ä¸­æ€§ ({combined_score:.2f})ã€‚\",\n",
        "        \"pattern_details\": [],\n",
        "        \"confidence\": 50\n",
        "    }\n",
        "\n",
        "    if combined_score >= 70:\n",
        "        recommendation[\"action\"] = \"è²·å…¥\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†å¼·å‹ ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score >= 60:\n",
        "        recommendation[\"action\"] = \"è²·å…¥è§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼· ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score <= 30:\n",
        "        recommendation[\"action\"] = \"è³£å‡º\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†ç–²å¼± ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score <= 40:\n",
        "        recommendation[\"action\"] = \"è³£å‡ºè§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼± ({combined_score:.2f})ã€‚\"\n",
        "\n",
        "    # è¨ˆç®—ä¿¡å¿ƒåº¦\n",
        "    distance_from_center = abs(combined_score - 50)\n",
        "    base_confidence = min(distance_from_center * 2, 100)\n",
        "    recommendation['confidence'] = int(base_confidence)\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "# =============================================================================\n",
        "# 7. å¯è¦–åŒ–æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "class StockVisualizer:\n",
        "    def __init__(self, symbol):\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def plot_stock_analysis(self, df):\n",
        "        \"\"\"ç¹ªè£½è‚¡ç¥¨æŠ€è¡“åˆ†æåœ–\"\"\"\n",
        "        fig, axes = plt.subplots(3, 1, figsize=(16, 12), sharex=True)\n",
        "        fig.suptitle(f'{self.symbol} æŠ€è¡“åˆ†æç¸½è¦½', fontsize=20, fontweight='bold')\n",
        "\n",
        "        # åƒ¹æ ¼èˆ‡å¸ƒæ—å¸¶\n",
        "        axes[0].plot(df['Date'], df['Close'], label='æ”¶ç›¤åƒ¹', linewidth=2)\n",
        "        if 'BB_Upper' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['BB_Upper'], label='å¸ƒæ—ä¸Šè»Œ', linestyle='--', alpha=0.7)\n",
        "            axes[0].plot(df['Date'], df['BB_Lower'], label='å¸ƒæ—ä¸‹è»Œ', linestyle='--', alpha=0.7)\n",
        "            axes[0].fill_between(df['Date'], df['BB_Lower'], df['BB_Upper'], alpha=0.1)\n",
        "        axes[0].set_title('åƒ¹æ ¼èˆ‡å¸ƒæ—é€šé“')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # MACD\n",
        "        if 'MACD' in df.columns:\n",
        "            axes[1].plot(df['Date'], df['MACD'], label='MACD', color='blue')\n",
        "            axes[1].plot(df['Date'], df['MACD_Signal'], label='è¨Šè™Ÿç·š', color='red', linestyle='--')\n",
        "            axes[1].bar(df['Date'], df['MACD'] - df['MACD_Signal'], label='æŸ±ç‹€åœ–', color='gray', alpha=0.5)\n",
        "        axes[1].set_title('MACD')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        # RSI\n",
        "        if 'RSI' in df.columns:\n",
        "            axes[2].plot(df['Date'], df['RSI'], label='RSI', color='purple')\n",
        "            axes[2].axhline(70, color='red', linestyle='--', alpha=0.7, label='è¶…è²·å€ (70)')\n",
        "            axes[2].axhline(30, color='green', linestyle='--', alpha=0.7, label='è¶…è³£å€ (30)')\n",
        "        axes[2].set_title('RSI ç›¸å°å¼·å¼±æŒ‡æ•¸')\n",
        "        axes[2].legend()\n",
        "        axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "        return fig\n",
        "\n",
        "    def plot_future_prediction(self, last_price, last_date, predictions):\n",
        "        \"\"\"ç¹ªè£½æœªä¾†é æ¸¬åœ–\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 7))\n",
        "        pred_dates, pred_prices_avg = [], []\n",
        "\n",
        "        current_date = last_date\n",
        "        for day, preds in predictions.items():\n",
        "            while True:\n",
        "                current_date += timedelta(days=1)\n",
        "                if current_date.weekday() < 5:\n",
        "                    break\n",
        "\n",
        "            pred_dates.append(current_date)\n",
        "            avg_price = np.mean(list(preds.values()))\n",
        "            pred_prices_avg.append(avg_price)\n",
        "\n",
        "        ax.plot(pred_dates, pred_prices_avg, 'ro-', label='å¹³å‡é æ¸¬åƒ¹æ ¼')\n",
        "        ax.axhline(last_price, color='gray', linestyle='--', label=f'ç•¶å‰åƒ¹æ ¼ ({last_price:.2f})')\n",
        "\n",
        "        for date, price in zip(pred_dates, pred_prices_avg):\n",
        "            ax.text(date, price, f'{price:.2f}', ha='center', va='bottom')\n",
        "\n",
        "        ax.set_title(f'{self.symbol} æœªä¾†ä¸€é€±æ¯æ—¥è‚¡åƒ¹é æ¸¬', fontsize=16)\n",
        "        ax.set_xlabel('æ—¥æœŸ')\n",
        "        ax.set_ylabel('é æ¸¬åƒ¹æ ¼')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_feature_importance(self, importances):\n",
        "        \"\"\"ç¹ªè£½ç‰¹å¾µé‡è¦æ€§åœ–\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        top_10 = importances.head(10)\n",
        "        ax.barh(top_10['ç‰¹å¾µ'], top_10['é‡è¦æ€§'], color='skyblue')\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_title('ç‰¹å¾µé‡è¦æ€§æ’å (éš¨æ©Ÿæ£®æ—)', fontsize=16)\n",
        "        ax.set_xlabel('é‡è¦æ€§')\n",
        "        for index, value in enumerate(top_10['é‡è¦æ€§']):\n",
        "            ax.text(value, index, f'{value:.3f}')\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "# =============================================================================\n",
        "# 8. é€šçŸ¥ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, chart_files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        if TELEGRAM_TOKEN and TELEGRAM_CHAT_ID:\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_ID:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† è‚¡ç¥¨åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {'chat_id': chat_id, 'text': part}\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id}\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—: {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤: {e}\")\n",
        "\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "                # ç™¼é€åœ–è¡¨æ–‡ä»¶\n",
        "                if chart_files:\n",
        "                    telegram_photo_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                    for chart_file in chart_files:\n",
        "                        if os.path.exists(chart_file):\n",
        "                            try:\n",
        "                                with open(chart_file, 'rb') as photo:\n",
        "                                    files = {'photo': photo}\n",
        "                                    data = {'chat_id': chat_id}\n",
        "\n",
        "                                    import requests\n",
        "                                    response = requests.post(telegram_photo_url, files=files, data=data, timeout=30)\n",
        "\n",
        "                                    if response.status_code == 200:\n",
        "                                        logger.info(f\"æˆåŠŸç™¼é€åœ–è¡¨åˆ° Telegram: {chart_file}\")\n",
        "                                    else:\n",
        "                                        logger.error(f\"ç™¼é€åœ–è¡¨å¤±æ•—: {response.status_code}\")\n",
        "                            except Exception as e:\n",
        "                                logger.error(f\"ç™¼é€åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL:\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "\n",
        "            if chart_files:\n",
        "                for chart_file in chart_files:\n",
        "                    if os.path.exists(chart_file):\n",
        "                        with open(chart_file, \"rb\") as f:\n",
        "                            webhook.add_file(file=f.read(), filename=os.path.basename(chart_file))\n",
        "\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# 9. è‚¡ç¥¨ç¯©é¸å™¨\n",
        "# =============================================================================\n",
        "\n",
        "def screen_stocks(stock_list, days_back, condition):\n",
        "    \"\"\"ç¯©é¸ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\"\"\"\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=days_back * 2)\n",
        "    results = pd.DataFrame(columns=['ticker', 'close', 'volume', 'change_pct'])\n",
        "\n",
        "    for ticker in stock_list:\n",
        "        try:\n",
        "            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "            if data.empty or len(data) < 20:\n",
        "                continue\n",
        "\n",
        "            data = data.tail(days_back)\n",
        "            data['change_pct'] = data['Close'].pct_change() * 100\n",
        "\n",
        "            if condition == \"çªç ´æ•´ç†å€é–“\":\n",
        "                high_20d = data['High'].rolling(window=20).max().shift(1)\n",
        "                if data['Close'].iloc[-1] > high_20d.iloc[-1]:\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"çˆ†é‡é•·ç´…\":\n",
        "                vol_5d_avg = data['Volume'].rolling(window=5).mean().shift(1)\n",
        "                if (data['Volume'].iloc[-1] > vol_5d_avg.iloc[-1] * 2 and\n",
        "                    data['change_pct'].iloc[-1] > 3):\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return results\n",
        "\n",
        "# =============================================================================\n",
        "# 10. ä¸»è¦åˆ†æç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "class MultiStockAnalysisSystem:\n",
        "    def __init__(self, symbols, period='1y'):\n",
        "        self.symbols = symbols if isinstance(symbols, list) else [symbols]\n",
        "        self.period = period\n",
        "        self.results = {}\n",
        "\n",
        "    async def analyze_stock(self, symbol):\n",
        "        \"\"\"åˆ†æå–®ä¸€è‚¡ç¥¨\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æ {symbol}...\")\n",
        "\n",
        "            # 1. ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            stock_df = fetch_stock_data(symbol, self.period)\n",
        "            if stock_df is None:\n",
        "                return None\n",
        "\n",
        "            # 2. ç²å–ææ‡¼è²ªå©ªæŒ‡æ•¸\n",
        "            days_needed = len(stock_df)\n",
        "            sentiment_df = get_fear_and_greed_data(days=days_needed + 60)\n",
        "\n",
        "            # 3. åˆä½µæ•¸æ“š\n",
        "            df = pd.merge(stock_df, sentiment_df, on='Date', how='left')\n",
        "\n",
        "            # 4. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—\n",
        "            df = calculate_technical_indicators(df)\n",
        "            df = feature_engineering(df)\n",
        "\n",
        "            # 5. Kç·šå‹æ…‹åˆ†æ\n",
        "            pattern_report = generate_pattern_report(df)\n",
        "\n",
        "            # 6. ç¶œåˆè©•åˆ†\n",
        "            combined_score = calculate_combined_score(df)\n",
        "\n",
        "            # 7. æ©Ÿå™¨å­¸ç¿’é æ¸¬\n",
        "            predictor = StockPredictor()\n",
        "            predictor.run_backtest(df)\n",
        "            predictor.predict_future(df)\n",
        "\n",
        "            # 8. ç”Ÿæˆå»ºè­°\n",
        "            recommendation = generate_recommendation(combined_score)\n",
        "\n",
        "            # 9. ç”Ÿæˆåœ–è¡¨\n",
        "            visualizer = StockVisualizer(symbol)\n",
        "\n",
        "            # ä¿å­˜åœ–è¡¨\n",
        "            chart_files = []\n",
        "\n",
        "            # æŠ€è¡“åˆ†æåœ–\n",
        "            fig1 = visualizer.plot_stock_analysis(df)\n",
        "            chart_path1 = os.path.join(CHARTS_DIR, f\"{symbol}_technical.png\")\n",
        "            fig1.savefig(chart_path1, dpi=150, bbox_inches='tight')\n",
        "            chart_files.append(chart_path1)\n",
        "            plt.close(fig1)\n",
        "\n",
        "            # é æ¸¬åœ–\n",
        "            if predictor.future_predictions:\n",
        "                fig2 = visualizer.plot_future_prediction(\n",
        "                    df['Close'].iloc[-1], df['Date'].iloc[-1], predictor.future_predictions\n",
        "                )\n",
        "                chart_path2 = os.path.join(CHARTS_DIR, f\"{symbol}_prediction.png\")\n",
        "                fig2.savefig(chart_path2, dpi=150, bbox_inches='tight')\n",
        "                chart_files.append(chart_path2)\n",
        "                plt.close(fig2)\n",
        "\n",
        "            # ç‰¹å¾µé‡è¦æ€§åœ–\n",
        "            if predictor.feature_importances is not None:\n",
        "                fig3 = visualizer.plot_feature_importance(predictor.feature_importances)\n",
        "                chart_path3 = os.path.join(CHARTS_DIR, f\"{symbol}_features.png\")\n",
        "                fig3.savefig(chart_path3, dpi=150, bbox_inches='tight')\n",
        "                chart_files.append(chart_path3)\n",
        "                plt.close(fig3)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'data_df': df,\n",
        "                'combined_score': combined_score,\n",
        "                'pattern_report': pattern_report,\n",
        "                'recommendation': recommendation,\n",
        "                'predictor': predictor,\n",
        "                'chart_files': chart_files,\n",
        "                'last_price': df['Close'].iloc[-1],\n",
        "                'last_date': df['Date'].iloc[-1]\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ {symbol}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    async def run_analysis(self):\n",
        "        \"\"\"åŸ·è¡Œå¤šè‚¡ç¥¨åˆ†æ\"\"\"\n",
        "        logger.info(f\"é–‹å§‹åˆ†æ {len(self.symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "        # ä¸¦è¡Œåˆ†ææ‰€æœ‰è‚¡ç¥¨\n",
        "        tasks = [self.analyze_stock(symbol) for symbol in self.symbols]\n",
        "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "        # æ•´ç†çµæœ\n",
        "        for i, result in enumerate(results):\n",
        "            if isinstance(result, Exception):\n",
        "                logger.error(f\"åˆ†æ {self.symbols[i]} æ™‚ç™¼ç”Ÿç•°å¸¸: {result}\")\n",
        "            elif result is not None:\n",
        "                self.results[self.symbols[i]] = result\n",
        "\n",
        "        # ç”Ÿæˆç¸½çµå ±å‘Š\n",
        "        await self.generate_summary_report()\n",
        "\n",
        "    async def generate_summary_report(self):\n",
        "        \"\"\"ç”Ÿæˆç¸½çµå ±å‘Šä¸¦ç™¼é€é€šçŸ¥\"\"\"\n",
        "        if not self.results:\n",
        "            logger.warning(\"æ²’æœ‰æˆåŠŸåˆ†æçš„è‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # ç”Ÿæˆå ±å‘Šæ–‡æœ¬\n",
        "        report_lines = []\n",
        "        report_lines.append(\"ğŸ“Š å¤šè‚¡ç¥¨åˆ†æå ±å‘Š\")\n",
        "        report_lines.append(\"=\" * 50)\n",
        "        report_lines.append(f\"åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        report_lines.append(f\"åˆ†æè‚¡ç¥¨æ•¸é‡: {len(self.results)}\")\n",
        "        report_lines.append(\"\")\n",
        "\n",
        "        # æŒ‰è©•åˆ†æ’åº\n",
        "        sorted_results = sorted(self.results.items(),\n",
        "                              key=lambda x: x[1]['combined_score'], reverse=True)\n",
        "\n",
        "        for symbol, result in sorted_results:\n",
        "            report_lines.append(f\"ğŸ¢ {symbol}\")\n",
        "            report_lines.append(f\"   ç¶œåˆè©•åˆ†: {result['combined_score']:.2f}\")\n",
        "            report_lines.append(f\"   ç•¶å‰åƒ¹æ ¼: {result['last_price']:.2f}\")\n",
        "            report_lines.append(f\"   æŠ•è³‡å»ºè­°: {result['recommendation']['action']}\")\n",
        "            report_lines.append(f\"   ä¿¡å¿ƒåº¦: {result['recommendation']['confidence']}%\")\n",
        "            report_lines.append(f\"   å»ºè­°åŸå› : {result['recommendation']['reason']}\")\n",
        "\n",
        "            # é æ¸¬åƒ¹æ ¼\n",
        "            if result['predictor'].future_predictions:\n",
        "                pred_1d = result['predictor'].future_predictions.get(1, {})\n",
        "                if pred_1d:\n",
        "                    avg_pred = np.mean(list(pred_1d.values()))\n",
        "                    change_pct = (avg_pred / result['last_price'] - 1) * 100\n",
        "                    report_lines.append(f\"   æ˜æ—¥é æ¸¬: {avg_pred:.2f} ({change_pct:+.2f}%)\")\n",
        "\n",
        "            report_lines.append(\"\")\n",
        "\n",
        "        # å¸‚å ´æ•´é«”åˆ†æ\n",
        "        avg_score = np.mean([r['combined_score'] for r in self.results.values()])\n",
        "        report_lines.append(\"ğŸ“ˆ å¸‚å ´æ•´é«”åˆ†æ\")\n",
        "        report_lines.append(f\"   å¹³å‡è©•åˆ†: {avg_score:.2f}\")\n",
        "\n",
        "        if avg_score >= 60:\n",
        "            market_sentiment = \"æ¨‚è§€\"\n",
        "        elif avg_score >= 40:\n",
        "            market_sentiment = \"ä¸­æ€§\"\n",
        "        else:\n",
        "            market_sentiment = \"è¬¹æ…\"\n",
        "\n",
        "        report_lines.append(f\"   å¸‚å ´æƒ…ç·’: {market_sentiment}\")\n",
        "        report_lines.append(\"\")\n",
        "\n",
        "        # æ¨è–¦è‚¡ç¥¨\n",
        "        buy_stocks = [symbol for symbol, result in sorted_results\n",
        "                     if result['recommendation']['action'] in ['è²·å…¥', 'å¼·çƒˆè²·å…¥']]\n",
        "\n",
        "        if buy_stocks:\n",
        "            report_lines.append(\"ğŸ’° æ¨è–¦è²·å…¥:\")\n",
        "            for stock in buy_stocks[:5]:  # æœ€å¤šæ¨è–¦5æ”¯\n",
        "                score = self.results[stock]['combined_score']\n",
        "                report_lines.append(f\"   â€¢ {stock} (è©•åˆ†: {score:.2f})\")\n",
        "\n",
        "        report_lines.append(\"\")\n",
        "        report_lines.append(\"âš ï¸ å…è²¬è²æ˜: æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…æ±ºç­–ã€‚\")\n",
        "\n",
        "        report_text = \"\\n\".join(report_lines)\n",
        "\n",
        "        # æ”¶é›†æ‰€æœ‰åœ–è¡¨æ–‡ä»¶\n",
        "        all_chart_files = []\n",
        "        for result in self.results.values():\n",
        "            all_chart_files.extend(result.get('chart_files', []))\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, report_text, all_chart_files)\n",
        "\n",
        "        # çµ‚ç«¯é¡¯ç¤º\n",
        "        print(\"\\n\" + report_text)\n",
        "\n",
        "# =============================================================================\n",
        "# 11. UI ä»‹é¢ (Jupyter Notebook)\n",
        "# =============================================================================\n",
        "\n",
        "if JUPYTER_AVAILABLE:\n",
        "    def create_stock_analysis_ui():\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨åˆ†æUIä»‹é¢\"\"\"\n",
        "        # æ¨£å¼è¨­å®š\n",
        "        style = {'description_width': '120px'}\n",
        "        layout = Layout(width='300px')\n",
        "\n",
        "        # æ§åˆ¶å…ƒä»¶\n",
        "        symbol_input = widgets.Text(\n",
        "            value='AAPL,TSLA,2330,2454',\n",
        "            placeholder='è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼Œç”¨é€—è™Ÿåˆ†éš”',\n",
        "            description='è‚¡ç¥¨ä»£ç¢¼:',\n",
        "            style=style,\n",
        "            layout=Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        period_dropdown = widgets.Dropdown(\n",
        "            options=[('1å¹´', '1y'), ('2å¹´', '2y'), ('5å¹´', '5y'), ('æœ€å¤§', 'max')],\n",
        "            value='1y',\n",
        "            description='æ™‚é–“ç¯„åœ:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        analyze_button = widgets.Button(\n",
        "            description='é–‹å§‹åˆ†æ',\n",
        "            button_style='primary',\n",
        "            layout=Layout(width='150px', height='40px')\n",
        "        )\n",
        "\n",
        "        output_area = widgets.Output()\n",
        "\n",
        "        def on_analyze_click(b):\n",
        "            with output_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"ğŸš€ é–‹å§‹åˆ†æ...\")\n",
        "\n",
        "                symbols = [s.strip().upper() for s in symbol_input.value.split(',') if s.strip()]\n",
        "                if not symbols:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    return\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem(symbols, period_dropdown.value)\n",
        "\n",
        "                    # åœ¨ Jupyter ä¸­é‹è¡Œç•°æ­¥ä»£ç¢¼\n",
        "                    import asyncio\n",
        "                    loop = asyncio.get_event_loop()\n",
        "                    loop.run_until_complete(system.run_analysis())\n",
        "\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼è«‹æŸ¥çœ‹ç”Ÿæˆçš„åœ–è¡¨å’Œé€šçŸ¥ã€‚\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        analyze_button.on_click(on_analyze_click)\n",
        "\n",
        "        # çµ„åˆUI\n",
        "        ui = VBox([\n",
        "            HTML('<h2>ğŸ“ˆ å¤šè‚¡ç¥¨åˆ†æç³»çµ±</h2>'),\n",
        "            HTML('<p>æ”¯æ´å°è‚¡(è¼¸å…¥æ•¸å­—ä»£ç¢¼å¦‚2330)å’Œç¾è‚¡(è¼¸å…¥å­—æ¯ä»£ç¢¼å¦‚AAPL)</p>'),\n",
        "            symbol_input,\n",
        "            period_dropdown,\n",
        "            analyze_button,\n",
        "            output_area\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "    def create_stock_screener_ui():\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨ç¯©é¸å™¨UI\"\"\"\n",
        "        # å°è‚¡ä»£ç¢¼åˆ—è¡¨ (ç°¡åŒ–ç‰ˆ)\n",
        "        tw_stocks = [\n",
        "            '2330', '2317', '2454', '2881', '2882', '2883', '2884', '2885',\n",
        "            '2886', '2887', '2888', '2889', '2890', '2891', '2892', '2912'\n",
        "        ]\n",
        "\n",
        "        # ç¾è‚¡ä»£ç¢¼åˆ—è¡¨ (ç°¡åŒ–ç‰ˆ)\n",
        "        us_stocks = [\n",
        "            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX',\n",
        "            'JPM', 'JNJ', 'V', 'PG', 'UNH', 'HD', 'MA', 'DIS'\n",
        "        ]\n",
        "\n",
        "        style = {'description_width': '120px'}\n",
        "        layout = Layout(width='300px')\n",
        "\n",
        "        market_dropdown = widgets.Dropdown(\n",
        "            options=[('å°è‚¡', 'tw'), ('ç¾è‚¡', 'us')],\n",
        "            value='tw',\n",
        "            description='å¸‚å ´:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        condition_dropdown = widgets.Dropdown(\n",
        "            options=[\n",
        "                ('çªç ´æ•´ç†å€é–“', 'çªç ´æ•´ç†å€é–“'),\n",
        "                ('çˆ†é‡é•·ç´…', 'çˆ†é‡é•·ç´…'),\n",
        "                ('çªç ´å­£ç·š', 'çªç ´å­£ç·š'),\n",
        "                ('å¤šé ­åå™¬', 'å¤šé ­åå™¬'),\n",
        "                ('5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰', '5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰')\n",
        "            ],\n",
        "            value='çªç ´æ•´ç†å€é–“',\n",
        "            description='ç¯©é¸æ¢ä»¶:',\n",
        "            style=style,\n",
        "            layout=Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        days_slider = widgets.IntSlider(\n",
        "            value=30,\n",
        "            min=10,\n",
        "            max=100,\n",
        "            step=10,\n",
        "            description='å›çœ‹å¤©æ•¸:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        screen_button = widgets.Button(\n",
        "            description='é–‹å§‹ç¯©é¸',\n",
        "            button_style='success',\n",
        "            layout=Layout(width='150px', height='40px')\n",
        "        )\n",
        "\n",
        "        output_area = widgets.Output()\n",
        "\n",
        "        def on_screen_click(b):\n",
        "            with output_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"ğŸ” é–‹å§‹ç¯©é¸è‚¡ç¥¨...\")\n",
        "\n",
        "                stock_list = tw_stocks if market_dropdown.value == 'tw' else us_stocks\n",
        "\n",
        "                try:\n",
        "                    results = screen_stocks(stock_list, days_slider.value, condition_dropdown.value)\n",
        "\n",
        "                    if results.empty:\n",
        "                        print(\"âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "                    else:\n",
        "                        print(f\"âœ… æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨:\")\n",
        "                        print(\"\\n\" + \"=\"*60)\n",
        "                        for _, row in results.iterrows():\n",
        "                            print(f\"è‚¡ç¥¨: {row['ticker']}\")\n",
        "                            print(f\"æ”¶ç›¤åƒ¹: {row['close']:.2f}\")\n",
        "                            print(f\"æˆäº¤é‡: {row['volume']:,.0f}\")\n",
        "                            print(f\"æ¼²è·Œå¹…: {row['change_pct']:.2f}%\")\n",
        "                            print(\"-\" * 30)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ ç¯©é¸éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        screen_button.on_click(on_screen_click)\n",
        "\n",
        "        ui = VBox([\n",
        "            HTML('<h2>ğŸ” è‚¡ç¥¨ç¯©é¸å™¨</h2>'),\n",
        "            market_dropdown,\n",
        "            condition_dropdown,\n",
        "            days_slider,\n",
        "            screen_button,\n",
        "            output_area\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "# =============================================================================\n",
        "# 12. å‘½ä»¤è¡Œä»‹é¢\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"ä¸»å‡½æ•¸ï¼Œé‹è¡Œäº’å‹•å¼ç•Œé¢\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\\nğŸš€ æ­¡è¿ä½¿ç”¨å¤šè‚¡ç¥¨åˆ†æé æ¸¬ç³»çµ±\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"1. å¤šè‚¡ç¥¨åˆ†æèˆ‡é æ¸¬\")\n",
        "        print(\"2. è‚¡ç¥¨ç¯©é¸å™¨\")\n",
        "        print(\"3. å–®è‚¡ç¥¨è©³ç´°åˆ†æ\")\n",
        "        if JUPYTER_AVAILABLE:\n",
        "            print(\"4. å•Ÿå‹• Jupyter UI ä»‹é¢\")\n",
        "        print(\"0. é€€å‡ºç¨‹åº\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        try:\n",
        "            choice = input(\"è«‹é¸æ“‡åŠŸèƒ½ (0-4): \").strip()\n",
        "\n",
        "            if choice == '0':\n",
        "                print(\"æ„Ÿè¬ä½¿ç”¨ï¼Œç¨‹åºé€€å‡ºã€‚\")\n",
        "                break\n",
        "\n",
        "            elif choice == '1':\n",
        "                symbols_input = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ (ç”¨é€—è™Ÿåˆ†éš”ï¼Œå¦‚: AAPL,TSLA,2330,2454): \").strip()\n",
        "                if not symbols_input:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    continue\n",
        "\n",
        "                symbols = [s.strip().upper() for s in symbols_input.split(',') if s.strip()]\n",
        "                period = input(\"è«‹è¼¸å…¥æ­·å²æ•¸æ“šå€é–“ (1y, 2y, 5y, max) [é è¨­: 1y]: \").strip().lower()\n",
        "                if not period:\n",
        "                    period = '1y'\n",
        "\n",
        "                print(f\"ğŸš€ é–‹å§‹åˆ†æ {len(symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem(symbols, period)\n",
        "                    asyncio.run(system.run_analysis())\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '2':\n",
        "                print(\"\\nè‚¡ç¥¨ç¯©é¸å™¨\")\n",
        "                print(\"1. å°è‚¡ç¯©é¸\")\n",
        "                print(\"2. ç¾è‚¡ç¯©é¸\")\n",
        "\n",
        "                market_choice = input(\"è«‹é¸æ“‡å¸‚å ´ (1-2): \").strip()\n",
        "                if market_choice not in ['1', '2']:\n",
        "                    print(\"âŒ ç„¡æ•ˆé¸æ“‡\")\n",
        "                    continue\n",
        "\n",
        "                conditions = [\n",
        "                    \"çªç ´æ•´ç†å€é–“\", \"çˆ†é‡é•·ç´…\", \"çªç ´å­£ç·š\", \"å¤šé ­åå™¬\", \"5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰\"\n",
        "                ]\n",
        "\n",
        "                print(\"\\nç¯©é¸æ¢ä»¶:\")\n",
        "                for i, condition in enumerate(conditions, 1):\n",
        "                    print(f\"{i}. {condition}\")\n",
        "\n",
        "                condition_choice = input(\"è«‹é¸æ“‡æ¢ä»¶ (1-5): \").strip()\n",
        "                try:\n",
        "                    condition_idx = int(condition_choice) - 1\n",
        "                    if condition_idx < 0 or condition_idx >= len(conditions):\n",
        "                        print(\"âŒ ç„¡æ•ˆé¸æ“‡\")\n",
        "                        continue\n",
        "                    selected_condition = conditions[condition_idx]\n",
        "                except ValueError:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æ•¸å­—\")\n",
        "                    continue\n",
        "\n",
        "                # ç°¡åŒ–çš„è‚¡ç¥¨åˆ—è¡¨\n",
        "                tw_stocks = ['2330.TW', '2317.TW', '2454.TW', '2881.TW', '2882.TW']\n",
        "                us_stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
        "\n",
        "                stock_list = tw_stocks if market_choice == '1' else us_stocks\n",
        "\n",
        "                try:\n",
        "                    results = screen_stocks(stock_list, 30, selected_condition)\n",
        "                    if results.empty:\n",
        "                        print(\"âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "                    else:\n",
        "                        print(f\"âœ… æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨:\")\n",
        "                        print(results.to_string(index=False))\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ ç¯©é¸éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "            elif choice == '3':\n",
        "                symbol = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼: \").strip().upper()\n",
        "                if not symbol:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    continue\n",
        "\n",
        "                period = input(\"è«‹è¼¸å…¥æ­·å²æ•¸æ“šå€é–“ (1y, 2y, 5y, max) [é è¨­: 1y]: \").strip().lower()\n",
        "                if not period:\n",
        "                    period = '1y'\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem([symbol], period)\n",
        "                    asyncio.run(system.run_analysis())\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "            elif choice == '4' and JUPYTER_AVAILABLE:\n",
        "                print(\"ğŸš€ å•Ÿå‹• Jupyter UI ä»‹é¢...\")\n",
        "                print(\"è«‹åœ¨ Jupyter Notebook ä¸­é‹è¡Œä»¥ä¸‹ä»£ç¢¼:\")\n",
        "                print(\"ui = create_stock_analysis_ui()\")\n",
        "                print(\"display(ui)\")\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                print(\"âŒ ç„¡æ•ˆçš„é¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\næ“ä½œè¢«ä¸­æ–·ã€‚è¿”å›ä¸»é¸å–®...\")\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "            input(\"\\næŒ‰Enteréµè¿”å›ä¸»é¸å–®...\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    # å‰µå»ºåˆ†æä»‹é¢\n",
        "    ui = create_stock_analysis_ui()\n",
        "    display(ui)\n",
        "\n",
        "    # å‰µå»ºç¯©é¸ä»‹é¢\n",
        "    screener_ui = create_stock_screener_ui()\n",
        "    display(screener_ui)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1iJnbW11aIPBeZBbYvy8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}