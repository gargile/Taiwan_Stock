{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gargile/Taiwan_Stock/blob/main/%E6%AF%8F%E6%97%A5%E5%BF%85%E8%B7%91%E7%A8%8B%E5%BC%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kfSM3m911ys",
        "outputId": "6503d001-190e-473f-f97c-5db14295bcb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "\n",
        "# å®‰è£è³‡æ–™è™•ç†å’Œåˆ†æå¥—ä»¶\n",
        "!pip install pandas numpy -q\n",
        "\n",
        "# å®‰è£è¦–è¦ºåŒ–å¥—ä»¶\n",
        "!pip install matplotlib seaborn mplfinance -q\n",
        "!pip install chineseize-matplotlib -q\n",
        "\n",
        "# å®‰è£è³‡æ–™ç²å–å¥—ä»¶\n",
        "!pip install yfinance requests lxml html5lib -q\n",
        "!pip install twstock -q\n",
        "\n",
        "# å®‰è£å°ç£è‚¡å¸‚ç›¸é—œå¥—ä»¶æ¬¸\n",
        "!pip install shioaji[speed] -q\n",
        "!uv add shioaji --extra speed -q\n",
        "!pip install pandas-market-calendars pytz -q\n",
        "\n",
        "# å®‰è£ç•°æ­¥å’Œé€šçŸ¥ç›¸é—œå¥—ä»¶\n",
        "!pip install python-telegram-bot aiohttp nest-asyncio -q\n",
        "!pip install discord-webhook -q\n",
        "!pip install python-dotenv -q\n",
        "\n",
        "# æª¢æŸ¥å·²å®‰è£çš„å¥—ä»¶\n",
        "get_ipython().system('pip list | grep -E \"yfinance|mplfinance|pandas|numpy|matplotlib|plotly|shioaji|beautifulsoup4\"')\n",
        "# -*- coding: utf-8 -*-\n",
        "!pip install mplfinance chineseize_matplotlib yfinance pandas numpy matplotlib plotly discord-webhook requests aiohttp python-telegram-bot nest-asyncio -q\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…·\n",
        "=======================\n",
        "åŠŸèƒ½ï¼š\n",
        "- è‡ªå‹•ç²å–å°è‚¡æ¸…å–®\n",
        "- æ‰¹æ¬¡ä¸‹è¼‰æ­·å²æ•¸æ“š\n",
        "- æŠ€è¡“æŒ‡æ¨™åˆ†æ\n",
        "- ç¶œåˆè©•åˆ†æ’å\n",
        "- è‡ªå‹•é€šçŸ¥æ¨é€\n",
        "- åœ–è¡¨ç”Ÿæˆèˆ‡å ±å‘ŠåŒ¯å‡º\n",
        "\n",
        "ä½œè€…ï¼šè‚¡ç¥¨åˆ†æç³»çµ±\n",
        "ç‰ˆæœ¬ï¼šv2.1\n",
        "æ›´æ–°æ—¥æœŸï¼š2025-08-08\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. åŸºç¤ Python æ¨™æº–åº«\n",
        "# ==============================================================================\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import platform\n",
        "import re\n",
        "import glob\n",
        "import asyncio\n",
        "import warnings\n",
        "from io import StringIO\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "import logging\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ•¸æ“šè™•ç†èˆ‡ç§‘å­¸è¨ˆç®—\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. ç¬¬ä¸‰æ–¹å¥—ä»¶ - ç¶²è·¯è«‹æ±‚èˆ‡ç•°æ­¥è™•ç†\n",
        "# ==============================================================================\n",
        "import requests\n",
        "import aiohttp\n",
        "import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥æ”¯æ´ Jupyter ç’°å¢ƒ\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. ç¬¬ä¸‰æ–¹å¥—ä»¶ - é‡‘èæ•¸æ“šæº\n",
        "# ==============================================================================\n",
        "import yfinance as yf\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ•¸æ“šå¯è¦–åŒ–\n",
        "# ==============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "import mplfinance as mpf\n",
        "import plotly.graph_objects as go\n",
        "from pathlib import Path\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ™‚å€èˆ‡é€šçŸ¥\n",
        "# ==============================================================================\n",
        "import pytz\n",
        "from discord_webhook import DiscordWebhook\n",
        "import telegram\n",
        "# ==============================================================================\n",
        "# 7. ä¸­æ–‡å­—é«”æ”¯æ´\n",
        "# ==============================================================================\n",
        "try:\n",
        "    import chineseize_matplotlib\n",
        "    chineseize_matplotlib.chineseize()\n",
        "    print(\"âœ… å·²è¼‰å…¥ chineseize_matplotlib ä¸­æ–‡å­—é«”æ”¯æ´\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ æœªå®‰è£ chineseize_matplotlibï¼Œå°‡ä½¿ç”¨è‡ªå®šç¾©å­—é«”è¨­å®š\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 8. å…¨åŸŸè¨­å®š\n",
        "# ==============================================================================\n",
        "# è­¦å‘Šéæ¿¾\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# æ™‚å€è¨­å®š\n",
        "taipei_tz = pytz.timezone('Asia/Taipei')\n",
        "\n",
        "\n",
        "# --- ç›®éŒ„è¨­å®š ---\n",
        "BASE_DIR = os.getcwd() # <--- æ–°å¢é€™ä¸€è¡Œ\n",
        "CACHE_DIR = 'cache'\n",
        "RESULTS_DIR = 'results'\n",
        "CHARTS_DIR = os.path.join(RESULTS_DIR, 'charts')\n",
        "STOCK_LIST_PATH = os.path.join(CACHE_DIR, 'stock_list.csv')\n",
        "HISTORY_DATA_CACHE_DIR = os.path.join(CACHE_DIR, 'history_data')\n",
        "ETF_LIST_PATH = os.path.join(CACHE_DIR, 'etf_list.csv')\n",
        "# --- åˆå§‹åŒ–ç›®éŒ„ ---\n",
        "# ç¢ºä¿ç›®éŒ„æ˜¯ç›¸å°æ–¼ BASE_DIR å»ºç«‹çš„ï¼Œé€™æ¨£æ›´ç©©å¥\n",
        "for directory in [os.path.join(BASE_DIR, CACHE_DIR),\n",
        "                  os.path.join(BASE_DIR, RESULTS_DIR),\n",
        "                  os.path.join(BASE_DIR, CHARTS_DIR),\n",
        "                  os.path.join(BASE_DIR, HISTORY_DATA_CACHE_DIR)]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ... å¾ŒçºŒç¨‹å¼ç¢¼ ...\n",
        "\n",
        "# åˆå§‹åŒ–ç›®éŒ„\n",
        "for directory in [CACHE_DIR, RESULTS_DIR, CHARTS_DIR, HISTORY_DATA_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# 9. é€šè¨Šèˆ‡é€šçŸ¥è¨­å®š\n",
        "# ==============================================================================\n",
        "# å»ºè­°å°‡ä¾†ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ– .env æª”æ¡ˆç®¡ç†å¯†é‘°ï¼Œä»¥ç­–å®‰å…¨\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]  # æ”¯æ´å¤šç”¨æˆ¶é€šçŸ¥\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 10. æ—¥èªŒç³»çµ±è¨­å®š\n",
        "# ==============================================================================\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"stock_analysis.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ==============================================================================\n",
        "# 11. å­—é«”èˆ‡ç’°å¢ƒè¨­å®šå‡½å¼\n",
        "# ==============================================================================\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "\n",
        "    æ”¯æ´çš„ä½œæ¥­ç³»çµ±ï¼š\n",
        "    - Windows: Microsoft JhengHei, Microsoft YaHei, SimHei\n",
        "    - macOS: PingFang HK, PingFang SC, Heiti TC\n",
        "    - Linux: Noto Sans CJK / WenQuanYi Zen Hei\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            # Windows ç³»çµ±å­—é«”è¨­å®šï¼ˆåŒ…å«ç¹é«”ä¸­æ–‡å„ªå…ˆï¼‰\n",
        "            font_candidates = [\n",
        "                'Microsoft JhengHei',  # å¾®è»Ÿæ­£é»‘é«”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰\n",
        "                'Microsoft YaHei',     # å¾®è»Ÿé›…é»‘ï¼ˆç°¡é«”ä¸­æ–‡ï¼‰\n",
        "                'Arial Unicode MS',    # è¬åœ‹ç¢¼å­—é«”\n",
        "                'SimHei',              # é»‘é«”\n",
        "                'KaiTi'                # æ¥·é«”\n",
        "            ]\n",
        "\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    # æ¸¬è©¦å­—é«”æ˜¯å¦å¯ç”¨\n",
        "                    test_fig, test_ax = plt.subplots(figsize=(1, 1))\n",
        "                    test_ax.text(0.5, 0.5, 'æ¸¬è©¦', fontname=font)\n",
        "                    plt.close(test_fig)\n",
        "\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        elif system == 'Darwin':  # macOS\n",
        "            # macOS ç³»çµ±å­—é«”è¨­å®š\n",
        "            font_candidates = [\n",
        "                'PingFang HK',      # è˜‹æ–¹-é¦™æ¸¯\n",
        "                'PingFang SC',      # è˜‹æ–¹-ç°¡é«”ä¸­æ–‡\n",
        "                'PingFang TC',      # è˜‹æ–¹-ç¹é«”ä¸­æ–‡\n",
        "                'Heiti TC',         # é»‘é«”-ç¹é«”ä¸­æ–‡\n",
        "                'Heiti SC',         # é»‘é«”-ç°¡é«”ä¸­æ–‡\n",
        "                'STHeiti'           # è¯æ–‡é»‘é«”\n",
        "            ]\n",
        "\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        else:  # Linux å’Œå…¶ä»–ç³»çµ±\n",
        "            # Linux ç³»çµ±å­—é«”è·¯å¾‘\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/ukai.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/uming.ttc',\n",
        "                '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'\n",
        "            ]\n",
        "\n",
        "            found_font_path = None\n",
        "            for path in font_paths:\n",
        "                if os.path.exists(path):\n",
        "                    found_font_path = path\n",
        "                    break\n",
        "\n",
        "            if found_font_path:\n",
        "                try:\n",
        "                    font_manager.fontManager.addfont(found_font_path)\n",
        "                    font_prop = font_manager.FontProperties(fname=found_font_path)\n",
        "                    font_name = font_prop.get_name()\n",
        "                    plt.rcParams['font.sans-serif'] = [font_name]\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"è¼‰å…¥å­—é«”å¤±æ•—: {e}\")\n",
        "                    font_name = \"DejaVu Sans\"\n",
        "            else:\n",
        "                print(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                font_name = \"DejaVu Sans\"\n",
        "\n",
        "        # è¨­å®š matplotlib åƒæ•¸\n",
        "        plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¢ºé¡¯ç¤ºè² è™Ÿ\n",
        "\n",
        "        # è¨­å®šå­—é«”å¤§å°\n",
        "        plt.rcParams['font.size'] = 10\n",
        "        plt.rcParams['axes.titlesize'] = 12\n",
        "        plt.rcParams['axes.labelsize'] = 10\n",
        "        plt.rcParams['xtick.labelsize'] = 9\n",
        "        plt.rcParams['ytick.labelsize'] = 9\n",
        "        plt.rcParams['legend.fontsize'] = 9\n",
        "\n",
        "        # è¨­å®šåœ–è¡¨å“è³ª\n",
        "        plt.rcParams['figure.dpi'] = 100\n",
        "        plt.rcParams['savefig.dpi'] = 150\n",
        "        plt.rcParams['savefig.bbox'] = 'tight'\n",
        "\n",
        "        if font_name and font_name != \"DejaVu Sans\":\n",
        "            print(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name} ({system})\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ä½¿ç”¨é è¨­å­—é«”: {font_name}\")\n",
        "            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"\n",
        "    æª¢æŸ¥åŸ·è¡Œç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶\n",
        "    \"\"\"\n",
        "    print(\"ğŸ” æª¢æŸ¥åŸ·è¡Œç’°å¢ƒ...\")\n",
        "    print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
        "    print(f\"ä½œæ¥­ç³»çµ±: {platform.system()} {platform.release()}\")\n",
        "    print(f\"ç•¶å‰æ™‚å€: {taipei_tz}\")\n",
        "\n",
        "    # æª¢æŸ¥é‡è¦å¥—ä»¶ç‰ˆæœ¬\n",
        "    required_packages = {\n",
        "        'pandas': pd.__version__,\n",
        "        'numpy': np.__version__,\n",
        "        'matplotlib': plt.matplotlib.__version__,\n",
        "        'requests': requests.__version__,\n",
        "        'yfinance': getattr(yf, '__version__', 'Unknown'),\n",
        "        'aiohttp': aiohttp.__version__,\n",
        "        'pytz': pytz.__version__\n",
        "    }\n",
        "\n",
        "    print(\"\\nğŸ“¦ å¥—ä»¶ç‰ˆæœ¬:\")\n",
        "    for package, version in required_packages.items():\n",
        "        print(f\"  {package}: {version}\")\n",
        "\n",
        "    # æª¢æŸ¥ç›®éŒ„æ¬Šé™\n",
        "    print(f\"\\nğŸ“ å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "    directories_status = {\n",
        "        'å¿«å–ç›®éŒ„': (CACHE_DIR, os.access(CACHE_DIR, os.W_OK)),\n",
        "        'çµæœç›®éŒ„': (RESULTS_DIR, os.access(RESULTS_DIR, os.W_OK)),\n",
        "        'åœ–è¡¨ç›®éŒ„': (CHARTS_DIR, os.access(CHARTS_DIR, os.W_OK))\n",
        "    }\n",
        "\n",
        "    for name, (path, writable) in directories_status.items():\n",
        "        status = 'âœ…' if writable else 'âŒ'\n",
        "        print(f\"{name}: {path} {status}\")\n",
        "\n",
        "    # æª¢æŸ¥ç¶²è·¯é€£ç·šï¼ˆç°¡å–®æ¸¬è©¦ï¼‰\n",
        "    try:\n",
        "        response = requests.get('https://httpbin.org/status/200', timeout=5)\n",
        "        network_status = 'âœ…' if response.status_code == 200 else 'âŒ'\n",
        "    except:\n",
        "        network_status = 'âŒ'\n",
        "\n",
        "    print(f\"ç¶²è·¯é€£ç·š: {network_status}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "def get_current_time():\n",
        "    \"\"\"\n",
        "    ç²å–ç•¶å‰å°åŒ—æ™‚é–“\n",
        "    \"\"\"\n",
        "    return datetime.now(taipei_tz)\n",
        "\n",
        "def format_timestamp(dt=None):\n",
        "    \"\"\"\n",
        "    æ ¼å¼åŒ–æ™‚é–“æˆ³è¨˜\n",
        "    \"\"\"\n",
        "    if dt is None:\n",
        "        dt = get_current_time()\n",
        "    return dt.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
        "\n",
        "# ==============================================================================\n",
        "# 12. ç¨‹å¼åˆå§‹åŒ–\n",
        "# ==============================================================================\n",
        "def initialize_application():\n",
        "    \"\"\"\n",
        "    æ‡‰ç”¨ç¨‹å¼åˆå§‹åŒ–\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· v2.1\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # æª¢æŸ¥ç’°å¢ƒ\n",
        "    check_environment()\n",
        "\n",
        "    # è¨­å®šä¸­æ–‡å­—é«”\n",
        "    set_chinese_font()\n",
        "\n",
        "    # è¨˜éŒ„å•Ÿå‹•æ™‚é–“\n",
        "    start_time = get_current_time()\n",
        "    logger.info(f\"æ‡‰ç”¨ç¨‹å¼å•Ÿå‹• - {format_timestamp(start_time)}\")\n",
        "    logger.info(f\"å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "\n",
        "    print(f\"âœ… åˆå§‹åŒ–å®Œæˆ - {format_timestamp(start_time)}\\n\")\n",
        "\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸\n",
        "# ==============================================================================\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram\n",
        "    try:\n",
        "        url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "        payload = {\"chat_id\": TELEGRAM_CHAT_ID, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "        await session.post(url_msg, json=payload, timeout=20)\n",
        "        logger.info(\"Telegram æ‘˜è¦ç™¼é€æˆåŠŸã€‚\")\n",
        "\n",
        "        if files:\n",
        "            url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "            for file_path in files:\n",
        "                if os.path.exists(file_path):\n",
        "                    data = aiohttp.FormData()\n",
        "                    data.add_field('chat_id', TELEGRAM_CHAT_ID)\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                        await session.post(url_photo, data=data, timeout=60)\n",
        "            logger.info(f\"Telegram åœ–æª”ç™¼é€æˆåŠŸ ({len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord\n",
        "    if MESSAGING_AVAILABLE:\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            if files:\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        with open(file_path, 'rb') as f:\n",
        "                            webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "    else:\n",
        "        logger.warning(\"Discord é€šçŸ¥åŠŸèƒ½æœªå•Ÿç”¨ï¼ˆå¥—ä»¶æœªå®‰è£ï¼‰\")\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        if taipei_tz:\n",
        "            current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        else:\n",
        "            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "\n",
        "ğŸ“Š TOP 5 æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f}\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "print(\"âœ… ç’°å¢ƒè¨­å®šå®Œæˆï¼\")\n",
        "print(f\"ğŸ“ å·¥ä½œç›®éŒ„: {BASE_DIR}\")\n",
        "print(f\"ğŸ“Š åœ–è¡¨ç›®éŒ„: {CHARTS_DIR}\")\n",
        "print(f\"ğŸ”” é€šçŸ¥åŠŸèƒ½: {'å·²å•Ÿç”¨' if MESSAGING_AVAILABLE else 'éƒ¨åˆ†å•Ÿç”¨ï¼ˆåƒ… Telegramï¼‰'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä¸Šé¢æ˜¯å®‰è£ç¨‹å¼ç¢¼"
      ],
      "metadata": {
        "id": "GlFqLBsVPgaJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lAv54yeW2Dqi"
      },
      "outputs": [],
      "source": [
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "import nest_asyncio\n",
        "\n",
        "# å®‰è£ nest_asyncioï¼ˆå¦‚æœå°šæœªå®‰è£ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥å…è¨±åµŒå¥—äº‹ä»¶å¾ªç’°\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()  # ä¿®æ­£ï¼šä½¿ç”¨ copy() é¿å…è­¦å‘Š\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()  # ä¿®æ­£ï¼šä½¿ç”¨ copy()\n",
        "                df.loc[:, 'market'] = market_name  # ä¿®æ­£ï¼šä½¿ç”¨ .loc è¨­å®šå€¼\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)].copy()\n",
        "\n",
        "            # ä¿®æ­£ï¼šä½¿ç”¨ .loc è¨­å®š yahoo_symbol\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨è‚¡ç¥¨æ¸…å–®\")\n",
        "\n",
        "            # æ“´å±•çŸ¥åè‚¡ç¥¨åˆ—è¡¨\n",
        "            famous_stocks = [\n",
        "                {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2412', 'stock_name': 'ä¸­è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2412.TW', 'industry': 'é€šä¿¡'},\n",
        "                {'stock_id': '1301', 'stock_name': 'å°å¡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1301.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '1303', 'stock_name': 'å—äº', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1303.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '2308', 'stock_name': 'å°é”é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2308.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2002', 'stock_name': 'ä¸­é‹¼', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2002.TW', 'industry': 'é‹¼éµ'},\n",
        "                {'stock_id': '2886', 'stock_name': 'å…†è±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2886.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2891.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '3008', 'stock_name': 'å¤§ç«‹å…‰', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3008.TW', 'industry': 'å…‰å­¸'},\n",
        "                {'stock_id': '2357', 'stock_name': 'è¯ç¢©', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2357.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2382', 'stock_name': 'å»£é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2382.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2395', 'stock_name': 'ç ”è¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2395.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '3711', 'stock_name': 'æ—¥æœˆå…‰æŠ•æ§', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3711.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2409', 'stock_name': 'å‹é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2409.TW', 'industry': 'é¢æ¿'},\n",
        "                {'stock_id': '2884', 'stock_name': 'ç‰å±±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2884.TW', 'industry': 'é‡‘è'},\n",
        "                # æ–°å¢æ›´å¤šè‚¡ç¥¨\n",
        "                {'stock_id': '2474', 'stock_name': 'å¯æˆ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2474.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2408', 'stock_name': 'å—äºç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2408.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2301', 'stock_name': 'å…‰å¯¶ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2301.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2207', 'stock_name': 'å’Œæ³°è»Š', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2207.TW', 'industry': 'æ±½è»Š'},\n",
        "                {'stock_id': '1216', 'stock_name': 'çµ±ä¸€', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1216.TW', 'industry': 'é£Ÿå“'},\n",
        "                {'stock_id': '1101', 'stock_name': 'å°æ³¥', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1101.TW', 'industry': 'æ°´æ³¥'},\n",
        "                {'stock_id': '2105', 'stock_name': 'æ­£æ–°', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2105.TW', 'industry': 'æ©¡è† '},\n",
        "                {'stock_id': '2912', 'stock_name': 'çµ±ä¸€è¶…', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2912.TW', 'industry': 'è²¿æ˜“ç™¾è²¨'},\n",
        "                {'stock_id': '2885', 'stock_name': 'å…ƒå¤§é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2885.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2892', 'stock_name': 'ç¬¬ä¸€é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2892.TW', 'industry': 'é‡‘è'},\n",
        "            ]\n",
        "\n",
        "            df = pd.DataFrame(famous_stocks)\n",
        "            logger.info(f\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_info.get('stock_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºå‰ååï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æ - å‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºå‰ååå„ªè³ªè‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† å‰ {len(top_stocks)} åå„ªè³ªè‚¡ç¥¨:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\" if price_change < 0 else \"â¡ï¸\"\n",
        "\n",
        "            # å»ºè­°ç¬¦è™Ÿ\n",
        "            rec_symbol = \"ğŸš€\" if \"å¼·åŠ›è²·\" in rec_text else \"ğŸ“ˆ\" if \"è²·\" in rec_text else \"ğŸ“Š\" if \"æŒæœ‰\" in rec_text else \"ğŸ“‰\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {stock_name} ({stock_id})\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f} ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   â­ è©•åˆ†: {score:.1f}/100\")\n",
        "            message_parts.append(f\"   {rec_symbol} å»ºè­°: {rec_text}\")\n",
        "            message_parts.append(f\"   ğŸ“Š æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # æ·»åŠ ä¸»è¦æŠ€è¡“æŒ‡æ¨™\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            rsi_value = tech.get('rsi_value', 50)\n",
        "            macd_signal = tech.get('macd_signal', 'ä¸­æ€§')\n",
        "            message_parts.append(f\"   ğŸ” RSI: {rsi_value:.1f} | MACD: {macd_signal}\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_score = sum(r.get('combined_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('combined_score', 0) >= 70])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ“Š å¹³å‡åˆ†æ•¸: {avg_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†è‚¡ç¥¨ (â‰¥70): {high_score_count}\")\n",
        "\n",
        "            # å»ºè­°åˆ†å¸ƒ\n",
        "            recommendations = {}\n",
        "            for result in top_stocks:\n",
        "                rec = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "                recommendations[rec] = recommendations.get(rec, 0) + 1\n",
        "\n",
        "            if recommendations:\n",
        "                message_parts.append(\"   ğŸ“ˆ å‰ååå»ºè­°åˆ†å¸ƒ:\")\n",
        "                for rec, count in recommendations.items():\n",
        "                    message_parts.append(f\"      {rec}: {count}\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        message_parts.append(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{score:<8.1f}{current_price:<10.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {stock_name} ({stock_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† å°è‚¡åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ å°è‚¡æŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQcFPQMbKs2j"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYVE8CMr_4sD"
      },
      "source": [
        "ä¸Šé¢æ˜¯å°è‚¡é¸æ“‡æ¯æ—¥1000å¼µï¼Œè©•åˆ†æœ€å„ªå‰åå"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xnj0aFDO_54D"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "import nest_asyncio\n",
        "\n",
        "# å®‰è£ nest_asyncioï¼ˆå¦‚æœå°šæœªå®‰è£ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥å…è¨±åµŒå¥—äº‹ä»¶å¾ªç’°\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.etf_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_etfs(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£ETFæ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.etf_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.etf_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥ETFåˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.etf_list_path, dtype={'etf_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°ETFæ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_etfs_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df.loc[:, 'market'] = market_name\n",
        "                all_etfs_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} ETFåˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_etfs_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•ETFæ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_etf_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_etfs_df, ignore_index=True)\n",
        "            df[['etf_id', 'etf_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "\n",
        "            # ç¯©é¸ETFï¼šåªä¿ç•™4ä½æ•¸å­—ä»£ç¢¼ä¸”åç¨±åŒ…å«ETFç›¸é—œé—œéµå­—çš„é …ç›®\n",
        "            df = df[df['etf_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "\n",
        "            # åªä¿ç•™ETFç›¸é—œçš„è­‰åˆ¸\n",
        "            etf_keywords = ['ETF', 'ETN', 'æŒ‡æ•¸', 'åŸºé‡‘', 'å‚˜å‹', 'æœŸè²¨', 'åå‘', 'æ§“æ¡¿']\n",
        "            df = df[df['etf_name'].str.contains('|'.join(etf_keywords), na=False)].copy()\n",
        "\n",
        "            # æ’é™¤ä¸€èˆ¬è‚¡ç¥¨å’Œå…¶ä»–éETFå•†å“\n",
        "            exclude_keywords = ['è³¼', 'ç‰›', 'ç†Š', 'èªè³¼', 'èªå”®', 'æ¬Šè­‰', 'å­˜è¨—æ†‘è­‰', 'TDR']\n",
        "            df = df[~df['etf_name'].str.contains('|'.join(exclude_keywords), na=False)].copy()\n",
        "\n",
        "            # è¨­å®šYahoo Financeç¬¦è™Ÿ\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['etf_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['etf_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['etf_id', 'etf_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(\n",
        "                columns={'ç”¢æ¥­åˆ¥': 'category', 'etf_id': 'etf_id', 'etf_name': 'etf_name'})\n",
        "            final_df = final_df.drop_duplicates(subset=['etf_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.etf_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯ETFæ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_etf_list()\n",
        "\n",
        "    def _get_backup_etf_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨ETFæ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨ETFæ¸…å–®\")\n",
        "\n",
        "            # å°ç£ä¸»è¦ETFåˆ—è¡¨\n",
        "            famous_etfs = [\n",
        "                # å¸‚å€¼å‹ETF\n",
        "                {'etf_id': '0050', 'etf_name': 'å…ƒå¤§å°ç£50', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '0050.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '0056', 'etf_name': 'å…ƒå¤§é«˜è‚¡æ¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '0056.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '006208', 'etf_name': 'å¯Œé‚¦å°50', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '006208.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00878', 'etf_name': 'åœ‹æ³°æ°¸çºŒé«˜è‚¡æ¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00878.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00881', 'etf_name': 'åœ‹æ³°å°ç£5G+', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00881.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # é«˜è‚¡æ¯ETF\n",
        "                {'etf_id': '00713', 'etf_name': 'å…ƒå¤§å°ç£é«˜æ¯ä½æ³¢', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00713.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00701', 'etf_name': 'åœ‹æ³°ä½æ³¢å‹•', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00701.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00692', 'etf_name': 'å¯Œé‚¦å…¬å¸æ²»ç†', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00692.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00900', 'etf_name': 'å¯Œé‚¦ç‰¹é¸é«˜è‚¡æ¯30', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00900.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00919', 'etf_name': 'ç¾¤ç›Šå°ç£ç²¾é¸é«˜æ¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00919.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # ç§‘æŠ€é¡ETF\n",
        "                {'etf_id': '00757', 'etf_name': 'çµ±ä¸€FANG+', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00757.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00861', 'etf_name': 'å…ƒå¤§å…¨çƒæœªä¾†é€šè¨Š', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00861.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00876', 'etf_name': 'å…ƒå¤§æœªä¾†é—œéµç§‘æŠ€', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00876.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # å‚µåˆ¸å‹ETF\n",
        "                {'etf_id': '00679B', 'etf_name': 'å…ƒå¤§ç¾å‚µ20å¹´', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00679B.TW', 'category': 'å‚µåˆ¸å‹ETF'},\n",
        "                {'etf_id': '00687B', 'etf_name': 'åœ‹æ³°20å¹´ç¾å‚µ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00687B.TW', 'category': 'å‚µåˆ¸å‹ETF'},\n",
        "                {'etf_id': '00720B', 'etf_name': 'å…ƒå¤§æŠ•è³‡ç´šå…¬å¸å‚µ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00720B.TW', 'category': 'å‚µåˆ¸å‹ETF'},\n",
        "                {'etf_id': '00751B', 'etf_name': 'å…ƒå¤§AAAè‡³Aå…¬å¸å‚µ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00751B.TW', 'category': 'å‚µåˆ¸å‹ETF'},\n",
        "\n",
        "                # åœ‹éš›è‚¡ç¥¨ETF\n",
        "                {'etf_id': '00646', 'etf_name': 'å…ƒå¤§S&P500', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00646.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00662', 'etf_name': 'å¯Œé‚¦NASDAQ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00662.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00670L', 'etf_name': 'å¯Œé‚¦NASDAQæ­£2', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00670L.TW', 'category': 'æ§“æ¡¿å‹ETF'},\n",
        "                {'etf_id': '00672L', 'etf_name': 'å…ƒå¤§S&P500æ­£2', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00672L.TW', 'category': 'æ§“æ¡¿å‹ETF'},\n",
        "\n",
        "                # åå‘ETF\n",
        "                {'etf_id': '00632R', 'etf_name': 'å…ƒå¤§å°ç£50å1', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00632R.TW', 'category': 'åå‘å‹ETF'},\n",
        "                {'etf_id': '00673R', 'etf_name': 'å…ƒå¤§S&P500å1', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00673R.TW', 'category': 'åå‘å‹ETF'},\n",
        "\n",
        "                # ä¸­å°å‹ETF\n",
        "                {'etf_id': '0051', 'etf_name': 'å…ƒå¤§ä¸­å‹100', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '0051.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '006201', 'etf_name': 'å…ƒå¤§å¯Œæ«ƒ50', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '006201.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # ESGç›¸é—œETF\n",
        "                {'etf_id': '00850', 'etf_name': 'å…ƒå¤§å°ç£ESGæ°¸çºŒ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00850.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00888', 'etf_name': 'æ°¸è±å°ç£ESG', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00888.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "\n",
        "                # ç”¢æ¥­å‹ETF\n",
        "                {'etf_id': '00891', 'etf_name': 'ä¸­ä¿¡é—œéµåŠå°é«”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00891.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00892', 'etf_name': 'å¯Œé‚¦å°ç£åŠå°é«”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00892.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "                {'etf_id': '00896', 'etf_name': 'ä¸­ä¿¡ç¶ èƒ½åŠé›»å‹•è»Š', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '00896.TW', 'category': 'è‚¡ç¥¨å‹ETF'},\n",
        "            ]\n",
        "\n",
        "            df = pd.DataFrame(famous_etfs)\n",
        "            logger.info(f\"å‚™ç”¨ETFæ¸…å–®åŒ…å« {len(df)} æ”¯ETF\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, etf_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=etf_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{etf_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{etf_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{etf_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        etf_name = stock_info['etf_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {etf_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'etf_name': etf_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'etf_name': etf_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'etf_name': etf_name,\n",
        "                'etf_id': stock_info.get('etf_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {etf_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'etf_name': etf_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_etfs()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºå‰ååï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ† å°è‚¡ETFæŠ€è¡“åˆ†æ - å‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºå‰ååå„ªè³ªè‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† å‰ {len(top_stocks)} åå„ªè³ªè‚¡ç¥¨:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\" if price_change < 0 else \"â¡ï¸\"\n",
        "\n",
        "            # å»ºè­°ç¬¦è™Ÿ\n",
        "            rec_symbol = \"ğŸš€\" if \"å¼·åŠ›è²·\" in rec_text else \"ğŸ“ˆ\" if \"è²·\" in rec_text else \"ğŸ“Š\" if \"æŒæœ‰\" in rec_text else \"ğŸ“‰\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {etf_name} ({etf_id})\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f} ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   â­ è©•åˆ†: {score:.1f}/100\")\n",
        "            message_parts.append(f\"   {rec_symbol} å»ºè­°: {rec_text}\")\n",
        "            message_parts.append(f\"   ğŸ“Š æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # æ·»åŠ ä¸»è¦æŠ€è¡“æŒ‡æ¨™\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            rsi_value = tech.get('rsi_value', 50)\n",
        "            macd_signal = tech.get('macd_signal', 'ä¸­æ€§')\n",
        "            message_parts.append(f\"   ğŸ” RSI: {rsi_value:.1f} | MACD: {macd_signal}\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_score = sum(r.get('combined_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('combined_score', 0) >= 70])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ“Š å¹³å‡åˆ†æ•¸: {avg_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†è‚¡ç¥¨ (â‰¥70): {high_score_count}\")\n",
        "\n",
        "            # å»ºè­°åˆ†å¸ƒ\n",
        "            recommendations = {}\n",
        "            for result in top_stocks:\n",
        "                rec = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "                recommendations[rec] = recommendations.get(rec, 0) + 1\n",
        "\n",
        "            if recommendations:\n",
        "                message_parts.append(\"   ğŸ“ˆ å‰ååå»ºè­°åˆ†å¸ƒ:\")\n",
        "                for rec, count in recommendations.items():\n",
        "                    message_parts.append(f\"      {rec}: {count}\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        message_parts.append(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ† å°è‚¡ETFæŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{etf_id:<8}{etf_name:<12}{score:<8.1f}{current_price:<10.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {etf_name} ({etf_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† å°è‚¡ETFåˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ å°è‚¡ETFæŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªETF\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰ETFï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGaMyvmZKupb"
      },
      "source": [
        "ä¸Šé¢æ˜¯å°ç£çš„ETFé¸è‚¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJPsAK8mK_G0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "import nest_asyncio\n",
        "\n",
        "# å®‰è£ nest_asyncioï¼ˆå¦‚æœå°šæœªå®‰è£ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥å…è¨±åµŒå¥—äº‹ä»¶å¾ªç’°\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_us_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–ç¾è‚¡è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥ç¾è‚¡è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾ç¶²è·¯ç²å–æœ€æ–°ç¾è‚¡æ¸…å–®...\")\n",
        "        all_stocks_df = []\n",
        "\n",
        "        # ä½¿ç”¨å¤šå€‹æ•¸æ“šæºç²å–ç¾è‚¡æ¸…å–®\n",
        "        try:\n",
        "            # æ–¹æ³•1: ä½¿ç”¨ yfinance ç²å– S&P 500 æˆåˆ†è‚¡\n",
        "            import yfinance as yf\n",
        "\n",
        "            # ç²å– S&P 500 æˆåˆ†è‚¡\n",
        "            sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "            sp500_df = pd.read_html(sp500_url)[0]\n",
        "            sp500_df = sp500_df.rename(columns={\n",
        "                'Symbol': 'stock_id',\n",
        "                'Security': 'stock_name',\n",
        "                'GICS Sector': 'industry'\n",
        "            })\n",
        "            sp500_df['market'] = 'NYSE/NASDAQ'\n",
        "            sp500_df['yahoo_symbol'] = sp500_df['stock_id']\n",
        "            all_stocks_df.append(sp500_df[['stock_id', 'stock_name', 'market', 'industry', 'yahoo_symbol']])\n",
        "\n",
        "            # ç²å– NASDAQ 100 æˆåˆ†è‚¡\n",
        "            nasdaq100_url = \"https://en.wikipedia.org/wiki/NASDAQ-100\"\n",
        "            nasdaq100_df = pd.read_html(nasdaq100_url)[4]  # é€šå¸¸æ˜¯ç¬¬4å€‹è¡¨æ ¼\n",
        "            nasdaq100_df = nasdaq100_df.rename(columns={\n",
        "                'Ticker': 'stock_id',\n",
        "                'Company': 'stock_name',\n",
        "                'GICS Sector': 'industry'\n",
        "            })\n",
        "            nasdaq100_df['market'] = 'NASDAQ'\n",
        "            nasdaq100_df['yahoo_symbol'] = nasdaq100_df['stock_id']\n",
        "            all_stocks_df.append(nasdaq100_df[['stock_id', 'stock_name', 'market', 'industry', 'yahoo_symbol']])\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å¾ç¶²è·¯ç²å–ç¾è‚¡æ¸…å–®å¤±æ•—: {e}\")\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨ç¾è‚¡æ¸…å–®\")\n",
        "            return self._get_backup_us_stock_list()\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•ç¾è‚¡æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_us_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "\n",
        "            # æ¸…ç†æ•¸æ“š\n",
        "            df = df.dropna(subset=['stock_id', 'stock_name']).copy()\n",
        "\n",
        "            # éæ¿¾ç¾è‚¡è‚¡ç¥¨ä»£ç¢¼ï¼ˆé€šå¸¸æ˜¯1-5å€‹å­—æ¯ï¼‰\n",
        "            df = df[df['stock_id'].str.match(r'^[A-Z]{1,5}$', na=False)].copy()\n",
        "\n",
        "            # æ’é™¤ETFã€åŸºé‡‘ç­‰éè‚¡ç¥¨å•†å“\n",
        "            exclude_keywords = ['ETF', 'Fund', 'Trust', 'LP', 'Inc.', 'Corp.', 'Ltd.']\n",
        "            # ä½†ä¿ç•™å…¬å¸åç¨±ä¸­å¸¸è¦‹çš„ Inc., Corp. ç­‰\n",
        "            exclude_pattern = r'\\b(ETF|Fund|Trust|LP)\\b'\n",
        "            df = df[~df['stock_name'].str.contains(exclude_pattern, case=False, na=False)].copy()\n",
        "\n",
        "            # å»é‡ä¸¦æ•´ç†\n",
        "            df = df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "\n",
        "            # å¡«å……ç¼ºå¤±çš„è¡Œæ¥­è³‡è¨Š\n",
        "            df['industry'] = df['industry'].fillna('å…¶ä»–')\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'industry', 'yahoo_symbol']]\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯ç¾è‚¡æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†ç¾è‚¡æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_us_stock_list()\n",
        "\n",
        "    def _get_backup_us_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨ç¾è‚¡æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨ç¾è‚¡æ¸…å–®\")\n",
        "\n",
        "            # ç¾åœ‹çŸ¥åè‚¡ç¥¨åˆ—è¡¨\n",
        "            famous_us_stocks = [\n",
        "            # ç§‘æŠ€è‚¡ (FAANG + å…¶ä»–)\n",
        "            {'stock_id': 'AAPL', 'stock_name': 'Apple Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'AAPL', 'industry': 'Technology'},\n",
        "            {'stock_id': 'MSFT', 'stock_name': 'Microsoft Corporation', 'market': 'NASDAQ', 'yahoo_symbol': 'MSFT', 'industry': 'Technology'},\n",
        "            {'stock_id': 'GOOGL', 'stock_name': 'Alphabet Inc. Class A', 'market': 'NASDAQ', 'yahoo_symbol': 'GOOGL', 'industry': 'Technology'},\n",
        "            {'stock_id': 'AMZN', 'stock_name': 'Amazon.com Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'AMZN', 'industry': 'Consumer Discretionary'},\n",
        "            {'stock_id': 'META', 'stock_name': 'Meta Platforms Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'META', 'industry': 'Technology'},\n",
        "            {'stock_id': 'TSLA', 'stock_name': 'Tesla Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'TSLA', 'industry': 'Consumer Discretionary'},\n",
        "            {'stock_id': 'NVDA', 'stock_name': 'NVIDIA Corporation', 'market': 'NASDAQ', 'yahoo_symbol': 'NVDA', 'industry': 'Technology'},\n",
        "            {'stock_id': 'NFLX', 'stock_name': 'Netflix Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'NFLX', 'industry': 'Communication Services'},\n",
        "\n",
        "            # å‚³çµ±å¤§å‹è‚¡\n",
        "            {'stock_id': 'BRK.B', 'stock_name': 'Berkshire Hathaway Inc. Class B', 'market': 'NYSE', 'yahoo_symbol': 'BRK-B', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'JPM', 'stock_name': 'JPMorgan Chase & Co.', 'market': 'NYSE', 'yahoo_symbol': 'JPM', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'JNJ', 'stock_name': 'Johnson & Johnson', 'market': 'NYSE', 'yahoo_symbol': 'JNJ', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'V', 'stock_name': 'Visa Inc.', 'market': 'NYSE', 'yahoo_symbol': 'V', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'PG', 'stock_name': 'Procter & Gamble Co.', 'market': 'NYSE', 'yahoo_symbol': 'PG', 'industry': 'Consumer Staples'},\n",
        "            {'stock_id': 'UNH', 'stock_name': 'UnitedHealth Group Inc.', 'market': 'NYSE', 'yahoo_symbol': 'UNH', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'HD', 'stock_name': 'Home Depot Inc.', 'market': 'NYSE', 'yahoo_symbol': 'HD', 'industry': 'Consumer Discretionary'},\n",
        "            {'stock_id': 'MA', 'stock_name': 'Mastercard Inc.', 'market': 'NYSE', 'yahoo_symbol': 'MA', 'industry': 'Financial Services'},\n",
        "\n",
        "            # å·¥æ¥­è‚¡\n",
        "            {'stock_id': 'BA', 'stock_name': 'Boeing Co.', 'market': 'NYSE', 'yahoo_symbol': 'BA', 'industry': 'Industrials'},\n",
        "            {'stock_id': 'CAT', 'stock_name': 'Caterpillar Inc.', 'market': 'NYSE', 'yahoo_symbol': 'CAT', 'industry': 'Industrials'},\n",
        "            {'stock_id': 'MMM', 'stock_name': '3M Co.', 'market': 'NYSE', 'yahoo_symbol': 'MMM', 'industry': 'Industrials'},\n",
        "            {'stock_id': 'GE', 'stock_name': 'General Electric Co.', 'market': 'NYSE', 'yahoo_symbol': 'GE', 'industry': 'Industrials'},\n",
        "\n",
        "            # èƒ½æºè‚¡\n",
        "            {'stock_id': 'XOM', 'stock_name': 'Exxon Mobil Corporation', 'market': 'NYSE', 'yahoo_symbol': 'XOM', 'industry': 'Energy'},\n",
        "            {'stock_id': 'CVX', 'stock_name': 'Chevron Corporation', 'market': 'NYSE', 'yahoo_symbol': 'CVX', 'industry': 'Energy'},\n",
        "\n",
        "            # é‡‘èè‚¡\n",
        "            {'stock_id': 'BAC', 'stock_name': 'Bank of America Corp.', 'market': 'NYSE', 'yahoo_symbol': 'BAC', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'WFC', 'stock_name': 'Wells Fargo & Co.', 'market': 'NYSE', 'yahoo_symbol': 'WFC', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'GS', 'stock_name': 'Goldman Sachs Group Inc.', 'market': 'NYSE', 'yahoo_symbol': 'GS', 'industry': 'Financial Services'},\n",
        "            {'stock_id': 'MS', 'stock_name': 'Morgan Stanley', 'market': 'NYSE', 'yahoo_symbol': 'MS', 'industry': 'Financial Services'},\n",
        "\n",
        "            # æ¶ˆè²»è‚¡\n",
        "            {'stock_id': 'KO', 'stock_name': 'Coca-Cola Co.', 'market': 'NYSE', 'yahoo_symbol': 'KO', 'industry': 'Consumer Staples'},\n",
        "            {'stock_id': 'PEP', 'stock_name': 'PepsiCo Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'PEP', 'industry': 'Consumer Staples'},\n",
        "            {'stock_id': 'WMT', 'stock_name': 'Walmart Inc.', 'market': 'NYSE', 'yahoo_symbol': 'WMT', 'industry': 'Consumer Staples'},\n",
        "            {'stock_id': 'MCD', 'stock_name': 'McDonald\\'s Corp.', 'market': 'NYSE', 'yahoo_symbol': 'MCD', 'industry': 'Consumer Discretionary'},\n",
        "\n",
        "            # é†«ç™‚ä¿å¥è‚¡\n",
        "            {'stock_id': 'PFE', 'stock_name': 'Pfizer Inc.', 'market': 'NYSE', 'yahoo_symbol': 'PFE', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'ABBV', 'stock_name': 'AbbVie Inc.', 'market': 'NYSE', 'yahoo_symbol': 'ABBV', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'MRK', 'stock_name': 'Merck & Co. Inc.', 'market': 'NYSE', 'yahoo_symbol': 'MRK', 'industry': 'Healthcare'},\n",
        "            {'stock_id': 'LLY', 'stock_name': 'Eli Lilly and Co.', 'market': 'NYSE', 'yahoo_symbol': 'LLY', 'industry': 'Healthcare'},\n",
        "\n",
        "            # é€šä¿¡è‚¡\n",
        "            {'stock_id': 'T', 'stock_name': 'AT&T Inc.', 'market': 'NYSE', 'yahoo_symbol': 'T', 'industry': 'Communication Services'},\n",
        "            {'stock_id': 'VZ', 'stock_name': 'Verizon Communications Inc.', 'market': 'NYSE', 'yahoo_symbol': 'VZ', 'industry': 'Communication Services'},\n",
        "\n",
        "            # åŠå°é«”è‚¡\n",
        "            {'stock_id': 'AMD', 'stock_name': 'Advanced Micro Devices Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'AMD', 'industry': 'Technology'},\n",
        "            {'stock_id': 'INTC', 'stock_name': 'Intel Corporation', 'market': 'NASDAQ', 'yahoo_symbol': 'INTC', 'industry': 'Technology'},\n",
        "            {'stock_id': 'QCOM', 'stock_name': 'Qualcomm Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'QCOM', 'industry': 'Technology'},\n",
        "\n",
        "            # å…¶ä»–çŸ¥åç§‘æŠ€è‚¡\n",
        "            {'stock_id': 'CRM', 'stock_name': 'Salesforce Inc.', 'market': 'NYSE', 'yahoo_symbol': 'CRM', 'industry': 'Technology'},\n",
        "            {'stock_id': 'ORCL', 'stock_name': 'Oracle Corporation', 'market': 'NYSE', 'yahoo_symbol': 'ORCL', 'industry': 'Technology'},\n",
        "            {'stock_id': 'ADBE', 'stock_name': 'Adobe Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'ADBE', 'industry': 'Technology'},\n",
        "            {'stock_id': 'PYPL', 'stock_name': 'PayPal Holdings Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'PYPL', 'industry': 'Financial Services'},\n",
        "\n",
        "            # é›»å‹•è»Šç›¸é—œ\n",
        "            {'stock_id': 'NIO', 'stock_name': 'NIO Inc.', 'market': 'NYSE', 'yahoo_symbol': 'NIO', 'industry': 'Consumer Discretionary'},\n",
        "            {'stock_id': 'RIVN', 'stock_name': 'Rivian Automotive Inc.', 'market': 'NASDAQ', 'yahoo_symbol': 'RIVN', 'industry': 'Consumer Discretionary'},\n",
        "\n",
        "            # æ–°èˆˆç§‘æŠ€è‚¡\n",
        "            {'stock_id': 'PLTR', 'stock_name': 'Palantir Technologies Inc.', 'market': 'NYSE', 'yahoo_symbol': 'PLTR', 'industry': 'Technology'},\n",
        "            {'stock_id': 'SNOW', 'stock_name': 'Snowflake Inc.', 'market': 'NYSE', 'yahoo_symbol': 'SNOW', 'industry': 'Technology'},\n",
        "            ]\n",
        "\n",
        "            df = pd.DataFrame(famous_us_stocks)\n",
        "            logger.info(f\"å‚™ç”¨ç¾è‚¡æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨ç¾è‚¡æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_info.get('stock_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_us_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºå‰ååï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ† ç¾è‚¡æŠ€è¡“åˆ†æ - å‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºå‰ååå„ªè³ªè‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† å‰ {len(top_stocks)} åå„ªè³ªè‚¡ç¥¨:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\" if price_change < 0 else \"â¡ï¸\"\n",
        "\n",
        "            # å»ºè­°ç¬¦è™Ÿ\n",
        "            rec_symbol = \"ğŸš€\" if \"å¼·åŠ›è²·\" in rec_text else \"ğŸ“ˆ\" if \"è²·\" in rec_text else \"ğŸ“Š\" if \"æŒæœ‰\" in rec_text else \"ğŸ“‰\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {stock_name} ({stock_id})\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f} ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   â­ è©•åˆ†: {score:.1f}/100\")\n",
        "            message_parts.append(f\"   {rec_symbol} å»ºè­°: {rec_text}\")\n",
        "            message_parts.append(f\"   ğŸ“Š æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # æ·»åŠ ä¸»è¦æŠ€è¡“æŒ‡æ¨™\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            rsi_value = tech.get('rsi_value', 50)\n",
        "            macd_signal = tech.get('macd_signal', 'ä¸­æ€§')\n",
        "            message_parts.append(f\"   ğŸ” RSI: {rsi_value:.1f} | MACD: {macd_signal}\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_score = sum(r.get('combined_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('combined_score', 0) >= 70])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ“Š å¹³å‡åˆ†æ•¸: {avg_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†è‚¡ç¥¨ (â‰¥70): {high_score_count}\")\n",
        "\n",
        "            # å»ºè­°åˆ†å¸ƒ\n",
        "            recommendations = {}\n",
        "            for result in top_stocks:\n",
        "                rec = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "                recommendations[rec] = recommendations.get(rec, 0) + 1\n",
        "\n",
        "            if recommendations:\n",
        "                message_parts.append(\"   ğŸ“ˆ å‰ååå»ºè­°åˆ†å¸ƒ:\")\n",
        "                for rec, count in recommendations.items():\n",
        "                    message_parts.append(f\"      {rec}: {count}\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        message_parts.append(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ† ç¾è‚¡æŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{score:<8.1f}{current_price:<10.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {stock_name} ({stock_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† ç¾è‚¡åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ ç¾è‚¡æŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰ç¾è‚¡ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DksukWJ0S61E"
      },
      "source": [
        "ä¸Šé¢æ˜¯ç¾è‚¡ç¯©é¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoUaEt1wTCMp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "class USETFAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–ç¾è‚¡ETFåˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.us_etfs = None\n",
        "        self.etf_list_path = \"us_etfs_cache.csv\"\n",
        "\n",
        "    def _get_comprehensive_us_etf_list(self) -> pd.DataFrame:\n",
        "        \"\"\"ç²å–å®Œæ•´ç¾è‚¡ETFæ¸…å–® - åŒ…å«å„é¡å‹ETFå’ŒæœŸè²¨\"\"\"\n",
        "        try:\n",
        "            logger.info(\"å»ºç«‹å®Œæ•´ç¾è‚¡ETF/æœŸè²¨/è²´é‡‘å±¬æ¸…å–®...\")\n",
        "\n",
        "            # å®Œæ•´ç¾è‚¡ETFå’ŒæœŸè²¨åˆ—è¡¨\n",
        "            us_etfs = [\n",
        "                # å¤§ç›¤æŒ‡æ•¸ETF\n",
        "                {'etf_id': 'SPY', 'etf_name': 'SPDR S&P 500 ETF Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'SPY', 'category': 'å¤§ç›¤æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'QQQ', 'etf_name': 'Invesco QQQ Trust', 'market': 'NASDAQ', 'yahoo_symbol': 'QQQ', 'category': 'ç§‘æŠ€æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'IWM', 'etf_name': 'iShares Russell 2000 ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'IWM', 'category': 'å°å‹è‚¡ETF'},\n",
        "                {'etf_id': 'VTI', 'etf_name': 'Vanguard Total Stock Market ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VTI', 'category': 'å…¨å¸‚å ´ETF'},\n",
        "                {'etf_id': 'VOO', 'etf_name': 'Vanguard S&P 500 ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VOO', 'category': 'å¤§ç›¤æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'DIA', 'etf_name': 'SPDR Dow Jones Industrial Average ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'DIA', 'category': 'é“ç“ŠæŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'VEA', 'etf_name': 'Vanguard FTSE Developed Markets ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VEA', 'category': 'å·²é–‹ç™¼å¸‚å ´ETF'},\n",
        "                {'etf_id': 'VWO', 'etf_name': 'Vanguard FTSE Emerging Markets ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VWO', 'category': 'æ–°èˆˆå¸‚å ´ETF'},\n",
        "\n",
        "                # æ§“æ¡¿ETF\n",
        "                {'etf_id': 'TQQQ', 'etf_name': 'ProShares UltraPro QQQ', 'market': 'NASDAQ', 'yahoo_symbol': 'TQQQ', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'UPRO', 'etf_name': 'ProShares UltraPro S&P500', 'market': 'NYSE Arca', 'yahoo_symbol': 'UPRO', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'SPXL', 'etf_name': 'Direxion Daily S&P 500 Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'SPXL', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'TNA', 'etf_name': 'Direxion Daily Small Cap Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TNA', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'TECL', 'etf_name': 'Direxion Daily Technology Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TECL', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'SOXL', 'etf_name': 'Direxion Daily Semiconductor Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'SOXL', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'LABU', 'etf_name': 'Direxion Daily S&P Biotech Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'LABU', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "                {'etf_id': 'FNGU', 'etf_name': 'MicroSectors FANG+ Index 3X Leveraged ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'FNGU', 'category': '3å€æ§“æ¡¿ETF'},\n",
        "\n",
        "                # åå‘ETF\n",
        "                {'etf_id': 'SQQQ', 'etf_name': 'ProShares UltraPro Short QQQ', 'market': 'NASDAQ', 'yahoo_symbol': 'SQQQ', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'SPXS', 'etf_name': 'Direxion Daily S&P 500 Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'SPXS', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'TZA', 'etf_name': 'Direxion Daily Small Cap Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TZA', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'SOXS', 'etf_name': 'Direxion Daily Semiconductor Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'SOXS', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'LABD', 'etf_name': 'Direxion Daily S&P Biotech Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'LABD', 'category': '3å€åå‘ETF'},\n",
        "                {'etf_id': 'FNGD', 'etf_name': 'MicroSectors FANG+ Index -3X Inverse Leveraged ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'FNGD', 'category': '3å€åå‘ETF'},\n",
        "\n",
        "                # æ³¢å‹•ç‡ETF\n",
        "                {'etf_id': 'UVXY', 'etf_name': 'ProShares Ultra VIX Short-Term Futures ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'UVXY', 'category': 'æ³¢å‹•ç‡ETF'},\n",
        "                {'etf_id': 'VXX', 'etf_name': 'iPath Series B S&P 500 VIX Short-Term Futures ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'VXX', 'category': 'æ³¢å‹•ç‡ETF'},\n",
        "                {'etf_id': 'SVXY', 'etf_name': 'ProShares Short VIX Short-Term Futures ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'SVXY', 'category': 'åå‘æ³¢å‹•ç‡ETF'},\n",
        "                {'etf_id': 'VIXY', 'etf_name': 'ProShares VIX Short-Term Futures ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VIXY', 'category': 'æ³¢å‹•ç‡ETF'},\n",
        "\n",
        "                # å‚µåˆ¸ETF\n",
        "                {'etf_id': 'TLT', 'etf_name': 'iShares 20+ Year Treasury Bond ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'TLT', 'category': 'é•·æœŸåœ‹å‚µETF'},\n",
        "                {'etf_id': 'IEF', 'etf_name': 'iShares 7-10 Year Treasury Bond ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'IEF', 'category': 'ä¸­æœŸåœ‹å‚µETF'},\n",
        "                {'etf_id': 'SHY', 'etf_name': 'iShares 1-3 Year Treasury Bond ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'SHY', 'category': 'çŸ­æœŸåœ‹å‚µETF'},\n",
        "                {'etf_id': 'HYG', 'etf_name': 'iShares iBoxx $ High Yield Corporate Bond ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'HYG', 'category': 'é«˜æ”¶ç›Šå‚µåˆ¸ETF'},\n",
        "                {'etf_id': 'LQD', 'etf_name': 'iShares iBoxx $ Investment Grade Corporate Bond ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'LQD', 'category': 'æŠ•è³‡ç´šå‚µåˆ¸ETF'},\n",
        "                {'etf_id': 'AGG', 'etf_name': 'iShares Core U.S. Aggregate Bond ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'AGG', 'category': 'ç¶œåˆå‚µåˆ¸ETF'},\n",
        "                {'etf_id': 'TMF', 'etf_name': 'Direxion Daily 20+ Year Treasury Bull 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TMF', 'category': '3å€æ§“æ¡¿å‚µåˆ¸ETF'},\n",
        "                {'etf_id': 'TMV', 'etf_name': 'Direxion Daily 20+ Year Treasury Bear 3X Shares', 'market': 'NYSE Arca', 'yahoo_symbol': 'TMV', 'category': '3å€åå‘å‚µåˆ¸ETF'},\n",
        "\n",
        "                # è²´é‡‘å±¬ETF\n",
        "                {'etf_id': 'GLD', 'etf_name': 'SPDR Gold Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'GLD', 'category': 'é»ƒé‡‘ETF'},\n",
        "                {'etf_id': 'SLV', 'etf_name': 'iShares Silver Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'SLV', 'category': 'ç™½éŠ€ETF'},\n",
        "                {'etf_id': 'PPLT', 'etf_name': 'abrdn Physical Platinum Shares ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'PPLT', 'category': 'é‰‘é‡‘ETF'},\n",
        "                {'etf_id': 'PALL', 'etf_name': 'abrdn Physical Palladium Shares ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'PALL', 'category': 'éˆ€é‡‘ETF'},\n",
        "                {'etf_id': 'IAU', 'etf_name': 'iShares Gold Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'IAU', 'category': 'é»ƒé‡‘ETF'},\n",
        "                {'etf_id': 'UGLD', 'etf_name': 'VelocityShares 3x Long Gold ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'UGLD', 'category': '3å€æ§“æ¡¿é»ƒé‡‘ETF'},\n",
        "                {'etf_id': 'DGLD', 'etf_name': 'VelocityShares 3x Inverse Gold ETN', 'market': 'NYSE Arca', 'yahoo_symbol': 'DGLD', 'category': '3å€åå‘é»ƒé‡‘ETF'},\n",
        "\n",
        "                # è²´é‡‘å±¬æœŸè²¨\n",
        "                {'etf_id': 'GC=F', 'etf_name': 'Gold Futures', 'market': 'COMEX', 'yahoo_symbol': 'GC=F', 'category': 'é»ƒé‡‘æœŸè²¨'},\n",
        "                {'etf_id': 'SI=F', 'etf_name': 'Silver Futures', 'market': 'COMEX', 'yahoo_symbol': 'SI=F', 'category': 'ç™½éŠ€æœŸè²¨'},\n",
        "                {'etf_id': 'PL=F', 'etf_name': 'Platinum Futures', 'market': 'NYMEX', 'yahoo_symbol': 'PL=F', 'category': 'é‰‘é‡‘æœŸè²¨'},\n",
        "                {'etf_id': 'PA=F', 'etf_name': 'Palladium Futures', 'market': 'NYMEX', 'yahoo_symbol': 'PA=F', 'category': 'éˆ€é‡‘æœŸè²¨'},\n",
        "\n",
        "                # èƒ½æºæœŸè²¨\n",
        "                {'etf_id': 'CL=F', 'etf_name': 'Crude Oil Futures', 'market': 'NYMEX', 'yahoo_symbol': 'CL=F', 'category': 'åŸæ²¹æœŸè²¨'},\n",
        "                {'etf_id': 'NG=F', 'etf_name': 'Natural Gas Futures', 'market': 'NYMEX', 'yahoo_symbol': 'NG=F', 'category': 'å¤©ç„¶æ°£æœŸè²¨'},\n",
        "                {'etf_id': 'RB=F', 'etf_name': 'Gasoline Futures', 'market': 'NYMEX', 'yahoo_symbol': 'RB=F', 'category': 'æ±½æ²¹æœŸè²¨'},\n",
        "                {'etf_id': 'HO=F', 'etf_name': 'Heating Oil Futures', 'market': 'NYMEX', 'yahoo_symbol': 'HO=F', 'category': 'ç‡ƒæ²¹æœŸè²¨'},\n",
        "\n",
        "                # åŸç‰©æ–™æœŸè²¨ETF\n",
        "                {'etf_id': 'USO', 'etf_name': 'United States Oil Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'USO', 'category': 'åŸæ²¹æœŸè²¨ETF'},\n",
        "                {'etf_id': 'UNG', 'etf_name': 'United States Natural Gas Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'UNG', 'category': 'å¤©ç„¶æ°£æœŸè²¨ETF'},\n",
        "                {'etf_id': 'DBA', 'etf_name': 'Invesco DB Agriculture Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'DBA', 'category': 'è¾²ç”¢å“æœŸè²¨ETF'},\n",
        "                {'etf_id': 'DBC', 'etf_name': 'Invesco DB Commodity Index Tracking Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'DBC', 'category': 'å•†å“æœŸè²¨ETF'},\n",
        "                {'etf_id': 'DBB', 'etf_name': 'Invesco DB Base Metals Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'DBB', 'category': 'åŸºæœ¬é‡‘å±¬æœŸè²¨ETF'},\n",
        "                {'etf_id': 'CORN', 'etf_name': 'Teucrium Corn Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'CORN', 'category': 'ç‰ç±³æœŸè²¨ETF'},\n",
        "                {'etf_id': 'WEAT', 'etf_name': 'Teucrium Wheat Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'WEAT', 'category': 'å°éº¥æœŸè²¨ETF'},\n",
        "                {'etf_id': 'SOYB', 'etf_name': 'Teucrium Soybean Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'SOYB', 'category': 'å¤§è±†æœŸè²¨ETF'},\n",
        "                {'etf_id': 'UCO', 'etf_name': 'ProShares Ultra Bloomberg Crude Oil', 'market': 'NYSE Arca', 'yahoo_symbol': 'UCO', 'category': '2å€æ§“æ¡¿åŸæ²¹ETF'},\n",
        "                {'etf_id': 'SCO', 'etf_name': 'ProShares UltraShort Bloomberg Crude Oil', 'market': 'NYSE Arca', 'yahoo_symbol': 'SCO', 'category': '2å€åå‘åŸæ²¹ETF'},\n",
        "\n",
        "                # è¾²ç”¢å“æœŸè²¨\n",
        "                {'etf_id': 'ZC=F', 'etf_name': 'Corn Futures', 'market': 'CBOT', 'yahoo_symbol': 'ZC=F', 'category': 'ç‰ç±³æœŸè²¨'},\n",
        "                {'etf_id': 'ZS=F', 'etf_name': 'Soybean Futures', 'market': 'CBOT', 'yahoo_symbol': 'ZS=F', 'category': 'å¤§è±†æœŸè²¨'},\n",
        "                {'etf_id': 'ZW=F', 'etf_name': 'Wheat Futures', 'market': 'CBOT', 'yahoo_symbol': 'ZW=F', 'category': 'å°éº¥æœŸè²¨'},\n",
        "                {'etf_id': 'CT=F', 'etf_name': 'Cotton Futures', 'market': 'ICE', 'yahoo_symbol': 'CT=F', 'category': 'æ£‰èŠ±æœŸè²¨'},\n",
        "                {'etf_id': 'SB=F', 'etf_name': 'Sugar Futures', 'market': 'ICE', 'yahoo_symbol': 'SB=F', 'category': 'ç³–æœŸè²¨'},\n",
        "                {'etf_id': 'KC=F', 'etf_name': 'Coffee Futures', 'market': 'ICE', 'yahoo_symbol': 'KC=F', 'category': 'å’–å•¡æœŸè²¨'},\n",
        "                {'etf_id': 'CC=F', 'etf_name': 'Cocoa Futures', 'market': 'ICE', 'yahoo_symbol': 'CC=F', 'category': 'å¯å¯æœŸè²¨'},\n",
        "\n",
        "                # å·¥æ¥­é‡‘å±¬æœŸè²¨\n",
        "                {'etf_id': 'HG=F', 'etf_name': 'Copper Futures', 'market': 'COMEX', 'yahoo_symbol': 'HG=F', 'category': 'éŠ…æœŸè²¨'},\n",
        "\n",
        "                # ç”¢æ¥­é¡ETF\n",
        "                {'etf_id': 'XLF', 'etf_name': 'Financial Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLF', 'category': 'é‡‘èæ¥­ETF'},\n",
        "                {'etf_id': 'XLE', 'etf_name': 'Energy Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLE', 'category': 'èƒ½æºæ¥­ETF'},\n",
        "                {'etf_id': 'XLK', 'etf_name': 'Technology Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLK', 'category': 'ç§‘æŠ€æ¥­ETF'},\n",
        "                {'etf_id': 'XLV', 'etf_name': 'Health Care Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLV', 'category': 'é†«ç™‚ä¿å¥ETF'},\n",
        "                {'etf_id': 'XLI', 'etf_name': 'Industrial Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLI', 'category': 'å·¥æ¥­ETF'},\n",
        "                {'etf_id': 'XLY', 'etf_name': 'Consumer Discretionary Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLY', 'category': 'éå¿…éœ€æ¶ˆè²»ETF'},\n",
        "                {'etf_id': 'XLP', 'etf_name': 'Consumer Staples Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLP', 'category': 'å¿…éœ€æ¶ˆè²»ETF'},\n",
        "                {'etf_id': 'XLU', 'etf_name': 'Utilities Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLU', 'category': 'å…¬ç”¨äº‹æ¥­ETF'},\n",
        "                {'etf_id': 'XLB', 'etf_name': 'Materials Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLB', 'category': 'åŸææ–™ETF'},\n",
        "                {'etf_id': 'XLRE', 'etf_name': 'Real Estate Select Sector SPDR Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'XLRE', 'category': 'æˆ¿åœ°ç”¢ETF'},\n",
        "                {'etf_id': 'SOXX', 'etf_name': 'iShares Semiconductor ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'SOXX', 'category': 'åŠå°é«”ETF'},\n",
        "\n",
        "                # åœ‹éš›å¸‚å ´ETF\n",
        "                {'etf_id': 'EEM', 'etf_name': 'iShares MSCI Emerging Markets ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'EEM', 'category': 'æ–°èˆˆå¸‚å ´ETF'},\n",
        "                {'etf_id': 'EFA', 'etf_name': 'iShares MSCI EAFE ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'EFA', 'category': 'æ­æ¾³é æ±ETF'},\n",
        "                {'etf_id': 'FXI', 'etf_name': 'iShares China Large-Cap ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'FXI', 'category': 'ä¸­åœ‹å¤§å‹è‚¡ETF'},\n",
        "                {'etf_id': 'EWJ', 'etf_name': 'iShares MSCI Japan ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'EWJ', 'category': 'æ—¥æœ¬ETF'},\n",
        "                {'etf_id': 'EWZ', 'etf_name': 'iShares MSCI Brazil ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'EWZ', 'category': 'å·´è¥¿ETF'},\n",
        "                {'etf_id': 'INDA', 'etf_name': 'iShares MSCI India ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'INDA', 'category': 'å°åº¦ETF'},\n",
        "                {'etf_id': 'RSX', 'etf_name': 'VanEck Russia ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'RSX', 'category': 'ä¿„ç¾…æ–¯ETF'},\n",
        "\n",
        "                # æˆ¿åœ°ç”¢ETF\n",
        "                {'etf_id': 'VNQ', 'etf_name': 'Vanguard Real Estate ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'VNQ', 'category': 'æˆ¿åœ°ç”¢ETF'},\n",
        "                {'etf_id': 'IYR', 'etf_name': 'iShares U.S. Real Estate ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'IYR', 'category': 'æˆ¿åœ°ç”¢ETF'},\n",
        "\n",
        "                # åŠ å¯†è²¨å¹£ç›¸é—œETF\n",
        "                {'etf_id': 'BITO', 'etf_name': 'ProShares Bitcoin Strategy ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'BITO', 'category': 'æ¯”ç‰¹å¹£æœŸè²¨ETF'},\n",
        "                {'etf_id': 'BITI', 'etf_name': 'ProShares Short Bitcoin Strategy ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'BITI', 'category': 'åå‘æ¯”ç‰¹å¹£æœŸè²¨ETF'},\n",
        "\n",
        "                # å‰µæ–°ç§‘æŠ€ETF\n",
        "                {'etf_id': 'ARKK', 'etf_name': 'ARK Innovation ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'ARKK', 'category': 'å‰µæ–°ç§‘æŠ€ETF'},\n",
        "                {'etf_id': 'ARKQ', 'etf_name': 'ARK Autonomous Technology & Robotics ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'ARKQ', 'category': 'è‡ªå‹•åŒ–ç§‘æŠ€ETF'},\n",
        "                {'etf_id': 'ARKW', 'etf_name': 'ARK Next Generation Internet ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'ARKW', 'category': 'ç¶²è·¯ç§‘æŠ€ETF'},\n",
        "                {'etf_id': 'ARKG', 'etf_name': 'ARK Genomic Revolution ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'ARKG', 'category': 'åŸºå› ç§‘æŠ€ETF'},\n",
        "\n",
        "                # æ³¢å‹•ç‡æŒ‡æ•¸\n",
        "                {'etf_id': 'VIX', 'etf_name': 'CBOE Volatility Index', 'market': 'CBOE', 'yahoo_symbol': '^VIX', 'category': 'æ³¢å‹•ç‡æŒ‡æ•¸'},\n",
        "\n",
        "                # å¤–åŒ¯ETF\n",
        "                {'etf_id': 'UUP', 'etf_name': 'Invesco DB US Dollar Index Bullish Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'UUP', 'category': 'ç¾å…ƒæŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'UDN', 'etf_name': 'Invesco DB US Dollar Index Bearish Fund', 'market': 'NYSE Arca', 'yahoo_symbol': 'UDN', 'category': 'åå‘ç¾å…ƒæŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'FXE', 'etf_name': 'Invesco CurrencyShares Euro Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'FXE', 'category': 'æ­å…ƒETF'},\n",
        "                {'etf_id': 'FXY', 'etf_name': 'Invesco CurrencyShares Japanese Yen Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'FXY', 'category': 'æ—¥åœ“ETF'},\n",
        "\n",
        "                # å…¶ä»–ç†±é–€ETF\n",
        "                {'etf_id': 'JETS', 'etf_name': 'U.S. Global Jets ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'JETS', 'category': 'èˆªç©ºæ¥­ETF'},\n",
        "                {'etf_id': 'ICLN', 'etf_name': 'iShares Global Clean Energy ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'ICLN', 'category': 'æ¸…æ½”èƒ½æºETF'},\n",
        "                                {'etf_id': 'BOTZ', 'etf_name': 'Global X Robotics & Artificial Intelligence ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'BOTZ', 'category': 'æ©Ÿå™¨äººAI ETF'},\n",
        "                {'etf_id': 'CLOU', 'etf_name': 'Global X Cloud Computing ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'CLOU', 'category': 'é›²ç«¯é‹ç®—ETF'},\n",
        "                {'etf_id': 'ESPO', 'etf_name': 'VanEck Video Gaming and eSports ETF', 'market': 'NASDAQ', 'yahoo_symbol': 'ESPO', 'category': 'é›»ç«¶éŠæˆ²ETF'},\n",
        "                {'etf_id': 'LIT', 'etf_name': 'Global X Lithium & Battery Tech ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'LIT', 'category': 'é‹°é›»æ± ETF'},\n",
        "                {'etf_id': 'KWEB', 'etf_name': 'KraneShares CSI China Internet ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'KWEB', 'category': 'ä¸­åœ‹ç¶²è·¯ETF'},\n",
        "                {'etf_id': 'MCHI', 'etf_name': 'iShares MSCI China ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'MCHI', 'category': 'ä¸­åœ‹ETF'},\n",
        "                {'etf_id': 'GDX', 'etf_name': 'VanEck Gold Miners ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'GDX', 'category': 'é»ƒé‡‘ç¤¦æ¥­ETF'},\n",
        "                {'etf_id': 'GDXJ', 'etf_name': 'VanEck Junior Gold Miners ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'GDXJ', 'category': 'å°å‹é»ƒé‡‘ç¤¦æ¥­ETF'},\n",
        "                {'etf_id': 'SIL', 'etf_name': 'Global X Silver Miners ETF', 'market': 'NYSE Arca', 'yahoo_symbol': 'SIL', 'category': 'ç™½éŠ€ç¤¦æ¥­ETF'},\n",
        "            ]\n",
        "\n",
        "            # é©—è­‰æ¯å€‹æ¨™çš„æ˜¯å¦å¯ä»¥å¾ yfinance ç²å–æ•¸æ“š\n",
        "            validated_etfs = self._validate_symbols_with_yfinance(us_etfs)\n",
        "\n",
        "            df = pd.DataFrame(validated_etfs)\n",
        "            logger.info(f\"å®Œæ•´ç¾è‚¡ETFæ¸…å–®åŒ…å« {len(df)} æ”¯å·²é©—è­‰çš„ETF/æœŸè²¨/è²´é‡‘å±¬\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆç¾è‚¡ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def _validate_symbols_with_yfinance(self, etf_list: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"ä½¿ç”¨ yfinance é©—è­‰æ¨™çš„æ˜¯å¦æœ‰æ•ˆ\"\"\"\n",
        "        logger.info(\"é–‹å§‹é©—è­‰æ¨™çš„æœ‰æ•ˆæ€§...\")\n",
        "        validated_etfs = []\n",
        "\n",
        "        def validate_single_symbol(etf_info):\n",
        "            \"\"\"é©—è­‰å–®ä¸€æ¨™çš„\"\"\"\n",
        "            try:\n",
        "                symbol = etf_info['yahoo_symbol']\n",
        "                ticker = yf.Ticker(symbol)\n",
        "\n",
        "                # å˜—è©¦ç²å–æœ€è¿‘5å¤©çš„æ•¸æ“šä¾†é©—è­‰æ¨™çš„æ˜¯å¦æœ‰æ•ˆ\n",
        "                hist = ticker.history(period=\"5d\")\n",
        "\n",
        "                if not hist.empty and len(hist) > 0:\n",
        "                    # ç²å–åŸºæœ¬ä¿¡æ¯\n",
        "                    info = ticker.info\n",
        "\n",
        "                    # æ›´æ–°æ¨™çš„åç¨±ï¼ˆå¦‚æœ yfinance æä¾›äº†æ›´æº–ç¢ºçš„åç¨±ï¼‰\n",
        "                    if 'longName' in info and info['longName']:\n",
        "                        etf_info['etf_name'] = info['longName']\n",
        "                    elif 'shortName' in info and info['shortName']:\n",
        "                        etf_info['etf_name'] = info['shortName']\n",
        "\n",
        "                    # æ·»åŠ é¡å¤–ä¿¡æ¯\n",
        "                    etf_info['last_price'] = float(hist['Close'].iloc[-1]) if not hist['Close'].empty else None\n",
        "                    etf_info['volume'] = int(hist['Volume'].iloc[-1]) if not hist['Volume'].empty else None\n",
        "                    etf_info['validated'] = True\n",
        "                    etf_info['validation_date'] = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
        "\n",
        "                    logger.debug(f\"âœ“ {symbol} é©—è­‰æˆåŠŸ\")\n",
        "                    return etf_info\n",
        "                else:\n",
        "                    logger.warning(f\"âœ— {symbol} ç„¡æ•¸æ“š\")\n",
        "                    return None\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"âœ— {etf_info['yahoo_symbol']} é©—è­‰å¤±æ•—: {e}\")\n",
        "                return None\n",
        "\n",
        "        # ä½¿ç”¨å¤šç·šç¨‹åŠ é€Ÿé©—è­‰éç¨‹\n",
        "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "            future_to_etf = {executor.submit(validate_single_symbol, etf): etf for etf in etf_list}\n",
        "\n",
        "            for future in as_completed(future_to_etf):\n",
        "                result = future.result()\n",
        "                if result is not None:\n",
        "                    validated_etfs.append(result)\n",
        "\n",
        "        logger.info(f\"é©—è­‰å®Œæˆ: {len(validated_etfs)}/{len(etf_list)} å€‹æ¨™çš„æœ‰æ•ˆ\")\n",
        "        return validated_etfs\n",
        "\n",
        "    def get_us_etfs(self, force_update=False):\n",
        "        \"\"\"ç²å–ç¾è‚¡ETFæ¸…å–® - ä½¿ç”¨çœŸå¯¦æ•¸æ“š\"\"\"\n",
        "        if not force_update and os.path.exists(self.etf_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.etf_list_path)) < 86400:  # 24å°æ™‚å¿«å–\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥ç¾è‚¡ETFåˆ—è¡¨\")\n",
        "                return pd.read_csv(self.etf_list_path, dtype={'etf_id': str})\n",
        "\n",
        "        logger.info(\"ç²å–ç¾è‚¡ETFæ¸…å–® - ä½¿ç”¨ yfinance çœŸå¯¦æ•¸æ“šé©—è­‰...\")\n",
        "\n",
        "        try:\n",
        "            # ç²å–ä¸¦é©—è­‰ETFæ¸…å–®\n",
        "            df = self._get_comprehensive_us_etf_list()\n",
        "\n",
        "            if not df.empty:\n",
        "                # ä¿å­˜åˆ°å¿«å–\n",
        "                df.to_csv(self.etf_list_path, index=False)\n",
        "                logger.info(f\"æˆåŠŸç²å–ä¸¦é©—è­‰ {len(df)} æ”¯ç¾è‚¡ETFæ¸…å–®ä¸¦ä¿å­˜å¿«å–\")\n",
        "\n",
        "                # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯\n",
        "                category_counts = df['category'].value_counts()\n",
        "                logger.info(\"æ¨™çš„é¡åˆ¥çµ±è¨ˆ:\")\n",
        "                for category, count in category_counts.items():\n",
        "                    logger.info(f\"  {category}: {count} æ”¯\")\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç²å–ç¾è‚¡ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            # å¦‚æœé©—è­‰å¤±æ•—ï¼Œè¿”å›åŸºæœ¬æ¸…å–®\n",
        "            return pd.DataFrame([\n",
        "                {'etf_id': 'SPY', 'etf_name': 'SPDR S&P 500 ETF Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'SPY', 'category': 'å¤§ç›¤æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'QQQ', 'etf_name': 'Invesco QQQ Trust', 'market': 'NASDAQ', 'yahoo_symbol': 'QQQ', 'category': 'ç§‘æŠ€æŒ‡æ•¸ETF'},\n",
        "                {'etf_id': 'GLD', 'etf_name': 'SPDR Gold Trust', 'market': 'NYSE Arca', 'yahoo_symbol': 'GLD', 'category': 'é»ƒé‡‘ETF'},\n",
        "            ])\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, etf_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–ETFæ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=etf_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{etf_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{etf_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{etf_id}] ç²å–æ•¸æ“šå¤±æ•—\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "            df['MA60'] = df['Close'].rolling(window=60).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_etf_async(self, session: aiohttp.ClientSession, etf_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯ETF\"\"\"\n",
        "        symbol = etf_info['yahoo_symbol']\n",
        "        etf_name = etf_info['etf_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æETF: {etf_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–ETFæ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'etf_name': etf_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„ETFæ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'etf_name': etf_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'etf_name': etf_name,\n",
        "                'etf_id': etf_info.get('etf_id', ''),\n",
        "                'market': etf_info.get('market', ''),\n",
        "                'category': etf_info.get('category', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {etf_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æETF {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'etf_name': etf_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_etfs(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰ETFï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´ETFæ¸…å–®\n",
        "            if self.us_etfs is None:\n",
        "                self.us_etfs = self.get_us_etfs()\n",
        "\n",
        "            if self.us_etfs.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–ETFæ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.us_etfs)} æ”¯ETFï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, etf_info in self.us_etfs.iterrows():\n",
        "                    task = self.analyze_etf_async(session, etf_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æETFæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºå‰ååï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ† ç¾è‚¡ETFæŠ€è¡“åˆ†æ - å‰ååå„ªè³ªæ¨™çš„\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯ETF/æœŸè²¨/è²´é‡‘å±¬\")\n",
        "        message_parts.append(f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªæ¨™çš„\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºå‰ååå„ªè³ªæ¨™çš„\n",
        "        top_etfs = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† å‰ {len(top_etfs)} åå„ªè³ªæ¨™çš„:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_etfs, 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            category = result.get('category', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\" if price_change < 0 else \"â¡ï¸\"\n",
        "\n",
        "            # å»ºè­°ç¬¦è™Ÿ\n",
        "            rec_symbol = \"ğŸš€\" if \"å¼·åŠ›è²·\" in rec_text else \"ğŸ“ˆ\" if \"è²·\" in rec_text else \"ğŸ“Š\" if \"æŒæœ‰\" in rec_text else \"ğŸ“‰\"\n",
        "\n",
        "            # é¡åˆ¥ç¬¦è™Ÿ\n",
        "            category_symbol = \"ğŸ›ï¸\" if \"æŒ‡æ•¸\" in category else \"âš¡\" if \"æ§“æ¡¿\" in category else \"ğŸ”„\" if \"åå‘\" in category else \"ğŸ¥‡\" if \"é»ƒé‡‘\" in category else \"ğŸ›¢ï¸\" if \"åŸæ²¹\" in category else \"ğŸŒ¾\" if \"è¾²ç”¢å“\" in category else \"ğŸ“Š\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {etf_name[:25]} ({etf_id})\")\n",
        "            message_parts.append(f\"   {category_symbol} é¡åˆ¥: {category}\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: ${current_price:.2f} ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   â­ è©•åˆ†: {score:.1f}/100\")\n",
        "            message_parts.append(f\"   {rec_symbol} å»ºè­°: {rec_text}\")\n",
        "            message_parts.append(f\"   ğŸ“Š æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # æ·»åŠ ä¸»è¦æŠ€è¡“æŒ‡æ¨™\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            rsi_value = tech.get('rsi_value', 50)\n",
        "            macd_signal = tech.get('macd_signal', 'ä¸­æ€§')\n",
        "            message_parts.append(f\"   ğŸ” RSI: {rsi_value:.1f} | MACD: {macd_signal}\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_score = sum(r.get('combined_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('combined_score', 0) >= 70])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ“Š å¹³å‡åˆ†æ•¸: {avg_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†æ¨™çš„ (â‰¥70): {high_score_count}\")\n",
        "\n",
        "            # å»ºè­°åˆ†å¸ƒ\n",
        "            recommendations = {}\n",
        "            for result in top_etfs:\n",
        "                rec = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "                recommendations[rec] = recommendations.get(rec, 0) + 1\n",
        "\n",
        "            if recommendations:\n",
        "                message_parts.append(\"   ğŸ“ˆ å‰ååå»ºè­°åˆ†å¸ƒ:\")\n",
        "                for rec, count in recommendations.items():\n",
        "                    message_parts.append(f\"      {rec}: {count}\")\n",
        "\n",
        "            # é¡åˆ¥åˆ†å¸ƒ\n",
        "            categories = {}\n",
        "            for result in top_etfs:\n",
        "                cat = result.get('category', 'Unknown')\n",
        "                categories[cat] = categories.get(cat, 0) + 1\n",
        "\n",
        "            if categories:\n",
        "                message_parts.append(\"   ğŸ·ï¸ å‰ååé¡åˆ¥åˆ†å¸ƒ:\")\n",
        "                for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):\n",
        "                    message_parts.append(f\"      {cat}: {count}\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºæ¨™çš„\")\n",
        "        message_parts.append(\"â€¢ åŒ…å«ETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰å¤šå…ƒåŒ–æ¨™çš„\")\n",
        "        message_parts.append(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "        message_parts.append(\"â€¢ æ§“æ¡¿å’Œåå‘ETFé¢¨éšªè¼ƒé«˜ï¼Œè«‹è¬¹æ…æ“ä½œ\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"ğŸ† ç¾è‚¡ETFæŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªæ¨™çš„\".center(100))\n",
        "        print(\"=\" * 100)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯ETF/æœŸè²¨/è²´é‡‘å±¬\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªæ¨™çš„\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'æ¨™çš„åç¨±':<20}{'é¡åˆ¥':<15}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 100)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_etfs = successful_results[:limit]\n",
        "        for i, result in enumerate(top_etfs, 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')[:18]  # é™åˆ¶é•·åº¦\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            category = result.get('category', 'Unknown')[:13]  # é™åˆ¶é•·åº¦\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{etf_id:<8}{etf_name:<20}{category:<15}{score:<8.1f}${current_price:<9.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        for i, result in enumerate(top_etfs[:5], 1):\n",
        "            etf_name = result.get('etf_name', 'Unknown')\n",
        "            etf_id = result.get('etf_id', 'Unknown')\n",
        "            category = result.get('category', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {etf_name} ({etf_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(f\"   ğŸ·ï¸ é¡åˆ¥: {category}\")\n",
        "            print(\"-\" * 60)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: ${result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        # é¡åˆ¥çµ±è¨ˆ\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"ğŸ“Š é¡åˆ¥çµ±è¨ˆåˆ†æ:\")\n",
        "        categories = {}\n",
        "        for result in successful_results:\n",
        "            cat = result.get('category', 'Unknown')\n",
        "            if cat not in categories:\n",
        "                categories[cat] = {'count': 0, 'avg_score': 0, 'scores': []}\n",
        "            categories[cat]['count'] += 1\n",
        "            categories[cat]['scores'].append(result.get('combined_score', 0))\n",
        "\n",
        "        for cat, data in categories.items():\n",
        "            data['avg_score'] = sum(data['scores']) / len(data['scores'])\n",
        "\n",
        "        sorted_categories = sorted(categories.items(), key=lambda x: x[1]['avg_score'], reverse=True)\n",
        "\n",
        "        print(f\"{'é¡åˆ¥':<20}{'æ•¸é‡':<8}{'å¹³å‡åˆ†æ•¸':<12}{'æœ€é«˜åˆ†':<10}\")\n",
        "        print(\"-\" * 50)\n",
        "        for cat, data in sorted_categories:\n",
        "            print(f\"{cat:<20}{data['count']:<8}{data['avg_score']:<12.1f}{max(data['scores']):<10.1f}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºæ¨™çš„\")\n",
        "        print(\"â€¢ åŒ…å«ETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰å¤šå…ƒåŒ–æŠ•è³‡å·¥å…·\")\n",
        "        print(\"â€¢ æ§“æ¡¿ETFå’Œåå‘ETFå…·æœ‰è¼ƒé«˜é¢¨éšªï¼Œè«‹è¬¹æ…æ“ä½œ\")\n",
        "        print(\"â€¢ æœŸè²¨å•†å“æ³¢å‹•è¼ƒå¤§ï¼Œé©åˆæœ‰ç¶“é©—çš„æŠ•è³‡è€…\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† ç¾è‚¡ETFåˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ - ä¿®æ”¹é€™éƒ¨åˆ†\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            # Discord é™åˆ¶ 2000 å­—ç¬¦ï¼Œéœ€è¦åˆ†å‰²è¨Šæ¯\n",
        "            max_discord_length = 1900  # ç•™ä¸€äº›ç·©è¡ç©ºé–“\n",
        "\n",
        "            if len(message) <= max_discord_length:\n",
        "                # è¨Šæ¯ä¸é•·ï¼Œç›´æ¥ç™¼é€\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "                response = webhook.execute()\n",
        "                if response.ok:\n",
        "                    logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "                else:\n",
        "                    logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "            else:\n",
        "                # è¨Šæ¯å¤ªé•·ï¼Œåˆ†å‰²ç™¼é€\n",
        "                lines = message.split('\\n')\n",
        "                current_chunk = \"\"\n",
        "                chunk_count = 1\n",
        "\n",
        "                for line in lines:\n",
        "                    # æª¢æŸ¥åŠ å…¥é€™è¡Œå¾Œæ˜¯å¦è¶…éé™åˆ¶\n",
        "                    test_chunk = current_chunk + line + '\\n'\n",
        "                    if len(f\"```\\n{test_chunk}\\n```\") > max_discord_length:\n",
        "                        # ç™¼é€ç•¶å‰å¡Š\n",
        "                        if current_chunk.strip():\n",
        "                            header = f\"ğŸ† ç¾è‚¡ETFåˆ†æå ±å‘Š (ç¬¬{chunk_count}éƒ¨åˆ†)\\n\\n\"\n",
        "                            chunk_content = header + current_chunk.strip()\n",
        "                            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk_content}\\n```\")\n",
        "                            response = webhook.execute()\n",
        "                            if response.ok:\n",
        "                                logger.info(f\"Discord é€šçŸ¥ç¬¬{chunk_count}éƒ¨åˆ†ç™¼é€æˆåŠŸ\")\n",
        "                            else:\n",
        "                                logger.error(f\"Discord é€šçŸ¥ç¬¬{chunk_count}éƒ¨åˆ†å¤±æ•—: {response.status_code}\")\n",
        "                            chunk_count += 1\n",
        "                            await asyncio.sleep(1)  # é¿å…ç™¼é€å¤ªå¿«\n",
        "\n",
        "                        # é–‹å§‹æ–°å¡Š\n",
        "                        current_chunk = line + '\\n'\n",
        "                    else:\n",
        "                        current_chunk = test_chunk\n",
        "\n",
        "                # ç™¼é€æœ€å¾Œä¸€å¡Š\n",
        "                if current_chunk.strip():\n",
        "                    header = f\"ğŸ† ç¾è‚¡ETFåˆ†æå ±å‘Š (ç¬¬{chunk_count}éƒ¨åˆ†)\\n\\n\"\n",
        "                    chunk_content = header + current_chunk.strip()\n",
        "                    webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk_content}\\n```\")\n",
        "                    response = webhook.execute()\n",
        "                    if response.ok:\n",
        "                        logger.info(f\"Discord é€šçŸ¥ç¬¬{chunk_count}éƒ¨åˆ†ç™¼é€æˆåŠŸ\")\n",
        "                    else:\n",
        "                        logger.error(f\"Discord é€šçŸ¥ç¬¬{chunk_count}éƒ¨åˆ†å¤±æ•—: {response.status_code}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ ç¾è‚¡ETFæŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªç¾è‚¡ETF/æœŸè²¨/è²´é‡‘å±¬\")\n",
        "        print(\"ğŸ“Š æ¶µè“‹: ETFã€æ§“æ¡¿ETFã€åå‘ETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = USETFAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨ETFåˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰ç¾è‚¡ETF/æœŸè²¨/è²´é‡‘å±¬ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_etfs()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"âœ… ç¾è‚¡ETFåˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªæ¨™çš„å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "        print(\"ğŸ“Š æ¶µè“‹å¤šç¨®æŠ•è³‡å·¥å…·ï¼šETFã€æœŸè²¨ã€è²´é‡‘å±¬ç­‰\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¾è‚¡ETFåˆ†æç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbUbI3hrsVGD"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# å¦‚æœæ‚¨åœ¨ Jupyter Notebook ä¸­ï¼Œè«‹ä½¿ç”¨é€™å€‹ç‰ˆæœ¬\n",
        "import nest_asyncio\n",
        "\n",
        "# å®‰è£ nest_asyncioï¼ˆå¦‚æœå°šæœªå®‰è£ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥å…è¨±åµŒå¥—äº‹ä»¶å¾ªç’°\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# Telegram è¨­å®š\n",
        "TELEGRAM_BOT_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_IDS = [879781796, 8113868436]\n",
        "\n",
        "# Discord è¨­å®š (å¯é¸)\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "MESSAGING_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "    logger.info(\"Discord webhook å¥—ä»¶æœªå®‰è£ï¼Œå°‡è·³é Discord é€šçŸ¥\")\n",
        "\n",
        "def stock_selection_formula(stock_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    è‚¡ç¥¨é¸è‚¡å…¬å¼è©•åˆ†ç³»çµ±\n",
        "    æ ¹æ“šæ¼²å¹…ã€é‡æ¯”ã€åƒ¹æ ¼åˆç†æ€§ã€æµå‹•æ€§é€²è¡Œè©•åˆ†\n",
        "    \"\"\"\n",
        "    try:\n",
        "        score = 0\n",
        "        details = {\n",
        "            'total_score': 0,\n",
        "            'criteria_scores': {},\n",
        "            'meets_threshold': False,\n",
        "            'selection_reasons': []\n",
        "        }\n",
        "\n",
        "        # ç²å–æ•¸æ“š\n",
        "        price_change_5d = stock_data.get('price_change_5d', 0)\n",
        "        current_price = stock_data.get('current_price', 0)\n",
        "        volume_analysis = stock_data.get('volume_analysis', {})\n",
        "        volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "        avg_volume_lots = volume_analysis.get('avg_volume_lots', 0)\n",
        "\n",
        "        # 1. æ¼²å¹…æ¬Šé‡ (40%)\n",
        "        price_score = 0\n",
        "        if price_change_5d > 9.5:\n",
        "            price_score = 40\n",
        "            details['selection_reasons'].append(f\"5æ—¥æ¼²å¹…é” {price_change_5d:.2f}% (>9.5%)\")\n",
        "        elif price_change_5d > 7.0:\n",
        "            price_score = 30\n",
        "            details['selection_reasons'].append(f\"5æ—¥æ¼²å¹… {price_change_5d:.2f}% (>7.0%)\")\n",
        "        elif price_change_5d > 5.0:\n",
        "            price_score = 20\n",
        "            details['selection_reasons'].append(f\"5æ—¥æ¼²å¹… {price_change_5d:.2f}% (>5.0%)\")\n",
        "        elif price_change_5d > 3.0:\n",
        "            price_score = 10\n",
        "\n",
        "        details['criteria_scores']['æ¼²å¹…è©•åˆ†'] = price_score\n",
        "        score += price_score\n",
        "\n",
        "        # 2. é‡æ¯”æ¬Šé‡ (30%)\n",
        "        volume_score = 0\n",
        "        if volume_ratio > 2.0:\n",
        "            volume_score = 30\n",
        "            details['selection_reasons'].append(f\"é‡æ¯”é” {volume_ratio:.2f} (çˆ†é‡)\")\n",
        "        elif volume_ratio > 1.5:\n",
        "            volume_score = 30\n",
        "            details['selection_reasons'].append(f\"é‡æ¯”é” {volume_ratio:.2f} (æ”¾é‡)\")\n",
        "        elif volume_ratio > 1.2:\n",
        "            volume_score = 20\n",
        "            details['selection_reasons'].append(f\"é‡æ¯” {volume_ratio:.2f} (æº«å’Œæ”¾é‡)\")\n",
        "        elif volume_ratio > 1.0:\n",
        "            volume_score = 20\n",
        "        elif volume_ratio > 0.8:\n",
        "            volume_score = 10\n",
        "\n",
        "        details['criteria_scores']['é‡æ¯”è©•åˆ†'] = volume_score\n",
        "        score += volume_score\n",
        "\n",
        "        # 3. åƒ¹æ ¼åˆç†æ€§ (20%)\n",
        "        price_score_reasonable = 0\n",
        "        if 20 <= current_price <= 500:\n",
        "            price_score_reasonable = 20\n",
        "            details['selection_reasons'].append(f\"åƒ¹æ ¼åˆç† {current_price:.2f}å…ƒ (20-500å…ƒ)\")\n",
        "        elif 10 <= current_price < 20:\n",
        "            price_score_reasonable = 15\n",
        "            details['selection_reasons'].append(f\"ä½åƒ¹è‚¡ {current_price:.2f}å…ƒ\")\n",
        "        elif 500 < current_price <= 1000:\n",
        "            price_score_reasonable = 15\n",
        "            details['selection_reasons'].append(f\"ä¸­é«˜åƒ¹è‚¡ {current_price:.2f}å…ƒ\")\n",
        "        elif 5 <= current_price < 10:\n",
        "            price_score_reasonable = 10\n",
        "        elif 1000 < current_price <= 2000:\n",
        "            price_score_reasonable = 10\n",
        "\n",
        "        details['criteria_scores']['åƒ¹æ ¼åˆç†æ€§'] = price_score_reasonable\n",
        "        score += price_score_reasonable\n",
        "\n",
        "        # 4. æµå‹•æ€§ (10%)\n",
        "        liquidity_score = 0\n",
        "        if avg_volume_lots > 5000:\n",
        "            liquidity_score = 10\n",
        "            details['selection_reasons'].append(f\"é«˜æµå‹•æ€§ {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "        elif avg_volume_lots > 2000:\n",
        "            liquidity_score = 10\n",
        "            details['selection_reasons'].append(f\"è‰¯å¥½æµå‹•æ€§ {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "        elif avg_volume_lots > 1000:\n",
        "            liquidity_score = 10\n",
        "            details['selection_reasons'].append(f\"åŸºæœ¬æµå‹•æ€§ {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "        elif avg_volume_lots > 500:\n",
        "            liquidity_score = 5\n",
        "\n",
        "        details['criteria_scores']['æµå‹•æ€§è©•åˆ†'] = liquidity_score\n",
        "        score += liquidity_score\n",
        "\n",
        "        # ç¸½åˆ†å’Œæ˜¯å¦ç¬¦åˆé–€æª»\n",
        "        details['total_score'] = score\n",
        "        details['meets_threshold'] = score >= 70\n",
        "\n",
        "        # é¡å¤–åŠ åˆ†æ¢ä»¶\n",
        "        bonus_score = 0\n",
        "        bonus_reasons = []\n",
        "\n",
        "        # æŠ€è¡“æŒ‡æ¨™åŠ åˆ†\n",
        "        technical_analysis = stock_data.get('technical_analysis', {})\n",
        "        rsi_value = technical_analysis.get('rsi_value', 50)\n",
        "        macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "\n",
        "        if 30 <= rsi_value <= 70 and macd_signal in ['é»ƒé‡‘äº¤å‰', 'å¤šé ­']:\n",
        "            bonus_score += 5\n",
        "            bonus_reasons.append(\"æŠ€è¡“æŒ‡æ¨™è‰¯å¥½\")\n",
        "\n",
        "        # è¶¨å‹¢åŠ åˆ†\n",
        "        trend_analysis = stock_data.get('trend_analysis', {})\n",
        "        trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "        if 'å¼·å‹¢ä¸Šæ¼²' in trend:\n",
        "            bonus_score += 5\n",
        "            bonus_reasons.append(\"å¼·å‹¢ä¸Šæ¼²è¶¨å‹¢\")\n",
        "        elif 'ä¸Šæ¼²' in trend:\n",
        "            bonus_score += 3\n",
        "            bonus_reasons.append(\"ä¸Šæ¼²è¶¨å‹¢\")\n",
        "\n",
        "        details['bonus_score'] = bonus_score\n",
        "        details['bonus_reasons'] = bonus_reasons\n",
        "        details['final_score'] = score + bonus_score\n",
        "        details['meets_threshold'] = (score + bonus_score) >= 70\n",
        "\n",
        "        return details\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¸è‚¡å…¬å¼è¨ˆç®—éŒ¯èª¤: {e}\")\n",
        "        return {\n",
        "            'total_score': 0,\n",
        "            'final_score': 0,\n",
        "            'criteria_scores': {},\n",
        "            'meets_threshold': False,\n",
        "            'selection_reasons': ['è¨ˆç®—éŒ¯èª¤'],\n",
        "            'bonus_score': 0,\n",
        "            'bonus_reasons': []\n",
        "        }\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'selection_threshold': 70,  # é¸è‚¡é–€æª»åˆ†æ•¸\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()  # ä¿®æ­£ï¼šä½¿ç”¨ copy() é¿å…è­¦å‘Š\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()  # ä¿®æ­£ï¼šä½¿ç”¨ copy()\n",
        "                df.loc[:, 'market'] = market_name  # ä¿®æ­£ï¼šä½¿ç”¨ .loc è¨­å®šå€¼\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)].copy()\n",
        "\n",
        "            # ä¿®æ­£ï¼šä½¿ç”¨ .loc è¨­å®š yahoo_symbol\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨è‚¡ç¥¨æ¸…å–®\")\n",
        "\n",
        "            # æ“´å±•çŸ¥åè‚¡ç¥¨åˆ—è¡¨\n",
        "            famous_stocks = [\n",
        "                {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2412', 'stock_name': 'ä¸­è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2412.TW', 'industry': 'é€šä¿¡'},\n",
        "                {'stock_id': '1301', 'stock_name': 'å°å¡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1301.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '1303', 'stock_name': 'å—äº', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1303.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '2308', 'stock_name': 'å°é”é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2308.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2002', 'stock_name': 'ä¸­é‹¼', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2002.TW', 'industry': 'é‹¼éµ'},\n",
        "                {'stock_id': '2886', 'stock_name': 'å…†è±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2886.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2891.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '3008', 'stock_name': 'å¤§ç«‹å…‰', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3008.TW', 'industry': 'å…‰å­¸'},\n",
        "                {'stock_id': '2357', 'stock_name': 'è¯ç¢©', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2357.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2382', 'stock_name': 'å»£é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2382.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2395', 'stock_name': 'ç ”è¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2395.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '3711', 'stock_name': 'æ—¥æœˆå…‰æŠ•æ§', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3711.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2409', 'stock_name': 'å‹é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2409.TW', 'industry': 'é¢æ¿'},\n",
        "                {'stock_id': '2884', 'stock_name': 'ç‰å±±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2884.TW', 'industry': 'é‡‘è'},\n",
        "                # æ–°å¢æ›´å¤šè‚¡ç¥¨\n",
        "                {'stock_id': '2474', 'stock_name': 'å¯æˆ', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2474.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2408', 'stock_name': 'å—äºç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2408.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2301', 'stock_name': 'å…‰å¯¶ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2301.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2207', 'stock_name': 'å’Œæ³°è»Š', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2207.TW', 'industry': 'æ±½è»Š'},\n",
        "                {'stock_id': '1216', 'stock_name': 'çµ±ä¸€', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1216.TW', 'industry': 'é£Ÿå“'},\n",
        "                {'stock_id': '1101', 'stock_name': 'å°æ³¥', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1101.TW', 'industry': 'æ°´æ³¥'},\n",
        "                {'stock_id': '2105', 'stock_name': 'æ­£æ–°', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2105.TW', 'industry': 'æ©¡è† '},\n",
        "                {'stock_id': '2912', 'stock_name': 'çµ±ä¸€è¶…', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2912.TW', 'industry': 'è²¿æ˜“ç™¾è²¨'},\n",
        "                {'stock_id': '2885', 'stock_name': 'å…ƒå¤§é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2885.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2892', 'stock_name': 'ç¬¬ä¸€é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2892.TW', 'industry': 'é‡‘è'},\n",
        "            ]\n",
        "\n",
        "            df = pd.DataFrame(famous_stocks)\n",
        "            logger.info(f\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "\n",
        "            # å–æœ€è¿‘20å¤©çš„å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            volume_lots = recent_volume / 1000\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æˆäº¤é‡è¦æ±‚\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "\n",
        "            if meets_volume:\n",
        "                logger.debug(f\"æˆäº¤é‡ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (â‰¥ {self.config['min_volume_lots']} å¼µ)\")\n",
        "            else:\n",
        "                logger.debug(f\"æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶: {volume_lots:.0f} å¼µ/æ—¥ (< {self.config['min_volume_lots']} å¼µ)\")\n",
        "\n",
        "            return meets_volume\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # MACD\n",
        "            macd_line, macd_signal, macd_histogram = self.calculate_macd(\n",
        "                df['Close'],\n",
        "                self.config['macd_fast'],\n",
        "                self.config['macd_slow'],\n",
        "                self.config['macd_signal']\n",
        "            )\n",
        "            df['MACD'] = macd_line\n",
        "            df['MACD_Signal'] = macd_signal\n",
        "            df['MACD_Histogram'] = macd_histogram\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(\n",
        "                df['Close'],\n",
        "                self.config['bb_period'],\n",
        "                self.config['bb_std']\n",
        "            )\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # KDæŒ‡æ¨™\n",
        "            k_percent, d_percent = self.calculate_kd(\n",
        "                df['High'],\n",
        "                df['Low'],\n",
        "                df['Close'],\n",
        "                self.config['kd_period']\n",
        "            )\n",
        "            df['K_Percent'] = k_percent\n",
        "            df['D_Percent'] = d_percent\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            ema_fast = prices.ewm(span=fast).mean()\n",
        "            ema_slow = prices.ewm(span=slow).mean()\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = macd_line.ewm(span=signal).mean()\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=period).min()\n",
        "            highest_high = high.rolling(window=period).max()\n",
        "\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
        "            k_percent = k_percent.rolling(window=3).mean()\n",
        "            d_percent = k_percent.rolling(window=3).mean()\n",
        "\n",
        "            return k_percent, d_percent\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨ï¼ˆåŠ å…¥é¸è‚¡å…¬å¼ï¼‰\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            # å»ºç«‹è‚¡ç¥¨æ•¸æ“šå­—å…¸ç”¨æ–¼é¸è‚¡å…¬å¼\n",
        "            stock_data = {\n",
        "                'price_change_5d': price_change,\n",
        "                'current_price': current_price,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'trend_analysis': trend_analysis\n",
        "            }\n",
        "\n",
        "            # æ‡‰ç”¨é¸è‚¡å…¬å¼\n",
        "            selection_result = stock_selection_formula(stock_data)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_info.get('stock_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'selection_result': selection_result,  # æ–°å¢é¸è‚¡å…¬å¼çµæœ\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            # è¨˜éŒ„æ˜¯å¦ç¬¦åˆé¸è‚¡æ¢ä»¶\n",
        "            selection_status = \"âœ… ç¬¦åˆ\" if selection_result['meets_threshold'] else \"âŒ ä¸ç¬¦åˆ\"\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - é¸è‚¡å…¬å¼: {selection_status} ({selection_result['final_score']}/100)\")\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥é¸è‚¡å…¬å¼ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸å’Œé¸è‚¡å…¬å¼ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "            selection_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                # æª¢æŸ¥æ˜¯å¦ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶\n",
        "                                selection_result = result.get('selection_result', {})\n",
        "                                if selection_result.get('meets_threshold', False):\n",
        "                                    results[result['symbol']] = result\n",
        "                                else:\n",
        "                                    selection_filtered_count += 1\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - ç¬¦åˆé¸è‚¡å…¬å¼: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - é¸è‚¡å…¬å¼æ·˜æ±°: {selection_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºè¨Šæ¯ï¼ˆé¡¯ç¤ºç¬¦åˆé¸è‚¡å…¬å¼çš„è‚¡ç¥¨ï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•ç¬¦åˆé¸è‚¡å…¬å¼çš„åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰é¸è‚¡å…¬å¼åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and\n",
        "               result.get('selection_result', {}).get('meets_threshold', False)\n",
        "        ]\n",
        "\n",
        "        # æŒ‰é¸è‚¡å…¬å¼æœ€çµ‚åˆ†æ•¸æ’åº\n",
        "        successful_results.sort(key=lambda x: x.get('selection_result', {}).get('final_score', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸ¯ å°è‚¡é¸è‚¡å…¬å¼ç¯©é¸çµæœ\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ† ç¬¦åˆæ¢ä»¶: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(f\"ğŸ“Š é¸è‚¡æ¢ä»¶:\")\n",
        "        message_parts.append(f\"   â€¢ 5æ—¥æ¼²å¹… >9.5% (40åˆ†)\")\n",
        "        message_parts.append(f\"   â€¢ é‡æ¯” >1.5 (30åˆ†)\")\n",
        "        message_parts.append(f\"   â€¢ åƒ¹æ ¼ 20-500å…ƒ (20åˆ†)\")\n",
        "        message_parts.append(f\"   â€¢ æˆäº¤é‡ >1000å¼µ (10åˆ†)\")\n",
        "        message_parts.append(f\"   â€¢ é–€æª»åˆ†æ•¸: â‰¥70åˆ†\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "            message_parts.append(\"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–ç­‰å¾…æ›´å¥½çš„å¸‚å ´æ™‚æ©Ÿ\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ† ç¬¦åˆé¸è‚¡å…¬å¼çš„å„ªè³ªè‚¡ç¥¨ (å‰{len(top_stocks)}å):\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            selection_result = result.get('selection_result', {})\n",
        "            final_score = selection_result.get('final_score', 0)\n",
        "            selection_reasons = selection_result.get('selection_reasons', [])\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            volume_ratio = volume_info.get('volume_ratio', 1.0)\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸš€\" if price_change > 15 else \"ğŸ“ˆ\" if price_change > 0 else \"ğŸ“‰\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {stock_name} ({stock_id})\")\n",
        "            message_parts.append(f\"   ğŸ¯ é¸è‚¡åˆ†æ•¸: {final_score}/100\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f}å…ƒ ({change_symbol}{price_change:+.2f}%)\")\n",
        "            message_parts.append(f\"   ğŸ“Š é‡æ¯”: {volume_ratio:.2f} | æˆäº¤é‡: {avg_volume_lots:.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # é¡¯ç¤ºé¸è‚¡åŸå› ï¼ˆå‰3å€‹ï¼‰\n",
        "            if selection_reasons:\n",
        "                reasons_text = \" | \".join(selection_reasons[:3])\n",
        "                message_parts.append(f\"   âœ… ç¬¦åˆæ¢ä»¶: {reasons_text}\")\n",
        "\n",
        "            # è©³ç´°è©•åˆ†\n",
        "            criteria_scores = selection_result.get('criteria_scores', {})\n",
        "            message_parts.append(f\"   ğŸ“‹ è©•åˆ†æ˜ç´°: æ¼²å¹…{criteria_scores.get('æ¼²å¹…è©•åˆ†', 0)} | é‡æ¯”{criteria_scores.get('é‡æ¯”è©•åˆ†', 0)} | åƒ¹æ ¼{criteria_scores.get('åƒ¹æ ¼åˆç†æ€§', 0)} | æµå‹•æ€§{criteria_scores.get('æµå‹•æ€§è©•åˆ†', 0)}\")\n",
        "\n",
        "            # åŠ åˆ†é …ç›®\n",
        "            bonus_score = selection_result.get('bonus_score', 0)\n",
        "            if bonus_score > 0:\n",
        "                bonus_reasons = selection_result.get('bonus_reasons', [])\n",
        "                message_parts.append(f\"   â­ åŠ åˆ†: +{bonus_score}åˆ† ({', '.join(bonus_reasons)})\")\n",
        "\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆæ‘˜è¦\n",
        "        if successful_results:\n",
        "            avg_selection_score = sum(r.get('selection_result', {}).get('final_score', 0) for r in successful_results) / len(successful_results)\n",
        "            high_score_count = len([r for r in successful_results if r.get('selection_result', {}).get('final_score', 0) >= 80])\n",
        "\n",
        "            message_parts.append(\"ğŸ“Š çµ±è¨ˆæ‘˜è¦:\")\n",
        "            message_parts.append(f\"   ğŸ¯ å¹³å‡é¸è‚¡åˆ†æ•¸: {avg_selection_score:.1f}\")\n",
        "            message_parts.append(f\"   ğŸŒŸ é«˜åˆ†è‚¡ç¥¨ (â‰¥80): {high_score_count}\")\n",
        "\n",
        "            # æ¼²å¹…åˆ†å¸ƒ\n",
        "            price_changes = [r.get('price_change_5d', 0) for r in top_stocks]\n",
        "            avg_change = sum(price_changes) / len(price_changes) if price_changes else 0\n",
        "            max_change = max(price_changes) if price_changes else 0\n",
        "\n",
        "            message_parts.append(f\"   ğŸ“ˆ å¹³å‡æ¼²å¹…: {avg_change:.2f}%\")\n",
        "            message_parts.append(f\"   ğŸš€ æœ€é«˜æ¼²å¹…: {max_change:.2f}%\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"ğŸ¯ é¸è‚¡å…¬å¼èªªæ˜:\")\n",
        "        message_parts.append(\"â€¢ æ¼²å¹…æ¬Šé‡40%: 5æ—¥æ¼²å¹…>9.5%ç²æ»¿åˆ†\")\n",
        "        message_parts.append(\"â€¢ é‡æ¯”æ¬Šé‡30%: é‡æ¯”>1.5ç²æ»¿åˆ†\")\n",
        "        message_parts.append(\"â€¢ åƒ¹æ ¼åˆç†æ€§20%: 20-500å…ƒç²æ»¿åˆ†\")\n",
        "        message_parts.append(\"â€¢ æµå‹•æ€§10%: >1000å¼µ/æ—¥ç²æ»¿åˆ†\")\n",
        "        message_parts.append(\"â€¢ æŠ€è¡“æŒ‡æ¨™å’Œè¶¨å‹¢å¯é¡å¤–åŠ åˆ†\")\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬é¸è‚¡å…¬å¼åƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å·²ç¯©é¸å‡ºç¬¦åˆå¤šé‡æ¢ä»¶çš„å¼·å‹¢è‚¡\")\n",
        "        message_parts.append(\"â€¢ è«‹æ³¨æ„é¢¨éšªæ§åˆ¶ï¼Œé©ç•¶åˆ†æ•£æŠ•è³‡\")\n",
        "        message_parts.append(\"â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœï¼ˆé¸è‚¡å…¬å¼ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•ç¬¦åˆé¸è‚¡å…¬å¼çš„åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾ç¬¦åˆé¸è‚¡å…¬å¼çš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and\n",
        "               result.get('selection_result', {}).get('meets_threshold', False)\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('selection_result', {}).get('final_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 90)\n",
        "        print(\"ğŸ¯ å°è‚¡é¸è‚¡å…¬å¼ç¯©é¸çµæœ\".center(90))\n",
        "        print(\"=\" * 90)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ† ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ“Š é¸è‚¡æ¢ä»¶: æ¼²å¹…>9.5%(40åˆ†) + é‡æ¯”>1.5(30åˆ†) + åƒ¹æ ¼20-500å…ƒ(20åˆ†) + æˆäº¤é‡>1000å¼µ(10åˆ†) â‰¥70åˆ†\")\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "            print(\"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–ç­‰å¾…æ›´å¥½çš„å¸‚å ´æ™‚æ©Ÿ\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'é¸è‚¡åˆ†æ•¸':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<10}{'é‡æ¯”':<8}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 90)\n",
        "\n",
        "        # é¡¯ç¤ºç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            selection_result = result.get('selection_result', {})\n",
        "            final_score = selection_result.get('final_score', 0)\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            volume_ratio = volume_info.get('volume_ratio', 1.0)\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{final_score:<8.0f}{current_price:<10.2f}{price_change:<+10.2f}{volume_ratio:<8.2f}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°é¸è‚¡åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            selection_result = result.get('selection_result', {})\n",
        "            final_score = selection_result.get('final_score', 0)\n",
        "            criteria_scores = selection_result.get('criteria_scores', {})\n",
        "            selection_reasons = selection_result.get('selection_reasons', [])\n",
        "            bonus_score = selection_result.get('bonus_score', 0)\n",
        "            bonus_reasons = selection_result.get('bonus_reasons', [])\n",
        "\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {stock_name} ({stock_id}) - é¸è‚¡åˆ†æ•¸: {final_score}/100\")\n",
        "            print(\"-\" * 60)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}å…ƒ\")\n",
        "            print(f\"ğŸš€ 5æ—¥æ¼²å¹…: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ“Š é‡æ¯”: {volume_analysis.get('volume_ratio', 1.0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥\")\n",
        "\n",
        "            # é¸è‚¡å…¬å¼è©•åˆ†æ˜ç´°\n",
        "            print(f\"ğŸ¯ é¸è‚¡å…¬å¼è©•åˆ†æ˜ç´°:\")\n",
        "            print(f\"   æ¼²å¹…è©•åˆ†: {criteria_scores.get('æ¼²å¹…è©•åˆ†', 0)}/40\")\n",
        "            print(f\"   é‡æ¯”è©•åˆ†: {criteria_scores.get('é‡æ¯”è©•åˆ†', 0)}/30\")\n",
        "            print(f\"   åƒ¹æ ¼åˆç†æ€§: {criteria_scores.get('åƒ¹æ ¼åˆç†æ€§', 0)}/20\")\n",
        "            print(f\"   æµå‹•æ€§è©•åˆ†: {criteria_scores.get('æµå‹•æ€§è©•åˆ†', 0)}/10\")\n",
        "            if bonus_score > 0:\n",
        "                print(f\"   åŠ åˆ†é …ç›®: +{bonus_score} ({', '.join(bonus_reasons)})\")\n",
        "\n",
        "            # ç¬¦åˆæ¢ä»¶èªªæ˜\n",
        "            if selection_reasons:\n",
        "                print(f\"âœ… ç¬¦åˆæ¢ä»¶: {', '.join(selection_reasons[:3])}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   è¶¨å‹¢: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 90)\n",
        "        print(\"ğŸ¯ é¸è‚¡å…¬å¼èªªæ˜:\")\n",
        "        print(\"â€¢ æ¼²å¹…æ¬Šé‡40%: 5æ—¥æ¼²å¹…>9.5%ç²40åˆ†ï¼Œ>7%ç²30åˆ†ï¼Œ>5%ç²20åˆ†ï¼Œ>3%ç²10åˆ†\")\n",
        "        print(\"â€¢ é‡æ¯”æ¬Šé‡30%: é‡æ¯”>2.0æˆ–>1.5ç²30åˆ†ï¼Œ>1.2ç²20åˆ†ï¼Œ>1.0ç²20åˆ†\")\n",
        "        print(\"â€¢ åƒ¹æ ¼åˆç†æ€§20%: 20-500å…ƒç²20åˆ†ï¼Œå…¶ä»–åƒ¹ä½æŒ‰åˆç†æ€§çµ¦åˆ†\")\n",
        "        print(\"â€¢ æµå‹•æ€§10%: æˆäº¤é‡>1000å¼µ/æ—¥ç²10åˆ†\")\n",
        "        print(\"â€¢ æŠ€è¡“æŒ‡æ¨™å’Œè¶¨å‹¢åˆ†æå¯é¡å¤–åŠ åˆ†\")\n",
        "        print(\"â€¢ ç¸½åˆ†â‰¥70åˆ†æ‰ç¬¦åˆé¸è‚¡æ¢ä»¶\")\n",
        "        print(\"\\nâš ï¸ æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬é¸è‚¡å…¬å¼å°ˆé–€ç¯©é¸å¼·å‹¢ä¸Šæ¼²ä¸”æœ‰é‡é…åˆçš„è‚¡ç¥¨\")\n",
        "        print(\"â€¢ å·²ç¬¦åˆå¤šé‡æŠ€è¡“æ¢ä»¶ï¼Œä½†æŠ•è³‡ä»æœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œè¨­å®šåœæé»\")\n",
        "        print(\"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ¯ é¸è‚¡å…¬å¼ç¯©é¸çµæœ (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸ¯ å°è‚¡é¸è‚¡å…¬å¼åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ“Š é¸è‚¡æ¢ä»¶:\")\n",
        "        print(\"   â€¢ 5æ—¥æ¼²å¹… >9.5% (40åˆ†)\")\n",
        "        print(\"   â€¢ é‡æ¯” >1.5 (30åˆ†)\")\n",
        "        print(\"   â€¢ åƒ¹æ ¼ 20-500å…ƒ (20åˆ†)\")\n",
        "        print(\"   â€¢ æˆäº¤é‡ >1000å¼µ/æ—¥ (10åˆ†)\")\n",
        "        print(\"   â€¢ é–€æª»åˆ†æ•¸: â‰¥70åˆ†\")\n",
        "        print(\"ğŸ¯ ç›®æ¨™: æ‰¾å‡ºç¬¦åˆé¸è‚¡å…¬å¼çš„å¼·å‹¢è‚¡ç¥¨\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡ï¼ˆæ‡‰ç”¨é¸è‚¡å…¬å¼ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªæ‰¾åˆ°ç¬¦åˆé¸è‚¡å…¬å¼æ¢ä»¶çš„è‚¡ç¥¨\"\n",
        "            print(error_message)\n",
        "            print(\"ğŸ’¡ å¯èƒ½åŸå› ï¼š\")\n",
        "            print(\"   â€¢ ç•¶å‰å¸‚å ´æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢è‚¡\")\n",
        "            print(\"   â€¢ é¸è‚¡æ¢ä»¶éæ–¼åš´æ ¼\")\n",
        "            print(\"   â€¢ å»ºè­°èª¿æ•´ç¯©é¸åƒæ•¸æˆ–ç­‰å¾…æ›´å¥½çš„å¸‚å ´æ™‚æ©Ÿ\")\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message + \"\\n\\nğŸ’¡ å»ºè­°ç­‰å¾…æ›´å¥½çš„å¸‚å ´æ™‚æ©Ÿæˆ–èª¿æ•´é¸è‚¡æ¢ä»¶\")\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é¸è‚¡çµæœåˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"âœ… é¸è‚¡å…¬å¼åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(f\"ğŸ¯ æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢è‚¡ç¥¨\")\n",
        "        print(\"ğŸ† ç¬¦åˆé¸è‚¡å…¬å¼çš„å„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ é¸è‚¡ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmIVDBrJ6NSf"
      },
      "source": [
        "ä¸Šé¢å¯å‚³è¨Šå¯ç™¼å ±å‘Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q3AcBn43rd6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import mplfinance as mpf\n",
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import glob\n",
        "import sys\n",
        "import traceback\n",
        "import requests\n",
        "from io import StringIO\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "import pytz\n",
        "import nest_asyncio\n",
        "from discord_webhook import DiscordWebhook\n",
        "import telegram\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥æ”¯æ´ Jupyter ç’°å¢ƒ\n",
        "nest_asyncio.apply()\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# è¨­å®šæ™‚å€\n",
        "taipei_tz = pytz.timezone('Asia/Taipei')\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å»ºç«‹åœ–è¡¨ç›®éŒ„\n",
        "CHARTS_DIR = \"charts\"\n",
        "os.makedirs(CHARTS_DIR, exist_ok=True)\n",
        "\n",
        "# è‚¡ç¥¨æ¸…å–®å¿«å–è·¯å¾‘\n",
        "STOCK_LIST_PATH = \"taiwan_stocks.csv\"\n",
        "\n",
        "# ==============================================================================\n",
        "# å…¨åŸŸå¸¸æ•¸èˆ‡å¯†é‘°ç®¡ç†\n",
        "# ==============================================================================\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸\n",
        "# ==============================================================================\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            await session.post(url_msg, json=payload, timeout=20)\n",
        "            logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        data = aiohttp.FormData()\n",
        "                        data.add_field('chat_id', str(chat_id))\n",
        "                        with open(file_path, 'rb') as f:\n",
        "                            data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                            await session.post(url_photo, data=data, timeout=60)\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "        if files:\n",
        "            for file_path in files:\n",
        "                if os.path.exists(file_path):\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "        response = webhook.execute()\n",
        "        if response.ok:\n",
        "            logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "        else:\n",
        "            logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "\n",
        "ğŸ“Š TOP 5 æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f}\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "def get_stock_symbols() -> List[str]:\n",
        "    \"\"\"ç²å–è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨\"\"\"\n",
        "    taiwan_stocks = StockAnalyzer().get_taiwan_stocks()\n",
        "    return taiwan_stocks['yahoo_symbol'].tolist()\n",
        "\n",
        "class TechnicalIndicators:\n",
        "    \"\"\"ç´” pandas/numpy æŠ€è¡“æŒ‡æ¨™è¨ˆç®—é¡\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def sma(data: pd.Series, window: int) -> pd.Series:\n",
        "        \"\"\"ç°¡å–®ç§»å‹•å¹³å‡ç·š\"\"\"\n",
        "        return data.rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "    @staticmethod\n",
        "    def ema(data: pd.Series, window: int) -> pd.Series:\n",
        "        \"\"\"æŒ‡æ•¸ç§»å‹•å¹³å‡ç·š\"\"\"\n",
        "        return data.ewm(span=window, adjust=False).mean()\n",
        "\n",
        "    @staticmethod\n",
        "    def rsi(data: pd.Series, window: int = 14) -> pd.Series:\n",
        "        \"\"\"ç›¸å°å¼·å¼±æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            delta = data.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=window, min_periods=1).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "            # é¿å…é™¤é›¶éŒ¯èª¤\n",
        "            rs = gain / loss.replace(0, np.nan)\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi.fillna(50)  # å¡«å…… NaN ç‚ºä¸­æ€§å€¼ 50\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®— RSI æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series([50] * len(data), index=data.index)\n",
        "\n",
        "    @staticmethod\n",
        "    def macd(data: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
        "        \"\"\"MACD æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            ema_fast = TechnicalIndicators.ema(data, fast)\n",
        "            ema_slow = TechnicalIndicators.ema(data, slow)\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            signal_line = TechnicalIndicators.ema(macd_line, signal)\n",
        "            histogram = macd_line - signal_line\n",
        "            return macd_line, signal_line, histogram\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®— MACD æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zeros = pd.Series([0] * len(data), index=data.index)\n",
        "            return zeros, zeros, zeros\n",
        "\n",
        "    @staticmethod\n",
        "    def bollinger_bands(data: pd.Series, window: int = 20, num_std: float = 2) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
        "        \"\"\"å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            sma = TechnicalIndicators.sma(data, window)\n",
        "            std = data.rolling(window=window, min_periods=1).std()\n",
        "            upper_band = sma + (std * num_std)\n",
        "            lower_band = sma - (std * num_std)\n",
        "            return upper_band, sma, lower_band\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            sma = TechnicalIndicators.sma(data, window)\n",
        "            return sma, sma, sma\n",
        "\n",
        "    @staticmethod\n",
        "    def stochastic(high: pd.Series, low: pd.Series, close: pd.Series,\n",
        "                   k_window: int = 14, d_window: int = 3) -> Tuple[pd.Series, pd.Series]:\n",
        "        \"\"\"KD éš¨æ©ŸæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            lowest_low = low.rolling(window=k_window, min_periods=1).min()\n",
        "            highest_high = high.rolling(window=k_window, min_periods=1).max()\n",
        "\n",
        "            # é¿å…é™¤é›¶éŒ¯èª¤\n",
        "            k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low).replace(0, np.nan))\n",
        "            k_percent = k_percent.fillna(50)\n",
        "\n",
        "            # å¹³æ»‘åŒ– K å€¼\n",
        "            k_smooth = k_percent.rolling(window=d_window, min_periods=1).mean()\n",
        "            d_smooth = k_smooth.rolling(window=d_window, min_periods=1).mean()\n",
        "\n",
        "            return k_smooth, d_smooth\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®— KD æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            default_series = pd.Series([50] * len(close), index=close.index)\n",
        "            return default_series, default_series\n",
        "\n",
        "    @staticmethod\n",
        "    def williams_r(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:\n",
        "        \"\"\"å¨å»‰æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            highest_high = high.rolling(window=window, min_periods=1).max()\n",
        "            lowest_low = low.rolling(window=window, min_periods=1).min()\n",
        "            wr = -100 * (highest_high - close) / (highest_high - lowest_low).replace(0, np.nan)\n",
        "            return wr.fillna(-50)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è¨ˆç®—å¨å»‰æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series([-50] * len(close), index=close.index)\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.taiwan_stocks = None\n",
        "        self.tech_indicators = TechnicalIndicators()\n",
        "        self.stock_data = {}\n",
        "        self.technical_indicators = {}\n",
        "        self.config = {\n",
        "            'top_n': 10,\n",
        "            'score_weights': {\n",
        "                'rsi': 0.3,\n",
        "                'macd': 0.3,\n",
        "                'volume': 0.2,\n",
        "                'price_trend': 0.2\n",
        "            }\n",
        "        }\n",
        "        self.stocks_df = pd.DataFrame()\n",
        "\n",
        "    def get_stock_symbols(self) -> List[str]:\n",
        "        \"\"\"ç²å–è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨\"\"\"\n",
        "        taiwan_stocks = self.get_taiwan_stocks()\n",
        "        return taiwan_stocks['yahoo_symbol'].tolist()\n",
        "\n",
        "    def standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "            return pd.DataFrame()\n",
        "        df = df.copy()\n",
        "        if df.index.name is not None and 'date' in df.index.name.lower():\n",
        "            df = df.reset_index()\n",
        "        column_mapping = {\n",
        "            'Date': 'Date', 'date': 'Date', 'æ—¥æœŸ': 'Date',\n",
        "            'Open': 'Open', 'open': 'Open', 'é–‹ç›¤åƒ¹': 'Open',\n",
        "            'High': 'High', 'high': 'High', 'æœ€é«˜åƒ¹': 'High',\n",
        "            'Low': 'Low', 'low': 'Low', 'æœ€ä½åƒ¹': 'Low',\n",
        "            'Close': 'Close', 'close': 'Close', 'æ”¶ç›¤åƒ¹': 'Close', 'Adj Close': 'Close',\n",
        "            'Volume': 'Volume', 'volume': 'Volume', 'æˆäº¤é‡': 'Volume',\n",
        "        }\n",
        "        rename_dict = {col: column_mapping.get(col, col) for col in df.columns}\n",
        "        df.rename(columns=rename_dict, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=False):\n",
        "        if not force_update and os.path.exists(STOCK_LIST_PATH):\n",
        "            if (time.time() - os.path.getmtime(STOCK_LIST_PATH)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(STOCK_LIST_PATH, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0]\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:]\n",
        "                df['market'] = market_name\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œç¨‹åºçµ‚æ­¢ã€‚\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "        df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "        df = df[df['stock_id'].str.match(r'^\\d{4}$')].copy()\n",
        "        exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "        df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)]\n",
        "        df['yahoo_symbol'] = df.apply(\n",
        "            lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "        final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "        final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "        final_df.to_csv(STOCK_LIST_PATH, index=False)\n",
        "        logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "        return final_df\n",
        "\n",
        "    def fetch_yfinance_data(self, symbol: str, period: str = '1y', interval: str = '1d') -> Optional[pd.DataFrame]:\n",
        "        \"\"\"ç²å– Yahoo Finance æ•¸æ“š\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            df = ticker.history(period=period, interval=interval)\n",
        "\n",
        "            if df.empty:\n",
        "                logger.warning(f\"ç„¡æ³•ç²å– {symbol} çš„æ•¸æ“š\")\n",
        "                return None\n",
        "\n",
        "            # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º\n",
        "            numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "            for col in numeric_columns:\n",
        "                if col in df.columns:\n",
        "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "            # ç§»é™¤ NaN å€¼\n",
        "            df = df.dropna()\n",
        "\n",
        "            if len(df) < 20:  # è‡³å°‘éœ€è¦20å¤©æ•¸æ“š\n",
        "                logger.warning(f\"{symbol} æ•¸æ“šä¸è¶³ï¼Œåªæœ‰ {len(df)} å¤©\")\n",
        "                return None\n",
        "\n",
        "            logger.info(f\"æˆåŠŸç²å– {symbol} æ•¸æ“šï¼Œå…± {len(df)} ç­†è¨˜éŒ„\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç²å– {symbol} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return None\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ - ç´” pandas ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            df = df.copy()\n",
        "\n",
        "            # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º\n",
        "            for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
        "                if col in df.columns:\n",
        "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "            # ç§»é™¤ NaN å€¼\n",
        "            df = df.dropna()\n",
        "\n",
        "            if len(df) < 20:  # éœ€è¦è¶³å¤ çš„æ•¸æ“šè¨ˆç®—æŒ‡æ¨™\n",
        "                logger.warning(\"æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•è¨ˆç®—æ‰€æœ‰æŠ€è¡“æŒ‡æ¨™\")\n",
        "                return df\n",
        "\n",
        "            # è¨ˆç®—ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = self.tech_indicators.sma(df['Close'], 5)\n",
        "            df['MA10'] = self.tech_indicators.sma(df['Close'], 10)\n",
        "            df['MA20'] = self.tech_indicators.sma(df['Close'], 20)\n",
        "            df['MA60'] = self.tech_indicators.sma(df['Close'], 60)\n",
        "\n",
        "            # è¨ˆç®— EMA\n",
        "            df['EMA12'] = self.tech_indicators.ema(df['Close'], 12)\n",
        "            df['EMA26'] = self.tech_indicators.ema(df['Close'], 26)\n",
        "\n",
        "            # è¨ˆç®— RSI\n",
        "            df['RSI'] = self.tech_indicators.rsi(df['Close'], 14)\n",
        "\n",
        "            # è¨ˆç®— MACD\n",
        "            macd, macd_signal, macd_hist = self.tech_indicators.macd(df['Close'])\n",
        "            df['MACD'] = macd\n",
        "            df['MACD_signal'] = macd_signal\n",
        "            df['Histogram'] = macd_hist\n",
        "\n",
        "            # è¨ˆç®—å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.tech_indicators.bollinger_bands(df['Close'])\n",
        "            df['BB_upper'] = bb_upper\n",
        "            df['BB_middle'] = bb_middle\n",
        "            df['BB_lower'] = bb_lower\n",
        "\n",
        "            # è¨ˆç®— KD æŒ‡æ¨™\n",
        "            k_percent, d_percent = self.tech_indicators.stochastic(\n",
        "                df['High'], df['Low'], df['Close']\n",
        "            )\n",
        "            df['K'] = k_percent\n",
        "            df['D'] = d_percent\n",
        "\n",
        "            # è¨ˆç®—å¨å»‰æŒ‡æ¨™\n",
        "            df['Williams_R'] = self.tech_indicators.williams_r(\n",
        "                df['High'], df['Low'], df['Close']\n",
        "            )\n",
        "\n",
        "            # è¨ˆç®—æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            df['Volume_MA5'] = self.tech_indicators.sma(df['Volume'], 5)\n",
        "            df['Volume_MA20'] = self.tech_indicators.sma(df['Volume'], 20)\n",
        "\n",
        "            # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ–ç‡\n",
        "            df['Price_Change'] = df['Close'].pct_change()\n",
        "            df['Price_Change_5d'] = df['Close'].pct_change(periods=5)\n",
        "\n",
        "            logger.info(\"æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å®Œæˆ\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return df\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ - å®Œå…¨ä¿®å¾©ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç„¡æ³•åˆ¤æ–·', 'strength': 0, 'score': 50}\n",
        "\n",
        "            # ç¢ºä¿å¿…è¦çš„æ¬„ä½å­˜åœ¨\n",
        "            required_columns = ['Close', 'MA5', 'MA20']\n",
        "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "            if missing_columns:\n",
        "                logger.warning(f\"ç¼ºå°‘å¿…è¦çš„åˆ—é€²è¡Œè¶¨å‹¢åˆ†æ: {missing_columns}\")\n",
        "                return {'trend': 'ç„¡æ³•åˆ¤æ–·', 'strength': 0, 'score': 50}\n",
        "\n",
        "            # ç²å–æœ€æ–°æ•¸æ“šï¼Œç¢ºä¿æ²’æœ‰ NaN\n",
        "            latest_data = df.dropna().tail(10)\n",
        "            if latest_data.empty:\n",
        "                return {'trend': 'ç„¡æ³•åˆ¤æ–·', 'strength': 0, 'score': 50}\n",
        "\n",
        "            # ä½¿ç”¨ .iloc[-1] ç²å–æ¨™é‡å€¼ï¼Œé¿å… Series å¸ƒæ—å€¼å•é¡Œ\n",
        "            current_price = float(latest_data['Close'].iloc[-1])\n",
        "            ma5_current = float(latest_data['MA5'].iloc[-1]) if not pd.isna(latest_data['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(latest_data['MA20'].iloc[-1]) if not pd.isna(latest_data['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ– - ä½¿ç”¨æ¨™é‡é‹ç®—\n",
        "            price_change_5d = 0\n",
        "            price_change_10d = 0\n",
        "\n",
        "            if len(latest_data) >= 6:\n",
        "                old_price_5d = float(latest_data['Close'].iloc[-6])\n",
        "                price_change_5d = (current_price - old_price_5d) / old_price_5d * 100\n",
        "\n",
        "            if len(df) >= 11:\n",
        "                old_price_10d = float(df['Close'].iloc[-11])\n",
        "                price_change_10d = (current_price - old_price_10d) / old_price_10d * 100\n",
        "\n",
        "            # è¶¨å‹¢åˆ¤æ–·é‚è¼¯ - ä½¿ç”¨æ¨™é‡æ¯”è¼ƒ\n",
        "            trend_score = 50  # ä¸­æ€§èµ·å§‹åˆ†æ•¸\n",
        "            trend = 'ç›¤æ•´'\n",
        "\n",
        "            # MA æ’åˆ—åˆ¤æ–·\n",
        "            if current_price > ma5_current and ma5_current > ma20_current:\n",
        "                trend_score += 15\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "            elif current_price < ma5_current and ma5_current < ma20_current:\n",
        "                trend_score -= 15\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "\n",
        "            # åƒ¹æ ¼è®ŠåŒ–åˆ¤æ–·\n",
        "            if price_change_5d > 3:\n",
        "                trend_score += 10\n",
        "            elif price_change_5d < -3:\n",
        "                trend_score -= 10\n",
        "\n",
        "            if price_change_10d > 5:\n",
        "                trend_score += 10\n",
        "            elif price_change_10d < -5:\n",
        "                trend_score -= 10\n",
        "\n",
        "            # è¨ˆç®—è¶¨å‹¢å¼·åº¦\n",
        "            if 'MA60' in df.columns and not pd.isna(latest_data['MA60'].iloc[-1]):\n",
        "                ma60_current = float(latest_data['MA60'].iloc[-1])\n",
        "                if current_price > ma60_current:\n",
        "                    trend_score += 5\n",
        "                else:\n",
        "                    trend_score -= 5\n",
        "\n",
        "            # é™åˆ¶åˆ†æ•¸ç¯„åœ\n",
        "            trend_score = max(0, min(100, trend_score))\n",
        "\n",
        "            # è¨ˆç®—å¼·åº¦\n",
        "            strength = abs(price_change_5d) + abs(price_change_10d)\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'score': trend_score,\n",
        "                'price_change_5d': price_change_5d,\n",
        "                'price_change_10d': price_change_10d,\n",
        "                'current_price': current_price,\n",
        "                'ma5': ma5_current,\n",
        "                'ma20': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'trend': 'ç„¡æ³•åˆ¤æ–·', 'strength': 0, 'score': 50}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ - å®Œå…¨ä¿®å¾©ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "            # ç¢ºä¿ Volume æ¬„ä½å­˜åœ¨ä¸”ç‚ºæ•¸å€¼å‹\n",
        "            if 'Volume' not in df.columns:\n",
        "                logger.warning(\"ç¼ºå°‘ Volume æ¬„ä½\")\n",
        "                return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "            # æ¸…ç†æ•¸æ“š\n",
        "            df_clean = df.dropna(subset=['Volume', 'Close']).copy()\n",
        "            if len(df_clean) < 10:\n",
        "                return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "            # è½‰æ›ç‚ºæ•¸å€¼å‹ä¸¦ç§»é™¤ç•°å¸¸å€¼\n",
        "            df_clean['Volume'] = pd.to_numeric(df_clean['Volume'], errors='coerce')\n",
        "            df_clean['Close'] = pd.to_numeric(df_clean['Close'], errors='coerce')\n",
        "            df_clean = df_clean.dropna(subset=['Volume', 'Close'])\n",
        "\n",
        "            if df_clean.empty:\n",
        "                return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "            # è¨ˆç®—æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            df_clean['Volume_MA5'] = df_clean['Volume'].rolling(window=5, min_periods=1).mean()\n",
        "            df_clean['Volume_MA20'] = df_clean['Volume'].rolling(window=min(20, len(df_clean)), min_periods=1).mean()\n",
        "\n",
        "            # ç²å–æœ€æ–°æ•¸æ“š - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            recent_data = df_clean.tail(10)\n",
        "            current_volume = float(recent_data['Volume'].iloc[-1])\n",
        "            volume_ma5 = float(recent_data['Volume_MA5'].iloc[-1])\n",
        "            volume_ma20 = float(recent_data['Volume_MA20'].iloc[-1])\n",
        "\n",
        "            # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ– - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            price_changes = recent_data['Close'].pct_change().fillna(0)\n",
        "            latest_price_change = float(price_changes.iloc[-1]) if len(price_changes) > 0 else 0\n",
        "\n",
        "            # åƒ¹é‡é…åˆåˆ†æ - ä½¿ç”¨æ¨™é‡æ¯”è¼ƒ\n",
        "            score = 50  # ä¸­æ€§åˆ†æ•¸\n",
        "            volume_trend = 'æ­£å¸¸'\n",
        "\n",
        "            try:\n",
        "                # æˆäº¤é‡è¶¨å‹¢åˆ¤æ–·\n",
        "                if current_volume > volume_ma5 * 1.2:  # æ”¾é‡\n",
        "                    if latest_price_change > 0.02:  # åƒ¹æ¼²é‡å¢\n",
        "                        score += 20\n",
        "                        volume_trend = 'åƒ¹æ¼²é‡å¢'\n",
        "                    elif latest_price_change < -0.02:  # åƒ¹è·Œé‡å¢\n",
        "                        score -= 15\n",
        "                        volume_trend = 'åƒ¹è·Œé‡å¢'\n",
        "                    else:\n",
        "                        score += 5\n",
        "                        volume_trend = 'æ”¾é‡'\n",
        "\n",
        "                elif current_volume < volume_ma5 * 0.8:  # ç¸®é‡\n",
        "                    if latest_price_change > 0.02:  # åƒ¹æ¼²é‡ç¸®\n",
        "                        score -= 10\n",
        "                        volume_trend = 'åƒ¹æ¼²é‡ç¸®'\n",
        "                    elif latest_price_change < -0.02:  # åƒ¹è·Œé‡ç¸®\n",
        "                        score += 10\n",
        "                        volume_trend = 'åƒ¹è·Œé‡ç¸®'\n",
        "                    else:\n",
        "                        volume_trend = 'ç¸®é‡'\n",
        "\n",
        "                # æª¢æŸ¥é€£çºŒæ”¾é‡ - ä½¿ç”¨ numpy é™£åˆ—é¿å… Series å•é¡Œ\n",
        "                recent_volumes = recent_data['Volume'].tail(3).values\n",
        "                if len(recent_volumes) >= 3:\n",
        "                    high_volume_count = np.sum(recent_volumes > volume_ma20 * 1.5)\n",
        "                    if high_volume_count >= 2:\n",
        "                        score += 10\n",
        "\n",
        "                # é™åˆ¶åˆ†æ•¸ç¯„åœ\n",
        "                score = max(0, min(100, score))\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"åƒ¹é‡é…åˆåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                score = 50\n",
        "                volume_trend = 'ç„¡æ³•åˆ¤æ–·'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'score': score,\n",
        "                'current_volume': current_volume,\n",
        "                'volume_ma5': volume_ma5,\n",
        "                'volume_ma20': volume_ma20,\n",
        "\n",
        "                'volume_ratio': current_volume / volume_ma20 if volume_ma20 > 0 else 1\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'volume_trend': 'ç„¡æ³•åˆ¤æ–·', 'score': 50}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ - å®Œå…¨ä¿®å¾©ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {'rsi_signal': 'ä¸­æ€§', 'macd_signal': 'ä¸­æ€§', 'kd_signal': 'ä¸­æ€§', 'bb_signal': 'ä¸­æ€§', 'score': 50}\n",
        "\n",
        "            # ç²å–æœ€æ–°æ•¸æ“š\n",
        "            latest = df.dropna().tail(1)\n",
        "            if latest.empty:\n",
        "                return {'rsi_signal': 'ä¸­æ€§', 'macd_signal': 'ä¸­æ€§', 'kd_signal': 'ä¸­æ€§', 'bb_signal': 'ä¸­æ€§', 'score': 50}\n",
        "\n",
        "            score = 50\n",
        "            signals = {}\n",
        "\n",
        "            # RSI åˆ†æ - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            if 'RSI' in latest.columns and not pd.isna(latest['RSI'].iloc[0]):\n",
        "                rsi_value = float(latest['RSI'].iloc[0])\n",
        "                if rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value < 50:\n",
        "                    signals['rsi_signal'] = 'åç©º'\n",
        "                    score -= 5\n",
        "                elif rsi_value > 50:\n",
        "                    signals['rsi_signal'] = 'åå¤š'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = rsi_value\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ç„¡æ•¸æ“š'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            if all(col in latest.columns for col in ['MACD', 'MACD_signal']) and \\\n",
        "               not pd.isna(latest['MACD'].iloc[0]) and not pd.isna(latest['MACD_signal'].iloc[0]):\n",
        "                macd_value = float(latest['MACD'].iloc[0])\n",
        "                signal_value = float(latest['MACD_signal'].iloc[0])\n",
        "\n",
        "                if macd_value > signal_value and macd_value > 0:\n",
        "                    signals['macd_signal'] = 'å¼·åŠ›è²·é€²'\n",
        "                    score += 15\n",
        "                elif macd_value > signal_value:\n",
        "                    signals['macd_signal'] = 'è²·é€²'\n",
        "                    score += 10\n",
        "                elif macd_value < signal_value and macd_value < 0:\n",
        "                    signals['macd_signal'] = 'å¼·åŠ›è³£å‡º'\n",
        "                    score -= 15\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'è³£å‡º'\n",
        "                    score -= 10\n",
        "\n",
        "                signals['macd_value'] = macd_value\n",
        "                signals['macd_signal_value'] = signal_value\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ç„¡æ•¸æ“š'\n",
        "                signals['macd_value'] = 0\n",
        "                signals['macd_signal_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            if all(col in latest.columns for col in ['K', 'D']) and \\\n",
        "               not pd.isna(latest['K'].iloc[0]) and not pd.isna(latest['D'].iloc[0]):\n",
        "                k_value = float(latest['K'].iloc[0])\n",
        "                d_value = float(latest['D'].iloc[0])\n",
        "\n",
        "                if k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 12\n",
        "                elif k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 12\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'è²·é€²'\n",
        "                    score += 8\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'è³£å‡º'\n",
        "                    score -= 8\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ç„¡æ•¸æ“š'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ - ä½¿ç”¨æ¨™é‡å€¼\n",
        "            if all(col in latest.columns for col in ['Close', 'BB_upper', 'BB_lower', 'BB_middle']) and \\\n",
        "               all(not pd.isna(latest[col].iloc[0]) for col in ['Close', 'BB_upper', 'BB_lower', 'BB_middle']):\n",
        "                close_price = float(latest['Close'].iloc[0])\n",
        "                bb_upper = float(latest['BB_upper'].iloc[0])\n",
        "                bb_lower = float(latest['BB_lower'].iloc[0])\n",
        "                bb_middle = float(latest['BB_middle'].iloc[0])\n",
        "\n",
        "                if close_price <= bb_lower:\n",
        "                    signals['bb_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif close_price >= bb_upper:\n",
        "                    signals['bb_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif close_price > bb_middle:\n",
        "                    signals['bb_signal'] = 'åå¤š'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'åç©º'\n",
        "                    score -= 5\n",
        "\n",
        "                signals['bb_position'] = (close_price - bb_lower) / (bb_upper - bb_lower) if (bb_upper - bb_lower) > 0 else 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ç„¡æ•¸æ“š'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            # å¨å»‰æŒ‡æ¨™åˆ†æ\n",
        "            if 'Williams_R' in latest.columns and not pd.isna(latest['Williams_R'].iloc[0]):\n",
        "                wr_value = float(latest['Williams_R'].iloc[0])\n",
        "                if wr_value < -80:\n",
        "                    score += 8\n",
        "                elif wr_value > -20:\n",
        "                    score -= 8\n",
        "                signals['williams_r'] = wr_value\n",
        "            else:\n",
        "                signals['williams_r'] = -50\n",
        "\n",
        "            # é™åˆ¶åˆ†æ•¸ç¯„åœ\n",
        "            score = max(0, min(100, score))\n",
        "\n",
        "            return {\n",
        "                **signals,\n",
        "                'score': score\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'rsi_signal': 'ä¸­æ€§', 'macd_signal': 'ä¸­æ€§', 'kd_signal': 'ä¸­æ€§', 'bb_signal': 'ä¸­æ€§', 'score': 50}\n",
        "\n",
        "    def analyze_stock(self, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"å®Œæ•´è‚¡ç¥¨åˆ†æ\"\"\"\n",
        "        try:\n",
        "            stock_id = stock_info.get('stock_id', '')\n",
        "            stock_name = stock_info.get('stock_name', '')\n",
        "            df = stock_info.get('data')\n",
        "\n",
        "            if df is None or df.empty:\n",
        "                logger.warning(f\"{stock_name} ç„¡æ•¸æ“šå¯åˆ†æ\")\n",
        "                return {'success': False, 'error': 'ç„¡æ•¸æ“š'}\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # å„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # ç¶œåˆè©•åˆ†è¨ˆç®— - ä½¿ç”¨æ¨™é‡é‹ç®—\n",
        "            trend_score = float(trend_analysis.get('score', 50))\n",
        "            volume_score = float(volume_analysis.get('score', 50))\n",
        "            technical_score = float(technical_analysis.get('score', 50))\n",
        "\n",
        "            # åŠ æ¬Šè¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = (trend_score * 0.4 + volume_score * 0.3 + technical_score * 0.3)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼å’ŒåŸºæœ¬è³‡è¨Š\n",
        "            latest_data = df_with_indicators.dropna().tail(1)\n",
        "            if not latest_data.empty:\n",
        "                current_price = float(latest_data['Close'].iloc[0])\n",
        "                current_volume = float(latest_data['Volume'].iloc[0]) if 'Volume' in latest_data.columns else 0\n",
        "            else:\n",
        "                current_price = 0\n",
        "                current_volume = 0\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            result = {\n",
        "                'success': True,\n",
        "                'stock_id': stock_id,\n",
        "                'stock_name': stock_name,\n",
        "                'current_price': current_price,\n",
        "                'current_volume': current_volume,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'data_df': df_with_indicators,\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'market': stock_info.get('market', '')\n",
        "            }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_info.get('stock_name', '')} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'success': False, 'error': str(e)}\n",
        "\n",
        "    def generate_recommendation(self, score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, str]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            # åŸºæ–¼ç¶œåˆåˆ†æ•¸çš„å»ºè­°\n",
        "            if score >= 75:\n",
        "                action = \"å¼·åŠ›è²·å…¥\"\n",
        "                reason = \"å¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹ä¸Šæ¼²è¶¨å‹¢\"\n",
        "            elif score >= 65:\n",
        "                action = \"è²·å…¥\"\n",
        "                reason = \"æŠ€è¡“é¢åå¤šï¼Œå»ºè­°é€¢ä½è²·å…¥\"\n",
        "            elif score >= 55:\n",
        "                action = \"æŒæœ‰\"\n",
        "                reason = \"ç›¤æ•´æ ¼å±€ï¼Œå¯æŒæœ‰è§€æœ›\"\n",
        "            elif score >= 45:\n",
        "                action = \"è§€æœ›\"\n",
        "                reason = \"è¶¨å‹¢ä¸æ˜ç¢ºï¼Œå»ºè­°è§€æœ›\"\n",
        "            elif score >= 35:\n",
        "                action = \"æ¸›ç¢¼\"\n",
        "                reason = \"æŠ€è¡“é¢è½‰å¼±ï¼Œå»ºè­°æ¸›ç¢¼\"\n",
        "            else:\n",
        "                action = \"è³£å‡º\"\n",
        "                reason = \"å¤šé …æŒ‡æ¨™é¡¯ç¤ºä¸‹è·Œè¶¨å‹¢\"\n",
        "\n",
        "            # åŠ å…¥ç‰¹æ®Šæƒ…æ³åˆ¤æ–·\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "\n",
        "            if rsi_signal == 'è¶…è³£' and trend != 'ä¸‹è·Œ':\n",
        "                action = \"é€¢ä½è²·å…¥\"\n",
        "                reason += \"ï¼ŒRSIé¡¯ç¤ºè¶…è³£\"\n",
        "            elif rsi_signal == 'è¶…è²·' and score < 70:\n",
        "                action = \"ç²åˆ©äº†çµ\"\n",
        "                reason += \"ï¼ŒRSIé¡¯ç¤ºè¶…è²·\"\n",
        "\n",
        "            return {\n",
        "                'action': action,\n",
        "                'reason': reason,\n",
        "                'confidence': min(100, abs(score - 50) * 2)  # ä¿¡å¿ƒåº¦\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'action': 'è§€æœ›', 'reason': 'åˆ†æç•°å¸¸', 'confidence': 0}\n",
        "\n",
        "    def advanced_multi_criteria_filter(self, analysis_results: Dict) -> Dict:\n",
        "        \"\"\"é€²éšå¤šé‡æ¢ä»¶ç¯©é¸\"\"\"\n",
        "        try:\n",
        "            if not analysis_results:\n",
        "                logger.warning(\"æ²’æœ‰åˆ†æçµæœå¯ä¾›ç¯©é¸\")\n",
        "                return {}\n",
        "\n",
        "            filtered_stocks = {}\n",
        "\n",
        "            for stock_id, result in analysis_results.items():\n",
        "                try:\n",
        "                    # åŸºæœ¬æ¢ä»¶æª¢æŸ¥\n",
        "                    if not result.get('success', False):\n",
        "                        continue\n",
        "\n",
        "                    score = float(result.get('combined_score', 0))\n",
        "                    trend_analysis = result.get('trend_analysis', {})\n",
        "                    technical_analysis = result.get('technical_analysis', {})\n",
        "                    volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "                    # ç¯©é¸æ¢ä»¶\n",
        "                    conditions_met = 0\n",
        "                    total_conditions = 6\n",
        "\n",
        "                    # 1. ç¶œåˆåˆ†æ•¸æ¢ä»¶\n",
        "                    if score >= 55:\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 2. è¶¨å‹¢æ¢ä»¶\n",
        "                    trend = trend_analysis.get('trend', '')\n",
        "                    if trend in ['ä¸Šæ¼²', 'ç›¤æ•´']:\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 3. RSI æ¢ä»¶ - é¿å…æ¥µç«¯è¶…è²·\n",
        "                    rsi_value = technical_analysis.get('rsi_value', 50)\n",
        "                    if 20 <= rsi_value <= 75:  # ä¸è¦æ¥µç«¯è¶…è²·æˆ–è¶…è³£\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 4. MACD æ¢ä»¶\n",
        "                    macd_signal = technical_analysis.get('macd_signal', '')\n",
        "                    if macd_signal in ['è²·é€²', 'å¼·åŠ›è²·é€²']:\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 5. æˆäº¤é‡æ¢ä»¶\n",
        "                    volume_trend = volume_analysis.get('volume_trend', '')\n",
        "                    if volume_trend in ['åƒ¹æ¼²é‡å¢', 'æ”¾é‡', 'æ­£å¸¸']:\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # 6. åƒ¹æ ¼è¶¨å‹¢æ¢ä»¶\n",
        "                    price_change_5d = trend_analysis.get('price_change_5d', 0)\n",
        "                    if price_change_5d >= -5:  # è¿‘æœŸè·Œå¹…ä¸è¶…é5%\n",
        "                        conditions_met += 1\n",
        "\n",
        "                    # è‡³å°‘æ»¿è¶³ 4/6 æ¢ä»¶æ‰ç´å…¥\n",
        "                    if conditions_met >= 4:\n",
        "                        filtered_stocks[stock_id] = result\n",
        "                        logger.info(f\"{result.get('stock_name', '')} é€šéç¯©é¸ ({conditions_met}/{total_conditions})\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"ç¯©é¸è‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # æŒ‰ç¶œåˆåˆ†æ•¸æ’åº\n",
        "            sorted_stocks = dict(sorted(\n",
        "                filtered_stocks.items(),\n",
        "                key=lambda x: x[1].get('combined_score', 0),\n",
        "                reverse=True\n",
        "            ))\n",
        "\n",
        "            logger.info(f\"ç¯©é¸å®Œæˆï¼Œå…± {len(sorted_stocks)} æ”¯è‚¡ç¥¨é€šéæ¢ä»¶\")\n",
        "            return sorted_stocks\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"é€²éšç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def print_advanced_filtered_stocks(self, filtered_results):\n",
        "        \"\"\"è¼¸å‡ºç¯©é¸çµæœ\"\"\"\n",
        "        try:\n",
        "            # å…ˆæª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™\n",
        "            if not filtered_results:\n",
        "                print(\"\\n\".join([\n",
        "                    \"âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\",\n",
        "                    \"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–å¢åŠ åˆ†æè‚¡ç¥¨æ•¸é‡\",\n",
        "                    \"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\"\n",
        "                ]))\n",
        "                return\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"ğŸ¯ æœ€çµ‚ç¯©é¸å„ªè³ªè‚¡ç¥¨æ¸…å–® ğŸ¯\".center(80))\n",
        "            print(\"=\"*80)\n",
        "            print(f\"{'æ’å':<4}{'ä»£ç¢¼':<7}{'åç¨±':<12}{'åˆ†æ•¸':<7}{'åƒ¹æ ¼':<10}{'å»ºè­°':<10}{'ç”¢æ¥­':<15}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "            # è¼¸å‡ºæ¯æ”¯è‚¡ç¥¨çš„è³‡è¨Š\n",
        "            for i, (stock_id, stock) in enumerate(list(filtered_results.items())[:10], 1):\n",
        "                print(\n",
        "                    f\"{i:<4}\"\n",
        "                    f\"{stock_id:<7}\"\n",
        "                    f\"{stock['stock_name'][:10]:<12}\"\n",
        "                    f\"{stock['combined_score']:<7.1f}\"\n",
        "                    f\"{stock['current_price']:<10.2f}\"\n",
        "                    f\"{stock['recommendation']['action'][:8]:<10}\"\n",
        "                    f\"{stock.get('industry', '')[:12]:<15}\"\n",
        "                )\n",
        "            print(\"=\" * 80)\n",
        "\n",
        "            # è¼¸å‡ºè©³ç´°å ±å‘Š\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"ğŸ“Š è©³ç´°åˆ†æå ±å‘Š ğŸ“Š\".center(80))\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            for i, (stock_id, stock) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "                print(f\"\\nå ±å‘Š #{i}: {stock_id} - {stock['stock_name']}\")\n",
        "                print(\"-\" * 50)\n",
        "                print(f\"ç¶œåˆè©•åˆ†: {stock['combined_score']:.1f}\")\n",
        "                print(f\"æœ€æ–°æ”¶ç›¤åƒ¹: {stock['current_price']:.2f} å…ƒ\")\n",
        "                print(f\"ç”¢æ¥­é¡åˆ¥: {stock.get('industry', 'æœªåˆ†é¡')}\")\n",
        "                print(f\"æ¨è–¦è¡Œå‹•: {stock['recommendation']['action']}\")\n",
        "                print(f\"ä¿¡å¿ƒåº¦: {stock['recommendation']['confidence']:.1f}%\")\n",
        "                print(f\"æ¨è–¦ç†ç”±: {stock['recommendation']['reason']}\")\n",
        "\n",
        "                # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "                tech = stock['technical_analysis']\n",
        "                trend = stock['trend_analysis']\n",
        "                print(f\"è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')} (5æ—¥æ¼²è·Œ: {trend.get('price_change_5d', 0):.2f}%)\")\n",
        "                print(f\"RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "                print(f\"MACD: {tech.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "                print(f\"KD: K={tech.get('k_value', 50):.1f}, D={tech.get('d_value', 50):.1f}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "            print(\"=\" * 80)\n",
        "            print(\"\\nğŸ“± åˆ†æçµæœå·²ç™¼é€åˆ° Telegram å’Œ Discord\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¼¸å‡ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            print(\"\\n\".join([\n",
        "                \"âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\",\n",
        "                \"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–å¢åŠ åˆ†æè‚¡ç¥¨æ•¸é‡\",\n",
        "                \"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\"\n",
        "            ]))\n",
        "\n",
        "    def create_stock_chart(self, stock_data: Dict, save_path: str = None) -> str:\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨åœ–è¡¨ - å¢å¼·ç‰ˆæœ¬\"\"\"\n",
        "        try:\n",
        "            df = stock_data['data_df'].copy()\n",
        "            stock_name = stock_data['stock_name']\n",
        "            stock_id = stock_data['stock_id']\n",
        "\n",
        "            if df.empty or len(df) < 20:\n",
        "                logger.warning(f\"æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•ç¹ªè£½ {stock_name} åœ–è¡¨\")\n",
        "                return None\n",
        "\n",
        "            # æº–å‚™æ•¸æ“š\n",
        "            df = df.dropna().tail(60)  # å–æœ€è¿‘60å¤©\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "\n",
        "            # è¨­å®šåœ–è¡¨æ¨£å¼\n",
        "            mc = mpf.make_marketcolors(up='r', down='g', inherit=True)\n",
        "            s = mpf.make_mpf_style(marketcolors=mc, gridstyle='-', y_on_right=False)\n",
        "\n",
        "            # æ·»åŠ æŠ€è¡“æŒ‡æ¨™\n",
        "            apds = []\n",
        "\n",
        "            # æ·»åŠ ç§»å‹•å¹³å‡ç·š\n",
        "            if all(col in df.columns for col in ['MA5', 'MA20', 'MA60']):\n",
        "                apds.append(mpf.make_addplot(df['MA5'], color='orange', width=1.5, alpha=0.8))\n",
        "                apds.append(mpf.make_addplot(df['MA20'], color='blue', width=1.5, alpha=0.8))\n",
        "                apds.append(mpf.make_addplot(df['MA60'], color='purple', width=1, alpha=0.7))\n",
        "\n",
        "            # æ·»åŠ å¸ƒæ—å¸¶\n",
        "            if all(col in df.columns for col in ['BB_upper', 'BB_lower']):\n",
        "                apds.append(mpf.make_addplot(df['BB_upper'], color='gray', width=0.8, alpha=0.5, linestyle='--'))\n",
        "                apds.append(mpf.make_addplot(df['BB_lower'], color='gray', width=0.8, alpha=0.5, linestyle='--'))\n",
        "\n",
        "            # æ·»åŠ æˆäº¤é‡\n",
        "            if 'Volume' in df.columns:\n",
        "                apds.append(mpf.make_addplot(df['Volume'], panel=1, type='bar', alpha=0.7, color='lightblue'))\n",
        "                if 'Volume_MA20' in df.columns:\n",
        "                    apds.append(mpf.make_addplot(df['Volume_MA20'], panel=1, color='red', width=1))\n",
        "\n",
        "            # æ·»åŠ  RSI\n",
        "            if 'RSI' in df.columns:\n",
        "                apds.append(mpf.make_addplot(df['RSI'], panel=2, color='purple', width=1.2))\n",
        "                # RSI è¶…è²·è¶…è³£ç·š\n",
        "                rsi_70 = pd.Series([70] * len(df), index=df.index)\n",
        "                rsi_30 = pd.Series([30] * len(df), index=df.index)\n",
        "                apds.append(mpf.make_addplot(rsi_70, panel=2, color='red', width=0.8, linestyle='--', alpha=0.7))\n",
        "                apds.append(mpf.make_addplot(rsi_30, panel=2, color='green', width=0.8, linestyle='--', alpha=0.7))\n",
        "\n",
        "            # è¨­å®šæª”æ¡ˆè·¯å¾‘\n",
        "            if save_path is None:\n",
        "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "                save_path = os.path.join(CHARTS_DIR, f\"{stock_id}_{stock_name}_{timestamp}.png\")\n",
        "\n",
        "            # ç²å–åˆ†æçµæœç”¨æ–¼æ¨™é¡Œ\n",
        "            current_price = stock_data.get('current_price', 0)\n",
        "            combined_score = stock_data.get('combined_score', 0)\n",
        "            recommendation = stock_data.get('recommendation', {}).get('action', 'è§€æœ›')\n",
        "\n",
        "            # ç¹ªè£½åœ–è¡¨\n",
        "            mpf.plot(\n",
        "                df,\n",
        "                type='candle',\n",
        "                style=s,\n",
        "                addplot=apds,\n",
        "                volume=False,  # æˆ‘å€‘æ‰‹å‹•æ·»åŠ æˆäº¤é‡\n",
        "                title=f\"{stock_name} ({stock_id}) - åƒ¹æ ¼: {current_price:.2f} | è©•åˆ†: {combined_score:.1f} | å»ºè­°: {recommendation}\",\n",
        "                ylabel='åƒ¹æ ¼ (TWD)',\n",
        "                ylabel_lower='æˆäº¤é‡',\n",
        "                figsize=(14, 10),\n",
        "                savefig=dict(fname=save_path, dpi=150, bbox_inches='tight'),\n",
        "                tight_layout=True,\n",
        "                panel_ratios=(3, 1, 1)  # ä¸»åœ–:æˆäº¤é‡:RSI = 3:1:1\n",
        "            )\n",
        "\n",
        "            logger.info(f\"æˆåŠŸå‰µå»º {stock_name} åœ–è¡¨: {save_path}\")\n",
        "            return save_path\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å‰µå»ºåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    async def run_analysis(self):\n",
        "        \"\"\"åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹ - æ•´åˆé€šçŸ¥åŠŸèƒ½\"\"\"\n",
        "        try:\n",
        "            logger.info(\"é–‹å§‹è‚¡ç¥¨åˆ†ææµç¨‹...\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ¸…å–®\n",
        "            stocks_df = self.get_taiwan_stocks()\n",
        "            if stocks_df.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return\n",
        "\n",
        "            # é™åˆ¶åˆ†ææ•¸é‡\n",
        "            stocks_to_analyze = stocks_df.head(2000)  # åˆ†æå‰50æ”¯è‚¡ç¥¨\n",
        "            logger.info(f\"å°‡åˆ†æ {len(stocks_to_analyze)} æ”¯è‚¡ç¥¨\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            analysis_results = {}\n",
        "            for _, stock in stocks_to_analyze.iterrows():\n",
        "                try:\n",
        "                    symbol = stock['yahoo_symbol']\n",
        "                    logger.info(f\"æ­£åœ¨ç²å– {stock['stock_name']} ({symbol}) æ•¸æ“š...\")\n",
        "\n",
        "                    df = self.fetch_yfinance_data(symbol)\n",
        "                    if df is not None and not df.empty:\n",
        "                        stock_info = stock.to_dict()\n",
        "                        stock_info['data'] = df\n",
        "\n",
        "                        # åˆ†æè‚¡ç¥¨\n",
        "                        result = self.analyze_stock(stock_info)\n",
        "                        if result.get('success', False):\n",
        "                            analysis_results[stock['stock_id']] = result\n",
        "                            logger.info(f\"å®Œæˆ {stock['stock_name']} åˆ†æï¼Œè©•åˆ†: {result.get('combined_score', 0):.1f}\")\n",
        "\n",
        "                    # é¿å…è«‹æ±‚éæ–¼é »ç¹\n",
        "                    await asyncio.sleep(0.5)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"åˆ†æ {stock['stock_name']} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # é€²éšç¯©é¸\n",
        "            filtered_results = self.advanced_multi_criteria_filter(analysis_results)\n",
        "\n",
        "            # è¼¸å‡ºçµæœ\n",
        "            self.print_advanced_filtered_stocks(filtered_results)\n",
        "\n",
        "            # ç”Ÿæˆåœ–è¡¨\n",
        "            chart_files = []\n",
        "            for stock_id, result in list(filtered_results.items())[:5]:  # åªç‚ºå‰5åç”Ÿæˆåœ–è¡¨\n",
        "                try:\n",
        "                    chart_path = self.create_stock_chart(result)\n",
        "                    if chart_path and os.path.exists(chart_path):\n",
        "                        chart_files.append(chart_path)\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"ç”Ÿæˆ {result.get('stock_name', '')} åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "            # ç™¼é€é€šçŸ¥\n",
        "            try:\n",
        "                async with aiohttp.ClientSession() as session:\n",
        "                    # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "                    message = format_notification_message(filtered_results)\n",
        "\n",
        "                    # ç™¼é€é€šçŸ¥å’Œåœ–è¡¨\n",
        "                    await send_notification(session, message, chart_files)\n",
        "                    logger.info(\"é€šçŸ¥ç™¼é€å®Œæˆ\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç™¼é€é€šçŸ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "            if chart_files:\n",
        "                logger.info(f\"æˆåŠŸç”Ÿæˆ {len(chart_files)} å€‹åœ–è¡¨æª”æ¡ˆ\")\n",
        "                print(f\"\\nğŸ“Š åœ–è¡¨æª”æ¡ˆå·²ä¿å­˜è‡³: {CHARTS_DIR}\")\n",
        "                for chart_file in chart_files:\n",
        "                    print(f\"   - {os.path.basename(chart_file)}\")\n",
        "            else:\n",
        "                logger.warning(\"æœªç”Ÿæˆä»»ä½•åœ–è¡¨æª”æ¡ˆ\")\n",
        "\n",
        "            return filtered_results, chart_files\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åŸ·è¡Œåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {}, []\n",
        "\n",
        "# ä¸»ç¨‹å¼\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼ - æ•´åˆé€šçŸ¥åŠŸèƒ½\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ é–‹å§‹å°è‚¡æŠ€è¡“åˆ†æ...\")\n",
        "        print(\"ğŸ“Š ä½¿ç”¨ç´” pandas/numpy è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\")\n",
        "        print(\"ğŸ“± å°‡è‡ªå‹•ç™¼é€åˆ†æçµæœåˆ° Telegram å’Œ Discord\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        analyzer = StockAnalyzer()\n",
        "        results, charts = await analyzer.run_analysis()\n",
        "\n",
        "        if results:\n",
        "            print(f\"\\nâœ… åˆ†æå®Œæˆï¼æ‰¾åˆ° {len(results)} æ”¯å„ªè³ªè‚¡ç¥¨\")\n",
        "            print(f\"ğŸ“Š ç”Ÿæˆäº† {len(charts)} å€‹åœ–è¡¨æª”æ¡ˆ\")\n",
        "            print(f\"ğŸ“± é€šçŸ¥å·²ç™¼é€åˆ° Telegram å’Œ Discord\")\n",
        "\n",
        "            # é¡¯ç¤ºè©³ç´°åˆ†æçµæœ\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"ğŸ“ˆ è©³ç´°åˆ†æçµæœ\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            for i, (stock_id, result) in enumerate(list(results.items())[:3], 1):\n",
        "                print(f\"\\n{i}. {result['stock_name']} ({stock_id})\")\n",
        "                print(f\"   ç¶œåˆè©•åˆ†: {result['combined_score']:.1f}\")\n",
        "                print(f\"   ç•¶å‰åƒ¹æ ¼: {result['current_price']:.2f}\")\n",
        "                print(f\"   æŠ•è³‡å»ºè­°: {result['recommendation']['action']}\")\n",
        "                print(f\"   å»ºè­°ç†ç”±: {result['recommendation']['reason']}\")\n",
        "\n",
        "                # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "                tech = result['technical_analysis']\n",
        "                trend = result['trend_analysis']\n",
        "                print(f\"   è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')} (5æ—¥æ¼²è·Œ: {trend.get('price_change_5d', 0):.2f}%)\")\n",
        "                print(f\"   RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "                print(f\"   MACD: {tech.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "                print(f\"   KD: K={tech.get('k_value', 50):.1f}, D={tech.get('d_value', 50):.1f}\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\nâŒ æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "            print(\"ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–å¢åŠ åˆ†æè‚¡ç¥¨æ•¸é‡\")\n",
        "\n",
        "            # å³ä½¿æ²’æœ‰çµæœä¹Ÿç™¼é€é€šçŸ¥\n",
        "            try:\n",
        "                async with aiohttp.ClientSession() as session:\n",
        "                    message = format_notification_message({})\n",
        "                    await send_notification(session, message)\n",
        "                    print(\"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç™¼é€ç©ºçµæœé€šçŸ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                error_message = f\"\"\"\n",
        "ğŸš¨ å°è‚¡åˆ†æç¨‹å¼åŸ·è¡ŒéŒ¯èª¤\n",
        "\n",
        "âŒ éŒ¯èª¤è¨Šæ¯: {str(e)}\n",
        "â° æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "è«‹æª¢æŸ¥ç¨‹å¼ç‹€æ…‹ä¸¦é‡æ–°åŸ·è¡Œã€‚\n",
        "\"\"\"\n",
        "                await send_notification(session, error_message)\n",
        "                logger.info(\"éŒ¯èª¤é€šçŸ¥å·²ç™¼é€\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "# åŸ·è¡Œç¨‹å¼\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6sgSzOBcZNx"
      },
      "source": [
        "ä¸Šé¢å¯ç™¼è¨Šdiscordæœ‰è¨Šæ¯ä¸”æœ‰åœ–ï¼Œtelgramæœ‰è¨Šæ¯ä¸”æœ‰åœ–ï¼Œçµ‚ç«¯æœ‰å ±å‘Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVCEg_gGR-rW"
      },
      "outputs": [],
      "source": [
        "!pip install mplfinance chineseize_matplotlib yfinance pandas numpy matplotlib plotly discord-webhook requests aiohttp python-telegram-bot nest-asyncio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOP5NOQk_fs2"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install mplfinance chineseize_matplotlib yfinance pandas numpy matplotlib plotly discord-webhook requests aiohttp python-telegram-bot nest-asyncio -q\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…·\n",
        "=======================\n",
        "åŠŸèƒ½ï¼š\n",
        "- è‡ªå‹•ç²å–å°è‚¡æ¸…å–®\n",
        "- æ‰¹æ¬¡ä¸‹è¼‰æ­·å²æ•¸æ“š\n",
        "- æŠ€è¡“æŒ‡æ¨™åˆ†æ\n",
        "- ç¶œåˆè©•åˆ†æ’å\n",
        "- è‡ªå‹•é€šçŸ¥æ¨é€\n",
        "- åœ–è¡¨ç”Ÿæˆèˆ‡å ±å‘ŠåŒ¯å‡º\n",
        "\n",
        "ä½œè€…ï¼šè‚¡ç¥¨åˆ†æç³»çµ±\n",
        "ç‰ˆæœ¬ï¼šv2.1\n",
        "æ›´æ–°æ—¥æœŸï¼š2025-08-08\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. åŸºç¤ Python æ¨™æº–åº«\n",
        "# ==============================================================================\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import platform\n",
        "import re\n",
        "import glob\n",
        "import asyncio\n",
        "import warnings\n",
        "from io import StringIO\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "import logging\n",
        "import random\n",
        "# ==============================================================================\n",
        "# 2. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ•¸æ“šè™•ç†èˆ‡ç§‘å­¸è¨ˆç®—\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. ç¬¬ä¸‰æ–¹å¥—ä»¶ - ç¶²è·¯è«‹æ±‚èˆ‡ç•°æ­¥è™•ç†\n",
        "# ==============================================================================\n",
        "import requests\n",
        "import aiohttp\n",
        "import nest_asyncio\n",
        "\n",
        "# æ‡‰ç”¨ nest_asyncio ä»¥æ”¯æ´ Jupyter ç’°å¢ƒ\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. ç¬¬ä¸‰æ–¹å¥—ä»¶ - é‡‘èæ•¸æ“šæº\n",
        "# ==============================================================================\n",
        "import yfinance as yf\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ•¸æ“šå¯è¦–åŒ–\n",
        "# ==============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "import mplfinance as mpf\n",
        "import plotly.graph_objects as go\n",
        "from pathlib import Path\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. ç¬¬ä¸‰æ–¹å¥—ä»¶ - æ™‚å€èˆ‡é€šçŸ¥\n",
        "# ==============================================================================\n",
        "import pytz\n",
        "from discord_webhook import DiscordWebhook\n",
        "import telegram\n",
        "# ==============================================================================\n",
        "# 7. ä¸­æ–‡å­—é«”æ”¯æ´\n",
        "# ==============================================================================\n",
        "try:\n",
        "    import chineseize_matplotlib\n",
        "    chineseize_matplotlib.chineseize()\n",
        "    print(\"âœ… å·²è¼‰å…¥ chineseize_matplotlib ä¸­æ–‡å­—é«”æ”¯æ´\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ æœªå®‰è£ chineseize_matplotlibï¼Œå°‡ä½¿ç”¨è‡ªå®šç¾©å­—é«”è¨­å®š\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 8. å…¨åŸŸè¨­å®š\n",
        "# ==============================================================================\n",
        "# è­¦å‘Šéæ¿¾\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# æ™‚å€è¨­å®š\n",
        "taipei_tz = pytz.timezone('Asia/Taipei')\n",
        "\n",
        "# ç›®éŒ„çµæ§‹è¨­å®š\n",
        "CACHE_DIR = 'cache'\n",
        "RESULTS_DIR = 'results'\n",
        "CHARTS_DIR = os.path.join(RESULTS_DIR, 'charts')\n",
        "STOCK_LIST_PATH = os.path.join(CACHE_DIR, 'stock_list.csv')\n",
        "HISTORY_DATA_CACHE_DIR = os.path.join(CACHE_DIR, 'history_data')\n",
        "\n",
        "# åˆå§‹åŒ–ç›®éŒ„\n",
        "for directory in [CACHE_DIR, RESULTS_DIR, CHARTS_DIR, HISTORY_DATA_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# 9. é€šè¨Šèˆ‡é€šçŸ¥è¨­å®š\n",
        "# ==============================================================================\n",
        "# å»ºè­°å°‡ä¾†ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ– .env æª”æ¡ˆç®¡ç†å¯†é‘°ï¼Œä»¥ç­–å®‰å…¨\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]  # æ”¯æ´å¤šç”¨æˆ¶é€šçŸ¥\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "# æ–°å¢æ­¤è¡Œï¼šå…¨åŸŸé€šçŸ¥é–‹é—œ\n",
        "# è¨­å®šç‚º True ä»¥å•Ÿç”¨ Telegram å’Œ Discord é€šçŸ¥ï¼Œè¨­å®šç‚º False å‰‡åœç”¨æ‰€æœ‰é€šçŸ¥\n",
        "\n",
        "MESSAGING_AVAILABLE = True\n",
        "# ==============================================================================\n",
        "# 10. æ—¥èªŒç³»çµ±è¨­å®š\n",
        "# ==============================================================================\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"stock_analysis.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ==============================================================================\n",
        "# 11. å­—é«”èˆ‡ç’°å¢ƒè¨­å®šå‡½å¼\n",
        "# ==============================================================================\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "\n",
        "    æ”¯æ´çš„ä½œæ¥­ç³»çµ±ï¼š\n",
        "    - Windows: Microsoft JhengHei, Microsoft YaHei, SimHei\n",
        "    - macOS: PingFang HK, PingFang SC, Heiti TC\n",
        "    - Linux: Noto Sans CJK / WenQuanYi Zen Hei\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            # Windows ç³»çµ±å­—é«”è¨­å®šï¼ˆåŒ…å«ç¹é«”ä¸­æ–‡å„ªå…ˆï¼‰\n",
        "            font_candidates = [\n",
        "                'Microsoft JhengHei',  # å¾®è»Ÿæ­£é»‘é«”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰\n",
        "                'Microsoft YaHei',     # å¾®è»Ÿé›…é»‘ï¼ˆç°¡é«”ä¸­æ–‡ï¼‰\n",
        "                'Arial Unicode MS',    # è¬åœ‹ç¢¼å­—é«”\n",
        "                'SimHei',              # é»‘é«”\n",
        "                'KaiTi'                # æ¥·é«”\n",
        "            ]\n",
        "\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    # æ¸¬è©¦å­—é«”æ˜¯å¦å¯ç”¨\n",
        "                    test_fig, test_ax = plt.subplots(figsize=(1, 1))\n",
        "                    test_ax.text(0.5, 0.5, 'æ¸¬è©¦', fontname=font)\n",
        "                    plt.close(test_fig)\n",
        "\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        elif system == 'Darwin':  # macOS\n",
        "            # macOS ç³»çµ±å­—é«”è¨­å®š\n",
        "            font_candidates = [\n",
        "                'PingFang HK',      # è˜‹æ–¹-é¦™æ¸¯\n",
        "                'PingFang SC',      # è˜‹æ–¹-ç°¡é«”ä¸­æ–‡\n",
        "                'PingFang TC',      # è˜‹æ–¹-ç¹é«”ä¸­æ–‡\n",
        "                'Heiti TC',         # é»‘é«”-ç¹é«”ä¸­æ–‡\n",
        "                'Heiti SC',         # é»‘é«”-ç°¡é«”ä¸­æ–‡\n",
        "                'STHeiti'           # è¯æ–‡é»‘é«”\n",
        "            ]\n",
        "\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        else:  # Linux å’Œå…¶ä»–ç³»çµ±\n",
        "            # Linux ç³»çµ±å­—é«”è·¯å¾‘\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/ukai.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/uming.ttc',\n",
        "                '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'\n",
        "            ]\n",
        "\n",
        "            found_font_path = None\n",
        "            for path in font_paths:\n",
        "                if os.path.exists(path):\n",
        "                    found_font_path = path\n",
        "                    break\n",
        "\n",
        "            if found_font_path:\n",
        "                try:\n",
        "                    font_manager.fontManager.addfont(found_font_path)\n",
        "                    font_prop = font_manager.FontProperties(fname=found_font_path)\n",
        "                    font_name = font_prop.get_name()\n",
        "                    plt.rcParams['font.sans-serif'] = [font_name]\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"è¼‰å…¥å­—é«”å¤±æ•—: {e}\")\n",
        "                    font_name = \"DejaVu Sans\"\n",
        "            else:\n",
        "                print(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                font_name = \"DejaVu Sans\"\n",
        "\n",
        "        # è¨­å®š matplotlib åƒæ•¸\n",
        "        plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¢ºé¡¯ç¤ºè² è™Ÿ\n",
        "\n",
        "        # è¨­å®šå­—é«”å¤§å°\n",
        "        plt.rcParams['font.size'] = 10\n",
        "        plt.rcParams['axes.titlesize'] = 12\n",
        "        plt.rcParams['axes.labelsize'] = 10\n",
        "        plt.rcParams['xtick.labelsize'] = 9\n",
        "        plt.rcParams['ytick.labelsize'] = 9\n",
        "        plt.rcParams['legend.fontsize'] = 9\n",
        "\n",
        "        # è¨­å®šåœ–è¡¨å“è³ª\n",
        "        plt.rcParams['figure.dpi'] = 100\n",
        "        plt.rcParams['savefig.dpi'] = 150\n",
        "        plt.rcParams['savefig.bbox'] = 'tight'\n",
        "\n",
        "        if font_name and font_name != \"DejaVu Sans\":\n",
        "            print(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name} ({system})\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ä½¿ç”¨é è¨­å­—é«”: {font_name}\")\n",
        "            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"\n",
        "    æª¢æŸ¥åŸ·è¡Œç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶\n",
        "    \"\"\"\n",
        "    print(\"ğŸ” æª¢æŸ¥åŸ·è¡Œç’°å¢ƒ...\")\n",
        "    print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
        "    print(f\"ä½œæ¥­ç³»çµ±: {platform.system()} {platform.release()}\")\n",
        "    print(f\"ç•¶å‰æ™‚å€: {taipei_tz}\")\n",
        "\n",
        "    # æª¢æŸ¥é‡è¦å¥—ä»¶ç‰ˆæœ¬\n",
        "    required_packages = {\n",
        "        'pandas': pd.__version__,\n",
        "        'numpy': np.__version__,\n",
        "        'matplotlib': plt.matplotlib.__version__,\n",
        "        'requests': requests.__version__,\n",
        "        'yfinance': getattr(yf, '__version__', 'Unknown'),\n",
        "        'aiohttp': aiohttp.__version__,\n",
        "        'pytz': pytz.__version__\n",
        "    }\n",
        "\n",
        "    print(\"\\nğŸ“¦ å¥—ä»¶ç‰ˆæœ¬:\")\n",
        "    for package, version in required_packages.items():\n",
        "        print(f\"  {package}: {version}\")\n",
        "\n",
        "    # æª¢æŸ¥ç›®éŒ„æ¬Šé™\n",
        "    print(f\"\\nğŸ“ å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "    directories_status = {\n",
        "        'å¿«å–ç›®éŒ„': (CACHE_DIR, os.access(CACHE_DIR, os.W_OK)),\n",
        "        'çµæœç›®éŒ„': (RESULTS_DIR, os.access(RESULTS_DIR, os.W_OK)),\n",
        "        'åœ–è¡¨ç›®éŒ„': (CHARTS_DIR, os.access(CHARTS_DIR, os.W_OK))\n",
        "    }\n",
        "\n",
        "    for name, (path, writable) in directories_status.items():\n",
        "        status = 'âœ…' if writable else 'âŒ'\n",
        "        print(f\"{name}: {path} {status}\")\n",
        "\n",
        "    # æª¢æŸ¥ç¶²è·¯é€£ç·šï¼ˆç°¡å–®æ¸¬è©¦ï¼‰\n",
        "    try:\n",
        "        response = requests.get('https://httpbin.org/status/200', timeout=5)\n",
        "        network_status = 'âœ…' if response.status_code == 200 else 'âŒ'\n",
        "    except:\n",
        "        network_status = 'âŒ'\n",
        "\n",
        "    print(f\"ç¶²è·¯é€£ç·š: {network_status}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "def get_current_time():\n",
        "    \"\"\"\n",
        "    ç²å–ç•¶å‰å°åŒ—æ™‚é–“\n",
        "    \"\"\"\n",
        "    return datetime.now(taipei_tz)\n",
        "\n",
        "def format_timestamp(dt=None):\n",
        "    \"\"\"\n",
        "    æ ¼å¼åŒ–æ™‚é–“æˆ³è¨˜\n",
        "    \"\"\"\n",
        "    if dt is None:\n",
        "        dt = get_current_time()\n",
        "    return dt.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
        "\n",
        "# ==============================================================================\n",
        "# 12. ç¨‹å¼åˆå§‹åŒ–\n",
        "# ==============================================================================\n",
        "def initialize_application():\n",
        "    \"\"\"\n",
        "    æ‡‰ç”¨ç¨‹å¼åˆå§‹åŒ–\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· v2.1\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # æª¢æŸ¥ç’°å¢ƒ\n",
        "    check_environment()\n",
        "\n",
        "    # è¨­å®šä¸­æ–‡å­—é«”\n",
        "    set_chinese_font()\n",
        "\n",
        "    # è¨˜éŒ„å•Ÿå‹•æ™‚é–“\n",
        "    start_time = get_current_time()\n",
        "    logger.info(f\"æ‡‰ç”¨ç¨‹å¼å•Ÿå‹• - {format_timestamp(start_time)}\")\n",
        "    logger.info(f\"å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "\n",
        "    print(f\"âœ… åˆå§‹åŒ–å®Œæˆ - {format_timestamp(start_time)}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# StockAnalyzer é¡å®šç¾© (èˆ‡ä¹‹å‰ç›¸åŒï¼Œç„¡éœ€è®Šæ›´)\n",
        "# ==============================================================================\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.stocks_df = pd.DataFrame()\n",
        "\n",
        "    def standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "            return pd.DataFrame()\n",
        "        df = df.copy()\n",
        "        if df.index.name is not None and 'date' in df.index.name.lower():\n",
        "            df = df.reset_index()\n",
        "        column_mapping = {\n",
        "            'Date': 'Date', 'date': 'Date', 'æ—¥æœŸ': 'Date',\n",
        "            'Open': 'Open', 'open': 'Open', 'é–‹ç›¤åƒ¹': 'Open',\n",
        "            'High': 'High', 'high': 'High', 'æœ€é«˜åƒ¹': 'High',\n",
        "            'Low': 'Low', 'low': 'Low', 'æœ€ä½åƒ¹': 'Low',\n",
        "            'Close': 'Close', 'close': 'Close', 'æ”¶ç›¤åƒ¹': 'Close', 'Adj Close': 'Close',\n",
        "            'Volume': 'Volume', 'volume': 'Volume', 'æˆäº¤é‡': 'Volume',\n",
        "        }\n",
        "        rename_dict = {col: column_mapping.get(col, col) for col in df.columns}\n",
        "        df.rename(columns=rename_dict, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=False):\n",
        "        if not force_update and os.path.exists(STOCK_LIST_PATH):\n",
        "            if (time.time() - os.path.getmtime(STOCK_LIST_PATH)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(STOCK_LIST_PATH, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0]\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:]\n",
        "                df['market'] = market_name\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œç¨‹åºçµ‚æ­¢ã€‚\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "        df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "        df = df[df['stock_id'].str.match(r'^\\d{4}$')].copy()\n",
        "        exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "        df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)]\n",
        "        df['yahoo_symbol'] = df.apply(\n",
        "            lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "        final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "        final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "        final_df.to_csv(STOCK_LIST_PATH, index=False)\n",
        "        logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "        return final_df\n",
        "\n",
        "    async def fetch_yfinance_data_async(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3, backoff_factor: float = 0.5):\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "                        if df[col].isna().all():\n",
        "                            logger.warning(f\"[{stock_id}] {col} æ•¸æ“šå…¨ç‚º NaN\")\n",
        "                            return pd.DataFrame()\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = backoff_factor * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦æ™‚ç™¼ç”Ÿç•°å¸¸: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    await asyncio.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] å› ç•°å¸¸ï¼Œåœ¨ {retries} æ¬¡å˜—è©¦å¾Œç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    async def fetch_all_stocks(self, stocks_df):\n",
        "        tasks = [self.fetch_yfinance_data_async(row['yahoo_symbol']) for _, row in stocks_df.iterrows()]\n",
        "        results = await analyzer.fetch_all_stocks(stocks_df)\n",
        "        for stock, data_df in zip(stocks_df.itertuples(), results):\n",
        "            stock_id = stock.stock_id\n",
        "            if isinstance(data_df, pd.DataFrame) and not data_df.empty and len(data_df) >= 60:\n",
        "                data_df = analyzer.standardize_columns(data_df.reset_index())\n",
        "                # Proceed with volume checks and analysis\n",
        "            else:\n",
        "                logger.warning(f\"[{stock_id}] æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—ï¼Œè·³éã€‚\")\n",
        "                failed_stocks.append(stock_id)\n",
        "                continue\n",
        "        return await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    def fetch_yfinance_data_single_robust(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3, backoff_factor: float = 0.5, request_timeout: int = 30):\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True, timeout=request_timeout)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "                # Handle multi-level columns if present\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)  # Flatten to first level\n",
        "                # Ensure all required columns are numeric\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "                        if df[col].isna().all():\n",
        "                            logger.warning(f\"[{stock_id}] {col} æ•¸æ“šå…¨ç‚º NaN\")\n",
        "                            return pd.DataFrame()\n",
        "                # Drop rows with any NaN in required columns\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] æ•¸æ“šæ¸…ç†å¾Œç‚ºç©º\")\n",
        "                    return pd.DataFrame()\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = backoff_factor * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦æ™‚ç™¼ç”Ÿç•°å¸¸: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] å› ç•°å¸¸ï¼Œåœ¨ {retries} æ¬¡å˜—è©¦å¾Œç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "    def calculate_all_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if df.empty or 'Close' not in df.columns or len(df) < 20:\n",
        "            return df\n",
        "        df = df.copy()\n",
        "        for days in [5, 10, 20, 60]:\n",
        "            df[f'MA{days}'] = df['Close'].rolling(window=days, min_periods=1).mean()\n",
        "        delta = df['Close'].diff()\n",
        "        gain = delta.where(delta > 0, 0).rolling(window=14).mean()\n",
        "        loss = -delta.where(delta < 0, 0).rolling(window=14).mean()\n",
        "        rs = gain / (loss + 1e-9)\n",
        "        df['RSI'] = 100 - (100 / (1 + rs))\n",
        "        exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "        exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "        df['MACD'] = exp1 - exp2\n",
        "        df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "        df['Histogram'] = df['MACD'] - df['MACD_signal']\n",
        "        df = df.fillna(method='bfill').fillna(method='ffill')\n",
        "        return df\n",
        "\n",
        "    def analyze_stock(self, stock_info: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        try:\n",
        "            df = stock_info['data'].copy()\n",
        "            if len(df) < 60:\n",
        "                return {'success': False, 'message': f\"æ•¸æ“šé‡ä¸è¶³ ({len(df)} < 60)\"}\n",
        "\n",
        "            df_with_indicators = self.calculate_all_indicators(df)\n",
        "            if df_with_indicators.empty:\n",
        "                return {'success': False, 'message': \"æŒ‡æ¨™è¨ˆç®—å¾Œæ•¸æ“šç‚ºç©º\"}\n",
        "\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            momentum_analysis = self.analyze_momentum(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            pattern_analysis = self.analyze_patterns(df_with_indicators)\n",
        "\n",
        "            weights = {'trend': 0.3, 'momentum': 0.3, 'volume': 0.2, 'pattern': 0.2}\n",
        "            combined_score = (\n",
        "                trend_analysis.get('score', 50) * weights['trend'] +\n",
        "                momentum_analysis.get('score', 50) * weights['momentum'] +\n",
        "                volume_analysis.get('score', 50) * weights['volume'] +\n",
        "                pattern_analysis.get('score', 50) * weights['pattern']\n",
        "            )\n",
        "\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, momentum_analysis, volume_analysis, pattern_analysis)\n",
        "\n",
        "            return {\n",
        "                'success': True, 'stock_id': stock_info['stock_id'], 'stock_name': stock_info['stock_name'],\n",
        "                'industry': stock_info['industry'], 'data_df': df_with_indicators,\n",
        "                'combined_score': round(combined_score, 2), 'recommendation': recommendation,\n",
        "                'last_price': df_with_indicators['Close'].iloc[-1]\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_info.get('stock_id', 'N/A')} æ™‚ç™¼ç”Ÿé ‚å±¤éŒ¯èª¤: {e}\")\n",
        "            return {'success': False, 'message': str(e)}\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        try:\n",
        "            if len(df) < 60: return {'score': 50}\n",
        "            recent_close = float(df['Close'].iloc[-1])\n",
        "            recent_ma20 = float(df['MA20'].iloc[-1])\n",
        "            recent_ma60 = float(df['MA60'].iloc[-1])\n",
        "            score = 50\n",
        "            if recent_close > recent_ma20: score += 15\n",
        "            if recent_close > recent_ma60: score += 15\n",
        "            if recent_ma20 > recent_ma60: score += 10\n",
        "            return {'score': max(0, min(100, score))}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\"); return {'score': 50}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        try:\n",
        "            if len(df) < 20 or 'Volume' not in df.columns or df['Volume'].isna().all():\n",
        "                return {'score': 50}\n",
        "            # Convert to numeric\n",
        "            df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')\n",
        "            recent_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20 = float(df['Volume'].iloc[-20:].mean())\n",
        "            score = 50\n",
        "            if pd.isna(avg_volume_20) or avg_volume_20 == 0:\n",
        "                return {'score': 50}\n",
        "            volume_ratio = recent_volume / avg_volume_20\n",
        "            if volume_ratio > 1.5:\n",
        "                score += 20\n",
        "            if len(df) >= 2:\n",
        "                price_change = (float(df['Close'].iloc[-1]) - float(df['Close'].iloc[-2])) / float(df['Close'].iloc[-2])\n",
        "                if price_change > 0.02 and volume_ratio > 1.2:\n",
        "                    score += 20\n",
        "                elif price_change < -0.02 and volume_ratio > 1.2:\n",
        "                    score -= 20\n",
        "            return {'score': max(0, min(100, score))}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'score': 50}\n",
        "    def analyze_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        try:\n",
        "            if len(df) < 21: return {'score': 50, 'patterns': []}\n",
        "            patterns_found = []\n",
        "            score = 50\n",
        "            high_20 = float(df['High'].iloc[-21:-1].max())\n",
        "            latest_high = float(df['High'].iloc[-1])\n",
        "            if latest_high > high_20:\n",
        "                score += 25; patterns_found.append(\"çªç ´20æ—¥é«˜é»\")\n",
        "            return {'score': max(0, min(100, score)), 'patterns': patterns_found}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å½¢æ…‹åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\"); return {'score': 50, 'patterns': []}\n",
        "\n",
        "    def analyze_momentum(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        try:\n",
        "            if len(df) < 30 or 'RSI' not in df.columns or 'Histogram' not in df.columns:\n",
        "                return {'score': 50}\n",
        "            score = 50\n",
        "            recent_rsi = float(df['RSI'].iloc[-1])\n",
        "            recent_macd_hist = float(df['Histogram'].iloc[-1])\n",
        "            if recent_rsi < 30: score += 20\n",
        "            elif recent_rsi > 70: score -= 20\n",
        "            if recent_macd_hist > 0 and float(df['Histogram'].iloc[-2]) < 0:\n",
        "                score += 20  # MACD æŸ±ç‹€é«”ç”±è² è½‰æ­£\n",
        "            elif recent_macd_hist > 0:\n",
        "                score += 10\n",
        "            return {'score': max(0, min(100, score))}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å‹•èƒ½åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\"); return {'score': 50}\n",
        "\n",
        "    def generate_recommendation(self, combined_score, trend_analysis, momentum_analysis, volume_analysis, pattern_analysis):\n",
        "        buy_threshold = 65\n",
        "        sell_threshold = 35\n",
        "        action = \"è§€æœ›\"\n",
        "        if combined_score >= buy_threshold: action = \"è²·å…¥\"\n",
        "        elif combined_score <= sell_threshold: action = \"è³£å‡º\"\n",
        "\n",
        "        reasons = []\n",
        "        if trend_analysis.get('score', 50) > 70: reasons.append(\"è¶¨å‹¢å¼·å‹å‘ä¸Š\")\n",
        "        if momentum_analysis.get('score', 50) > 70: reasons.append(\"å‹•èƒ½å……æ²›\")\n",
        "        if volume_analysis.get('score', 50) > 70: reasons.append(\"åƒ¹é‡é…åˆè‰¯å¥½\")\n",
        "        if pattern_analysis.get('patterns'): reasons.extend(pattern_analysis['patterns'])\n",
        "        if not reasons: reasons.append(\"å¤šç©ºæŒ‡æ¨™å‡è¡¡\")\n",
        "\n",
        "        if combined_score > 50:\n",
        "            confidence = (combined_score - 50) / 50 * 100\n",
        "        else:\n",
        "            confidence = (50 - combined_score) / 50 * 100\n",
        "\n",
        "        return {'action': action, 'reasons': reasons, 'confidence': round(confidence, 2)}\n",
        "\n",
        "    def generate_detailed_analysis_report(self, stock_id: str, stock_name: str, stock_data: Dict, save_path: str):\n",
        "        df = stock_data.get('data_df')\n",
        "        if df is None or df.empty:\n",
        "            logger.error(f\"ç„¡æ³•ç‚º {stock_id} ç”Ÿæˆåœ–è¡¨ï¼Œç¼ºå°‘ data_dfã€‚\")\n",
        "            return None\n",
        "\n",
        "        df_chart = df.copy()\n",
        "\n",
        "        cols_to_convert = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "        for col in cols_to_convert:\n",
        "            if col in df_chart.columns:\n",
        "                df_chart[col] = pd.to_numeric(df_chart[col], errors='coerce')\n",
        "\n",
        "        df_chart.dropna(subset=cols_to_convert, inplace=True)\n",
        "\n",
        "        if not isinstance(df_chart.index, pd.DatetimeIndex):\n",
        "            if 'Date' in df_chart.columns:\n",
        "                df_chart['Date'] = pd.to_datetime(df_chart['Date'])\n",
        "                df_chart.set_index('Date', inplace=True)\n",
        "            else:\n",
        "                df_chart.index = pd.to_datetime(df_chart.index)\n",
        "\n",
        "        apds = [\n",
        "            mpf.make_addplot(df_chart['MA5'], color='orange', width=0.7),\n",
        "            mpf.make_addplot(df_chart['MA20'], color='blue', width=0.7),\n",
        "            mpf.make_addplot(df_chart['RSI'], panel=2, color='purple', ylabel='RSI'),\n",
        "            mpf.make_addplot(df_chart[['MACD', 'MACD_signal']], panel=3, ylabel='MACD'),\n",
        "            mpf.make_addplot(df_chart['Histogram'], type='bar', panel=3, color='gray', alpha=0.5)\n",
        "        ]\n",
        "        mc = mpf.make_marketcolors(up='r', down='g', inherit=True)\n",
        "        s = mpf.make_mpf_style(marketcolors=mc, gridstyle='--', facecolor='#F0F0F0', rc={'font.family': 'SimHei'})\n",
        "        title = f\"#{stock_id} {stock_name} - Score: {stock_data.get('combined_score', 0):.0f}\"\n",
        "\n",
        "        try:\n",
        "            mpf.plot(df_chart.tail(180), type='candle', style=s, title=title,\n",
        "                     volume=True, addplot=apds, figsize=(16, 9),\n",
        "                     panel_ratios=(3, 1, 1, 1), savefig=save_path)\n",
        "            logger.info(f\"æˆåŠŸç”Ÿæˆåœ–è¡¨: {save_path}\")\n",
        "            return save_path\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç‚º {stock_id} ç¹ªè£½åœ–è¡¨å¤±æ•—: {e}\")\n",
        "            return None\n",
        "\n",
        "    def print_advanced_filtered_stocks(self, results: Dict, top_n=20):\n",
        "        if not results:\n",
        "            logger.warning(\"æ²’æœ‰è‚¡ç¥¨é€šéæœ€çµ‚ç¯©é¸ã€‚\")\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"ğŸ¯ æœ€çµ‚ç¯©é¸å„ªè³ªè‚¡ç¥¨æ¸…å–® ğŸ¯\".center(80))\n",
        "            print(\"=\"*80)\n",
        "            print(\"ç„¡è‚¡ç¥¨é€šéç¯©é¸æ¢ä»¶ã€‚\")\n",
        "            print(\"=\"*80)\n",
        "            return\n",
        "\n",
        "        sorted_stocks = sorted(results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)[:top_n]\n",
        "\n",
        "        # Print summary table\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ¯ æœ€çµ‚ç¯©é¸å„ªè³ªè‚¡ç¥¨æ¸…å–® ğŸ¯\".center(80))\n",
        "        print(\"=\"*80)\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<7}{'åç¨±':<12}{'åˆ†æ•¸':<7}{'åƒ¹æ ¼':<10}{'å»ºè­°':<10}{'ç”¢æ¥­':<15}\")\n",
        "        print(\"-\" * 80)\n",
        "        for i, stock in enumerate(sorted_stocks, 1):\n",
        "            # å®‰å…¨è™•ç† industry æ¬„ä½ï¼Œç¢ºä¿æ˜¯å­—ä¸²é¡å‹\n",
        "            industry = stock.get('industry', '')\n",
        "            if pd.isna(industry) or not isinstance(industry, str):\n",
        "                industry = 'æœªåˆ†é¡'\n",
        "\n",
        "            print(\n",
        "            f\"{i:<4}\"\n",
        "            f\"{stock.get('stock_id', ''):<7}\"\n",
        "            f\"{stock.get('stock_name', '')[:10]:<12}\"\n",
        "            f\"{stock.get('combined_score', 0):<7.0f}\"\n",
        "            f\"{stock.get('last_price', 0):<10.2f}\"\n",
        "            f\"{stock.get('recommendation', {}).get('action', ''):<10}\"\n",
        "            f\"{industry[:12]:<15}\"\n",
        "            )\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # Print detailed report for each stock\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ“Š è©³ç´°åˆ†æå ±å‘Š ğŸ“Š\".center(80))\n",
        "        print(\"=\"*80)\n",
        "        for i, stock in enumerate(sorted_stocks, 1):\n",
        "            # åŒæ¨£å®‰å…¨è™•ç† industry æ¬„ä½\n",
        "            industry = stock.get('industry', '')\n",
        "            if pd.isna(industry) or not isinstance(industry, str):\n",
        "                industry = 'æœªåˆ†é¡'\n",
        "\n",
        "        print(f\"\\nå ±å‘Š #{i}: {stock.get('stock_id', 'N/A')} - {stock.get('stock_name', 'N/A')}\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"ç¶œåˆè©•åˆ†: {stock.get('combined_score', 0):.2f}\")\n",
        "        print(f\"æœ€æ–°æ”¶ç›¤åƒ¹: {stock.get('last_price', 0):.2f} å…ƒ\")\n",
        "        print(f\"ç”¢æ¥­é¡åˆ¥: {industry}\")\n",
        "        print(f\"æ¨è–¦è¡Œå‹•: {stock.get('recommendation', {}).get('action', 'N/A')}\")\n",
        "        print(f\"ä¿¡å¿ƒåº¦: {stock.get('recommendation', {}).get('confidence', 0):.2f}%\")\n",
        "        print(\"æ¨è–¦ç†ç”±:\")\n",
        "        reasons = stock.get('recommendation', {}).get('reasons', ['ç„¡ç‰¹å®šç†ç”±'])\n",
        "        for reason in reasons:\n",
        "            print(f\"  - {reason}\")\n",
        "        print(\"-\" * 50)\n",
        "    print(\"=\" * 80)\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸ - å¢å¼·ç‰ˆæœ¬\n",
        "# ==============================================================================\n",
        "# ä¿®æ”¹ send_notification å‡½æ•¸ï¼Œä½¿ session æˆç‚ºå¯é¸åƒæ•¸\n",
        "async def send_notification(message: str, files: List[str] = None, session: aiohttp.ClientSession = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾› sessionï¼Œå‰‡å‰µå»ºä¸€å€‹æ–°çš„\n",
        "    session_created = False\n",
        "    if session is None:\n",
        "        session = aiohttp.ClientSession()\n",
        "        session_created = True\n",
        "\n",
        "    try:\n",
        "        # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "        if not files:\n",
        "            chart_dir = \"/content/results/charts/\"\n",
        "            if os.path.exists(chart_dir):\n",
        "                # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "                files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                        if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "                if files:\n",
        "                    logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "                else:\n",
        "                    logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "        # Telegram\n",
        "        try:\n",
        "            # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "            for chat_id in TELEGRAM_CHAT_ID:\n",
        "                # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "                url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "                payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "                async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                    if response.status == 200:\n",
        "                        logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                    else:\n",
        "                        response_text = await response.text()\n",
        "                        logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "                if files:\n",
        "                    url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                    sent_count = 0\n",
        "                    for file_path in files:\n",
        "                        if os.path.exists(file_path):\n",
        "                            try:\n",
        "                                data = aiohttp.FormData()\n",
        "                                data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                                # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                                caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                                data.add_field('caption', caption)\n",
        "\n",
        "                                with open(file_path, 'rb') as f:\n",
        "                                    data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                    async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                        if response.status == 200:\n",
        "                                            sent_count += 1\n",
        "                                        else:\n",
        "                                            response_text = await response.text()\n",
        "                                            logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                                # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                                await asyncio.sleep(0.5)\n",
        "                            except Exception as file_error:\n",
        "                                logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                    logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "        # Discord\n",
        "        try:\n",
        "            # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "            message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "            for chunk in message_chunks:\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "            # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "            if files:\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(files), batch_size):\n",
        "                    batch_files = files[i:i+batch_size]\n",
        "                    webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                    for file_path in batch_files:\n",
        "                        if os.path.exists(file_path):\n",
        "                            try:\n",
        "                                with open(file_path, 'rb') as f:\n",
        "                                    webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                            except Exception as file_error:\n",
        "                                logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                    response = webhook.execute()\n",
        "                    if response and response.ok:\n",
        "                        logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                    else:\n",
        "                        status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                        content = response.content if response else \"æœªçŸ¥\"\n",
        "                        logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "    finally:\n",
        "        # å¦‚æœæˆ‘å€‘å‰µå»ºäº† sessionï¼Œå‰‡é—œé–‰å®ƒ\n",
        "        if session_created:\n",
        "            await session.close()\n",
        "async def send_chart_files(chart_path, caption=\"\"):\n",
        "    \"\"\"\n",
        "    ç™¼é€åœ–è¡¨æ–‡ä»¶åˆ° Telegram å’Œ Discord\n",
        "    \"\"\"\n",
        "    if not os.path.exists(chart_path):\n",
        "        logger.error(f\"åœ–è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {chart_path}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # ä½¿ç”¨ send_notification å‡½æ•¸ç™¼é€å–®å€‹æ–‡ä»¶\n",
        "        await send_notification(caption, files=[chart_path])\n",
        "        logger.info(f\"å·²ç™¼é€åœ–è¡¨: {os.path.basename(chart_path)}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€åœ–è¡¨æ™‚å‡ºéŒ¯: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "def format_notification_message(sorted_results):\n",
        "    \"\"\"\n",
        "    æ ¼å¼åŒ–é€šçŸ¥æ¶ˆæ¯\n",
        "    \"\"\"\n",
        "    if not sorted_results:\n",
        "        return \"âš ï¸ åˆ†æå®Œæˆï¼Œä½†æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ã€‚\"\n",
        "\n",
        "    # å–å‰ 10 å\n",
        "    top_n = min(10, len(sorted_results))\n",
        "    top_stocks = sorted_results[:top_n]\n",
        "\n",
        "    # è¨ˆç®—å‹•ä½œçµ±è¨ˆ\n",
        "    action_counts = {}\n",
        "    for stock in sorted_results:\n",
        "        action = stock.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "        action_counts[action] = action_counts.get(action, 0) + 1\n",
        "\n",
        "    # æ ¼å¼åŒ–æ¶ˆæ¯\n",
        "    message = f\"ğŸ“Š å°è‚¡æŠ€è¡“åˆ†æçµæœ ({datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M')})\\n\"\n",
        "    message += f\"å…±åˆ†æ {len(sorted_results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\\n\"\n",
        "    message += f\"è²·å…¥: {action_counts.get('è²·å…¥', 0)} | æŒæœ‰: {action_counts.get('æŒæœ‰', 0)} | è³£å‡º: {action_counts.get('è³£å‡º', 0)}\\n\\n\"\n",
        "\n",
        "    message += \"ğŸ† è©•åˆ†æœ€é«˜çš„è‚¡ç¥¨:\\n\"\n",
        "    for i, stock in enumerate(top_stocks, 1):\n",
        "        stock_id = stock['stock_id']\n",
        "        stock_name = stock['stock_name']\n",
        "        score = stock.get('combined_score', 0)\n",
        "        price = stock.get('last_price', 0)\n",
        "        action = stock.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "        confidence = stock.get('recommendation', {}).get('confidence', 0)\n",
        "\n",
        "        message += f\"{i}. {stock_name} ({stock_id}) - {price:.2f} å…ƒ\\n\"\n",
        "        message += f\"   è©•åˆ†: {score:.1f}/100 | å»ºè­°: {action} ({confidence:.0f}%)\\n\"\n",
        "\n",
        "    message += \"\\nğŸ“ˆ è©³ç´°åˆ†æåœ–è¡¨å·²ç”Ÿæˆï¼Œè«‹æŸ¥çœ‹é™„ä»¶ã€‚\"\n",
        "    return message\n",
        "\n",
        "\n",
        "async def generate_and_send_summary_chart(results, report_time):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆä¸¦ç™¼é€æ‘˜è¦åœ–è¡¨\n",
        "    \"\"\"\n",
        "    if not results:\n",
        "        logger.warning(\"æ²’æœ‰çµæœå¯ä¾›ç”Ÿæˆæ‘˜è¦åœ–è¡¨\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # å‰µå»ºæ‘˜è¦åœ–è¡¨\n",
        "        logger.info(\"ç”Ÿæˆæ‘˜è¦åœ–è¡¨...\")\n",
        "\n",
        "        # è¨­å®šåœ–è¡¨å¤§å° - 4K è§£æåº¦\n",
        "        plt.figure(figsize=(32, 18), dpi=150)  # 4K ç­‰æ•ˆ (4800x2700)\n",
        "\n",
        "        # è¨­å®šæ¨™é¡Œ\n",
        "        plt.suptitle(f'å°è‚¡æŠ€è¡“åˆ†ææ‘˜è¦ - {report_time}', fontsize=24, y=0.98)\n",
        "\n",
        "        # å–å‰ 20 åé€²è¡Œå±•ç¤º\n",
        "        top_n = min(20, len(results))\n",
        "        top_stocks = results[:top_n]\n",
        "\n",
        "        # æº–å‚™æ•¸æ“š\n",
        "        stock_ids = [f\"{r['stock_id']} {r['stock_name']}\" for r in top_stocks]\n",
        "        scores = [r.get('combined_score', 0) for r in top_stocks]\n",
        "        actions = [r.get('recommendation', {}).get('action', 'æŒæœ‰') for r in top_stocks]\n",
        "\n",
        "        # è¨­å®šé¡è‰²æ˜ å°„\n",
        "        colors = []\n",
        "        for action in actions:\n",
        "            if action == 'è²·å…¥':\n",
        "                colors.append('#FF5252')  # ç´…è‰²\n",
        "            elif action == 'è³£å‡º':\n",
        "                colors.append('#4CAF50')  # ç¶ è‰²\n",
        "            else:\n",
        "                colors.append('#FFC107')  # é»ƒè‰²\n",
        "\n",
        "        # ç¹ªè£½è©•åˆ†æ¢å½¢åœ–\n",
        "        ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
        "        bars = ax1.barh(stock_ids, scores, color=colors, alpha=0.8)\n",
        "        ax1.set_title('è‚¡ç¥¨ç¶œåˆè©•åˆ† (è¶Šé«˜è¶Šçœ‹å¥½)', fontsize=18)\n",
        "        ax1.set_xlim(0, 100)\n",
        "        ax1.axvline(x=50, color='gray', linestyle='--', alpha=0.5)\n",
        "        ax1.set_xlabel('è©•åˆ†', fontsize=14)\n",
        "        ax1.grid(axis='x', linestyle='--', alpha=0.3)\n",
        "\n",
        "        # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
        "        for bar, score in zip(bars, scores):\n",
        "            ax1.text(min(score + 2, 95), bar.get_y() + bar.get_height()/2,\n",
        "                    f'{score:.1f}', va='center', fontsize=12)\n",
        "\n",
        "        # ç¹ªè£½è©•åˆ†åˆ†ä½ˆç›´æ–¹åœ–\n",
        "        ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
        "        all_scores = [r.get('combined_score', 0) for r in results]\n",
        "        ax2.hist(all_scores, bins=20, range=(0, 100), color='skyblue', edgecolor='black', alpha=0.7)\n",
        "        ax2.set_title('æ‰€æœ‰è‚¡ç¥¨è©•åˆ†åˆ†ä½ˆ', fontsize=18)\n",
        "        ax2.set_xlabel('è©•åˆ†', fontsize=14)\n",
        "        ax2.set_ylabel('è‚¡ç¥¨æ•¸é‡', fontsize=14)\n",
        "        ax2.grid(linestyle='--', alpha=0.3)\n",
        "\n",
        "        # ç¹ªè£½å»ºè­°å‹•ä½œé¤…åœ–\n",
        "        ax3 = plt.subplot2grid((2, 2), (1, 1))\n",
        "        action_counts = {}\n",
        "        for r in results:\n",
        "            action = r.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "            action_counts[action] = action_counts.get(action, 0) + 1\n",
        "\n",
        "        labels = list(action_counts.keys())\n",
        "        sizes = list(action_counts.values())\n",
        "        colors_pie = ['#FF5252', '#FFC107', '#4CAF50']  # ç´…(è²·å…¥), é»ƒ(æŒæœ‰), ç¶ (è³£å‡º)\n",
        "        explode = [0.1 if label == 'è²·å…¥' else 0 for label in labels]  # çªå‡º\"è²·å…¥\"\n",
        "\n",
        "        ax3.pie(sizes, explode=explode, labels=labels, colors=colors_pie, autopct='%1.1f%%',\n",
        "               shadow=True, startangle=90, textprops={'fontsize': 14})\n",
        "        ax3.set_title('å»ºè­°å‹•ä½œåˆ†ä½ˆ', fontsize=18)\n",
        "\n",
        "        # æ·»åŠ åœ–ä¾‹\n",
        "        from matplotlib.lines import Line2D\n",
        "        legend_elements = [\n",
        "            Line2D([0], [0], color='#FF5252', lw=4, label='è²·å…¥'),\n",
        "            Line2D([0], [0], color='#FFC107', lw=4, label='æŒæœ‰'),\n",
        "            Line2D([0], [0], color='#4CAF50', lw=4, label='è³£å‡º')\n",
        "        ]\n",
        "        ax1.legend(handles=legend_elements, loc='lower right', fontsize=14)\n",
        "\n",
        "        # æ·»åŠ è¨»è…³\n",
        "        plt.figtext(0.5, 0.01,\n",
        "                   f'åˆ†ææ™‚é–“: {report_time} | å…±åˆ†æ {len(results)} æ”¯è‚¡ç¥¨ | ä½¿ç”¨æŒ‡æ¨™: è¶¨å‹¢ã€å‹•èƒ½ã€æˆäº¤é‡ã€å½¢æ…‹',\n",
        "                   ha='center', fontsize=12, bbox=dict(facecolor='#f0f0f0', alpha=0.5))\n",
        "\n",
        "        # èª¿æ•´ä½ˆå±€\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "        # ä¿å­˜åœ–è¡¨\n",
        "        summary_chart_path = os.path.join(CHARTS_DIR, f'summary_report_{datetime.now(taipei_tz).strftime(\"%Y%m%d_%H%M%S\")}.png')\n",
        "        plt.savefig(summary_chart_path, dpi=150, bbox_inches='tight')\n",
        "        logger.info(f\"æ‘˜è¦åœ–è¡¨å·²ä¿å­˜åˆ°: {summary_chart_path}\")\n",
        "\n",
        "        # é—œé–‰åœ–è¡¨ï¼Œé‡‹æ”¾è¨˜æ†¶é«”\n",
        "        plt.close()\n",
        "\n",
        "        return summary_chart_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”Ÿæˆæ‘˜è¦åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "        return None\n",
        "\n",
        "\n",
        "# å¦‚æœä½ é‚„éœ€è¦ä¸€å€‹ç´”çµ±è¨ˆåœ–è¡¨çš„ç‰ˆæœ¬ï¼Œå¯ä»¥é¡å¤–æ·»åŠ é€™å€‹å‡½æ•¸\n",
        "async def generate_and_send_statistics_chart(final_results: list, report_time: str):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆä¸¦ç™¼é€çµ±è¨ˆåˆ†æåœ–è¡¨ï¼ˆè¡Œæ¥­åˆ†å¸ƒ + è©•åˆ†åˆ†å¸ƒï¼‰\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not final_results:\n",
        "            logger.info(\"ç„¡çµæœæ•¸æ“šï¼Œè·³éçµ±è¨ˆåœ–è¡¨ç”Ÿæˆ\")\n",
        "            return\n",
        "\n",
        "        # å‰µå»ºåœ–è¡¨ - 1x2 å¸ƒå±€\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "        fig.suptitle(f'ğŸ“Š å°è‚¡åˆ†æçµ±è¨ˆåœ–è¡¨ - {report_time}', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # 1. è¡Œæ¥­åˆ†å¸ƒåœ“é¤…åœ–\n",
        "        industry_counts = {}\n",
        "        for stock in final_results:\n",
        "            industry = stock.get('industry', 'å…¶ä»–')\n",
        "            industry_counts[industry] = industry_counts.get(industry, 0) + 1\n",
        "\n",
        "        if industry_counts:\n",
        "            industries = list(industry_counts.keys())\n",
        "            counts = list(industry_counts.values())\n",
        "            colors = plt.cm.Set3(np.linspace(0, 1, len(industries)))\n",
        "\n",
        "            wedges, texts, autotexts = ax1.pie(counts, labels=industries, autopct='%1.0f%%',\n",
        "                                              colors=colors, startangle=90)\n",
        "            ax1.set_title('ğŸ­ è¡Œæ¥­åˆ†å¸ƒ', fontweight='bold', fontsize=14)\n",
        "\n",
        "            # èª¿æ•´æ–‡å­—å¤§å°\n",
        "            for text in texts:\n",
        "                text.set_fontsize(10)\n",
        "            for autotext in autotexts:\n",
        "                autotext.set_fontsize(9)\n",
        "                autotext.set_fontweight('bold')\n",
        "\n",
        "        # 2. è©•åˆ†åˆ†å¸ƒç›´æ–¹åœ–\n",
        "        all_scores = [s.get('combined_score', 0) for s in final_results]\n",
        "        n, bins, patches = ax2.hist(all_scores, bins=10, color='#4682B4', alpha=0.7, edgecolor='black')\n",
        "        ax2.set_xlabel('ç¶œåˆè©•åˆ†', fontsize=12)\n",
        "        ax2.set_ylabel('è‚¡ç¥¨æ•¸é‡', fontsize=12)\n",
        "        ax2.set_title('ğŸ“ˆ è©•åˆ†åˆ†å¸ƒ', fontweight='bold', fontsize=14)\n",
        "        ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "        # åœ¨ç›´æ–¹åœ–æŸ±å­ä¸Šé¡¯ç¤ºæ•¸é‡\n",
        "        for i, (count, patch) in enumerate(zip(n, patches)):\n",
        "            if count > 0:\n",
        "                ax2.text(patch.get_x() + patch.get_width()/2, patch.get_height() + 0.1,\n",
        "                        f'{int(count)}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "        # æ·»åŠ çµ±è¨ˆç·š\n",
        "        mean_score = np.mean(all_scores)\n",
        "        ax2.axvline(mean_score, color='red', linestyle='--', linewidth=2, label=f'å¹³å‡åˆ†: {mean_score:.1f}')\n",
        "        ax2.legend(fontsize=11)\n",
        "\n",
        "        # èª¿æ•´å¸ƒå±€\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # å„²å­˜åœ–è¡¨\n",
        "        stats_chart_path = os.path.join(CHARTS_DIR, f\"statistics_report_{datetime.now(taipei_tz).strftime('%Y%m%d_%H%M%S')}.png\")\n",
        "        plt.savefig(stats_chart_path, dpi=150, bbox_inches='tight',\n",
        "                   facecolor='white', edgecolor='none')\n",
        "        plt.close()\n",
        "\n",
        "        # ç™¼é€çµ±è¨ˆåœ–è¡¨\n",
        "        caption = f\"ğŸ“Š å°è‚¡åˆ†æçµ±è¨ˆåœ–è¡¨\\nâ° {report_time}\\nğŸ“ˆ å…± {len(final_results)} æ”¯ç¬¦åˆæ¢ä»¶\"\n",
        "        await send_chart_files(stats_chart_path, caption)\n",
        "\n",
        "        logger.info(f\"å·²ç”Ÿæˆä¸¦ç™¼é€çµ±è¨ˆåœ–è¡¨: {stats_chart_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”Ÿæˆçµ±è¨ˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "# ==============================================================================\n",
        "# ä¸»åŸ·è¡Œæµç¨‹ (main) - å¢å¼·ç‰ˆæœ¬\n",
        "# ==============================================================================\n",
        "async def main():\n",
        "    start_time = time.time()\n",
        "    report_time = format_timestamp()  # ä½¿ç”¨å°åŒ—æ™‚å€æ™‚é–“\n",
        "\n",
        "    logger.info(f\"==== ğŸ“ˆ é–‹å§‹åŸ·è¡Œå°è‚¡åˆ†æå·¥å…· (æ™‚é–“: {report_time}) ====\")\n",
        "\n",
        "    analyzer = StockAnalyzer()\n",
        "\n",
        "    # --- éšæ®µ 1: ç²å–è‚¡ç¥¨æ¸…å–® ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 1/5] ç²å–è‚¡ç¥¨æ¸…å–® ---\")\n",
        "    stocks_df = analyzer.get_taiwan_stocks()\n",
        "    if stocks_df.empty:\n",
        "        logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®ï¼Œç¨‹åºçµ‚æ­¢ã€‚\")\n",
        "        return\n",
        "    logger.info(f\"å…±ç²å– {len(stocks_df)} æ”¯è‚¡ç¥¨ã€‚\")\n",
        "\n",
        "    # --- éšæ®µ 2: é€ä¸€è™•ç†èˆ‡åˆ†æ ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 2/5] é€²è¡Œç¯©é¸ã€åˆ†æèˆ‡è©•åˆ† ---\")\n",
        "    all_results = []\n",
        "    failed_stocks = []\n",
        "    MIN_VOLUME = 1000 * 1000  # 1000å¼µ\n",
        "\n",
        "    for index, stock in stocks_df.iterrows():\n",
        "        stock_id = stock['stock_id']\n",
        "        yahoo_symbol = stock['yahoo_symbol']\n",
        "        logger.info(f\"--- è™•ç†ä¸­ ({index + 1}/{len(stocks_df)}): {stock_id} {stock['stock_name']} ---\")\n",
        "\n",
        "        try:\n",
        "            data_df = analyzer.fetch_yfinance_data_single_robust(yahoo_symbol, period='1y', interval='1d')\n",
        "            if data_df.empty or len(data_df) < 60:\n",
        "                logger.warning(f\"[{stock_id}] æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—ï¼Œè·³éã€‚\")\n",
        "                failed_stocks.append(stock_id)\n",
        "                continue\n",
        "\n",
        "            data_df = analyzer.standardize_columns(data_df.reset_index())\n",
        "\n",
        "            # Ensure Volume is numeric and handle missing/invalid data\n",
        "            if 'Volume' not in data_df.columns:\n",
        "                logger.info(f\"[{stock_id}] ç¼ºå°‘æˆäº¤é‡æ¬„ä½ï¼Œè·³éã€‚\")\n",
        "                failed_stocks.append(stock_id)\n",
        "                continue\n",
        "\n",
        "            # Convert Volume to numeric, coercing errors to NaN\n",
        "            data_df['Volume'] = pd.to_numeric(data_df['Volume'], errors='coerce')\n",
        "\n",
        "            # Check if recent volume data is sufficient and valid\n",
        "            recent_volume = data_df['Volume'].tail(15)\n",
        "            if recent_volume.empty or recent_volume.isna().all() or pd.isna(recent_volume.mean()) or recent_volume.mean() < MIN_VOLUME:\n",
        "                logger.info(f\"[{stock_id}] æœªé€šéæˆäº¤é‡ç¯©é¸ï¼Œè·³éã€‚\")\n",
        "                failed_stocks.append(stock_id)\n",
        "                continue\n",
        "\n",
        "            stock_info = {\n",
        "                'stock_id': stock_id, 'stock_name': stock['stock_name'],\n",
        "                'industry': stock['industry'], 'data': data_df\n",
        "            }\n",
        "            analysis_result = analyzer.analyze_stock(stock_info)\n",
        "\n",
        "            if analysis_result and analysis_result.get('success'):\n",
        "                all_results.append(analysis_result)\n",
        "                logger.info(f\"[{stock_id}] åˆ†æå®Œæˆï¼Œç¶œåˆè©•åˆ†: {analysis_result.get('combined_score')}\")\n",
        "            else:\n",
        "                logger.error(f\"å° {stock_id} çš„åˆ†æå¤±æ•—: {analysis_result.get('message', 'æœªçŸ¥éŒ¯èª¤')}\")\n",
        "                failed_stocks.append(stock_id)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç† {stock_id} æ™‚ç™¼ç”Ÿç•°å¸¸: {e}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            failed_stocks.append(stock_id)\n",
        "            continue\n",
        "\n",
        "   # --- éšæ®µ 3: é€²éšç¯©é¸èˆ‡å ±å‘Š ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 3/5] é€²è¡Œé€²éšç¯©é¸èˆ‡è¼¸å‡ºçµæœ ---\")\n",
        "    # é€™è£¡å®šç¾© final_results\n",
        "    final_results = [res for res in all_results if res.get('combined_score', 0) > 65 and res.get('recommendation', {}).get('action') == 'è²·å…¥']\n",
        "\n",
        "    # æŒ‰è©•åˆ†æ’åº - ç¢ºä¿å³ä½¿æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ï¼Œä¹Ÿæœ‰ä¸€å€‹ç©ºåˆ—è¡¨\n",
        "    sorted_results = sorted(final_results, key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "    final_results_dict = {res['stock_id']: res for res in final_results}\n",
        "    analyzer.print_advanced_filtered_stocks(final_results_dict, top_n=20)\n",
        "    # --- éšæ®µ 4: ç”Ÿæˆå€‹è‚¡åœ–è¡¨èˆ‡ç™¼é€é€šçŸ¥ ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 4/5] ç”Ÿæˆå€‹è‚¡åœ–è¡¨èˆ‡ç™¼é€é€šçŸ¥ ---\")\n",
        "    top_stocks_for_report = sorted_results[:5]  # å–å‰5å\n",
        "\n",
        "    if not top_stocks_for_report:\n",
        "        logger.warning(\"æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨å¯ä¾›å ±å‘Šã€‚\")\n",
        "        summary_message = f\"ğŸ“ˆ å°è‚¡åˆ†ææœ¬æ—¥ç²¾é¸ ğŸ“ˆ\\nâ° {report_time}\\n\\nä»Šæ—¥ç„¡ç‰¹åˆ¥äº®çœ¼æ¨™çš„ï¼Œå»ºè­°æŒçºŒè§€å¯Ÿå¸‚å ´ã€‚\"\n",
        "        await send_notification(summary_message)\n",
        "    else:\n",
        "        # ç™¼é€æ–‡å­—æ‘˜è¦\n",
        "        summary_lines = [f\"ğŸ“ˆ å°è‚¡åˆ†ææœ¬æ—¥ç²¾é¸ ğŸ“ˆ\", f\"â° {report_time}\", \"\"]\n",
        "        for i, stock in enumerate(top_stocks_for_report, 1):\n",
        "            rec = stock['recommendation']\n",
        "            summary_lines.append(\n",
        "                f\"{i}. *{stock['stock_id']} {stock['stock_name']}*\\n\"\n",
        "                f\"   è©•åˆ†: {stock['combined_score']:.0f} | \"\n",
        "                f\"å»ºè­°: *{rec['action']}* | \"\n",
        "                f\"ä¿¡å¿ƒåº¦: {rec.get('confidence', 0):.0f}%\"\n",
        "            )\n",
        "\n",
        "        summary_lines.append(f\"\\nğŸ“Š ç¸½è¨ˆ {len(final_results)} æ”¯ç¬¦åˆæ¢ä»¶è‚¡ç¥¨\")\n",
        "        summary_message = \"\\n\".join(summary_lines)\n",
        "\n",
        "        logger.info(\"æº–å‚™ç™¼é€æ‘˜è¦é€šçŸ¥...\")\n",
        "        await send_notification(summary_message)\n",
        "\n",
        "        # ç”Ÿæˆè©³ç´°å ±å‘Šæ–‡ä»¶\n",
        "        with open('stock_report.txt', 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"å°è‚¡åˆ†æè©³ç´°å ±å‘Š\\n\")\n",
        "            f.write(f\"å ±å‘Šæ™‚é–“: {report_time}\\n\")\n",
        "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "            original_stdout = sys.stdout\n",
        "            sys.stdout = f\n",
        "            analyzer.print_advanced_filtered_stocks(final_results_dict, top_n=10)\n",
        "            sys.stdout = original_stdout\n",
        "\n",
        "        # ç™¼é€å€‹è‚¡è©³ç´°åœ–è¡¨\n",
        "        logger.info(\"æº–å‚™ç™¼é€å€‹è‚¡è©³ç´°åœ–è¡¨...\")\n",
        "        for i, stock in enumerate(top_stocks_for_report, 1):\n",
        "            stock_id = stock['stock_id']\n",
        "            stock_name = stock['stock_name']\n",
        "            save_path = os.path.join(CHARTS_DIR, f\"{stock_id}_{stock_name}_report.png\")\n",
        "\n",
        "            chart_path = analyzer.generate_detailed_analysis_report(stock_id, stock_name, stock, save_path)\n",
        "\n",
        "            if chart_path:\n",
        "                caption = f\"ğŸ“Š {i}/5 - {stock_id} {stock_name}\\nè©•åˆ†: {stock['combined_score']:.0f}\"\n",
        "                await send_chart_files(chart_path, caption)\n",
        "                await asyncio.sleep(2)  # é¿å…ç™¼é€éå¿«\n",
        "\n",
        "   # --- éšæ®µ 5: ç”Ÿæˆä¸¦ç™¼é€æœ€çµ‚æ‘˜è¦åœ–è¡¨ ---\n",
        "    logger.info(\"\\n--- [éšæ®µ 5/5] ç”Ÿæˆæœ€çµ‚æ‘˜è¦åœ–è¡¨ ---\")\n",
        "    if final_results:\n",
        "        summary_chart_path = await generate_and_send_summary_chart(final_results, report_time)\n",
        "        stats_chart_path = await generate_and_send_statistics_chart(final_results, report_time)\n",
        "\n",
        "        # æ”¶é›†æ‰€æœ‰åœ–è¡¨è·¯å¾‘\n",
        "        all_chart_paths = []\n",
        "        if summary_chart_path:\n",
        "            all_chart_paths.append(summary_chart_path)\n",
        "        if 'stats_chart_path' in locals() and stats_chart_path:\n",
        "            all_chart_paths.append(stats_chart_path)\n",
        "\n",
        "    # ç™¼é€åŸ·è¡Œå®Œæˆé€šçŸ¥\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    completion_time = format_timestamp()\n",
        "\n",
        "    # ä½¿ç”¨ sorted_results è€Œä¸æ˜¯ final_resultsï¼Œä¸¦ç¢ºä¿å®ƒå·²å®šç¾©\n",
        "    # é€™è£¡æ˜¯é—œéµä¿®å¾©éƒ¨åˆ†\n",
        "    if 'sorted_results' in locals() and sorted_results:\n",
        "        completion_message = format_notification_message(sorted_results)\n",
        "    else:\n",
        "        completion_message = f\"\"\"\n",
        "ğŸ‰ **åˆ†æå®Œæˆé€šçŸ¥** ğŸ‰\n",
        "\n",
        "â° é–‹å§‹æ™‚é–“: {report_time}\n",
        "â° å®Œæˆæ™‚é–“: {completion_time}\n",
        "âŒ› åŸ·è¡Œæ™‚é•·: {execution_time:.1f} ç§’\n",
        "\n",
        "ğŸ“Š **åŸ·è¡Œçµæœ:**\n",
        "â€¢ ç¸½è™•ç†è‚¡ç¥¨: {len(stocks_df)} æ”¯\n",
        "â€¢ æˆåŠŸåˆ†æ: {len(all_results)} æ”¯\n",
        "â€¢ ç¬¦åˆæ¢ä»¶: 0 æ”¯\n",
        "â€¢ å¤±æ•—è‚¡ç¥¨: {len(failed_stocks)} æ”¯\n",
        "\n",
        "âš ï¸ æ²’æœ‰ç¬¦åˆç¯©é¸æ¢ä»¶çš„è‚¡ç¥¨ã€‚\n",
        "\"\"\"\n",
        "\n",
        "    # ç™¼é€æœ€çµ‚é€šçŸ¥\n",
        "    await send_notification(completion_message)\n",
        "\n",
        "    logger.info(f\"\\nğŸ‰ğŸ‰ğŸ‰ å…¨éƒ¨æµç¨‹åŸ·è¡Œå®Œç•¢ï¼\")\n",
        "    logger.info(f\"ğŸ“Š è™•ç†çµ±è¨ˆ: ç¸½è¨ˆ {len(stocks_df)} æ”¯ï¼ŒæˆåŠŸ {len(all_results)} æ”¯ï¼Œç¬¦åˆæ¢ä»¶ {len(final_results)} æ”¯\")\n",
        "    logger.info(f\"âŒ› ç¸½è€—æ™‚: {execution_time:.2f} ç§’\")\n",
        "    logger.info(f\"â° å®Œæˆæ™‚é–“: {completion_time}\")\n",
        "# ==============================================================================\n",
        "# ä¸»ç¨‹å¼å…¥å£é»\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # æª¢æŸ¥æ˜¯å¦åœ¨ Jupyter ç’°å¢ƒä¸­\n",
        "        in_jupyter = 'ipykernel' in sys.modules\n",
        "\n",
        "        if in_jupyter:\n",
        "            # Jupyter ç’°å¢ƒè™•ç†\n",
        "            loop = asyncio.get_event_loop()\n",
        "            if loop.is_running():\n",
        "                # å¦‚æœäº‹ä»¶å¾ªç’°æ­£åœ¨é‹è¡Œï¼Œå‰µå»ºä»»å‹™\n",
        "                task = loop.create_task(main())\n",
        "                logger.info(\"åœ¨ Jupyter ç’°å¢ƒä¸­å‰µå»ºç•°æ­¥ä»»å‹™\")\n",
        "            else:\n",
        "                # å¦‚æœäº‹ä»¶å¾ªç’°æœªé‹è¡Œï¼Œç›´æ¥åŸ·è¡Œ\n",
        "                loop.run_until_complete(main())\n",
        "        else:\n",
        "            # ä¸€èˆ¬ Python ç’°å¢ƒ\n",
        "            asyncio.run(main())\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"ç”¨æˆ¶ä¸­æ–·ç¨‹å¼åŸ·è¡Œ\")\n",
        "    except Exception as e:\n",
        "        error_time = format_timestamp()\n",
        "        logger.critical(f\"ç¨‹å¼åŸ·è¡Œæ™‚ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤ ({error_time}): {e}\")\n",
        "        logger.critical(traceback.format_exc())\n",
        "\n",
        "        # ç™¼é€éŒ¯èª¤é€šçŸ¥ï¼ˆå¦‚æœé€šè¨ŠåŠŸèƒ½å¯ç”¨ï¼‰\n",
        "        if 'MESSAGING_AVAILABLE' in globals() and MESSAGING_AVAILABLE:\n",
        "            try:\n",
        "                error_message = f\"\"\"\n",
        "âŒ **ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤** âŒ\n",
        "\n",
        "â° éŒ¯èª¤æ™‚é–“: {error_time}\n",
        "ğŸ éŒ¯èª¤è¨Šæ¯: {str(e)}\n",
        "\n",
        "è«‹æª¢æŸ¥æ—¥èªŒæª”æ¡ˆä»¥ç²å–è©³ç´°è³‡è¨Šã€‚\n",
        "                \"\"\".strip()\n",
        "                asyncio.run(send_notification(error_message))\n",
        "            except:\n",
        "                pass  # é¿å…é€šçŸ¥ç™¼é€å¤±æ•—å°è‡´ç¨‹å¼å´©æ½°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb8sxRURqZ49"
      },
      "source": [
        "å¯å‚³è¨Šä½†çµ‚ç«¯æ²’æœ‰é¡¯ç¾å‡ºå ±å‘Šï¼Œå‚³è¨Šæœ‰åœ–ç‰‡ä½†æœƒå»¶é²å‡ºç¾ï¼Œè»Ÿé«”è¦è·‘å¾ˆä¹…ã€‚discordèˆ‡telegram éƒ½æˆåŠŸï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BqQdXWUVGzfD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- åŸºç¤ Python æ¨™æº–åº« ---\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import platform\n",
        "import re\n",
        "from io import StringIO\n",
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "\n",
        "# --- æ•¸æ“šè™•ç†èˆ‡ç§‘å­¸è¨ˆç®— ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- ç¶²è·¯è«‹æ±‚ ---\n",
        "import requests\n",
        "import aiohttp # ç•°æ­¥è«‹æ±‚\n",
        "import asyncio # ç•°æ­¥æ¡†æ¶\n",
        "\n",
        "# --- é‡‘èæ•¸æ“šæº ---\n",
        "import yfinance as yf\n",
        "\n",
        "# --- æ•¸æ“šå¯è¦–åŒ– ---\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "import mplfinance as mpf\n",
        "# import chineseize_matplotlib # å»ºè­°ä½¿ç”¨ set_chinese_font() é€²è¡Œæ›´å¯æ§çš„è¨­å®š\n",
        "\n",
        "# --- é€šçŸ¥ç›¸é—œ ---\n",
        "import pytz\n",
        "from discord_webhook import DiscordWebhook\n",
        "\n",
        "# ==============================================\n",
        "# å…¨åŸŸè¨­å®šèˆ‡åˆå§‹åŒ–\n",
        "# ==============================================\n",
        "\n",
        "# --- ç›®éŒ„è¨­å®š ---\n",
        "CACHE_DIR = 'cache'\n",
        "RESULTS_DIR = 'results'\n",
        "CHARTS_DIR = os.path.join(RESULTS_DIR, 'charts')\n",
        "STOCK_LIST_PATH = os.path.join(CACHE_DIR, 'stock_list.csv')\n",
        "HISTORY_DATA_CACHE_DIR = os.path.join(CACHE_DIR, 'history_data')\n",
        "\n",
        "# --- åˆå§‹åŒ–ç›®éŒ„ ---\n",
        "for directory in [CACHE_DIR, RESULTS_DIR, CHARTS_DIR, HISTORY_DATA_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# --- é€šçŸ¥è¨­å®š (è«‹å¡«å…¥æ‚¨çš„é‡‘é‘°) ---\n",
        "# ==============================================================================\n",
        "# 9. é€šè¨Šèˆ‡é€šçŸ¥è¨­å®š\n",
        "# ==============================================================================\n",
        "# å»ºè­°å°‡ä¾†ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ– .env æª”æ¡ˆç®¡ç†å¯†é‘°ï¼Œä»¥ç­–å®‰å…¨\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]  # æ”¯æ´å¤šç”¨æˆ¶é€šçŸ¥\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "# --- æ—¥èªŒèˆ‡æ™‚å€è¨­å®š ---\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "try:\n",
        "    taipei_tz = pytz.timezone('Asia/Taipei')\n",
        "except pytz.UnknownTimeZoneError:\n",
        "    logger.error(\"æ™‚å€ 'Asia/Taipei' æ‰¾ä¸åˆ°ï¼Œè«‹ç¢ºä¿ pytz åº«å·²å®‰è£ä¸”æ•¸æ“šç‚ºæœ€æ–°ã€‚\")\n",
        "    taipei_tz = pytz.utc # é™ç´šä½¿ç”¨ UTC\n",
        "\n",
        "# ==============================================\n",
        "# è¼”åŠ©å‡½å¼èˆ‡ç’°å¢ƒè¨­å®š\n",
        "# ==============================================\n",
        "\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            font_name = 'Microsoft YaHei'\n",
        "        elif system == 'Darwin': # macOS\n",
        "            font_name = 'PingFang HK'\n",
        "        else: # Linux\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "            ]\n",
        "            found_font_path = next((path for path in font_paths if os.path.exists(path)), None)\n",
        "            if found_font_path:\n",
        "                font_manager.fontManager.addfont(found_font_path)\n",
        "                font_name = font_manager.FontProperties(fname=found_font_path).get_name()\n",
        "            else:\n",
        "                logger.warning(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                # ä½¿ç”¨ chineseize_matplotlib ä½œç‚ºå‚™æ´\n",
        "                import chineseize_matplotlib\n",
        "                logger.info(\"å•Ÿç”¨ chineseize_matplotlib ä½œç‚ºå‚™æ´å­—é«”æ–¹æ¡ˆã€‚\")\n",
        "                return\n",
        "\n",
        "        plt.rcParams['font.sans-serif'] = [font_name]\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "        if font_name:\n",
        "            logger.info(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# ==============================================\n",
        "# æ ¸å¿ƒåŠŸèƒ½å‡½å¼ (è³‡æ–™ç²å–ã€åˆ†æã€è©•åˆ†)\n",
        "# ==============================================\n",
        "\n",
        "def get_taiwan_stocks(cache_path=STOCK_LIST_PATH, force_update=False):\n",
        "    if not force_update and os.path.exists(cache_path) and (time.time() - os.path.getmtime(cache_path)) < 86400:\n",
        "        try:\n",
        "            df = pd.read_csv(cache_path, dtype={'stock_id': str})\n",
        "            if not df.empty and 'yahoo_symbol' in df.columns:\n",
        "                print(f\"âœ… å¾å¿«å–è¼‰å…¥ {len(df)} æ”¯è‚¡ç¥¨æ¸…å–®ã€‚\")\n",
        "                return df\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ è¼‰å…¥è‚¡ç¥¨æ¸…å–®å¿«å–å¤±æ•—: {e}ã€‚\")\n",
        "\n",
        "    print(\"ğŸŒ æ­£åœ¨ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–® (å¾è­‰äº¤æ‰€)...\")\n",
        "    try:\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        for market, url in urls.items():\n",
        "            response = requests.get(url, timeout=20)\n",
        "            df = pd.read_html(StringIO(response.text))[0]\n",
        "            df.columns = df.iloc[0]\n",
        "            df = df.iloc[1:].dropna(thresh=3, axis=0)\n",
        "            df['å¸‚å ´åˆ¥'] = market\n",
        "            all_stocks_df.append(df)\n",
        "\n",
        "        df_combined = pd.concat(all_stocks_df, ignore_index=True)\n",
        "        df_combined.columns = ['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±', 'åœ‹éš›è­‰åˆ¸è­˜åˆ¥ç¢¼', 'ä¸Šå¸‚æ—¥', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'CFI', 'å‚™è¨»']\n",
        "        df_combined[['stock_id', 'stock_name']] = df_combined['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', n=1, expand=True)\n",
        "        df_combined['stock_id'] = df_combined['stock_id'].str.strip()\n",
        "        df_combined['stock_name'] = df_combined['stock_name'].str.strip()\n",
        "        df_stocks = df_combined[df_combined['stock_id'].str.match(r'^\\d{4}$')].copy()\n",
        "        exclude_keywords = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š']\n",
        "        df_stocks = df_stocks[~df_stocks['stock_name'].str.contains('|'.join(exclude_keywords), na=False)]\n",
        "        df_stocks['yahoo_symbol'] = df_stocks.apply(\n",
        "            lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['å¸‚å ´åˆ¥'] else f\"{row['stock_id']}.TWO\",\n",
        "            axis=1\n",
        "        )\n",
        "        final_df = df_stocks[['stock_id', 'stock_name', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "        final_df.rename(columns={'å¸‚å ´åˆ¥': 'market', 'ç”¢æ¥­åˆ¥': 'industry'}, inplace=True)\n",
        "        final_df.to_csv(cache_path, index=False)\n",
        "        print(f\"âœ… æˆåŠŸå¾è­‰äº¤æ‰€ç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜ã€‚\")\n",
        "        return final_df\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å¾è­‰äº¤æ‰€ç²å–è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        if os.path.exists(cache_path):\n",
        "            print(\"â— é™ç´šä½¿ç”¨èˆŠçš„å¿«å–è‚¡ç¥¨æ¸…å–®ã€‚\")\n",
        "            return pd.read_csv(cache_path, dtype={'stock_id': str})\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def get_stock_basic_info(force_update=False):\n",
        "    stocks_df = get_taiwan_stocks(force_update=force_update)\n",
        "    if stocks_df.empty: return {}\n",
        "    return {str(row['stock_id']): row.to_dict() for _, row in stocks_df.iterrows()}\n",
        "\n",
        "# ***** é—œéµä¿®æ­£å‡½å¼ *****\n",
        "def fetch_stock_data(stock_id, yahoo_symbol, period='1y', force_update=False, retries=3, delay=2, cache_dir=HISTORY_DATA_CACHE_DIR):\n",
        "    \"\"\"ä¸‹è¼‰è‚¡åƒ¹æ•¸æ“šï¼Œå¢åŠ å° MultiIndex æ¬„ä½çš„è™•ç†ã€‚\"\"\"\n",
        "    formatted_id = str(stock_id)\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    cache_path = os.path.join(cache_dir, f\"{formatted_id}.json\")\n",
        "\n",
        "    if not force_update and os.path.exists(cache_path) and (time.time() - os.path.getmtime(cache_path)) < 86400:\n",
        "        try:\n",
        "            with open(cache_path, 'r', encoding='utf-8') as f:\n",
        "                return json.load(f)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            temp_df = yf.download(yahoo_symbol, period=period, progress=False, auto_adjust=True)\n",
        "\n",
        "            if temp_df.empty:\n",
        "                print(f\"âš ï¸ {yahoo_symbol} åœ¨æ­¤æœŸé–“ç„¡æ•¸æ“šã€‚\")\n",
        "                return None\n",
        "\n",
        "            # --- START OF THE FIX ---\n",
        "            # æª¢æŸ¥ä¸¦è™•ç† yfinance å¯èƒ½è¿”å›çš„å¤šé‡ç´¢å¼• (MultiIndex) åˆ—æ¨™é ­\n",
        "            if isinstance(temp_df.columns, pd.MultiIndex):\n",
        "                # å°‡å¤šé‡ç´¢å¼• 'flatten' ç‚ºå–®å±¤ç´¢å¼•\n",
        "                temp_df.columns = temp_df.columns.get_level_values(0)\n",
        "            # --- END OF THE FIX ---\n",
        "\n",
        "            df = temp_df.reset_index()\n",
        "            df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "            result = {\n",
        "                'data': df.to_dict('records'),\n",
        "                'stock_id': formatted_id,\n",
        "                'yahoo_symbol': yahoo_symbol,\n",
        "                'last_price': df['Close'].iloc[-1] if not df.empty else 0\n",
        "            }\n",
        "            with open(cache_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                # åœ¨æ­¤è™•å°å‡ºéŒ¯èª¤ï¼Œè®“ä¸»æµç¨‹çŸ¥é“ç™¼ç”Ÿäº†ä»€éº¼\n",
        "                print(f\"ä¸‹è¼‰ {yahoo_symbol} å¤±æ•—: {e}\")\n",
        "    return None\n",
        "\n",
        "def fetch_multiple_stocks_data(stocks_info, period='1y', force_update=False):\n",
        "    results = {}\n",
        "    stocks_list = list(stocks_info.values())\n",
        "    total_stocks = len(stocks_list)\n",
        "\n",
        "    for idx, stock in enumerate(stocks_list):\n",
        "        stock_id = str(stock.get('stock_id'))\n",
        "        stock_name = stock.get('stock_name', 'N/A')\n",
        "        yahoo_symbol = stock.get('yahoo_symbol')\n",
        "\n",
        "        if not yahoo_symbol:\n",
        "            print(f\"âš ï¸ è‚¡ç¥¨ {stock_id} {stock_name} ç¼ºå°‘ 'yahoo_symbol'ï¼Œè·³éã€‚\")\n",
        "            continue\n",
        "\n",
        "        print(f\"[{idx+1}/{total_stocks}] æ­£åœ¨ç²å–: {stock_id} {stock_name}...\")\n",
        "        stock_data = fetch_stock_data(\n",
        "            stock_id=stock_id,\n",
        "            yahoo_symbol=yahoo_symbol,\n",
        "            period=period,\n",
        "            force_update=force_update\n",
        "        )\n",
        "\n",
        "        if stock_data and 'data' in stock_data and stock_data['data']:\n",
        "            stock_data.update(stock) # å°‡è‚¡ç¥¨åŸºæœ¬è³‡æ–™åˆä½µé€²å»\n",
        "            results[stock_id] = stock_data\n",
        "\n",
        "    print(f\"\\nè™•ç†å®Œæˆï¼Œå…±ç²å– {len(results)}/{total_stocks} æ”¯è‚¡ç¥¨çš„æ•¸æ“šã€‚\")\n",
        "    return results\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# å‡è¨­æ‚¨çš„ç¨‹å¼ä¸­å·²ç¶“è¨­å®šäº† logger\n",
        "# å¦‚æœæ²’æœ‰ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢é€™è¡Œçš„è¨»è§£\n",
        "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def fetch_stock_history(stock_id, period='1y', retries=3, delay=5):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨ yfinance ç²å–æŒ‡å®šè‚¡ç¥¨çš„æ­·å²æ•¸æ“šï¼Œä¸¦è™•ç†å°ç£å¸‚å ´çš„è‚¡ç¥¨ä»£è™Ÿã€‚\n",
        "\n",
        "    åƒæ•¸:\n",
        "    stock_id (str): è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚ '2330')\n",
        "    period (str): æ•¸æ“šæœŸé–“ (ä¾‹å¦‚ '1y', '2y', 'max')\n",
        "    retries (int): ä¸‹è¼‰å¤±æ•—æ™‚çš„é‡è©¦æ¬¡æ•¸\n",
        "    delay (int): é‡è©¦å‰çš„å»¶é²ç§’æ•¸\n",
        "\n",
        "    è¿”å›:\n",
        "    pandas.DataFrame or None: åŒ…å« OHLCV æ•¸æ“šçš„ DataFrameï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› None\n",
        "    \"\"\"\n",
        "    # æ ¹æ“šè‚¡ç¥¨ä»£è™Ÿæ ¼å¼åˆ¤æ–·å¸‚å ´\n",
        "    # å°æ–¼æ•¸å­—ä»£è™Ÿï¼Œå„ªå…ˆå˜—è©¦ .TW (ä¸Šå¸‚)ï¼Œå¤±æ•—å‰‡å˜—è©¦ .TWO (ä¸Šæ«ƒ)\n",
        "    # å°æ–¼éæ•¸å­—ä»£è™Ÿ (å¦‚ ETF)ï¼Œç›´æ¥ä½¿ç”¨ .TW\n",
        "    ticker_symbol_tw = f\"{stock_id}.TW\"\n",
        "    ticker_symbol_two = f\"{stock_id}.TWO\"\n",
        "\n",
        "    # ç¢ºå®šè¦å˜—è©¦çš„è‚¡ç¥¨ä»£è™Ÿåˆ—è¡¨\n",
        "    symbols_to_try = [ticker_symbol_tw]\n",
        "    if stock_id.isdigit():\n",
        "        symbols_to_try.append(ticker_symbol_two)\n",
        "\n",
        "    for symbol in symbols_to_try:\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                stock = yf.Ticker(symbol)\n",
        "                data = stock.history(period=period, auto_adjust=False) # ä½¿ç”¨ auto_adjust=False ä¿ç•™åŸå§‹OHLC\n",
        "\n",
        "                if not data.empty:\n",
        "                    # è½‰æ›ç‚ºå°ç£æ™‚å€ä¸¦é‡è¨­ç´¢å¼•\n",
        "                    if data.index.tz is None:\n",
        "                        data = data.tz_localize('UTC').tz_convert('Asia/Taipei')\n",
        "                    else:\n",
        "                        data = data.tz_convert('Asia/Taipei')\n",
        "\n",
        "                    data = data.reset_index()\n",
        "\n",
        "                    # å°‡ 'Date' æˆ– 'Datetime' åˆ—çš„æ™‚å€è³‡è¨Šç§»é™¤ï¼Œä»¥æ–¹ä¾¿å¾ŒçºŒè™•ç†\n",
        "                    date_col = 'Date' if 'Date' in data.columns else 'Datetime'\n",
        "                    if date_col in data.columns:\n",
        "                        data[date_col] = data[date_col].dt.tz_localize(None)\n",
        "\n",
        "                    # æ›´æ”¹æ¬„ä½åç¨±ä»¥ç¬¦åˆç¿’æ…£\n",
        "                    data.rename(columns={\n",
        "                        date_col: 'date',\n",
        "                        'Open': 'open',\n",
        "                        'High': 'high',\n",
        "                        'Low': 'low',\n",
        "                        'Close': 'close',\n",
        "                        'Volume': 'volume'\n",
        "                    }, inplace=True)\n",
        "\n",
        "                    # ç§»é™¤ä¸éœ€è¦çš„æ¬„ä½\n",
        "                    cols_to_drop = ['Dividends', 'Stock Splits']\n",
        "                    data = data.drop(columns=[col for col in cols_to_drop if col in data.columns])\n",
        "\n",
        "                    logger.info(f\"âœ… æˆåŠŸç²å– {symbol} çš„æ­·å²æ•¸æ“šã€‚\")\n",
        "                    return data\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ä¸‹è¼‰ {symbol} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ (ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦): {e}\")\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(delay)\n",
        "                else:\n",
        "                    logger.error(f\"é‡è©¦ {retries} æ¬¡å¾Œï¼Œä»ç„¡æ³•ä¸‹è¼‰ {symbol} çš„æ•¸æ“šã€‚\")\n",
        "\n",
        "    logger.warning(f\"æœ€çµ‚ç„¡æ³•ç²å–è‚¡ç¥¨ {stock_id} çš„ä»»ä½•æ­·å²æ•¸æ“šã€‚\")\n",
        "    return None\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    if df.empty or 'Close' not in df.columns: return df\n",
        "    result = df.copy()\n",
        "    for days in [5, 10, 20, 60]: result[f'MA{days}'] = result['Close'].rolling(window=days).mean()\n",
        "    delta = result['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0); loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean(); avg_loss = loss.rolling(window=14).mean()\n",
        "    rs = avg_gain / (avg_loss + 1e-9); result['RSI'] = 100 - (100 / (1 + rs))\n",
        "    exp1 = result['Close'].ewm(span=12, adjust=False).mean(); exp2 = result['Close'].ewm(span=26, adjust=False).mean()\n",
        "    result['MACD'] = exp1 - exp2; result['Signal'] = result['MACD'].ewm(span=9, adjust=False).mean()\n",
        "    result['Histogram'] = result['MACD'] - result['Signal']\n",
        "    low_min = result['Low'].rolling(window=14).min(); high_max = result['High'].rolling(window=14).max()\n",
        "    result['K'] = 100 * ((result['Close'] - low_min) / (high_max - low_min + 1e-9))\n",
        "    result['D'] = result['K'].rolling(window=3).mean()\n",
        "    return result.fillna(0)\n",
        "\n",
        "def analyze_stock(stock_id, stock_data):\n",
        "    if not stock_data or not stock_data.get('data'):\n",
        "        return {'success': False, 'message': \"ç„¡æ•ˆæ•¸æ“š\"}\n",
        "    df = pd.DataFrame(stock_data['data'])\n",
        "    if len(df) < 60: return {'success': False, 'message': \"æ•¸æ“šä¸è¶³\"}\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df['Date']); df.set_index('Date', inplace=True)\n",
        "    df_with_indicators = add_technical_indicators(df)\n",
        "\n",
        "    price_change_1m = ((df['Close'].iloc[-1] / df['Close'].iloc[-22]) - 1) * 100 if len(df) > 21 else 0\n",
        "\n",
        "    return {\n",
        "        'stock_id': stock_id,\n",
        "        'stock_name': stock_data.get('stock_name', 'N/A'),\n",
        "        'last_price': stock_data.get('last_price', 0),\n",
        "        'price_change': {'1m': price_change_1m},\n",
        "        'data_df': df_with_indicators,\n",
        "        'success': True\n",
        "    }\n",
        "\n",
        "def calculate_comprehensive_score(analysis_result):\n",
        "    scores = {'trend_score': 50, 'momentum_score': 50, 'volume_score': 50}\n",
        "    df = analysis_result.get('data_df')\n",
        "    if df is None or df.empty or len(df) < 60: return scores, 50\n",
        "\n",
        "    if df['MA5'].iloc[-1] > df['MA10'].iloc[-1] > df['MA20'].iloc[-1] > df['MA60'].iloc[-1]:\n",
        "        scores['trend_score'] = 85\n",
        "    else: scores['trend_score'] = 20\n",
        "\n",
        "    momentum_points = 50\n",
        "    if df['RSI'].iloc[-1] > 60: momentum_points += 15\n",
        "    if df['MACD'].iloc[-1] > df['Signal'].iloc[-1]: momentum_points += 20\n",
        "    if df['K'].iloc[-1] > df['D'].iloc[-1]: momentum_points += 15\n",
        "    scores['momentum_score'] = max(0, min(100, momentum_points))\n",
        "\n",
        "    if df['Volume'].iloc[-1] > df['Volume'].rolling(window=20).mean().iloc[-1] * 1.5:\n",
        "        scores['volume_score'] = 80\n",
        "\n",
        "    final_score = scores['trend_score'] * 0.4 + scores['momentum_score'] * 0.45 + scores['volume_score'] * 0.15\n",
        "    return scores, final_score\n",
        "\n",
        "def generate_recommendation(score):\n",
        "    if score >= 75: return 'å¼·åŠ›è²·å…¥'\n",
        "    if score >= 60: return 'è²·å…¥'\n",
        "    if score >= 40: return 'æŒæœ‰'\n",
        "    if score >= 25: return 'è§€æœ›'\n",
        "    return 'è³£å‡º'\n",
        "\n",
        "\n",
        "\n",
        "import mplfinance as mpf\n",
        "print(f\"mplfinance ç‰ˆæœ¬: {mpf.__version__}\")\n",
        "\n",
        "def generate_detailed_analysis_report(stock_id, stock_name, stock_data, save_path=None):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆå–®ä¸€è‚¡ç¥¨çš„è©³ç´°åˆ†æåœ–è¡¨ (ä¿®æ­£ç‰ˆ)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. ç²å–åŒ…å«å®Œæ•´æŒ‡æ¨™çš„ DataFrame ä¸¦è¼¸å‡ºè©³ç´°è¨ºæ–·è³‡è¨Š\n",
        "        logger.info(f\"é–‹å§‹ç‚º {stock_id} {stock_name} ç”Ÿæˆåœ–è¡¨...\")\n",
        "\n",
        "        # æª¢æŸ¥ stock_data çš„çµæ§‹\n",
        "        if not isinstance(stock_data, dict):\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): stock_data ä¸æ˜¯å­—å…¸é¡å‹ï¼Œè€Œæ˜¯ {type(stock_data)}\")\n",
        "            return\n",
        "\n",
        "        # æª¢æŸ¥ data_df æ˜¯å¦å­˜åœ¨\n",
        "        if 'data_df' not in stock_data:\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): stock_data ä¸­ç¼ºå°‘ 'data_df' éµã€‚å¯ç”¨çš„éµ: {list(stock_data.keys())}\")\n",
        "            return\n",
        "\n",
        "        df_with_indicators = stock_data.get('data_df')\n",
        "\n",
        "        # æª¢æŸ¥ df_with_indicators æ˜¯å¦ç‚º DataFrame\n",
        "        if not isinstance(df_with_indicators, pd.DataFrame):\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): data_df ä¸æ˜¯ DataFrameï¼Œè€Œæ˜¯ {type(df_with_indicators)}\")\n",
        "            return\n",
        "\n",
        "        if df_with_indicators is None or df_with_indicators.empty:\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): data_df ç‚ºç©ºæˆ– None\")\n",
        "            return\n",
        "\n",
        "        # è¼¸å‡º DataFrame çš„åŸºæœ¬è³‡è¨Š\n",
        "        logger.info(f\"DataFrame è³‡è¨Š: è¡Œæ•¸={len(df_with_indicators)}, åˆ—æ•¸={len(df_with_indicators.columns)}\")\n",
        "        logger.info(f\"DataFrame åˆ—å: {list(df_with_indicators.columns)}\")\n",
        "\n",
        "        # æª¢æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨\n",
        "        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'MA5', 'MA20', 'MACD', 'Signal', 'Histogram', 'RSI']\n",
        "        missing_cols = [col for col in required_cols if col not in df_with_indicators.columns]\n",
        "        if missing_cols:\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}\")\n",
        "            return\n",
        "\n",
        "        # 2. æˆªå–æœ€è¿‘ 120 å¤©çš„æ•¸æ“šç”¨æ–¼ç¹ªåœ–ï¼Œä½¿ç”¨ .copy() é¿å…è­¦å‘Š\n",
        "        df_plot = df_with_indicators.tail(120).copy()\n",
        "        logger.info(f\"æˆªå–å¾Œçš„ DataFrame è¡Œæ•¸: {len(df_plot)}\")\n",
        "\n",
        "        if len(df_plot) < 20: # ç¢ºä¿æœ‰è¶³å¤ æ•¸æ“šç¹ªè£½æŒ‡æ¨™\n",
        "            logger.warning(f\"ç¹ªè£½åœ–è¡¨å¤±æ•—({stock_id}): æœ‰æ•ˆæ•¸æ“šä¸è¶³ (<20)ã€‚\")\n",
        "            return\n",
        "\n",
        "        # 3. æª¢æŸ¥æ˜¯å¦æœ‰ NaN å€¼\n",
        "        nan_counts = df_plot.isna().sum()\n",
        "        if nan_counts.sum() > 0:\n",
        "            logger.warning(f\"DataFrame ä¸­å­˜åœ¨ NaN å€¼: {nan_counts[nan_counts > 0]}\")\n",
        "            # å¡«å…… NaN å€¼ï¼Œé¿å…ç¹ªåœ–éŒ¯èª¤\n",
        "            df_plot = df_plot.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "        # 4. æª¢æŸ¥ DataFrame çš„ç´¢å¼•é¡å‹ - ç§»åˆ°é€™è£¡ï¼Œç¢ºä¿ df_plot å·²ç¶“å®šç¾©\n",
        "        if not isinstance(df_plot.index, pd.DatetimeIndex):\n",
        "            logger.warning(f\"DataFrame ç´¢å¼•ä¸æ˜¯ DatetimeIndexï¼Œå˜—è©¦è½‰æ›...\")\n",
        "            try:\n",
        "                # å¦‚æœ 'Date' æ˜¯åˆ—è€Œä¸æ˜¯ç´¢å¼•\n",
        "                if 'Date' in df_plot.columns:\n",
        "                    df_plot.set_index('Date', inplace=True)\n",
        "                # å˜—è©¦å°‡ç¾æœ‰ç´¢å¼•è½‰æ›ç‚º DatetimeIndex\n",
        "                df_plot.index = pd.to_datetime(df_plot.index)\n",
        "                logger.info(\"ç´¢å¼•è½‰æ›æˆåŠŸ\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"è½‰æ›ç´¢å¼•å¤±æ•—: {e}\")\n",
        "                # å¦‚æœè½‰æ›å¤±æ•—ï¼Œå˜—è©¦å‰µå»ºä¸€å€‹å‡çš„æ—¥æœŸç´¢å¼•\n",
        "                logger.info(\"å˜—è©¦å‰µå»ºå‡çš„æ—¥æœŸç´¢å¼•...\")\n",
        "                df_plot.index = pd.date_range(start='2023-01-01', periods=len(df_plot))\n",
        "                logger.info(\"å‰µå»ºå‡çš„æ—¥æœŸç´¢å¼•æˆåŠŸ\")\n",
        "\n",
        "        # 5. ä¿®æ­£æ¨£å¼è¨­å®šï¼šä½¿ç”¨ 'gridstyle' è€Œä¸æ˜¯ 'gridwidth'\n",
        "        mc = mpf.make_marketcolors(up='r', down='g', inherit=True)\n",
        "        s = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=mc, gridstyle='--')\n",
        "\n",
        "        # 6. å¾æˆªå–å¾Œçš„ df_plot å‰µå»ºé™„åŠ åœ–ï¼Œç¢ºä¿æ‰€æœ‰æ•¸æ“šé•·åº¦ä¸€è‡´\n",
        "        logger.info(\"é–‹å§‹å‰µå»ºé™„åŠ åœ–...\")\n",
        "        try:\n",
        "            apds = [\n",
        "                mpf.make_addplot(df_plot['MA5'], color='orange', width=0.7),\n",
        "                mpf.make_addplot(df_plot['MA20'], color='blue', width=0.7),\n",
        "                mpf.make_addplot(df_plot['Histogram'], type='bar', panel=1, color='grey', alpha=0.5),\n",
        "                mpf.make_addplot(df_plot[['MACD', 'Signal']], panel=1),\n",
        "                mpf.make_addplot(df_plot['RSI'], panel=2),\n",
        "            ]\n",
        "            logger.info(\"é™„åŠ åœ–å‰µå»ºæˆåŠŸ\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å‰µå»ºé™„åŠ åœ–æ™‚å‡ºéŒ¯: {e}\")\n",
        "            # å˜—è©¦ç°¡åŒ–é™„åŠ åœ–\n",
        "            try:\n",
        "                logger.info(\"å˜—è©¦ç°¡åŒ–é™„åŠ åœ–...\")\n",
        "                apds = [mpf.make_addplot(df_plot['MA5'], color='orange')]\n",
        "                logger.info(\"ç°¡åŒ–é™„åŠ åœ–å‰µå»ºæˆåŠŸ\")\n",
        "            except Exception as e2:\n",
        "                logger.error(f\"å‰µå»ºç°¡åŒ–é™„åŠ åœ–ä¹Ÿå¤±æ•—: {e2}\")\n",
        "                apds = []\n",
        "\n",
        "        # 7. è¨­å®šåœ–è¡¨æ¨™é¡Œèˆ‡å„²å­˜è·¯å¾‘\n",
        "        title = f\"{stock_id} {stock_name} (Score: {int(round(stock_data.get('combined_score', 0)))})\"\n",
        "        if not save_path:\n",
        "            save_path = os.path.join(CHARTS_DIR, f\"{stock_id}_report.png\")\n",
        "\n",
        "        logger.info(f\"æº–å‚™ç¹ªè£½åœ–è¡¨ï¼Œå„²å­˜è‡³: {save_path}\")\n",
        "\n",
        "        # 8. ç¹ªè£½åœ–è¡¨\n",
        "        try:\n",
        "            mpf.plot(\n",
        "                df_plot,\n",
        "                type='candle',\n",
        "                style=s,\n",
        "                title=title,\n",
        "                volume=True,\n",
        "                addplot=apds,\n",
        "                panel_ratios=(6, 2, 2), # (ä¸»åœ–, MACDé¢æ¿, RSIé¢æ¿)\n",
        "                figsize=(16, 9),\n",
        "                savefig=dict(fname=save_path, dpi=150)\n",
        "            )\n",
        "            logger.info(f\"âœ… åœ–è¡¨ç¹ªè£½æˆåŠŸä¸¦å„²å­˜è‡³: {save_path}\")\n",
        "        except Exception as plot_error:\n",
        "            logger.error(f\"ç¹ªè£½åœ–è¡¨æ™‚å‡ºéŒ¯: {plot_error}\")\n",
        "            # å˜—è©¦æœ€ç°¡å–®çš„ç¹ªåœ–æ–¹å¼\n",
        "            try:\n",
        "                logger.info(\"å˜—è©¦æœ€ç°¡å–®çš„ç¹ªåœ–æ–¹å¼...\")\n",
        "                plt.figure(figsize=(16, 9))\n",
        "                plt.title(title)\n",
        "                plt.plot(df_plot['Close'], label='Close')\n",
        "                plt.savefig(save_path, dpi=150)\n",
        "                logger.info(f\"âœ… ç°¡åŒ–åœ–è¡¨ç¹ªè£½æˆåŠŸä¸¦å„²å­˜è‡³: {save_path}\")\n",
        "            except Exception as simple_plot_error:\n",
        "                logger.error(f\"ç°¡åŒ–ç¹ªåœ–ä¹Ÿå¤±æ•—: {simple_plot_error}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç‚º {stock_id} ç¹ªè£½åœ–è¡¨æ™‚ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤: {e}\")\n",
        "        logger.error(traceback.format_exc())  # è¼¸å‡ºå®Œæ•´çš„å †ç–Šè¿½è¹¤\n",
        "    finally:\n",
        "        # 9. ç¢ºä¿é—œé–‰åœ–è¡¨ï¼Œé‡‹æ”¾è¨˜æ†¶é«”ï¼Œé¿å…åœ¨å¤§é‡è¿´åœˆä¸­è€—ç›¡è³‡æº\n",
        "        plt.close('all')\n",
        "\n",
        "# ==============================================\n",
        "# ä½¿ç”¨è€…ä»‹é¢ (UI) ç›¸é—œå‡½å¼\n",
        "# ==============================================\n",
        "\n",
        "def input_stock_ids():\n",
        "    while True:\n",
        "        user_input = input(\"\\nè«‹è¼¸å…¥æ¬²åˆ†æçš„4ä½å°è‚¡è‚¡ç¥¨ä»£ç¢¼ï¼ˆç”¨é€—è™Ÿæˆ–ç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚ 2330,2303 2603ï¼‰ï¼š\\n> \")\n",
        "        stock_ids = re.findall(r'\\b\\d{4}\\b', user_input)\n",
        "        if stock_ids:\n",
        "            print(f\"å·²è­˜åˆ¥è‚¡ç¥¨ä»£ç¢¼: {', '.join(stock_ids)}\")\n",
        "            return list(dict.fromkeys(stock_ids))\n",
        "        print(\"â— è¼¸å…¥æ ¼å¼éŒ¯èª¤æˆ–æœªåŒ…å«æœ‰æ•ˆçš„4ä½æ•¸ä»£ç¢¼ï¼Œè«‹é‡æ–°è¼¸å…¥ï¼\")\n",
        "\n",
        "def filter_by_volume(stock_data, min_volume_shares=1000000, days=22):\n",
        "    filtered = {}\n",
        "    print(f\"\\né€²è¡Œæˆäº¤é‡éæ¿¾ (è¿‘{days}æ—¥æˆäº¤é‡ > {min_volume_shares/1000:,.0f} å¼µ)...\")\n",
        "    for stock_id, data in stock_data.items():\n",
        "        if not data or 'data' not in data: continue\n",
        "        df = pd.DataFrame(data['data'])\n",
        "        if len(df) >= days and (df['Volume'].tail(days) >= min_volume_shares).all():\n",
        "            filtered[stock_id] = data\n",
        "    print(f\"æˆäº¤é‡éæ¿¾å¾Œï¼Œå‰©ä¸‹ {len(filtered)} / {len(stock_data)} æ”¯è‚¡ç¥¨ã€‚\")\n",
        "    return filtered\n",
        "\n",
        "def top_percentile_filter(results, score_key='combined_score', percentile=98):\n",
        "    if not results: return {}\n",
        "    all_scores = [r.get(score_key, 0) for r in results.values()]\n",
        "    if not all_scores: return {}\n",
        "    threshold = np.percentile(all_scores, percentile)\n",
        "    print(f\"\\né€²è¡Œé ‚å°–ç¯©é¸ (åˆ†æ•¸éœ€ >= {threshold:.0f}ï¼Œå³å‰ {100-percentile}%)\")\n",
        "    filtered = {sid: r for sid, r in results.items() if r.get(score_key, 0) >= threshold}\n",
        "    print(f\"é ‚å°–ç¯©é¸å¾Œï¼Œå‰©ä¸‹ {len(filtered)} / {len(results)} æ”¯è‚¡ç¥¨ã€‚\")\n",
        "    return filtered\n",
        "\n",
        "def print_top_stocks(results, top_n=10):\n",
        "    sorted_stocks = sorted(results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)[:top_n]\n",
        "    print(\"\\n\" + \"=\"*60); print(\"ğŸ†\" * 8 + \" å‰ååç¸¾å„ªè‚¡åˆ—è¡¨ \" + \"ğŸ†\" * 8); print(\"=\"*60)\n",
        "    print(f\"{'æ’å':<4}{'ä»£ç¢¼':<6}{'åç¨±':<12}{'åˆ†æ•¸':<6}{'åƒ¹æ ¼':<8}{'æœˆæ¼²å¹…(%)':<10}{'å»ºè­°':<8}\")\n",
        "    print(\"-\" * 60)\n",
        "    for i, stock in enumerate(sorted_stocks, 1):\n",
        "        print(f\"{i:<4}{stock.get('stock_id',''):<6}{stock.get('stock_name',''):<12}\"\n",
        "              f\"{int(round(stock.get('combined_score', 0))):<6}\"\n",
        "              f\"{int(round(stock.get('last_price', 0))):<8}\"\n",
        "              f\"{int(round(stock.get('price_change',{}).get('1m',0))):<10}\"\n",
        "              f\"{stock.get('recommendation',''):<8}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸\n",
        "# ==============================================================================\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "    if not files:\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        if os.path.exists(chart_dir):\n",
        "            # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "            files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                    if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            if files:\n",
        "                logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "            else:\n",
        "                logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                if response.status == 200:\n",
        "                    logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                else:\n",
        "                    response_text = await response.text()\n",
        "                    logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                sent_count = 0\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            data = aiohttp.FormData()\n",
        "                            data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                            # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                            caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                            data.add_field('caption', caption)\n",
        "\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                    if response.status == 200:\n",
        "                                        sent_count += 1\n",
        "                                    else:\n",
        "                                        response_text = await response.text()\n",
        "                                        logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                            # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                            await asyncio.sleep(0.5)\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "        message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "        for chunk in message_chunks:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response and response.ok:\n",
        "                logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                content = response.content if response else \"æœªçŸ¥\"\n",
        "                logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "        # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "        if files:\n",
        "            batch_size = 10\n",
        "            for i in range(0, len(files), batch_size):\n",
        "                batch_files = files[i:i+batch_size]\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                for file_path in batch_files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        # ç²å–åœ–è¡¨æª”æ¡ˆæ•¸é‡\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        chart_count = 0\n",
        "        if os.path.exists(chart_dir):\n",
        "            chart_files = [f for f in os.listdir(chart_dir) if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            chart_count = len(chart_files)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ“Š ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ“ˆ TOP {min(5, len(filtered_results))} æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            # ç²å–æ›´å¤šæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\n",
        "            macd = tech.get('macd_value', 0)\n",
        "            signal = tech.get('signal_value', 0)\n",
        "            macd_status = \"å¤šé ­\" if macd > signal else \"ç©ºé ­\" if macd < signal else \"ä¸­æ€§\"\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_status', 'ä¸­æ€§')})\n",
        "   ğŸ“‰ MACD: {macd_status}\n",
        "\"\"\"\n",
        "\n",
        "        # æ·»åŠ åœ–è¡¨è³‡è¨Š\n",
        "        if chart_count > 0:\n",
        "            message += f\"\"\"\n",
        "ğŸ“Š è©³ç´°åˆ†æåœ–è¡¨:\n",
        "â€¢ å·²ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "â€¢ åœ–è¡¨åŒ…å«Kç·šã€å‡ç·šã€æˆäº¤é‡ã€MACDåŠRSIæŒ‡æ¨™\n",
        "â€¢ åœ–è¡¨å°‡åœ¨æ­¤è¨Šæ¯å¾Œç™¼é€\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "#=======================================\n",
        "# ä¸»ç¨‹å¼åŸ·è¡Œæµç¨‹\n",
        "# ==============================================\n",
        "\n",
        "async def main_menu():\n",
        "    print(\"=\"*40)\n",
        "    print(\"==== å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· ====\")\n",
        "    print(\"=\"*40)\n",
        "    print(\"ğŸš€ é–‹å§‹è‡ªå‹•åˆ†ææ‰€æœ‰è‚¡ç¥¨...\")\n",
        "\n",
        "    print(\"\\n[éšæ®µ1/5] ç²å–æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬è³‡æ–™...\")\n",
        "    stocks_info = get_stock_basic_info()\n",
        "    stock_ids = list(stocks_info.keys())\n",
        "\n",
        "    print(\"\\n[éšæ®µ2/5] æ‰¹æ¬¡ä¸‹è¼‰æ­·å²è³‡æ–™ (ä¸€å¹´æœŸ)...\")\n",
        "    all_stocks_data = fetch_multiple_stocks_data(stocks_info, period='1y')\n",
        "    if not all_stocks_data:\n",
        "        print(\"âŒ ç„¡æ³•å–å¾—ä»»ä½•è‚¡ç¥¨æ­·å²è³‡æ–™ï¼Œæµç¨‹ä¸­æ­¢ã€‚\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n[éšæ®µ3/5] éæ¿¾ä½æˆäº¤é‡è‚¡ç¥¨...\")\n",
        "    filtered_data = filter_by_volume(all_stocks_data, min_volume_shares=1000 * 1000)\n",
        "    if not filtered_data:\n",
        "        print(\"âŒ æ²’æœ‰ä»»ä½•å€‹è‚¡ç¬¦åˆæˆäº¤é‡æ¨™æº– (è¿‘ä¸€å€‹æœˆæ¯æ—¥æˆäº¤é‡ > 1000å¼µ)ã€‚\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n[éšæ®µ4/5] é€²è¡Œæ ¸å¿ƒåˆ†æèˆ‡ç¶œåˆè©•åˆ†...\")\n",
        "    all_analysis_results = {}\n",
        "    for i, (stock_id, stock_data) in enumerate(filtered_data.items()):\n",
        "        print(f\"  åˆ†æä¸­ ({i+1}/{len(filtered_data)}): {stock_id} {stock_data.get('stock_name', '')}\")\n",
        "        analysis_result = analyze_stock(stock_id, stock_data)\n",
        "        if analysis_result.get('success'):\n",
        "            scores, final_score = calculate_comprehensive_score(analysis_result)\n",
        "            analysis_result['scores'] = {k: int(round(v)) for k, v in scores.items()}\n",
        "            analysis_result['combined_score'] = int(round(final_score))\n",
        "            analysis_result['recommendation'] = generate_recommendation(final_score)\n",
        "            all_analysis_results[stock_id] = analysis_result\n",
        "\n",
        "    if not all_analysis_results: # <- ä¿®æ­£äº†è®Šæ•¸åç¨±ä¸¦è£œä¸Šå†’è™Ÿ\n",
        "        print(\"âŒ æ ¸å¿ƒåˆ†æå¾Œï¼Œæ²’æœ‰ä»»ä½•è‚¡ç¥¨ç¬¦åˆæ¨™æº–ã€‚\")\n",
        "        # ç™¼é€ç©ºçµæœé€šçŸ¥\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            empty_message = format_notification_message({})\n",
        "            await send_notification(session, empty_message)\n",
        "        print(\"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\")\n",
        "        return # çµæŸå‡½å¼\n",
        "\n",
        "    print(\"\\n[éšæ®µ5/5] ç¯©é¸é ‚å°–å€‹è‚¡ä¸¦ç”¢å‡ºå ±å‘Š...\")\n",
        "    elite_results = top_percentile_filter(all_analysis_results, percentile=98)\n",
        "    results_to_show = elite_results if elite_results else all_analysis_results\n",
        "\n",
        "    if not results_to_show:\n",
        "        print(\"ğŸ¤· æ‰¾ä¸åˆ°ä»»ä½•å¯é¡¯ç¤ºçš„çµæœã€‚\")\n",
        "        return\n",
        "\n",
        "    if not elite_results:\n",
        "        print(\"ğŸ¤· æ²’æœ‰å€‹è‚¡åˆ†æ•¸é”åˆ°å‰2%çš„é–€æª»ã€‚å°‡é¡¯ç¤ºåŸå§‹æ¸…å–®ä¸­åˆ†æ•¸æœ€é«˜çš„è‚¡ç¥¨ã€‚\")\n",
        "\n",
        "    print_top_stocks(results_to_show, top_n=10)\n",
        "\n",
        "    print(\"\\n--- æ­£åœ¨ç‚ºé ‚å°–å€‹è‚¡ç”Ÿæˆè©³ç´°åœ–è¡¨å ±å‘Š ---\")\n",
        "    top_stocks_to_report = sorted(results_to_show.values(), key=lambda x: x.get('combined_score', 0), reverse=True)[:10]\n",
        "    for stock in top_stocks_to_report:\n",
        "        generate_detailed_analysis_report(\n",
        "            stock_id=stock['stock_id'],\n",
        "            stock_name=stock['stock_name'],\n",
        "            stock_data=stock\n",
        "        )\n",
        "    print(\"\\nğŸ‰ å…¨éƒ¨æµç¨‹åŸ·è¡Œå®Œç•¢ï¼\")\n",
        "    # å³ä½¿æ²’æœ‰çµæœä¹Ÿç™¼é€é€šçŸ¥            try:\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            message = format_notification_message({})\n",
        "            await send_notification(session, message)\n",
        "            print(\"ğŸ“± ç©ºçµæœé€šçŸ¥å·²ç™¼é€\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ç©ºçµæœé€šçŸ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "if __name__ == \"__main__\":\n",
        "    set_chinese_font()\n",
        "    asyncio.run(main_menu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG0sUErIIRDT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…·\n",
        "=======================\n",
        "åŠŸèƒ½ï¼š\n",
        "- è‡ªå‹•ç²å–å°è‚¡æ¸…å–®\n",
        "- æ‰¹æ¬¡ä¸‹è¼‰æ­·å²æ•¸æ“š\n",
        "- æŠ€è¡“æŒ‡æ¨™åˆ†æ\n",
        "- ç¶œåˆè©•åˆ†æ’å\n",
        "- è‡ªå‹•é€šçŸ¥æ¨é€\n",
        "- åœ–è¡¨ç”Ÿæˆèˆ‡å ±å‘ŠåŒ¯å‡º\n",
        "\n",
        "ä½œè€…ï¼šè‚¡ç¥¨åˆ†æç³»çµ±\n",
        "ç‰ˆæœ¬ï¼šv2.0\n",
        "æ›´æ–°æ—¥æœŸï¼š2025-08-08\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. åŸºç¤ Python æ¨™æº–åº«\n",
        "# ==============================================================================\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import platform\n",
        "import re\n",
        "from io import StringIO\n",
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "import re  # ç”¨æ–¼æ­£å‰‡è¡¨é”å¼è™•ç†\n",
        "# ==============================================================================\n",
        "# 2. ç¬¬ä¸‰æ–¹å¥—ä»¶\n",
        "# ==============================================================================\n",
        "# æ•¸æ“šè™•ç†èˆ‡ç§‘å­¸è¨ˆç®—\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ç¶²è·¯è«‹æ±‚\n",
        "import requests\n",
        "\n",
        "# é‡‘èæ•¸æ“šæº\n",
        "import yfinance as yf\n",
        "\n",
        "# æ•¸æ“šå¯è¦–åŒ–\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "import mplfinance as mpf\n",
        "import plotly.graph_objects as go\n",
        "from pathlib import Path\n",
        "\n",
        "# é€šçŸ¥å¥—ä»¶ (ä¿®æ­£ï¼šæ–°å¢ discord_webhook åŒ¯å…¥)\n",
        "from discord_webhook import DiscordWebhook\n",
        "import telegram\n",
        "# ä¸­æ–‡å­—é«”æ”¯æ´ï¼ˆå¦‚æœæœ‰å®‰è£çš„è©±ï¼‰\n",
        "try:\n",
        "    import chineseize_matplotlib\n",
        "    chineseize_matplotlib.chineseize()\n",
        "    print(\"âœ… å·²è¼‰å…¥ chineseize_matplotlib ä¸­æ–‡å­—é«”æ”¯æ´\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ æœªå®‰è£ chineseize_matplotlibï¼Œå°‡ä½¿ç”¨è‡ªå®šç¾©å­—é«”è¨­å®š\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import re\n",
        "# ==============================================================================\n",
        "# 3. å…¨åŸŸè¨­å®šèˆ‡ç›®éŒ„çµæ§‹\n",
        "# ==============================================================================\n",
        "# ç›®éŒ„çµæ§‹è¨­å®š\n",
        "CACHE_DIR = 'cache'\n",
        "RESULTS_DIR = 'results'\n",
        "CHARTS_DIR = os.path.join(RESULTS_DIR, 'charts')\n",
        "STOCK_LIST_PATH = os.path.join(CACHE_DIR, 'stock_list.csv')\n",
        "HISTORY_DATA_CACHE_DIR = os.path.join(CACHE_DIR, 'history_data')\n",
        "\n",
        "# åˆå§‹åŒ–ç›®éŒ„\n",
        "for directory in [CACHE_DIR, RESULTS_DIR, CHARTS_DIR, HISTORY_DATA_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. é€šè¨Šèˆ‡é€šçŸ¥è¨­å®š\n",
        "# ==============================================================================\n",
        "# å»ºè­°å°‡ä¾†ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ– .env æª”æ¡ˆç®¡ç†å¯†é‘°ï¼Œä»¥ç­–å®‰å…¨\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. æ—¥èªŒç³»çµ±è¨­å®š\n",
        "# ==============================================================================\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"stock_analysis.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. è¼”åŠ©å‡½å¼èˆ‡ç’°å¢ƒè¨­å®š\n",
        "# ==============================================================================\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "\n",
        "    æ”¯æ´çš„ä½œæ¥­ç³»çµ±ï¼š\n",
        "    - Windows: Microsoft YaHei\n",
        "    - macOS: PingFang HK\n",
        "    - Linux: Noto Sans CJK / WenQuanYi Zen Hei\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            # Windows ç³»çµ±å­—é«”è¨­å®š\n",
        "            font_candidates = ['Microsoft YaHei', 'SimHei', 'KaiTi']\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        elif system == 'Darwin':  # macOS\n",
        "            # macOS ç³»çµ±å­—é«”è¨­å®š\n",
        "            font_candidates = ['PingFang HK', 'PingFang SC', 'Heiti TC', 'STHeiti']\n",
        "            for font in font_candidates:\n",
        "                try:\n",
        "                    plt.rcParams['font.sans-serif'] = [font]\n",
        "                    font_name = font\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        else:  # Linux å’Œå…¶ä»–ç³»çµ±\n",
        "            # Linux ç³»çµ±å­—é«”è·¯å¾‘\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/ukai.ttc',\n",
        "                '/usr/share/fonts/truetype/arphic/uming.ttc',\n",
        "            ]\n",
        "\n",
        "            found_font_path = None\n",
        "            for path in font_paths:\n",
        "                if os.path.exists(path):\n",
        "                    found_font_path = path\n",
        "                    break\n",
        "\n",
        "            if found_font_path:\n",
        "                try:\n",
        "                    font_manager.fontManager.addfont(found_font_path)\n",
        "                    font_prop = font_manager.FontProperties(fname=found_font_path)\n",
        "                    font_name = font_prop.get_name()\n",
        "                    plt.rcParams['font.sans-serif'] = [font_name]\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"è¼‰å…¥å­—é«”å¤±æ•—: {e}\")\n",
        "                    font_name = \"DejaVu Sans\"\n",
        "            else:\n",
        "                print(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                font_name = \"DejaVu Sans\"\n",
        "\n",
        "        # è¨­å®šè² è™Ÿé¡¯ç¤º\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "        # è¨­å®šå­—é«”å¤§å°\n",
        "        plt.rcParams['font.size'] = 10\n",
        "        plt.rcParams['axes.titlesize'] = 12\n",
        "        plt.rcParams['axes.labelsize'] = 10\n",
        "        plt.rcParams['xtick.labelsize'] = 9\n",
        "        plt.rcParams['ytick.labelsize'] = 9\n",
        "        plt.rcParams['legend.fontsize'] = 9\n",
        "\n",
        "        if font_name and font_name != \"DejaVu Sans\":\n",
        "            print(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name} ({system})\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ä½¿ç”¨é è¨­å­—é«”: {font_name}\")\n",
        "            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"\n",
        "    æª¢æŸ¥åŸ·è¡Œç’°å¢ƒèˆ‡ç›¸ä¾å¥—ä»¶\n",
        "    \"\"\"\n",
        "    print(\"ğŸ” æª¢æŸ¥åŸ·è¡Œç’°å¢ƒ...\")\n",
        "    print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
        "    print(f\"ä½œæ¥­ç³»çµ±: {platform.system()} {platform.release()}\")\n",
        "\n",
        "    # æª¢æŸ¥é‡è¦å¥—ä»¶ç‰ˆæœ¬\n",
        "    required_packages = {\n",
        "        'pandas': pd.__version__,\n",
        "        'numpy': np.__version__,\n",
        "        'matplotlib': plt.matplotlib.__version__,\n",
        "        'requests': requests.__version__,\n",
        "        'yfinance': yf.__version__ if hasattr(yf, '__version__') else 'Unknown'\n",
        "    }\n",
        "\n",
        "    print(\"\\nğŸ“¦ å¥—ä»¶ç‰ˆæœ¬:\")\n",
        "    for package, version in required_packages.items():\n",
        "        print(f\"  {package}: {version}\")\n",
        "\n",
        "    # æª¢æŸ¥ç›®éŒ„æ¬Šé™\n",
        "    print(f\"\\nğŸ“ å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
        "    print(f\"å¿«å–ç›®éŒ„: {CACHE_DIR} {'âœ…' if os.access(CACHE_DIR, os.W_OK) else 'âŒ'}\")\n",
        "    print(f\"çµæœç›®éŒ„: {RESULTS_DIR} {'âœ…' if os.access(RESULTS_DIR, os.W_OK) else 'âŒ'}\")\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "# ==============================================================================\n",
        "# 1. æ–°å¢ï¼šKç·šå‹æ…‹ä¸­æ–‡ç¿»è­¯å­—å…¸èˆ‡è¼”åŠ©å‡½æ•¸\n",
        "# ==============================================================================\n",
        "import re\n",
        "\n",
        "# ä¸­æ–‡ç¿»è­¯å­—å…¸\n",
        "PATTERN_TRANSLATIONS = {\n",
        "    # å‡ç·šæŒ‡æ¨™ (MA)\n",
        "    \"ma5\": \"5æ—¥å‡ç·š\",\n",
        "    \"ma10\": \"10æ—¥å‡ç·š\",\n",
        "    \"ma20\": \"20æ—¥å‡ç·š (æœˆç·š)\",\n",
        "    \"ma60\": \"60æ—¥å‡ç·š (å­£ç·š)\",\n",
        "    \"ma120\": \"120æ—¥å‡ç·š (åŠå¹´ç·š)\",\n",
        "\n",
        "    # Kç·šåŸºç¤å±¬æ€§\n",
        "    \"body size\": \"å¯¦é«”å¤§å°\",\n",
        "    \"upper shadow\": \"ä¸Šå½±ç·š\",\n",
        "    \"lower shadow\": \"ä¸‹å½±ç·š\",\n",
        "    \"total range\": \"ç¸½æ³¢å¹…\",\n",
        "    \"prev open\": \"æ˜¨æ—¥é–‹ç›¤åƒ¹\",\n",
        "    \"prev high\": \"æ˜¨æ—¥æœ€é«˜åƒ¹\",\n",
        "    \"prev low\": \"æ˜¨æ—¥æœ€ä½åƒ¹\",\n",
        "    \"prev close\": \"æ˜¨æ—¥æ”¶ç›¤åƒ¹\",\n",
        "    \"prev volume\": \"æ˜¨æ—¥æˆäº¤é‡\",\n",
        "\n",
        "    # å¸¸è¦‹Kç·šå‹æ…‹ (å¯æ ¹æ“šæ‚¨çš„åˆ†æåº«æ“´å……)\n",
        "    \"hammer\": \"éšå­ç·š\",\n",
        "    \"hanging man\": \"åŠäººç·š\",\n",
        "    \"inverted hammer\": \"å€’éšå­ç·š\",\n",
        "    \"shooting star\": \"å°„æ“Šä¹‹æ˜Ÿ\",\n",
        "    \"doji\": \"åå­—æ˜Ÿ\",\n",
        "    \"dragonfly doji\": \"èœ»èœ“åå­—\",\n",
        "    \"gravestone doji\": \"å¢“ç¢‘åå­—\",\n",
        "    \"bullish engulfing\": \"çœ‹æ¼²åå™¬\",\n",
        "    \"bearish engulfing\": \"çœ‹è·Œåå™¬\",\n",
        "    \"morning star\": \"æ™¨æ˜Ÿ\",\n",
        "    \"evening star\": \"å¤œæ˜Ÿ\",\n",
        "    \"marubozu\": \"å…‰é ­å…‰è…³Kç·š\"\n",
        "}\n",
        "\n",
        "def translate_pattern(pattern_name):\n",
        "    \"\"\" ç¿»è­¯è‹±æ–‡patternç‚ºä¸­æ–‡ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å›åŸæ–‡ \"\"\"\n",
        "    # ç§»é™¤ \"çœ‹æ¼²\" æˆ– \"çœ‹è·Œ\" å‰ç¶´ä¾†æŸ¥æ‰¾åŸºç¤æ¨¡å¼\n",
        "    clean_name = pattern_name.replace(\"çœ‹æ¼²\", \"\").replace(\"çœ‹è·Œ\", \"\").strip()\n",
        "\n",
        "    # è™•ç†å¸¶æœ‰æ¯”è¼ƒè©çš„æ¨¡å¼ (ä¾‹å¦‚ \"body size > prev body size\")\n",
        "    parts = re.split(r'([<>=])', clean_name)\n",
        "    if len(parts) > 1:\n",
        "        translated_parts = [PATTERN_TRANSLATIONS.get(p.strip(), p.strip()) for p in parts]\n",
        "        return \" \".join(translated_parts)\n",
        "\n",
        "    return PATTERN_TRANSLATIONS.get(clean_name, clean_name)\n",
        "\n",
        "# æ ¸å¿ƒåŠŸèƒ½å‡½å¼ (è³‡æ–™ç²å–ã€åˆ†æã€è©•åˆ†)\n",
        "def get_taiwan_stocks(cache_path=STOCK_LIST_PATH, force_update=False):\n",
        "    if not force_update and os.path.exists(cache_path) and (time.time() - os.path.getmtime(cache_path)) < 86400:\n",
        "        try:\n",
        "            df = pd.read_csv(cache_path, dtype={'stock_id': str})\n",
        "            if not df.empty and 'yahoo_symbol' in df.columns:\n",
        "                print(f\"âœ… å¾å¿«å–è¼‰å…¥ {len(df)} æ”¯è‚¡ç¥¨æ¸…å–®ã€‚\")\n",
        "                return df\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ è¼‰å…¥è‚¡ç¥¨æ¸…å–®å¿«å–å¤±æ•—: {e}ã€‚\")\n",
        "\n",
        "    print(\"ğŸŒ æ­£åœ¨ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–® (å¾è­‰äº¤æ‰€)...\")\n",
        "    try:\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        for market, url in urls.items():\n",
        "            response = requests.get(url, timeout=20)\n",
        "            df = pd.read_html(StringIO(response.text))[0]\n",
        "            df.columns = df.iloc[0]\n",
        "            df = df.iloc[1:].dropna(thresh=3, axis=0)\n",
        "            df['å¸‚å ´åˆ¥'] = market\n",
        "            all_stocks_df.append(df)\n",
        "\n",
        "        df_combined = pd.concat(all_stocks_df, ignore_index=True)\n",
        "        df_combined.columns = ['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±', 'åœ‹éš›è­‰åˆ¸è­˜åˆ¥ç¢¼', 'ä¸Šå¸‚æ—¥', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'CFI', 'å‚™è¨»']\n",
        "        df_combined[['stock_id', 'stock_name']] = df_combined['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', n=1, expand=True)\n",
        "        df_combined['stock_id'] = df_combined['stock_id'].str.strip()\n",
        "        df_combined['stock_name'] = df_combined['stock_name'].str.strip()\n",
        "        df_stocks = df_combined[df_combined['stock_id'].str.match(r'^\\d{4}$')].copy()\n",
        "        exclude_keywords = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š']\n",
        "        df_stocks = df_stocks[~df_stocks['stock_name'].str.contains('|'.join(exclude_keywords), na=False)]\n",
        "        df_stocks['yahoo_symbol'] = df_stocks.apply(\n",
        "            lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['å¸‚å ´åˆ¥'] else f\"{row['stock_id']}.TWO\",\n",
        "            axis=1\n",
        "        )\n",
        "        final_df = df_stocks[['stock_id', 'stock_name', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "        final_df.rename(columns={'å¸‚å ´åˆ¥': 'market', 'ç”¢æ¥­åˆ¥': 'industry'}, inplace=True)\n",
        "        final_df.to_csv(cache_path, index=False)\n",
        "        print(f\"âœ… æˆåŠŸå¾è­‰äº¤æ‰€ç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜ã€‚\")\n",
        "        return final_df\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å¾è­‰äº¤æ‰€ç²å–è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        if os.path.exists(cache_path):\n",
        "            print(\"â— é™ç´šä½¿ç”¨èˆŠçš„å¿«å–è‚¡ç¥¨æ¸…å–®ã€‚\")\n",
        "            return pd.read_csv(cache_path, dtype={'stock_id': str})\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def get_stock_basic_info(force_update=False):\n",
        "    stocks_df = get_taiwan_stocks(force_update=force_update)\n",
        "    if stocks_df.empty: return {}\n",
        "    return {str(row['stock_id']): row.to_dict() for _, row in stocks_df.iterrows()}\n",
        "\n",
        "# ***** é—œéµä¿®æ­£å‡½å¼ *****\n",
        "# ==============================================================================\n",
        "# è«‹ç”¨é€™å…©å€‹å„ªåŒ–å¾Œçš„å‡½æ•¸ï¼Œå®Œæ•´æ›¿æ›æ‚¨ç¨‹å¼ç¢¼ä¸­å°æ‡‰çš„å‡½æ•¸\n",
        "# ==============================================================================\n",
        "\n",
        "import traceback\n",
        "import requests # ç¢ºä¿å°å…¥ requests\n",
        "\n",
        "def fetch_stock_data(stock_id, yahoo_symbol, period='1y', force_update=False, retries=3, delay=3, cache_dir=HISTORY_DATA_CACHE_DIR):\n",
        "    \"\"\"\n",
        "    ã€å„ªåŒ–ç‰ˆã€‘ä¸‹è¼‰å–®ä¸€è‚¡ç¥¨æ•¸æ“šï¼Œå…·å‚™æ›´å¼·çš„éŒ¯èª¤è™•ç†ã€æ—¥èªŒè¨˜éŒ„å’Œç©©å¥æ€§ã€‚\n",
        "    \"\"\"\n",
        "    formatted_id = str(stock_id)\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    cache_path = os.path.join(cache_dir, f\"{formatted_id}.json\")\n",
        "\n",
        "    if not force_update and os.path.exists(cache_path) and (time.time() - os.path.getmtime(cache_path)) < 86400:\n",
        "        try:\n",
        "            with open(cache_path, 'r', encoding='utf-8') as f:\n",
        "                logger.info(f\"å¾å¿«å–è¼‰å…¥ {stock_id} ({yahoo_symbol}) çš„æ•¸æ“šã€‚\")\n",
        "                return json.load(f)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"è®€å– {stock_id} çš„å¿«å–æª”æ¡ˆå¤±æ•—: {e}ï¼Œå°‡é‡æ–°å¾ç¶²è·¯ç²å–ã€‚\")\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            time.sleep(0.5)\n",
        "            logger.info(f\"å˜—è©¦ç²å– {stock_id} ({yahoo_symbol}) æ•¸æ“š... (ç¬¬ {attempt + 1}/{retries} æ¬¡)\")\n",
        "            temp_df = yf.download(yahoo_symbol, period=period, progress=False, auto_adjust=True, timeout=20)\n",
        "\n",
        "            if temp_df.empty:\n",
        "                logger.warning(f\"è‚¡ç¥¨ {stock_id} ({yahoo_symbol}) ä¸‹è¼‰å¾Œæ•¸æ“šç‚ºç©ºã€‚å¯èƒ½åŸå› ï¼šä»£è™ŸéŒ¯èª¤ã€å·²ä¸‹å¸‚æˆ–è©²æ™‚æ®µç„¡äº¤æ˜“æ•¸æ“šã€‚\")\n",
        "                return None\n",
        "\n",
        "            if isinstance(temp_df.columns, pd.MultiIndex):\n",
        "                temp_df.columns = temp_df.columns.get_level_values(0)\n",
        "\n",
        "            df = temp_df.reset_index()\n",
        "            df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
        "            result = {\n",
        "                'data': df.to_dict('records'), 'stock_id': formatted_id, 'yahoo_symbol': yahoo_symbol,\n",
        "                'last_price': df['Close'].iloc[-1] if not df.empty else 0,\n",
        "                'fetch_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            }\n",
        "            with open(cache_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "            return result\n",
        "        except requests.exceptions.ConnectionError as e:\n",
        "            logger.error(f\"ä¸‹è¼‰ {yahoo_symbol} æ™‚ç™¼ç”Ÿç¶²è·¯é€£ç·šéŒ¯èª¤: {e}ã€‚è«‹æª¢æŸ¥æ‚¨çš„ç¶²è·¯é€£ç·šæˆ–é˜²ç«ç‰†è¨­å®šã€‚\")\n",
        "            if attempt < retries - 1: time.sleep(delay)\n",
        "            else: return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ä¸‹è¼‰ {yahoo_symbol} æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}\")\n",
        "            logger.debug(traceback.format_exc())\n",
        "            if attempt < retries - 1: time.sleep(delay)\n",
        "            else: return None\n",
        "    return None\n",
        "\n",
        "def fetch_multiple_stocks_data(stocks_info, period='1y', force_update=False):\n",
        "    \"\"\"\n",
        "    ã€å„ªåŒ–ç‰ˆã€‘æ‰¹æ¬¡ç²å–å¤šæ”¯è‚¡ç¥¨æ•¸æ“šï¼Œä¸¦æä¾›è©³ç´°çš„æˆåŠŸ/å¤±æ•—æ‘˜è¦ã€‚\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    failed_stocks = []\n",
        "    stocks_list = list(stocks_info.values())\n",
        "    total_stocks = len(stocks_list)\n",
        "\n",
        "    if total_stocks == 0:\n",
        "        logger.warning(\"å‚³å…¥çš„è‚¡ç¥¨æ¸…å–®ç‚ºç©ºï¼Œç„¡éœ€ç²å–æ•¸æ“šã€‚\")\n",
        "        return {}\n",
        "\n",
        "    for idx, stock in enumerate(stocks_list):\n",
        "        stock_id = str(stock.get('stock_id'))\n",
        "        stock_name = stock.get('stock_name', 'N/A')\n",
        "        yahoo_symbol = stock.get('yahoo_symbol')\n",
        "\n",
        "        if not yahoo_symbol:\n",
        "            logger.warning(f\"è‚¡ç¥¨ {stock_id} {stock_name} ç¼ºå°‘ 'yahoo_symbol'ï¼Œå·²è·³éã€‚\")\n",
        "            failed_stocks.append(f\"{stock_id} {stock_name} (ç¼ºå°‘Symbol)\")\n",
        "            continue\n",
        "\n",
        "        # é€™è£¡ä¸å†å°å‡ºæ—¥èªŒï¼Œäº¤çµ¦ fetch_stock_data å…§éƒ¨è™•ç†\n",
        "        print(f\"[{idx + 1}/{total_stocks}] æ­£åœ¨è™•ç†: {stock_id} {stock_name}\")\n",
        "\n",
        "        stock_data = fetch_stock_data(\n",
        "            stock_id=stock_id, yahoo_symbol=yahoo_symbol, period=period, force_update=force_update\n",
        "        )\n",
        "\n",
        "        if stock_data and 'data' in stock_data and stock_data['data']:\n",
        "            stock_data.update(stock)\n",
        "            results[stock_id] = stock_data\n",
        "        else:\n",
        "            failed_stocks.append(f\"{stock_id} {stock_name}\")\n",
        "\n",
        "    logger.info(\"\\n\" + \"=\"*20 + \" æ•¸æ“šç²å–æ‘˜è¦ \" + \"=\"*20)\n",
        "    logger.info(f\"ä»»å‹™å®Œæˆã€‚æˆåŠŸç²å– {len(results)} / {total_stocks} æ”¯è‚¡ç¥¨çš„æ•¸æ“šã€‚\")\n",
        "    if failed_stocks:\n",
        "        logger.warning(f\"æœªèƒ½ç²å–ä»¥ä¸‹ {len(failed_stocks)} æ”¯è‚¡ç¥¨çš„æ•¸æ“š: {', '.join(failed_stocks)}\")\n",
        "    logger.info(\"=\"*58 + \"\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    \"\"\"\n",
        "    ç‚ºæ•¸æ“šæ¡†æ·»åŠ æŠ€è¡“æŒ‡æ¨™ã€‚\n",
        "    æ¥å—å¤§å¯«æ¬„ä½åç¨± (Open, High, Low, Close, Volume)ï¼Œ\n",
        "    å…§éƒ¨ä½¿ç”¨å°å¯«è™•ç†ï¼Œç„¶å¾Œè¿”å›ä¿æŒåŸå§‹å¤§å¯«æ ¼å¼çš„DataFrameã€‚\n",
        "\n",
        "    åƒæ•¸:\n",
        "    df - åŒ…å«OHLCVæ•¸æ“šçš„DataFrameï¼Œä½¿ç”¨å¤§å¯«æ¬„ä½åç¨±\n",
        "\n",
        "    è¿”å›:\n",
        "    DataFrame - æ·»åŠ äº†æŠ€è¡“æŒ‡æ¨™çš„DataFrameï¼Œä¿æŒå¤§å¯«æ¬„ä½åç¨±\n",
        "    \"\"\"\n",
        "    # è¤‡è£½DataFrameä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š\n",
        "    result = df.copy()\n",
        "\n",
        "    # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨\n",
        "    required_cols = ['Close', 'High', 'Low']\n",
        "    missing_cols = [col for col in required_cols if col not in result.columns]\n",
        "    if missing_cols or result.empty:\n",
        "        print(f\"è­¦å‘Š: ç¼ºå°‘è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ‰€éœ€çš„æ¬„ä½: {missing_cols}\")\n",
        "        return df  # è¿”å›åŸå§‹DataFrame\n",
        "\n",
        "    # æš«æ™‚å°‡æ¬„ä½åç¨±è½‰æ›ç‚ºå°å¯«ä»¥é€²è¡Œè¨ˆç®—\n",
        "    lowercase_mapping = {col: col.lower() for col in result.columns if col in ['Open', 'High', 'Low', 'Close', 'Volume']}\n",
        "    result = result.rename(columns=lowercase_mapping)\n",
        "\n",
        "    # è¨ˆç®—ç°¡å–®ç§»å‹•å¹³å‡ç·š (MA)\n",
        "    for days in [5, 10, 20, 60, 120, 200]:\n",
        "        result[f'ma{days}'] = result['close'].rolling(window=days).mean()\n",
        "\n",
        "    # è¨ˆç®—ç›¸å°å¼·å¼±æŒ‡æ¨™ (RSI)\n",
        "    delta = result['close'].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean()\n",
        "    avg_loss = loss.rolling(window=14).mean()\n",
        "    rs = avg_gain / (avg_loss + 1e-9)  # é¿å…é™¤ä»¥é›¶\n",
        "    result['rsi'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # è¨ˆç®—MACD\n",
        "    exp1 = result['close'].ewm(span=12, adjust=False).mean()\n",
        "    exp2 = result['close'].ewm(span=26, adjust=False).mean()\n",
        "    result['macd'] = exp1 - exp2\n",
        "    result['macdsignal'] = result['macd'].ewm(span=9, adjust=False).mean()\n",
        "    result['histogram'] = result['macd'] - result['macdsignal']\n",
        "\n",
        "    # è¨ˆç®—å¸ƒæ—é€šé“ (Bollinger Bands)\n",
        "    result['middle_band'] = result['close'].rolling(window=20).mean()\n",
        "    result['std'] = result['close'].rolling(window=20).std()\n",
        "    result['bollinger_upper'] = result['middle_band'] + (result['std'] * 2)\n",
        "    result['bollinger_lower'] = result['middle_band'] - (result['std'] * 2)\n",
        "\n",
        "    # è¨ˆç®—KDæŒ‡æ¨™\n",
        "    low_min = result['low'].rolling(window=9).min()\n",
        "    high_max = result['high'].rolling(window=9).max()\n",
        "    result['rsv'] = 100 * ((result['close'] - low_min) / (high_max - low_min + 1e-9))\n",
        "    result['k'] = result['rsv'].ewm(alpha=1/3, adjust=False).mean()\n",
        "    result['d'] = result['k'].ewm(alpha=1/3, adjust=False).mean()\n",
        "\n",
        "    # å¡«å……NaNå€¼\n",
        "    result = result.fillna(0)\n",
        "\n",
        "    # å°‡åŸå§‹æ¬„ä½åç¨±è½‰æ›å›å¤§å¯«\n",
        "    uppercase_mapping = {col.lower(): col for col in df.columns if col in ['Open', 'High', 'Low', 'Close', 'Volume']}\n",
        "    result = result.rename(columns=uppercase_mapping)\n",
        "\n",
        "    return result\n",
        "\n",
        "# ==============================================================================\n",
        "# è«‹ç”¨é€™æ•´å€‹å‡½æ•¸æ›¿æ›æ‰æ‚¨åŸæœ‰çš„ analyze_stock å‡½æ•¸\n",
        "# ==============================================================================\n",
        "def analyze_stock(stock_id, stock_data, min_periods=60):\n",
        "    \"\"\"\n",
        "    å°å–®ä¸€è‚¡ç¥¨é€²è¡Œå®Œæ•´çš„æŠ€è¡“åˆ†æã€‚\n",
        "\n",
        "    æ­¤ç‰ˆæœ¬ä¿®æ­£äº† NameError ä¸¦é‡æ§‹äº†å…§éƒ¨é‚è¼¯ï¼Œä½¿å…¶æ›´ç©©å¥ã€æ¸…æ™°ã€‚\n",
        "\n",
        "    åƒæ•¸:\n",
        "    stock_id (str): è‚¡ç¥¨ä»£è™Ÿ\n",
        "    stock_data (dict): åŒ…å«è‚¡ç¥¨åŸºæœ¬è³‡æ–™å’Œæ­·å²æ•¸æ“šçš„å­—å…¸\n",
        "    min_periods (int): é€²è¡Œåˆ†ææ‰€éœ€çš„æœ€å°‘æ­·å²æ•¸æ“šé»æ•¸é‡\n",
        "\n",
        "    è¿”å›:\n",
        "    dict or None: åŒ…å«åˆ†æçµæœçš„å­—å…¸ï¼Œå¦‚æœæ•¸æ“šç„¡æ•ˆæˆ–åˆ†æå¤±æ•—å‰‡è¿”å› None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- æ­¥é©Ÿ 1: é©—è­‰å‚³å…¥çš„æ•¸æ“šæ˜¯å¦æœ‰æ•ˆ ---\n",
        "        if not stock_data or not stock_data.get('data'):\n",
        "            logger.warning(f\"åˆ†æè‚¡ç¥¨ {stock_id} å¤±æ•—ï¼šå‚³å…¥çš„ stock_data ç‚ºç©ºæˆ–ç¼ºå°‘ 'data' éµã€‚\")\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame(stock_data['data'])\n",
        "\n",
        "        if df.empty or len(df) < min_periods:\n",
        "            logger.warning(f\"è·³éè‚¡ç¥¨ {stock_id}ï¼šæ•¸æ“šé»ä¸è¶³ {min_periods} å€‹ (å¯¦éš›: {len(df)})ã€‚\")\n",
        "            return None\n",
        "\n",
        "        # --- æ­¥é©Ÿ 2: æ¨™æº–åŒ–æ¬„ä½åç¨±èˆ‡ç´¢å¼• ---\n",
        "        # çµ±ä¸€æ—¥æœŸæ¬„ä½\n",
        "        date_col_candidates = ['Date', 'date', 'æ—¥æœŸ']\n",
        "        date_col = next((col for col in date_col_candidates if col in df.columns), None)\n",
        "\n",
        "        if date_col:\n",
        "            df[date_col] = pd.to_datetime(df[date_col])\n",
        "            df.set_index(date_col, inplace=True)\n",
        "        else:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} å¤±æ•—ï¼šæ‰¾ä¸åˆ°å¯ç”¨çš„æ—¥æœŸæ¬„ä½ã€‚\")\n",
        "            return None\n",
        "\n",
        "        # çµ±ä¸€åƒ¹æ ¼æ¬„ä½ (å°‡ä¸­æ–‡æ¬„ä½å°æ‡‰åˆ°æ¨™æº–è‹±æ–‡æ¬„ä½)\n",
        "        column_mapping = {\n",
        "            'é–‹ç›¤': 'Open', 'æœ€é«˜': 'High', 'æœ€ä½': 'Low', 'æ”¶ç›¤': 'Close', 'æˆäº¤é‡': 'Volume',\n",
        "            'é–‹ç›¤åƒ¹': 'Open', 'æœ€é«˜åƒ¹': 'High', 'æœ€ä½åƒ¹': 'Low', 'æ”¶ç›¤åƒ¹': 'Close'\n",
        "        }\n",
        "        df.rename(columns=column_mapping, inplace=True)\n",
        "\n",
        "        # æª¢æŸ¥å¿…è¦çš„åƒ¹æ ¼æ¬„ä½æ˜¯å¦å­˜åœ¨\n",
        "        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} å¤±æ•—ï¼šç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}ã€‚\")\n",
        "            return None\n",
        "\n",
        "        # --- æ­¥é©Ÿ 3: è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ ---\n",
        "        df_with_indicators = add_technical_indicators(df.copy())\n",
        "\n",
        "        # --- æ­¥é©Ÿ 4: è¨ˆç®—åƒ¹æ ¼è®ŠåŒ–ç‡ ---\n",
        "        price_changes = {}\n",
        "        periods = {'1d': 2, '1w': 5, '1m': 20, '3m': 60}\n",
        "        for label, days in periods.items():\n",
        "            if len(df_with_indicators) >= days:\n",
        "                price_changes[label] = ((df_with_indicators['Close'].iloc[-1] / df_with_indicators['Close'].iloc[-days]) - 1) * 100\n",
        "            else:\n",
        "                price_changes[label] = 0\n",
        "\n",
        "        # --- æ­¥é©Ÿ 5: çµ„åˆåˆ†æçµæœ ---\n",
        "        last_row = df_with_indicators.iloc[-1]\n",
        "        analysis_result = {\n",
        "            'success': True,\n",
        "            'stock_id': stock_id,\n",
        "            'stock_name': stock_data.get('stock_name', 'N/A'),\n",
        "            'market': stock_data.get('market', 'Unknown'),\n",
        "            'industry': stock_data.get('industry', 'Unknown'),\n",
        "            'last_price': last_row['Close'],\n",
        "            'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'price_change': price_changes,\n",
        "            'data_df': df_with_indicators # ä¿ç•™ DataFrame ä»¥ä¾›å¾ŒçºŒè©•åˆ†å’Œç¹ªåœ–ä½¿ç”¨\n",
        "        }\n",
        "        return analysis_result\n",
        "\n",
        "    except Exception as e:\n",
        "        # æ•æ‰æ‰€æœ‰æœªé æœŸçš„éŒ¯èª¤ï¼Œç¢ºä¿ä¸»ç¨‹åºä¸æœƒå› å–®ä¸€è‚¡ç¥¨è€Œä¸­æ–·\n",
        "        logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”Ÿç„¡æ³•é æœŸçš„ç•°å¸¸: {e}\")\n",
        "        logger.debug(traceback.format_exc()) # åœ¨æ—¥èªŒä¸­è¨˜éŒ„è©³ç´°çš„éŒ¯èª¤å †ç–Š\n",
        "        return None\n",
        "def calculate_comprehensive_score(analysis_result):\n",
        "    \"\"\"\n",
        "    è¨ˆç®—ç¶œåˆè©•åˆ†ã€‚\n",
        "    \"\"\"\n",
        "    scores = {'trend_score': 50, 'momentum_score': 50, 'volume_score': 50}\n",
        "    df = analysis_result.get('data_df')\n",
        "    if df is None or df.empty or len(df) < 60:\n",
        "        return scores, 50\n",
        "\n",
        "    try:\n",
        "        # è¶¨å‹¢è©•åˆ†\n",
        "        if all(col in df.columns for col in ['MA5', 'MA10', 'MA20', 'MA60']):\n",
        "            if df['MA5'].iloc[-1] > df['MA10'].iloc[-1] > df['MA20'].iloc[-1] > df['MA60'].iloc[-1]:\n",
        "                scores['trend_score'] = 85\n",
        "            else:\n",
        "                scores['trend_score'] = 20\n",
        "\n",
        "        # å‹•é‡è©•åˆ†\n",
        "        momentum_points = 50\n",
        "        if 'RSI' in df.columns and df['RSI'].iloc[-1] > 60:\n",
        "            momentum_points += 15\n",
        "        if all(col in df.columns for col in ['MACD', 'Signal']) and df['MACD'].iloc[-1] > df['Signal'].iloc[-1]:\n",
        "            momentum_points += 20\n",
        "        if all(col in df.columns for col in ['K', 'D']) and df['K'].iloc[-1] > df['D'].iloc[-1]:\n",
        "            momentum_points += 15\n",
        "        scores['momentum_score'] = max(0, min(100, momentum_points))\n",
        "\n",
        "        # æˆäº¤é‡è©•åˆ†\n",
        "        if 'Volume' in df.columns:\n",
        "            current_volume = df['Volume'].iloc[-1]\n",
        "            avg_volume = df['Volume'].rolling(window=20).mean().iloc[-1]\n",
        "            if current_volume > avg_volume * 1.5:\n",
        "                scores['volume_score'] = 80\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"è¨ˆç®—è©•åˆ†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    final_score = scores['trend_score'] * 0.4 + scores['momentum_score'] * 0.45 + scores['volume_score'] * 0.15\n",
        "    return scores, final_score\n",
        "\n",
        "def generate_recommendation(score):\n",
        "    \"\"\"\n",
        "    æ ¹æ“šè©•åˆ†ç”Ÿæˆäº¤æ˜“å»ºè­°ã€‚\n",
        "    \"\"\"\n",
        "    if score >= 75:\n",
        "        return {\n",
        "            'action': 'å¼·åŠ›è²·å…¥',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™é¡¯ç¤ºå¼·å‹¢', 'æˆäº¤é‡æ”¾å¤§', 'åƒ¹æ ¼è¶¨å‹¢å‘ä¸Š'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'ä¸­ç­‰',\n",
        "            'time_frame': '1-3å€‹æœˆ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "    elif score >= 60:\n",
        "        return {\n",
        "            'action': 'è²·å…¥',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™æ­£é¢', 'æˆäº¤é‡ç©©å®š'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'ä½',\n",
        "            'time_frame': '1-3å€‹æœˆ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "    elif score >= 40:\n",
        "        return {\n",
        "            'action': 'æŒæœ‰',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™ä¸­æ€§', 'ç„¡æ˜é¡¯è¶¨å‹¢'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'ä½',\n",
        "            'time_frame': '1å€‹æœˆ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "    elif score >= 25:\n",
        "        return {\n",
        "            'action': 'è§€æœ›',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™åå¼±', 'æˆäº¤é‡ä¸è¶³'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'é«˜',\n",
        "            'time_frame': 'çŸ­æœŸ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            'action': 'è³£å‡º',\n",
        "            'reasons': ['æŠ€è¡“æŒ‡æ¨™çœ‹è·Œ', 'æˆäº¤é‡èç¸®'],\n",
        "            'confidence': int(score),\n",
        "            'risk_level': 'é«˜',\n",
        "            'time_frame': 'çŸ­æœŸ',\n",
        "            'stop_loss': None,\n",
        "            'take_profit': None\n",
        "        }\n",
        "\n",
        "def generate_detailed_analysis_report(stock_id, stock_name, stock_data, save_path=None):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆè©³ç´°åˆ†æåœ–è¡¨ï¼ˆKç·šåœ–ã€æŠ€è¡“æŒ‡æ¨™ï¼‰ - ä¿®æ­£ç‰ˆæœ¬ã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df_plot = stock_data.get('data_df')\n",
        "        if df_plot is None or df_plot.empty:\n",
        "            logger.error(f\"ç„¡æ³•ç”Ÿæˆåœ–è¡¨: {stock_id} ç„¡æœ‰æ•ˆæ•¸æ“š\")\n",
        "            return None\n",
        "\n",
        "        # ç¢ºä¿æ•¸æ“šæ¡†æœ‰è¶³å¤ çš„æ•¸æ“š\n",
        "        if len(df_plot) < 20:\n",
        "            logger.error(f\"æ•¸æ“šä¸è¶³ä»¥ç”Ÿæˆåœ–è¡¨: {stock_id}\")\n",
        "            return None\n",
        "\n",
        "        df_plot = df_plot.tail(120).copy()\n",
        "\n",
        "        # ç¢ºä¿å¿…è¦çš„æ¬„ä½å­˜åœ¨\n",
        "        required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "        missing_columns = [col for col in required_columns if col not in df_plot.columns]\n",
        "        if missing_columns:\n",
        "            logger.error(f\"åœ–è¡¨ç”Ÿæˆå¤±æ•—ï¼Œç¼ºå°‘æ¬„ä½: {missing_columns}\")\n",
        "            return None\n",
        "\n",
        "        # ç¢ºä¿ç´¢å¼•æ˜¯æ—¥æœŸæ™‚é–“æ ¼å¼\n",
        "        if not isinstance(df_plot.index, pd.DatetimeIndex):\n",
        "            if 'Date' in df_plot.columns:\n",
        "                df_plot['Date'] = pd.to_datetime(df_plot['Date'])\n",
        "                df_plot.set_index('Date', inplace=True)\n",
        "            else:\n",
        "                df_plot.index = pd.date_range(start='2023-01-01', periods=len(df_plot), freq='D')\n",
        "\n",
        "        # è¨­å®šåœ–è¡¨æ¨£å¼\n",
        "        mc = mpf.make_marketcolors(up='r', down='g', inherit=True)\n",
        "        s = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=mc)\n",
        "\n",
        "        # æº–å‚™é™„åŠ åœ–è¡¨\n",
        "        apds = []\n",
        "\n",
        "        # æ·»åŠ ç§»å‹•å¹³å‡ç·š\n",
        "        if all(col in df_plot.columns for col in ['MA5', 'MA20']):\n",
        "            apds.append(mpf.make_addplot(df_plot[['MA5', 'MA20']], width=0.7))\n",
        "\n",
        "        # æ·»åŠ  MACD\n",
        "        if all(col in df_plot.columns for col in ['MACD', 'Signal']):\n",
        "            apds.append(mpf.make_addplot(df_plot[['MACD', 'Signal']], panel=2))\n",
        "\n",
        "        # æ·»åŠ  RSI\n",
        "        if 'RSI' in df_plot.columns:\n",
        "            apds.append(mpf.make_addplot(df_plot['RSI'], panel=3))\n",
        "\n",
        "        title = f\"{stock_id} {stock_name} (åˆ†æ•¸: {int(round(stock_data.get('combined_score', 0)))})\"\n",
        "\n",
        "        if not save_path:\n",
        "            save_path = os.path.join(CHARTS_DIR, f\"{stock_id}_report.png\")\n",
        "\n",
        "        # ç”Ÿæˆåœ–è¡¨\n",
        "        mpf.plot(\n",
        "            df_plot,\n",
        "            type='candle',\n",
        "            style=s,\n",
        "            title=title,\n",
        "            volume=True,\n",
        "            addplot=apds if apds else None,\n",
        "            panel_ratios=(6, 2, 2, 2) if len(apds) >= 2 else (6, 2),\n",
        "            figsize=(16, 9),\n",
        "            savefig=dict(fname=save_path, dpi=150, bbox_inches='tight')\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… åœ–è¡¨å ±å‘Šå·²å„²å­˜è‡³: {save_path}\")\n",
        "        plt.close('all')\n",
        "        return save_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”Ÿæˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "def identify_candlestick_patterns(df):\n",
        "    \"\"\"\n",
        "    è­˜åˆ¥å¸¸è¦‹çš„Kç·šå‹æ…‹ï¼Œä¸ä½¿ç”¨ talibã€ta-lib æˆ– pandas_ta\n",
        "\n",
        "    åƒæ•¸:\n",
        "    df - åŒ…å«OHLCVæ•¸æ“šçš„DataFrame\n",
        "\n",
        "    è¿”å›:\n",
        "    DataFrame - åŒ…å«å„ç¨®Kç·šå‹æ…‹çš„è­˜åˆ¥çµæœ\n",
        "    \"\"\"\n",
        "    # è¤‡è£½æ•¸æ“šä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š\n",
        "    result_df = df.copy()\n",
        "\n",
        "    # è¨ˆç®—å¯¦é«”é•·åº¦å’Œå½±ç·šé•·åº¦\n",
        "    result_df['body_size'] = abs(result_df['close'] - result_df['open'])\n",
        "    result_df['upper_shadow'] = result_df['high'] - result_df[['open', 'close']].max(axis=1)\n",
        "    result_df['lower_shadow'] = result_df[['open', 'close']].min(axis=1) - result_df['low']\n",
        "    result_df['total_range'] = result_df['high'] - result_df['low']\n",
        "\n",
        "    # è¨ˆç®—å‰ä¸€å¤©çš„æ•¸æ“š\n",
        "    result_df['prev_open'] = result_df['open'].shift(1)\n",
        "    result_df['prev_high'] = result_df['high'].shift(1)\n",
        "    result_df['prev_low'] = result_df['low'].shift(1)\n",
        "    result_df['prev_close'] = result_df['close'].shift(1)\n",
        "    result_df['prev_body_size'] = result_df['body_size'].shift(1)\n",
        "    result_df['prev_total_range'] = result_df['total_range'].shift(1)\n",
        "\n",
        "    # è¨ˆç®—å‰å…©å¤©çš„æ•¸æ“š\n",
        "    result_df['prev2_open'] = result_df['open'].shift(2)\n",
        "    result_df['prev2_high'] = result_df['high'].shift(2)\n",
        "    result_df['prev2_low'] = result_df['low'].shift(2)\n",
        "    result_df['prev2_close'] = result_df['close'].shift(2)\n",
        "\n",
        "    # è¨ˆç®—å‰ä¸‰å¤©çš„æ•¸æ“š\n",
        "    result_df['prev3_open'] = result_df['open'].shift(3)\n",
        "    result_df['prev3_high'] = result_df['high'].shift(3)\n",
        "    result_df['prev3_low'] = result_df['low'].shift(3)\n",
        "    result_df['prev3_close'] = result_df['close'].shift(3)\n",
        "\n",
        "    # è¨ˆç®—Kç·šè¶¨å‹¢\n",
        "    result_df['is_bullish'] = result_df['close'] > result_df['open']\n",
        "    result_df['prev_is_bullish'] = result_df['prev_close'] > result_df['prev_open']\n",
        "    result_df['prev2_is_bullish'] = result_df['prev2_close'] > result_df['prev2_open']\n",
        "    result_df['prev3_is_bullish'] = result_df['prev3_close'] > result_df['prev3_open']\n",
        "\n",
        "    # è¨ˆç®—ç°¡å–®ç§»å‹•å¹³å‡ç·šç”¨æ–¼åˆ¤æ–·è¶¨å‹¢\n",
        "    result_df['sma5'] = result_df['close'].rolling(window=5).mean()\n",
        "    result_df['sma10'] = result_df['close'].rolling(window=10).mean()\n",
        "    result_df['sma20'] = result_df['close'].rolling(window=20).mean()\n",
        "\n",
        "    # åˆ¤æ–·è¶¨å‹¢\n",
        "    result_df['uptrend'] = (result_df['sma5'] > result_df['sma20']) & (result_df['close'] > result_df['sma20'])\n",
        "    result_df['downtrend'] = (result_df['sma5'] < result_df['sma20']) & (result_df['close'] < result_df['sma20'])\n",
        "\n",
        "    # åˆå§‹åŒ–æ‰€æœ‰å‹æ…‹ç‚º0\n",
        "    pattern_columns = [\n",
        "        'åå­—æ˜Ÿ_ä¸­æ€§', 'éŒ˜å­ç·š_çœ‹æ¼²', 'éŒ˜å­ç·š_çœ‹è·Œ', 'æµæ˜Ÿç·š_çœ‹è·Œ',\n",
        "        'åå™¬_çœ‹æ¼²', 'åå™¬_çœ‹è·Œ', 'æ¯å­ç·š_çœ‹æ¼²', 'æ¯å­ç·š_çœ‹è·Œ',\n",
        "        'æ™¨æ˜Ÿ_çœ‹æ¼²', 'æš®æ˜Ÿ_çœ‹è·Œ', 'ä¸‰ç™½å…µ_çœ‹æ¼²', 'ä¸‰é»‘é´‰_çœ‹è·Œ',\n",
        "        'ç©¿åˆºç·š_çœ‹æ¼²', 'çƒé›²è“‹é ‚_çœ‹è·Œ', 'é•·è…³åå­—ç·š_ä¸­æ€§', 'ä¸ŠåŠç·š_çœ‹è·Œ',\n",
        "        'é™€èº_ä¸­æ€§', 'åè½‰_çœ‹æ¼²', 'åè½‰_çœ‹è·Œ', 'å³¶å½¢åè½‰_çœ‹æ¼²', 'å³¶å½¢åè½‰_çœ‹è·Œ',\n",
        "        'é ­è‚©é ‚_çœ‹è·Œ', 'é ­è‚©åº•_çœ‹æ¼²', 'é›™é ‚_çœ‹è·Œ', 'é›™åº•_çœ‹æ¼²'\n",
        "    ]\n",
        "\n",
        "    for col in pattern_columns:\n",
        "        result_df[col] = 0\n",
        "\n",
        "    # 1. è­˜åˆ¥åå­—æ˜Ÿ (Doji)\n",
        "    # åå­—æ˜Ÿ: é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒ\n",
        "    doji_condition = result_df['body_size'] <= 0.1 * result_df['total_range']\n",
        "    result_df.loc[doji_condition, 'åå­—æ˜Ÿ_ä¸­æ€§'] = 1\n",
        "\n",
        "    # 2. è­˜åˆ¥éŒ˜å­ç·š (Hammer) å’Œæµæ˜Ÿç·š (Shooting Star)\n",
        "    hammer_condition = (\n",
        "        (result_df['lower_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['upper_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "\n",
        "    shooting_star_condition = (\n",
        "        (result_df['upper_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['lower_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "\n",
        "    # åœ¨ä¸‹è·Œè¶¨å‹¢ä¸­çš„éŒ˜å­ç·šæ˜¯çœ‹æ¼²ä¿¡è™Ÿ\n",
        "    result_df.loc[hammer_condition & result_df['downtrend'], 'éŒ˜å­ç·š_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­çš„éŒ˜å­ç·šæ˜¯çœ‹è·Œä¿¡è™Ÿ\n",
        "    result_df.loc[hammer_condition & result_df['uptrend'], 'éŒ˜å­ç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # æµæ˜Ÿç·šé€šå¸¸æ˜¯çœ‹è·Œä¿¡è™Ÿ\n",
        "    result_df.loc[shooting_star_condition & result_df['uptrend'], 'æµæ˜Ÿç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 3. è­˜åˆ¥åå™¬å‹æ…‹ (Engulfing)\n",
        "    bullish_engulfing = (\n",
        "        (~result_df['prev_is_bullish']) &  # å‰ä¸€å¤©æ˜¯ä¸‹è·Œ\n",
        "        result_df['is_bullish'] &          # ç•¶å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['open'] < result_df['prev_close']) &  # é–‹ç›¤ä½æ–¼å‰ä¸€å¤©æ”¶ç›¤\n",
        "        (result_df['close'] > result_df['prev_open'])    # æ”¶ç›¤é«˜æ–¼å‰ä¸€å¤©é–‹ç›¤\n",
        "    )\n",
        "\n",
        "    bearish_engulfing = (\n",
        "        result_df['prev_is_bullish'] &     # å‰ä¸€å¤©æ˜¯ä¸Šæ¼²\n",
        "        (~result_df['is_bullish']) &       # ç•¶å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['open'] > result_df['prev_close']) &  # é–‹ç›¤é«˜æ–¼å‰ä¸€å¤©æ”¶ç›¤\n",
        "        (result_df['close'] < result_df['prev_open'])    # æ”¶ç›¤ä½æ–¼å‰ä¸€å¤©é–‹ç›¤\n",
        "    )\n",
        "\n",
        "    result_df.loc[bullish_engulfing & result_df['downtrend'], 'åå™¬_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[bearish_engulfing & result_df['uptrend'], 'åå™¬_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 4. è­˜åˆ¥æ¯å­ç·š (Harami)\n",
        "    bullish_harami = (\n",
        "        (~result_df['prev_is_bullish']) &  # å‰ä¸€å¤©æ˜¯ä¸‹è·Œ\n",
        "        result_df['is_bullish'] &          # ç•¶å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['high'] < result_df['prev_high']) &   # æœ€é«˜åƒ¹ä½æ–¼å‰ä¸€å¤©æœ€é«˜åƒ¹\n",
        "        (result_df['low'] > result_df['prev_low']) &     # æœ€ä½åƒ¹é«˜æ–¼å‰ä¸€å¤©æœ€ä½åƒ¹\n",
        "        (result_df['body_size'] < result_df['prev_body_size'])  # å¯¦é«”å°æ–¼å‰ä¸€å¤©\n",
        "    )\n",
        "\n",
        "    bearish_harami = (\n",
        "        result_df['prev_is_bullish'] &     # å‰ä¸€å¤©æ˜¯ä¸Šæ¼²\n",
        "        (~result_df['is_bullish']) &       # ç•¶å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['high'] < result_df['prev_high']) &   # æœ€é«˜åƒ¹ä½æ–¼å‰ä¸€å¤©æœ€é«˜åƒ¹\n",
        "        (result_df['low'] > result_df['prev_low']) &     # æœ€ä½åƒ¹é«˜æ–¼å‰ä¸€å¤©æœ€ä½åƒ¹\n",
        "        (result_df['body_size'] < result_df['prev_body_size'])  # å¯¦é«”å°æ–¼å‰ä¸€å¤©\n",
        "    )\n",
        "\n",
        "    result_df.loc[bullish_harami & result_df['downtrend'], 'æ¯å­ç·š_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[bearish_harami & result_df['uptrend'], 'æ¯å­ç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 5. è­˜åˆ¥æ™¨æ˜Ÿ (Morning Star) å’Œæš®æ˜Ÿ (Evening Star)\n",
        "    morning_star = (\n",
        "        (~result_df['prev2_is_bullish']) &  # å‰å…©å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['prev_body_size'] <= 0.3 * result_df['prev_total_range']) &  # å‰ä¸€å¤©æ˜¯å°å¯¦é«”\n",
        "        result_df['is_bullish'] &           # ç•¶å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['close'] > (result_df['prev2_open'] + result_df['prev2_close']) / 2)  # æ”¶ç›¤åƒ¹é«˜æ–¼å‰å…©å¤©å¯¦é«”ä¸­é»\n",
        "    )\n",
        "\n",
        "    evening_star = (\n",
        "        result_df['prev2_is_bullish'] &     # å‰å…©å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['prev_body_size'] <= 0.3 * result_df['prev_total_range']) &  # å‰ä¸€å¤©æ˜¯å°å¯¦é«”\n",
        "        (~result_df['is_bullish']) &        # ç•¶å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['close'] < (result_df['prev2_open'] + result_df['prev2_close']) / 2)  # æ”¶ç›¤åƒ¹ä½æ–¼å‰å…©å¤©å¯¦é«”ä¸­é»\n",
        "    )\n",
        "\n",
        "    result_df.loc[morning_star & result_df['downtrend'], 'æ™¨æ˜Ÿ_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[evening_star & result_df['uptrend'], 'æš®æ˜Ÿ_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 6. è­˜åˆ¥ä¸‰ç™½å…µ (Three White Soldiers) å’Œä¸‰é»‘é´‰ (Three Black Crows)\n",
        "    # éœ€è¦æª¢æŸ¥é€£çºŒä¸‰å¤©çš„Kç·š\n",
        "    three_white_soldiers = (\n",
        "        result_df['is_bullish'] &\n",
        "        result_df['prev_is_bullish'] &\n",
        "        result_df['prev2_is_bullish'] &\n",
        "        (result_df['close'] > result_df['prev_close']) &\n",
        "        (result_df['prev_close'] > result_df['prev2_close']) &\n",
        "        (result_df['open'] > result_df['prev_open']) &\n",
        "        (result_df['prev_open'] > result_df['prev2_open'])\n",
        "    )\n",
        "\n",
        "    three_black_crows = (\n",
        "        (~result_df['is_bullish']) &\n",
        "        (~result_df['prev_is_bullish']) &\n",
        "        (~result_df['prev2_is_bullish']) &\n",
        "        (result_df['close'] < result_df['prev_close']) &\n",
        "        (result_df['prev_close'] < result_df['prev2_close']) &\n",
        "        (result_df['open'] < result_df['prev_open']) &\n",
        "        (result_df['prev_open'] < result_df['prev2_open'])\n",
        "    )\n",
        "\n",
        "    result_df.loc[three_white_soldiers, 'ä¸‰ç™½å…µ_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[three_black_crows, 'ä¸‰é»‘é´‰_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 7. è­˜åˆ¥ç©¿åˆºç·š (Piercing) å’Œçƒé›²è“‹é ‚ (Dark Cloud Cover)\n",
        "    piercing = (\n",
        "        (~result_df['prev_is_bullish']) &  # å‰ä¸€å¤©æ˜¯ä¸‹è·Œ\n",
        "        result_df['is_bullish'] &          # ç•¶å¤©æ˜¯ä¸Šæ¼²\n",
        "        (result_df['open'] < result_df['prev_low']) &  # é–‹ç›¤ä½æ–¼å‰ä¸€å¤©æœ€ä½åƒ¹\n",
        "        (result_df['close'] > (result_df['prev_open'] + result_df['prev_close']) / 2) &  # æ”¶ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©å¯¦é«”ä¸­é»\n",
        "        (result_df['close'] < result_df['prev_open'])  # æ”¶ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©é–‹ç›¤åƒ¹\n",
        "    )\n",
        "\n",
        "    dark_cloud_cover = (\n",
        "        result_df['prev_is_bullish'] &     # å‰ä¸€å¤©æ˜¯ä¸Šæ¼²\n",
        "        (~result_df['is_bullish']) &       # ç•¶å¤©æ˜¯ä¸‹è·Œ\n",
        "        (result_df['open'] > result_df['prev_high']) &  # é–‹ç›¤é«˜æ–¼å‰ä¸€å¤©æœ€é«˜åƒ¹\n",
        "        (result_df['close'] < (result_df['prev_open'] + result_df['prev_close']) / 2) &  # æ”¶ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©å¯¦é«”ä¸­é»\n",
        "        (result_df['close'] > result_df['prev_close'])  # æ”¶ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©æ”¶ç›¤åƒ¹\n",
        "    )\n",
        "\n",
        "    result_df.loc[piercing & result_df['downtrend'], 'ç©¿åˆºç·š_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[dark_cloud_cover & result_df['uptrend'], 'çƒé›²è“‹é ‚_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 8. è­˜åˆ¥é•·è…³åå­—ç·š (Long-Legged Doji)\n",
        "    long_legged_doji = (\n",
        "        doji_condition &\n",
        "        (result_df['upper_shadow'] >= 0.3 * result_df['total_range']) &\n",
        "        (result_df['lower_shadow'] >= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "\n",
        "    result_df.loc[long_legged_doji, 'é•·è…³åå­—ç·š_ä¸­æ€§'] = 1\n",
        "\n",
        "    # 9. è­˜åˆ¥ä¸ŠåŠç·š (Hanging Man)\n",
        "    hanging_man = (\n",
        "        (result_df['lower_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['upper_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range']) &\n",
        "        result_df['uptrend']\n",
        "    )\n",
        "\n",
        "    result_df.loc[hanging_man, 'ä¸ŠåŠç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 10. è­˜åˆ¥é™€èº (Spinning Top)\n",
        "    spinning_top = (\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range']) &\n",
        "        (result_df['upper_shadow'] >= 0.2 * result_df['total_range']) &\n",
        "        (result_df['lower_shadow'] >= 0.2 * result_df['total_range'])\n",
        "    )\n",
        "\n",
        "    result_df.loc[spinning_top, 'é™€èº_ä¸­æ€§'] = 1\n",
        "\n",
        "    # 11. è­˜åˆ¥åè½‰å‹æ…‹ (Reversal)\n",
        "    # çœ‹æ¼²åè½‰: åœ¨ä¸‹è·Œè¶¨å‹¢ä¸­ï¼Œå‡ºç¾ä¸€æ ¹å¤§é™½ç·šï¼Œæ”¶ç›¤åƒ¹é«˜æ–¼å‰å¹¾å¤©çš„æœ€é«˜åƒ¹\n",
        "    bullish_reversal = (\n",
        "        result_df['is_bullish'] &\n",
        "        result_df['downtrend'] &\n",
        "        (result_df['close'] > result_df[['prev_high', 'prev2_high']].max(axis=1))\n",
        "    )\n",
        "\n",
        "    # çœ‹è·Œåè½‰: åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­ï¼Œå‡ºç¾ä¸€æ ¹å¤§é™°ç·šï¼Œæ”¶ç›¤åƒ¹ä½æ–¼å‰å¹¾å¤©çš„æœ€ä½åƒ¹\n",
        "    bearish_reversal = (\n",
        "        (~result_df['is_bullish']) &\n",
        "        result_df['uptrend'] &\n",
        "        (result_df['close'] < result_df[['prev_low', 'prev2_low']].min(axis=1))\n",
        "    )\n",
        "\n",
        "    result_df.loc[bullish_reversal, 'åè½‰_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[bearish_reversal, 'åè½‰_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 12. è­˜åˆ¥å³¶å½¢åè½‰ (Island Reversal)\n",
        "    # çœ‹æ¼²å³¶å½¢åè½‰: åœ¨ä¸‹è·Œè¶¨å‹¢ä¸­ï¼Œå‡ºç¾å‘ä¸‹è·³ç©ºï¼Œç„¶å¾Œåƒ¹æ ¼åœ¨ä½ä½ç›¤æ•´ï¼Œæœ€å¾Œå‘ä¸Šè·³ç©º\n",
        "    bullish_island_reversal = (\n",
        "        result_df['downtrend'] &\n",
        "        (result_df['low'] > result_df['prev_high']) &  # å‘ä¸Šè·³ç©º\n",
        "        (result_df['prev_low'] > result_df['prev2_high'])  # å‰ä¸€å¤©å‘ä¸‹è·³ç©º\n",
        "    )\n",
        "\n",
        "    # çœ‹è·Œå³¶å½¢åè½‰: åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­ï¼Œå‡ºç¾å‘ä¸Šè·³ç©ºï¼Œç„¶å¾Œåƒ¹æ ¼åœ¨é«˜ä½ç›¤æ•´ï¼Œæœ€å¾Œå‘ä¸‹è·³ç©º\n",
        "    bearish_island_reversal = (\n",
        "        result_df['uptrend'] &\n",
        "        (result_df['high'] < result_df['prev_low']) &  # å‘ä¸‹è·³ç©º\n",
        "        (result_df['prev_high'] < result_df['prev2_low'])  # å‰ä¸€å¤©å‘ä¸Šè·³ç©º\n",
        "    )\n",
        "\n",
        "    result_df.loc[bullish_island_reversal, 'å³¶å½¢åè½‰_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[bearish_island_reversal, 'å³¶å½¢åè½‰_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # 13. è­˜åˆ¥é ­è‚©é ‚å’Œé ­è‚©åº•\n",
        "    # é€™äº›å‹æ…‹éœ€è¦æ›´å¤šçš„æ•¸æ“šé»å’Œè¤‡é›œçš„é‚è¼¯ï¼Œé€™è£¡æä¾›ä¸€å€‹ç°¡åŒ–ç‰ˆæœ¬\n",
        "\n",
        "    # é ­è‚©é ‚: ä¸‰å€‹é«˜é»ï¼Œä¸­é–“çš„é«˜é»æœ€é«˜ï¼Œå…©å´é«˜é»å¤§è‡´ç›¸ç­‰\n",
        "    head_shoulders_top = (\n",
        "        result_df['uptrend'] &\n",
        "        (result_df['prev2_high'] < result_df['prev_high']) &  # å·¦è‚©ä½æ–¼é ­éƒ¨\n",
        "        (result_df['high'] < result_df['prev_high']) &        # å³è‚©ä½æ–¼é ­éƒ¨\n",
        "        (abs(result_df['high'] - result_df['prev2_high']) / result_df['prev2_high'] < 0.05)  # å·¦å³è‚©å¤§è‡´ç›¸ç­‰\n",
        "    )\n",
        "\n",
        "    # é ­è‚©åº•: ä¸‰å€‹ä½é»ï¼Œä¸­é–“çš„ä½é»æœ€ä½ï¼Œå…©å´ä½é»å¤§è‡´ç›¸ç­‰\n",
        "    head_shoulders_bottom = (\n",
        "        result_df['downtrend'] &\n",
        "        (result_df['prev2_low'] > result_df['prev_low']) &  # å·¦è‚©é«˜æ–¼é ­éƒ¨\n",
        "        (result_df['low'] > result_df['prev_low']) &        # å³è‚©é«˜æ–¼é ­éƒ¨\n",
        "        (abs(result_df['low'] - result_df['prev2_low']) / result_df['prev2_low'] < 0.05)  # å·¦å³è‚©å¤§è‡´ç›¸ç­‰\n",
        "    )\n",
        "\n",
        "    result_df.loc[head_shoulders_top, 'é ­è‚©é ‚_çœ‹è·Œ'] = -1\n",
        "    result_df.loc[head_shoulders_bottom, 'é ­è‚©åº•_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # 14. è­˜åˆ¥é›™é ‚å’Œé›™åº•\n",
        "    # é›™é ‚: å…©å€‹ç›¸è¿‘çš„é«˜é»ï¼Œä¸­é–“æœ‰ä¸€å€‹ä½é»\n",
        "    double_top = (\n",
        "        result_df['uptrend'] &\n",
        "        (abs(result_df['high'] - result_df['prev2_high']) / result_df['prev2_high'] < 0.03) &  # å…©å€‹é«˜é»ç›¸è¿‘\n",
        "        (result_df['prev_high'] < result_df['high']) &  # ä¸­é–“æœ‰ä¸€å€‹ä½é»\n",
        "        (result_df['prev_high'] < result_df['prev2_high'])\n",
        "    )\n",
        "\n",
        "    # é›™åº•: å…©å€‹ç›¸è¿‘çš„ä½é»ï¼Œä¸­é–“æœ‰ä¸€å€‹é«˜é»\n",
        "    double_bottom = (\n",
        "        result_df['downtrend'] &\n",
        "        (abs(result_df['low'] - result_df['prev2_low']) / result_df['prev2_low'] < 0.03) &  # å…©å€‹ä½é»ç›¸è¿‘\n",
        "        (result_df['prev_low'] > result_df['low']) &  # ä¸­é–“æœ‰ä¸€å€‹é«˜é»\n",
        "        (result_df['prev_low'] > result_df['prev2_low'])\n",
        "    )\n",
        "\n",
        "    result_df.loc[double_top, 'é›™é ‚_çœ‹è·Œ'] = -1\n",
        "    result_df.loc[double_bottom, 'é›™åº•_çœ‹æ¼²'] = 1\n",
        "\n",
        "    return result_df\n",
        "# ==============================================================================\n",
        "# Kç·šå‹æ…‹å„ªå…ˆç´šå®šç¾© (æ•¸å­—è¶Šå¤§å„ªå…ˆç´šè¶Šé«˜)\n",
        "PATTERN_PRIORITY = {\n",
        "    # é ‚éƒ¨åè½‰å‹æ…‹ (é«˜å„ªå…ˆç´š)\n",
        "    \"é ­è‚©é ‚\": 10,\n",
        "    \"é›™é ‚\": 9,\n",
        "    \"ä¸‰é ‚\": 8,\n",
        "    \"åœ“é ‚\": 7,\n",
        "    \"ä¸Šå‡æ¥”å½¢\": 7,\n",
        "    \"ä¸Šå‡ä¸‰è§’å½¢\": 6,\n",
        "\n",
        "    # åº•éƒ¨åè½‰å‹æ…‹ (é«˜å„ªå…ˆç´š)\n",
        "    \"é ­è‚©åº•\": 10,\n",
        "    \"é›™åº•\": 9,\n",
        "    \"ä¸‰åº•\": 8,\n",
        "    \"åœ“åº•\": 7,\n",
        "    \"ä¸‹é™æ¥”å½¢\": 7,\n",
        "    \"ä¸‹é™ä¸‰è§’å½¢\": 6,\n",
        "\n",
        "    # æŒçºŒå‹æ…‹ (ä¸­ç­‰å„ªå…ˆç´š)\n",
        "    \"å°ç¨±ä¸‰è§’å½¢\": 5,\n",
        "    \"çŸ©å½¢\": 5,\n",
        "    \"æ——å½¢\": 4,\n",
        "    \"ä¸‰è§’æ——\": 4,\n",
        "\n",
        "    # å–®æ—¥å‹æ…‹ (è¼ƒä½å„ªå…ˆç´š)\n",
        "    \"åå™¬\": 3,\n",
        "    \"åå­—æ˜Ÿ\": 3,\n",
        "    \"éŒ˜å­\": 3,\n",
        "    \"ä¸ŠåŠç·š\": 3,\n",
        "    \"æµæ˜Ÿ\": 3,\n",
        "    \"å¤šé ­åå™¬\": 3,\n",
        "    \"ç©ºé ­åå™¬\": 3,\n",
        "    \"å¤šé ­åˆºé€\": 2,\n",
        "    \"ç©ºé ­çƒé›²è“‹é ‚\": 2,\n",
        "    \"å¤šé ­åè½‰\": 2,\n",
        "    \"ç©ºé ­åè½‰\": 2,\n",
        "\n",
        "    # ç¼ºå£å‹æ…‹\n",
        "    \"çªç ´ç¼ºå£\": 3,\n",
        "    \"é€ƒé€¸ç¼ºå£\": 3,\n",
        "    \"æ¶ˆè€—ç¼ºå£\": 2,\n",
        "\n",
        "    # å…¶ä»–å¸¸è¦‹å‹æ…‹\n",
        "    \"å³¶ç‹€åè½‰\": 6,\n",
        "    \"Vå‹åè½‰\": 5,\n",
        "    \"Wå‹åè½‰\": 5,\n",
        "    \"ç®±é«”çªç ´\": 4,\n",
        "    \"é»ƒæ˜ä¹‹æ˜Ÿ\": 4,\n",
        "    \"æ›™å…‰ä¹‹æ˜Ÿ\": 4,\n",
        "    \"å¤šé ­ä¸‰æ˜Ÿ\": 3,\n",
        "    \"ç©ºé ­ä¸‰æ˜Ÿ\": 3\n",
        "}\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def generate_condensed_pattern_report_and_summary(full_pattern_report):\n",
        "    \"\"\"\n",
        "    å°‡å®Œæ•´çš„Kç·šå‹æ…‹å ±å‘Šç°¡åŒ–ç‚ºç²¾è¯æ‘˜è¦ï¼Œä¸¦æå–çµæ§‹åŒ–æ•¸æ“š\n",
        "\n",
        "    Args:\n",
        "        full_pattern_report (str): å®Œæ•´çš„Kç·šå‹æ…‹å ±å‘Š\n",
        "\n",
        "    Returns:\n",
        "        tuple: (condensed_report, report_summary)\n",
        "            - condensed_report (str): ç°¡åŒ–å¾Œçš„å ±å‘Šæ–‡æœ¬\n",
        "            - report_summary (dict): çµæ§‹åŒ–çš„å ±å‘Šæ‘˜è¦æ•¸æ“š\n",
        "    \"\"\"\n",
        "    # åˆå§‹åŒ–è¿”å›å€¼\n",
        "    condensed_report = \"\"\n",
        "    report_summary = {\n",
        "        \"daily\": {\"bullish\": [], \"bearish\": [], \"neutral\": []},\n",
        "        \"weekly\": {\"bullish\": [], \"bearish\": [], \"neutral\": []},\n",
        "        \"monthly\": {\"bullish\": [], \"bearish\": [], \"neutral\": []}\n",
        "    }\n",
        "\n",
        "    # æª¢æŸ¥å ±å‘Šæ˜¯å¦ç‚ºç©ºæˆ–ç„¡æ•ˆ\n",
        "    if not full_pattern_report or not isinstance(full_pattern_report, str):\n",
        "        return \"ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼šå ±å‘Šç‚ºç©ºæˆ–æ ¼å¼éŒ¯èª¤\", report_summary\n",
        "\n",
        "    try:\n",
        "        # å°‡å ±å‘Šåˆ†å‰²ç‚ºä¸åŒæ™‚é–“é€±æœŸçš„éƒ¨åˆ†\n",
        "        periods = [\"æ—¥ç·š\", \"é€±ç·š\", \"æœˆç·š\"]\n",
        "        period_keys = [\"daily\", \"weekly\", \"monthly\"]\n",
        "        pattern_types = [\"çœ‹æ¼²\", \"çœ‹è·Œ\", \"ä¸­æ€§\"]\n",
        "        type_keys = [\"bullish\", \"bearish\", \"neutral\"]\n",
        "\n",
        "        # åˆå§‹åŒ–çµæœå­—ç¬¦ä¸²\n",
        "        result_parts = []\n",
        "\n",
        "        # æª¢æŸ¥å ±å‘Šæ ¼å¼ - å˜—è©¦å°‹æ‰¾æ™‚é–“é€±æœŸæ¨™è¨˜\n",
        "        has_valid_format = False\n",
        "        for period in periods:\n",
        "            if period in full_pattern_report:\n",
        "                has_valid_format = True\n",
        "                break\n",
        "\n",
        "        if not has_valid_format:\n",
        "            # å¦‚æœå ±å‘Šæ²’æœ‰é æœŸçš„æ ¼å¼ï¼Œå˜—è©¦ç›´æ¥è§£ææ–‡æœ¬\n",
        "            lines = full_pattern_report.strip().split('\\n')\n",
        "            if lines:\n",
        "                condensed_report = \"Kç·šå‹æ…‹æ‘˜è¦:\\n\"\n",
        "                for line in lines[:10]:  # åªå–å‰10è¡Œ\n",
        "                    if line.strip():\n",
        "                        condensed_report += f\"â€¢ {line.strip()}\\n\"\n",
        "\n",
        "                # ç°¡å–®æª¢æ¸¬å ±å‘Šä¸­çš„é—œéµè©ä¾†å¡«å……æ‘˜è¦\n",
        "                for i, period_key in enumerate(period_keys):\n",
        "                    for j, type_key in enumerate(type_keys):\n",
        "                        for line in lines:\n",
        "                            if pattern_types[j] in line:\n",
        "                                pattern = line.strip()\n",
        "                                report_summary[period_key][type_key].append(pattern)\n",
        "\n",
        "                return condensed_report, report_summary\n",
        "\n",
        "        # æ­£å¸¸è§£ææ ¼å¼åŒ–å ±å‘Š\n",
        "        for i, period in enumerate(periods):\n",
        "            period_key = period_keys[i]\n",
        "            period_section = \"\"\n",
        "\n",
        "            # å°‹æ‰¾è©²æ™‚é–“é€±æœŸçš„éƒ¨åˆ†\n",
        "            start_idx = full_pattern_report.find(f\"{period}åˆ†æ:\")\n",
        "            if start_idx == -1:\n",
        "                continue\n",
        "\n",
        "            end_idx = -1\n",
        "            for next_period in periods[i+1:]:\n",
        "                end_idx = full_pattern_report.find(f\"{next_period}åˆ†æ:\", start_idx)\n",
        "                if end_idx != -1:\n",
        "                    break\n",
        "\n",
        "            if end_idx == -1:\n",
        "                period_content = full_pattern_report[start_idx:]\n",
        "            else:\n",
        "                period_content = full_pattern_report[start_idx:end_idx]\n",
        "\n",
        "            # è§£æè©²æ™‚é–“é€±æœŸä¸‹çš„å‹æ…‹\n",
        "            period_lines = []\n",
        "            for j, pattern_type in enumerate(pattern_types):\n",
        "                type_key = type_keys[j]\n",
        "                type_start = period_content.find(f\"{pattern_type}å‹æ…‹:\")\n",
        "                if type_start == -1:\n",
        "                    continue\n",
        "\n",
        "                type_end = -1\n",
        "                for next_type in pattern_types[j+1:]:\n",
        "                    type_end = period_content.find(f\"{next_type}å‹æ…‹:\", type_start)\n",
        "                    if type_end != -1:\n",
        "                        break\n",
        "\n",
        "                if type_end == -1:\n",
        "                    type_content = period_content[type_start:]\n",
        "                else:\n",
        "                    type_content = period_content[type_start:type_end]\n",
        "\n",
        "                # æå–å‹æ…‹åˆ—è¡¨\n",
        "                pattern_list_start = type_content.find(\":\")\n",
        "                if pattern_list_start != -1:\n",
        "                    pattern_list = type_content[pattern_list_start+1:].strip()\n",
        "                    patterns = [p.strip() for p in pattern_list.split(',') if p.strip() and p.strip() != 'ç„¡']\n",
        "\n",
        "                    # æ·»åŠ åˆ°æ‘˜è¦æ•¸æ“š\n",
        "                    report_summary[period_key][type_key].extend(patterns)\n",
        "\n",
        "                    # åªæœ‰ç•¶æœ‰å‹æ…‹æ™‚æ‰æ·»åŠ åˆ°å ±å‘Šä¸­\n",
        "                    if patterns:\n",
        "                        pattern_line = f\"â€¢ {pattern_type}: {', '.join(patterns)}\"\n",
        "                        period_lines.append(pattern_line)\n",
        "\n",
        "            # åªæœ‰ç•¶è©²æ™‚é–“é€±æœŸæœ‰å‹æ…‹æ™‚æ‰æ·»åŠ åˆ°æœ€çµ‚å ±å‘Š\n",
        "            if period_lines:\n",
        "                period_section = f\"{period}åˆ†æ:\\n\" + \"\\n\".join(period_lines)\n",
        "                result_parts.append(period_section)\n",
        "\n",
        "        # çµ„åˆæœ€çµ‚å ±å‘Š\n",
        "        if result_parts:\n",
        "            condensed_report = \"\\n\\n\".join(result_parts)\n",
        "        else:\n",
        "            condensed_report = \"æœªæª¢æ¸¬åˆ°æ˜é¡¯Kç·šå‹æ…‹\"\n",
        "\n",
        "        return condensed_report, report_summary\n",
        "\n",
        "    except Exception as e:\n",
        "        # å¦‚æœè§£æéç¨‹ä¸­å‡ºç¾ä»»ä½•éŒ¯èª¤ï¼Œè¿”å›ä¸€å€‹ç°¡å–®çš„éŒ¯èª¤ä¿¡æ¯\n",
        "        error_msg = f\"ç„¡æ³•è§£æKç·šå ±å‘Š: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        return \"ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼šè§£æéç¨‹å‡ºéŒ¯\", report_summary\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. æ–°å¢ï¼šæ™ºèƒ½äº¤æ˜“å»ºè­°å¼•æ“\n",
        "# ==============================================================================\n",
        "# ==============================================================================\n",
        "# å‡ç´šï¼šæ™ºèƒ½å»ºè­°å¼•æ“ V2 (æ›¿æ›èˆŠç‰ˆæœ¬)\n",
        "# åŠŸèƒ½ï¼šçµåˆç¶œåˆè©•åˆ†èˆ‡Kç·šçµæ§‹åŒ–å ±å‘Šï¼Œç”Ÿæˆæ›´æ·±å…¥çš„å»ºè­°\n",
        "# ==============================================================================\n",
        "import math\n",
        "import logging\n",
        "\n",
        "def generate_recommendation(combined_score, report_summary=None):\n",
        "    \"\"\"\n",
        "    æ ¹æ“šç¶œåˆè©•åˆ†å’Œè©³ç´°çš„Kç·šå‹æ…‹å ±å‘Šç”ŸæˆæŠ•è³‡å»ºè­°ã€åŸå› ã€ä¿¡å¿ƒåº¦åŠå‹æ…‹è©³æƒ…ã€‚\n",
        "    \"\"\"\n",
        "    # ğŸ” èª¿è©¦ä¿¡æ¯ï¼šç¢ºèªå‡½æ•¸è¢«èª¿ç”¨ä¸”åƒæ•¸æ­£ç¢º\n",
        "    #print(f\"ğŸ” [DEBUG] generate_recommendation è¢«èª¿ç”¨:\")\n",
        "    print(f\"    combined_score: {combined_score} (type: {type(combined_score)})\")\n",
        "    print(f\"    report_summary: {report_summary is not None}\")\n",
        "\n",
        "    # ç¢ºä¿ combined_score æ˜¯æ•¸å­—é¡å‹\n",
        "    try:\n",
        "        combined_score = float(combined_score)\n",
        "    except (ValueError, TypeError):\n",
        "        print(f\"âš ï¸  [WARNING] combined_score ç„¡æ³•è½‰æ›ç‚ºæ•¸å­—ï¼Œä½¿ç”¨é è¨­å€¼ 50\")\n",
        "        combined_score = 50.0\n",
        "\n",
        "    # --- ç¬¬1æ­¥ï¼šæ ¹æ“šç¶œåˆè©•åˆ†è¨­å®šåŸºæœ¬å»ºè­° ---\n",
        "    recommendation = {\n",
        "        \"action\": \"ä¸­ç«‹è§€å¯Ÿ\",\n",
        "        \"reason\": f\"ç¶œåˆè©•åˆ†ä¸­æ€§ ({combined_score:.2f})ã€‚\",\n",
        "        \"pattern_details\": []\n",
        "    }\n",
        "\n",
        "    if combined_score >= 70:\n",
        "        recommendation[\"action\"] = \"è²·å…¥\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†å¼·å‹ ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score >= 60:\n",
        "        recommendation[\"action\"] = \"è²·å…¥è§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼· ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score <= 30:\n",
        "        recommendation[\"action\"] = \"è³£å‡º\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†ç–²å¼± ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score <= 40:\n",
        "        recommendation[\"action\"] = \"è³£å‡ºè§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼± ({combined_score:.2f})ã€‚\"\n",
        "\n",
        "    # --- ç¬¬2æ­¥ï¼šæ ¹æ“šKç·šå‹æ…‹å¾®èª¿å»ºè­° ---\n",
        "    pattern_boost = 0  # Kç·šå‹æ…‹å°ä¿¡å¿ƒåº¦çš„åŠ æˆ\n",
        "\n",
        "    if report_summary:\n",
        "        try:\n",
        "            # è¨ˆç®—åŠ æ¬Šå¾Œçš„Kç·šå‹æ…‹æ•¸é‡\n",
        "            bullish_count = len(report_summary.get('daily', {}).get('bullish', [])) \\\n",
        "                          + len(report_summary.get('weekly', {}).get('bullish', [])) * 2 \\\n",
        "                          + len(report_summary.get('monthly', {}).get('monthly', [])) * 3\n",
        "            bearish_count = len(report_summary.get('daily', {}).get('bearish', [])) \\\n",
        "                          + len(report_summary.get('weekly', {}).get('bearish', [])) * 2 \\\n",
        "                          + len(report_summary.get('monthly', {}).get('bearish', [])) * 3\n",
        "\n",
        "            #print(f\"ğŸ” [DEBUG] Kç·šå‹æ…‹çµ±è¨ˆ: çœ‹æ¼²={bullish_count}, çœ‹è·Œ={bearish_count}\")\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦æœ‰å¼·çƒˆçš„Kç·šä¿¡è™Ÿ\n",
        "            if bullish_count >= 3 and bullish_count > bearish_count * 1.5:\n",
        "                if combined_score >= 50:\n",
        "                    recommendation[\"action\"] = \"å¼·çƒˆè²·å…¥\"\n",
        "                    recommendation[\"reason\"] += \" å¤šå€‹çœ‹æ¼²Kç·šå‹æ…‹æä¾›å¼·åŠ›æ”¯æ’ã€‚\"\n",
        "                    pattern_boost = 20  # å¼·çƒˆä¿¡è™ŸåŠ æˆ\n",
        "                else:\n",
        "                    recommendation[\"action\"] = \"è²·å…¥è§€æœ›\"\n",
        "                    recommendation[\"reason\"] += \" Kç·šå‹æ…‹çœ‹æ¼²ï¼Œä½†éœ€æ³¨æ„æŠ€è¡“æŒ‡æ¨™è¼ƒå¼±ã€‚\"\n",
        "                    pattern_boost = 10\n",
        "            elif bearish_count >= 3 and bearish_count > bullish_count * 1.5:\n",
        "                if combined_score <= 50:\n",
        "                    recommendation[\"action\"] = \"å¼·çƒˆè³£å‡º\"\n",
        "                    recommendation[\"reason\"] += \" å¤šå€‹çœ‹è·ŒKç·šå‹æ…‹æ§‹æˆå¼·åŠ›å£“åŠ›ã€‚\"\n",
        "                    pattern_boost = 20  # å¼·çƒˆä¿¡è™ŸåŠ æˆ\n",
        "                else:\n",
        "                    recommendation[\"action\"] = \"è³£å‡ºè§€æœ›\"\n",
        "                    recommendation[\"reason\"] += \" Kç·šå‹æ…‹çœ‹è·Œï¼Œä½†éœ€æ³¨æ„æŠ€è¡“æŒ‡æ¨™è¼ƒå¼·ã€‚\"\n",
        "                    pattern_boost = 10\n",
        "            elif bullish_count > bearish_count:\n",
        "                recommendation[\"reason\"] += \" Kç·šå‹æ…‹æ•´é«”åå‘çœ‹æ¼²ã€‚\"\n",
        "                pattern_boost = 5\n",
        "            elif bearish_count > bullish_count:\n",
        "                recommendation[\"reason\"] += \" Kç·šå‹æ…‹æ•´é«”åå‘çœ‹è·Œã€‚\"\n",
        "                pattern_boost = 5\n",
        "\n",
        "            # æ•´ç†Kç·šå‹æ…‹è©³æƒ…\n",
        "            pattern_details = []\n",
        "            for period in ['daily', 'weekly', 'monthly']:\n",
        "                period_data = report_summary.get(period, {})\n",
        "                period_patterns = []\n",
        "                if period_data.get('bullish'):\n",
        "                    period_patterns.append(f\"çœ‹æ¼²: {', '.join(period_data['bullish'])}\")\n",
        "                if period_data.get('bearish'):\n",
        "                    period_patterns.append(f\"çœ‹è·Œ: {', '.join(period_data['bearish'])}\")\n",
        "\n",
        "                if period_patterns:\n",
        "                    period_name = {'daily': 'æ—¥ç·š', 'weekly': 'é€±ç·š', 'monthly': 'æœˆç·š'}[period]\n",
        "                    pattern_details.append(f\"{period_name}: {'; '.join(period_patterns)}\")\n",
        "\n",
        "            if pattern_details:\n",
        "                recommendation[\"pattern_details\"] = pattern_details\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†Kç·šå ±å‘Šæ‘˜è¦æ™‚å‡ºéŒ¯: {str(e)}\")\n",
        "\n",
        "    # --- ç¬¬3æ­¥ï¼šè¨ˆç®—ä¿¡å¿ƒåº¦ï¼ˆä¿®æ­£ç‰ˆï¼‰ ---\n",
        "    # ä½¿ç”¨ç·šæ€§å‡½æ•¸è€Œéå¹³æ–¹å‡½æ•¸ï¼Œè®“ä¿¡å¿ƒåº¦æ›´åˆç†\n",
        "    distance_from_center = abs(combined_score - 50)\n",
        "\n",
        "    # åŸºç¤ä¿¡å¿ƒåº¦ï¼šè·é›¢ä¸­å¿ƒè¶Šé ï¼Œä¿¡å¿ƒåº¦è¶Šé«˜\n",
        "    base_confidence = min(distance_from_center * 2, 100)  # æ¯åé›¢1åˆ†å¢åŠ 2%ä¿¡å¿ƒåº¦ï¼Œæœ€é«˜100%\n",
        "\n",
        "    # åŠ ä¸ŠKç·šå‹æ…‹åŠ æˆ\n",
        "    total_confidence = min(base_confidence + pattern_boost, 100)\n",
        "\n",
        "    recommendation['confidence'] = int(total_confidence)\n",
        "\n",
        "    # ğŸ” èª¿è©¦ä¿¡æ¯ï¼šç¢ºèªä¿¡å¿ƒåº¦è¨ˆç®—\n",
        "    #print(f\"ğŸ” [DEBUG] ä¿¡å¿ƒåº¦è¨ˆç®—:\")\n",
        "    #print(f\"    distance_from_center: {distance_from_center}\")\n",
        "    #print(f\"    base_confidence: {base_confidence}\")\n",
        "    #print(f\"    pattern_boost: {pattern_boost}\")\n",
        "    #print(f\"    total_confidence: {total_confidence}\")\n",
        "    #print(f\"ğŸ” [DEBUG] æœ€çµ‚å»ºè­°: {recommendation}\")\n",
        "    #print(\"-\" * 50)\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "\n",
        "def get_pattern_explanation(pattern_name):\n",
        "    \"\"\"\n",
        "    ç²å–Kç·šå‹æ…‹çš„è§£é‡‹å’Œäº¤æ˜“å»ºè­°\n",
        "\n",
        "    åƒæ•¸:\n",
        "    pattern_name - Kç·šå‹æ…‹åç¨±\n",
        "\n",
        "    è¿”å›:\n",
        "    dict - åŒ…å«è§£é‡‹å’Œå»ºè­°çš„å­—å…¸\n",
        "    \"\"\"\n",
        "    pattern_dict = {\n",
        "        \"çœ‹æ¼²éŒ˜å­ç·š\": {\n",
        "            \"explanation\": \"åœ¨ä¸‹è·Œè¶¨å‹¢ä¸­å‡ºç¾ï¼Œå…·æœ‰è¼ƒé•·çš„ä¸‹å½±ç·šï¼Œè¡¨ç¤ºè²·æ–¹åŠ›é‡æ­£åœ¨å¢å¼·ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½æ˜¯åº•éƒ¨åè½‰ä¿¡è™Ÿï¼Œè€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨éŒ˜å­ç·šçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·ŒéŒ˜å­ç·š\": {\n",
        "            \"explanation\": \"åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­å‡ºç¾ï¼Œå…·æœ‰è¼ƒé•·çš„ä¸‹å½±ç·šï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡æ­£åœ¨å¢å¼·ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½æ˜¯é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œè€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨éŒ˜å­ç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œæµæ˜Ÿç·š\": {\n",
        "            \"explanation\": \"åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­å‡ºç¾ï¼Œå…·æœ‰è¼ƒé•·çš„ä¸Šå½±ç·šï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡æ­£åœ¨å¢å¼·ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½æ˜¯é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œè€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨æµæ˜Ÿç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"ä¸­æ€§åå­—æ˜Ÿ\": {\n",
        "            \"explanation\": \"é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒï¼Œè¡¨ç¤ºå¸‚å ´çŒ¶è±«ä¸æ±ºï¼Œå¤šç©ºåŠ›é‡å‡è¡¡ã€‚\",\n",
        "            \"suggestion\": \"é€šå¸¸è¡¨ç¤ºè¶¨å‹¢å¯èƒ½å³å°‡åè½‰ï¼Œå»ºè­°ç­‰å¾…ç¢ºèªä¿¡è™Ÿã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²åå™¬\": {\n",
        "            \"explanation\": \"å°é™°ç·šå¾Œå‡ºç¾å¤§é™½ç·šï¼Œä¸”é™½ç·šå®Œå…¨ã€Œåå™¬ã€äº†å‰ä¸€å¤©çš„é™°ç·šå¯¦é«”ï¼Œè¡¨ç¤ºè²·æ–¹åŠ›é‡å¼·å‹ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„çœ‹æ¼²ä¿¡è™Ÿï¼Œç‰¹åˆ¥æ˜¯åœ¨ä¸‹è·Œè¶¨å‹¢æœ«æœŸï¼Œå¯è€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨åå™¬Kç·šçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œåå™¬\": {\n",
        "            \"explanation\": \"å°é™½ç·šå¾Œå‡ºç¾å¤§é™°ç·šï¼Œä¸”é™°ç·šå®Œå…¨ã€Œåå™¬ã€äº†å‰ä¸€å¤©çš„é™½ç·šå¯¦é«”ï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡å¼·å‹ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„çœ‹è·Œä¿¡è™Ÿï¼Œç‰¹åˆ¥æ˜¯åœ¨ä¸Šæ¼²è¶¨å‹¢æœ«æœŸï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨åå™¬Kç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²æ¯å­ç·š\": {\n",
        "            \"explanation\": \"å¤§é™°ç·šå¾Œå‡ºç¾å°é™½ç·šï¼Œä¸”å°é™½ç·šå®Œå…¨åœ¨å‰ä¸€å¤©å¤§é™°ç·šå¯¦é«”ç¯„åœå…§ï¼Œè¡¨ç¤ºä¸‹è·Œå‹•èƒ½æ¸›å¼±ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½çš„åº•éƒ¨åè½‰ä¿¡è™Ÿï¼Œå»ºè­°ç­‰å¾…é€²ä¸€æ­¥ç¢ºèªå¾Œå†åšå¤šï¼Œæ­¢æè¨­åœ¨æ¯å­ç·šçµ„åˆçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œæ¯å­ç·š\": {\n",
        "            \"explanation\": \"å¤§é™½ç·šå¾Œå‡ºç¾å°é™°ç·šï¼Œä¸”å°é™°ç·šå®Œå…¨åœ¨å‰ä¸€å¤©å¤§é™½ç·šå¯¦é«”ç¯„åœå…§ï¼Œè¡¨ç¤ºä¸Šæ¼²å‹•èƒ½æ¸›å¼±ã€‚\",\n",
        "            \"suggestion\": \"å¯èƒ½çš„é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œå»ºè­°ç­‰å¾…é€²ä¸€æ­¥ç¢ºèªå¾Œå†åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨æ¯å­ç·šçµ„åˆçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²æ™¨æ˜Ÿ\": {\n",
        "            \"explanation\": \"ç”±ä¸‰æ ¹Kç·šçµ„æˆï¼šå¤§é™°ç·šã€å°å¯¦é«”ç·šï¼ˆé€šå¸¸æ˜¯åå­—æ˜Ÿï¼‰å’Œå¤§é™½ç·šï¼Œè¡¨ç¤ºå¸‚å ´ç”±ç©ºé ­è½‰ç‚ºå¤šé ­ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„åº•éƒ¨åè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨æ™¨æ˜Ÿçµ„åˆçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œæš®æ˜Ÿ\": {\n",
        "            \"explanation\": \"ç”±ä¸‰æ ¹Kç·šçµ„æˆï¼šå¤§é™½ç·šã€å°å¯¦é«”ç·šï¼ˆé€šå¸¸æ˜¯åå­—æ˜Ÿï¼‰å’Œå¤§é™°ç·šï¼Œè¡¨ç¤ºå¸‚å ´ç”±å¤šé ­è½‰ç‚ºç©ºé ­ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨æš®æ˜Ÿçµ„åˆçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²ä¸‰ç™½å…µ\": {\n",
        "            \"explanation\": \"é€£çºŒä¸‰æ ¹ä¸Šæ¼²çš„é™½ç·šï¼Œæ¯æ ¹çš„æ”¶ç›¤åƒ¹éƒ½é«˜æ–¼å‰ä¸€æ ¹ï¼Œè¡¨ç¤ºè²·æ–¹æŒçºŒæ§åˆ¶å¸‚å ´ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„ä¸Šæ¼²è¶¨å‹¢ç¢ºèªä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨ç¬¬ä¸€æ ¹Kç·šçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œä¸‰é»‘é´‰\": {\n",
        "            \"explanation\": \"é€£çºŒä¸‰æ ¹ä¸‹è·Œçš„é™°ç·šï¼Œæ¯æ ¹çš„æ”¶ç›¤åƒ¹éƒ½ä½æ–¼å‰ä¸€æ ¹ï¼Œè¡¨ç¤ºè³£æ–¹æŒçºŒæ§åˆ¶å¸‚å ´ã€‚\",\n",
        "            \"suggestion\": \"å¼·çƒˆçš„ä¸‹è·Œè¶¨å‹¢ç¢ºèªä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨ç¬¬ä¸€æ ¹Kç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹æ¼²ç©¿åˆºç·š\": {\n",
        "            \"explanation\": \"å¤§é™°ç·šå¾Œå‡ºç¾å¤§é™½ç·šï¼Œä¸”é™½ç·šé–‹ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©æœ€ä½åƒ¹ï¼Œæ”¶ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©å¯¦é«”ä¸­é»ï¼Œè¡¨ç¤ºè²·æ–¹åŠ›é‡å¼·å‹ã€‚\",\n",
        "            \"suggestion\": \"çœ‹æ¼²åè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšå¤šï¼Œæ­¢æè¨­åœ¨ç©¿åˆºç·šçš„æœ€ä½é»ä¸‹æ–¹ã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œçƒé›²è“‹é ‚\": {\n",
        "            \"explanation\": \"å¤§é™½ç·šå¾Œå‡ºç¾å¤§é™°ç·šï¼Œä¸”é™°ç·šé–‹ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©æœ€é«˜åƒ¹ï¼Œæ”¶ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©å¯¦é«”ä¸­é»ï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡å¼·å‹ã€‚\",\n",
        "            \"suggestion\": \"çœ‹è·Œåè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨çƒé›²è“‹é ‚çš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"ä¸­æ€§é•·è…³åå­—ç·š\": {\n",
        "            \"explanation\": \"é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒï¼Œä½†æœ‰å¾ˆé•·çš„ä¸Šä¸‹å½±ç·šï¼Œè¡¨ç¤ºå¸‚å ´æ³¢å‹•åŠ‡çƒˆä½†æœªå½¢æˆæ˜ç¢ºæ–¹å‘ã€‚\",\n",
        "            \"suggestion\": \"å¸‚å ´çŒ¶è±«ä¸æ±ºçš„ä¿¡è™Ÿï¼Œå¯èƒ½é ç¤ºè‘—åŠ‡çƒˆæ³¢å‹•ï¼Œå»ºè­°ç­‰å¾…æ›´æ˜ç¢ºçš„æ–¹å‘ä¿¡è™Ÿã€‚\"\n",
        "        },\n",
        "        \"çœ‹è·Œä¸ŠåŠç·š\": {\n",
        "            \"explanation\": \"åœ¨ä¸Šæ¼²è¶¨å‹¢ä¸­å‡ºç¾ï¼Œå½¢ç‹€é¡ä¼¼éŒ˜å­ç·šä½†å‡ºç¾åœ¨ä¸Šæ¼²è¶¨å‹¢é ‚éƒ¨ï¼Œå…·æœ‰è¼ƒé•·çš„ä¸‹å½±ç·šï¼Œè¡¨ç¤ºè³£æ–¹åŠ›é‡æ­£åœ¨å¢å¼·ã€‚\",\n",
        "            \"suggestion\": \"é ‚éƒ¨åè½‰ä¿¡è™Ÿï¼Œå¯è€ƒæ…®åšç©ºæˆ–æ¸›æŒï¼Œæ­¢æè¨­åœ¨ä¸ŠåŠç·šçš„æœ€é«˜é»ä¸Šæ–¹ã€‚\"\n",
        "        },\n",
        "        \"ä¸­æ€§é™€èº\": {\n",
        "            \"explanation\": \"å°å¯¦é«”Kç·šï¼Œä¸Šä¸‹å½±ç·šé•·åº¦ç›¸è¿‘ï¼Œè¡¨ç¤ºå¸‚å ´çŒ¶è±«ä¸æ±ºï¼Œå¤šç©ºåŠ›é‡ç›¸ç•¶ã€‚\",\n",
        "            \"suggestion\": \"é€šå¸¸è¡¨ç¤ºå¸‚å ´ä¸ç¢ºå®šæ€§å¢åŠ ï¼Œå»ºè­°ç­‰å¾…æ›´æ˜ç¢ºçš„æ–¹å‘ä¿¡è™Ÿã€‚\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # å¾å®Œæ•´åç¨±ä¸­æå–åŸºæœ¬å‹æ…‹åç¨±\n",
        "    for key in pattern_dict.keys():\n",
        "        if key in pattern_name:\n",
        "            return pattern_dict[key]\n",
        "\n",
        "    return {\n",
        "        \"explanation\": \"é€™æ˜¯ä¸€ç¨®æŠ€è¡“å½¢æ…‹ï¼Œå¯èƒ½è¡¨ç¤ºå¸‚å ´è¶¨å‹¢çš„è®ŠåŒ–ã€‚\",\n",
        "        \"suggestion\": \"å»ºè­°çµåˆå…¶ä»–æŠ€è¡“æŒ‡æ¨™é€²è¡Œç¢ºèªã€‚\"\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def generate_pattern_report(df, periods=['daily']):\n",
        "    \"\"\"\n",
        "    ç”ŸæˆKç·šå‹æ…‹åˆ†æå ±å‘Šï¼ˆä¸ä¾è³´talibï¼‰\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): åŒ…å«OHLCæ•¸æ“šçš„DataFrame\n",
        "        periods (list): è¦åˆ†æçš„æ™‚é–“é€±æœŸåˆ—è¡¨ï¼Œå¯ä»¥æ˜¯ 'daily', 'weekly', 'monthly'\n",
        "\n",
        "    Returns:\n",
        "        str: æ ¼å¼åŒ–çš„Kç·šå‹æ…‹å ±å‘Š\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šæ•¸æ“šç‚ºç©º\"\n",
        "\n",
        "    # ç¢ºä¿å¿…è¦çš„åˆ—å­˜åœ¨\n",
        "    required_cols = ['open', 'high', 'low', 'close']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        missing = [col for col in required_cols if col not in df.columns]\n",
        "        return f\"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šç¼ºå°‘å¿…è¦åˆ— {', '.join(missing)}\"\n",
        "\n",
        "    # å®šç¾©ç°¡å–®çš„Kç·šå‹æ…‹æª¢æ¸¬å‡½æ•¸\n",
        "    def detect_patterns(ohlc_data):\n",
        "        \"\"\"ä½¿ç”¨ç°¡å–®è¦å‰‡æª¢æ¸¬å¸¸è¦‹Kç·šå‹æ…‹\"\"\"\n",
        "        patterns = {\n",
        "            \"çœ‹æ¼²\": [],\n",
        "            \"çœ‹è·Œ\": [],\n",
        "            \"ä¸­æ€§\": []\n",
        "        }\n",
        "\n",
        "        # ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“š\n",
        "        if len(ohlc_data) < 5:\n",
        "            return patterns\n",
        "\n",
        "        # å–æœ€è¿‘çš„Kç·šæ•¸æ“šé€²è¡Œåˆ†æ\n",
        "        recent = ohlc_data.tail(10).copy()\n",
        "\n",
        "        # è¨ˆç®—æ¯æ ¹Kç·šçš„å¯¦é«”å¤§å°å’Œå½±ç·šé•·åº¦\n",
        "        recent['body_size'] = abs(recent['close'] - recent['open'])\n",
        "        recent['upper_shadow'] = recent['high'] - recent[['open', 'close']].max(axis=1)\n",
        "        recent['lower_shadow'] = recent[['open', 'close']].min(axis=1) - recent['low']\n",
        "        recent['is_bullish'] = recent['close'] > recent['open']\n",
        "        recent['is_bearish'] = recent['close'] < recent['open']\n",
        "\n",
        "        # è¨ˆç®—ç§»å‹•å¹³å‡ç·š\n",
        "        recent['ma5'] = recent['close'].rolling(window=5).mean()\n",
        "        recent['ma10'] = recent['close'].rolling(window=10).mean()\n",
        "\n",
        "        # æœ€è¿‘3æ ¹Kç·š\n",
        "        last3 = recent.tail(3)\n",
        "\n",
        "        # æª¢æ¸¬çœ‹æ¼²å‹æ…‹\n",
        "\n",
        "        # ä¸‰ç™½å…µ: é€£çºŒä¸‰æ ¹ä¸Šæ¼²Kç·šï¼Œæ¯æ ¹æ”¶ç›¤åƒ¹éƒ½é«˜æ–¼å‰ä¸€æ ¹\n",
        "        if len(last3) == 3 and all(last3['is_bullish']) and \\\n",
        "           last3['close'].iloc[0] < last3['close'].iloc[1] < last3['close'].iloc[2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"ä¸‰ç™½å…µ\")\n",
        "\n",
        "        # å¤šé ­åå™¬: ä¸€æ ¹çœ‹è·ŒKç·šå¾Œè·Ÿä¸€æ ¹è¼ƒå¤§çš„çœ‹æ¼²Kç·šï¼Œå®Œå…¨åå™¬å‰ä¸€æ ¹\n",
        "        if len(last3) >= 2 and last3['is_bearish'].iloc[-2] and last3['is_bullish'].iloc[-1] and \\\n",
        "           last3['open'].iloc[-1] <= last3['close'].iloc[-2] and \\\n",
        "           last3['close'].iloc[-1] >= last3['open'].iloc[-2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"å¤šé ­åå™¬\")\n",
        "\n",
        "        # çœ‹æ¼²éŒ˜é ­: ä¸‹å½±ç·šé•·ï¼Œå¹¾ä¹æ²’æœ‰ä¸Šå½±ç·šï¼Œå°å¯¦é«”\n",
        "        if any(last3['lower_shadow'] > 2 * last3['body_size']) and \\\n",
        "           any(last3['upper_shadow'] < 0.2 * last3['body_size']) and \\\n",
        "           any(last3['is_bullish']):\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"çœ‹æ¼²éŒ˜é ­\")\n",
        "\n",
        "        # æª¢æ¸¬çœ‹è·Œå‹æ…‹\n",
        "\n",
        "        # ä¸‰é»‘é´‰: é€£çºŒä¸‰æ ¹ä¸‹è·ŒKç·šï¼Œæ¯æ ¹æ”¶ç›¤åƒ¹éƒ½ä½æ–¼å‰ä¸€æ ¹\n",
        "        if len(last3) == 3 and all(last3['is_bearish']) and \\\n",
        "           last3['close'].iloc[0] > last3['close'].iloc[1] > last3['close'].iloc[2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ä¸‰é»‘é´‰\")\n",
        "\n",
        "        # ç©ºé ­åå™¬: ä¸€æ ¹çœ‹æ¼²Kç·šå¾Œè·Ÿä¸€æ ¹è¼ƒå¤§çš„çœ‹è·ŒKç·šï¼Œå®Œå…¨åå™¬å‰ä¸€æ ¹\n",
        "        if len(last3) >= 2 and last3['is_bullish'].iloc[-2] and last3['is_bearish'].iloc[-1] and \\\n",
        "           last3['open'].iloc[-1] >= last3['close'].iloc[-2] and \\\n",
        "           last3['close'].iloc[-1] <= last3['open'].iloc[-2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ç©ºé ­åå™¬\")\n",
        "\n",
        "        # çœ‹è·ŒåŠéŒ˜: ä¸Šå½±ç·šé•·ï¼Œå¹¾ä¹æ²’æœ‰ä¸‹å½±ç·šï¼Œå°å¯¦é«”\n",
        "        if any(last3['upper_shadow'] > 2 * last3['body_size']) and \\\n",
        "           any(last3['lower_shadow'] < 0.2 * last3['body_size']) and \\\n",
        "           any(last3['is_bearish']):\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"çœ‹è·ŒåŠéŒ˜\")\n",
        "\n",
        "        # æª¢æ¸¬ä¸­æ€§å‹æ…‹\n",
        "\n",
        "        # åå­—æ˜Ÿ: é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒ\n",
        "        if any(last3['body_size'] < 0.1 * (last3['high'] - last3['low'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"åå­—æ˜Ÿ\")\n",
        "\n",
        "        # é•·è…¿åå­—: é–‹ç›¤åƒ¹å’Œæ”¶ç›¤åƒ¹å¹¾ä¹ç›¸åŒï¼Œä¸Šä¸‹å½±ç·šéƒ½å¾ˆé•·\n",
        "        if any((last3['body_size'] < 0.1 * (last3['high'] - last3['low'])) &\n",
        "               (last3['upper_shadow'] > last3['body_size']) &\n",
        "               (last3['lower_shadow'] > last3['body_size'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"é•·è…¿åå­—\")\n",
        "\n",
        "        # ç´¡éŒ˜é ‚: å°å¯¦é«”ï¼Œä¸Šä¸‹å½±ç·šå·®ä¸å¤šé•·\n",
        "        if any((last3['body_size'] < 0.3 * (last3['high'] - last3['low'])) &\n",
        "               (abs(last3['upper_shadow'] - last3['lower_shadow']) < 0.2 * (last3['high'] - last3['low']))):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"ç´¡éŒ˜\")\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    report_parts = []\n",
        "\n",
        "    # ç‚ºæ¯å€‹æ™‚é–“é€±æœŸç”Ÿæˆå ±å‘Š\n",
        "    for period in periods:\n",
        "        period_df = df.copy()\n",
        "\n",
        "        # ç¢ºä¿æ—¥æœŸåˆ—æ˜¯æ—¥æœŸé¡å‹\n",
        "        date_col = None\n",
        "        if 'date' in period_df.columns:\n",
        "            date_col = 'date'\n",
        "        elif 'datetime' in period_df.columns:\n",
        "            date_col = 'datetime'\n",
        "        elif 'time' in period_df.columns:\n",
        "            date_col = 'time'\n",
        "\n",
        "        # å¦‚æœæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œè¨­ç½®ç‚ºç´¢å¼•\n",
        "        if date_col:\n",
        "            try:\n",
        "                # å˜—è©¦å°‡æ—¥æœŸåˆ—è½‰æ›ç‚ºdatetimeé¡å‹\n",
        "                period_df[date_col] = pd.to_datetime(period_df[date_col])\n",
        "                period_df.set_index(date_col, inplace=True)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"ç„¡æ³•å°‡ {date_col} è¨­ç½®ç‚ºç´¢å¼•: {str(e)}\")\n",
        "                # å¦‚æœç„¡æ³•è¨­ç½®æ—¥æœŸç´¢å¼•ï¼Œå°±ä½¿ç”¨åŸå§‹æ•¸æ“š\n",
        "\n",
        "        # æ ¹æ“šæ™‚é–“é€±æœŸé‡æ–°å–æ¨£æ•¸æ“š (åªæœ‰ç•¶ç´¢å¼•æ˜¯DatetimeIndexæ™‚æ‰åŸ·è¡Œ)\n",
        "        try:\n",
        "            if period != 'daily' and isinstance(period_df.index, pd.DatetimeIndex):\n",
        "                if period == 'weekly':\n",
        "                    period_df = period_df.resample('W').agg({\n",
        "                        'open': 'first',\n",
        "                        'high': 'max',\n",
        "                        'low': 'min',\n",
        "                        'close': 'last'\n",
        "                    })\n",
        "                elif period == 'monthly':\n",
        "                    period_df = period_df.resample('M').agg({\n",
        "                        'open': 'first',\n",
        "                        'high': 'max',\n",
        "                        'low': 'min',\n",
        "                        'close': 'last'\n",
        "                    })\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"é‡æ¡æ¨£åˆ° {period} æ™‚å‡ºéŒ¯: {str(e)}\")\n",
        "            # å¦‚æœé‡æ¡æ¨£å¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨åŸå§‹æ•¸æ“š\n",
        "\n",
        "        # ç§»é™¤NaNå€¼\n",
        "        period_df = period_df.dropna()\n",
        "\n",
        "        if period_df.empty:\n",
        "            continue\n",
        "\n",
        "        # ä¸­æ–‡æ™‚é–“é€±æœŸåç¨±\n",
        "        period_name = {\n",
        "            'daily': 'æ—¥ç·š',\n",
        "            'weekly': 'é€±ç·š',\n",
        "            'monthly': 'æœˆç·š'\n",
        "        }.get(period, period)\n",
        "\n",
        "        # æª¢æ¸¬Kç·šå‹æ…‹\n",
        "        try:\n",
        "            patterns = detect_patterns(period_df)\n",
        "\n",
        "            period_report = [f\"{period_name}åˆ†æ:\"]\n",
        "\n",
        "            # æ·»åŠ æª¢æ¸¬åˆ°çš„å‹æ…‹åˆ°å ±å‘Šä¸­\n",
        "            for pattern_type, detected_patterns in patterns.items():\n",
        "                if detected_patterns:\n",
        "                    pattern_str = \", \".join(detected_patterns)\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: {pattern_str}\")\n",
        "                else:\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: ç„¡\")\n",
        "\n",
        "            # æ·»åŠ è©²æ™‚é–“é€±æœŸçš„å ±å‘Š\n",
        "            report_parts.append(\"\\n\".join(period_report))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {period_name} å‹æ…‹æ™‚å‡ºéŒ¯: {str(e)}\")\n",
        "            report_parts.append(f\"{period_name}åˆ†æ:\\nåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "    # å¦‚æœæ²’æœ‰ç”Ÿæˆä»»ä½•å ±å‘Šéƒ¨åˆ†ï¼Œè¿”å›ä¸€å€‹é»˜èªæ¶ˆæ¯\n",
        "    if not report_parts:\n",
        "        return \"æœªæª¢æ¸¬åˆ°æ˜é¡¯Kç·šå‹æ…‹\"\n",
        "\n",
        "    # çµ„åˆæœ€çµ‚å ±å‘Š\n",
        "    return \"\\n\\n\".join(report_parts)\n",
        "\n",
        "\n",
        "def analyze_multi_timeframe(df):\n",
        "    \"\"\"\n",
        "    å¤šæ™‚é–“æ¡†æ¶åˆ†æã€‚\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return {'error': 'ç„¡æœ‰æ•ˆæ•¸æ“š'}\n",
        "\n",
        "    try:\n",
        "        result = {\n",
        "            'D': {'quadrant': 'Q1', 'description': 'çœ‹æ¼²' if 'MA20' in df.columns and df['Close'].iloc[-1] > df['MA20'].iloc[-1] else 'ä¸­æ€§'},\n",
        "            'W': {'quadrant': 'Q2', 'description': 'ä¸­æ€§'},\n",
        "            'M': {'quadrant': 'Q1', 'description': 'çœ‹æ¼²' if 'MA60' in df.columns and df['Close'].iloc[-1] > df['MA60'].iloc[-1] else 'ä¸­æ€§'},\n",
        "            'combined': {\n",
        "                'trend_consistency': 'çœ‹æ¼²' if 'MA20' in df.columns and df['Close'].iloc[-1] > df['MA20'].iloc[-1] else 'ä¸­æ€§',\n",
        "                'strength': 'å¼·å‹¢' if 'RSI' in df.columns and df['RSI'].iloc[-1] > 60 else 'ä¸€èˆ¬',\n",
        "                'suggestion': 'è²·å…¥' if 'MA20' in df.columns and df['Close'].iloc[-1] > df['MA20'].iloc[-1] else 'æŒæœ‰'\n",
        "            }\n",
        "        }\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¤šæ™‚é–“æ¡†æ¶åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return {'error': f'åˆ†æå¤±æ•—: {str(e)}'}\n",
        "\n",
        "def analyze_market_structure(df):\n",
        "    \"\"\"\n",
        "    å¸‚å ´çµæ§‹åˆ†æã€‚\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return {'error': 'ç„¡æœ‰æ•ˆæ•¸æ“š'}\n",
        "\n",
        "    try:\n",
        "        last_price = df['Close'].iloc[-1]\n",
        "        support_levels = df['Low'].rolling(window=20).min().tail(5).tolist()\n",
        "        resistance_levels = df['High'].rolling(window=20).max().tail(5).tolist()\n",
        "        recent_volatility = df['Close'].pct_change().tail(20).std() * 100\n",
        "        long_term_volatility = df['Close'].pct_change().std() * 100\n",
        "\n",
        "        return {\n",
        "            'price_levels': {\n",
        "                'position': 'é«˜æ–¼æ”¯æ’ä½' if last_price > max(support_levels) else 'ä½æ–¼é˜»åŠ›ä½',\n",
        "                'resistance_levels': resistance_levels,\n",
        "                'support_levels': support_levels\n",
        "            },\n",
        "            'trend': 'çœ‹æ¼²' if 'MA20' in df.columns and df['Close'].iloc[-1] > df['MA20'].iloc[-1] else 'çœ‹è·Œ',\n",
        "            'volatility': {\n",
        "                'status': 'é«˜' if recent_volatility > long_term_volatility else 'ä½',\n",
        "                'recent': round(recent_volatility, 2),\n",
        "                'long_term': round(long_term_volatility, 2)\n",
        "            },\n",
        "            'volume': {\n",
        "                'status': 'å¢åŠ ' if 'Volume' in df.columns and df['Volume'].iloc[-1] > df['Volume'].rolling(window=20).mean().iloc[-1] else 'æ¸›å°‘',\n",
        "                'recent_avg': int(df['Volume'].tail(20).mean()) if 'Volume' in df.columns else 0,\n",
        "                'long_term_avg': int(df['Volume'].mean()) if 'Volume' in df.columns else 0\n",
        "            },\n",
        "            'sentiment': {\n",
        "                'status': 'è¶…è²·' if 'RSI' in df.columns and df['RSI'].iloc[-1] > 70 else 'è¶…è³£' if 'RSI' in df.columns and df['RSI'].iloc[-1] < 30 else 'ä¸­æ€§',\n",
        "                'rsi': round(df['RSI'].iloc[-1], 2) if 'RSI' in df.columns else 50\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¸‚å ´çµæ§‹åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return {'error': f'åˆ†æå¤±æ•—: {str(e)}'}\n",
        "\n",
        "def generate_indicator_summary(status):\n",
        "    \"\"\"\n",
        "    ç”ŸæˆæŠ€è¡“æŒ‡æ¨™æ‘˜è¦ã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if isinstance(status, dict) and 'error' in status:\n",
        "            return \"ç„¡æœ‰æ•ˆæŠ€è¡“æŒ‡æ¨™\"\n",
        "\n",
        "        summary = []\n",
        "        df = status.get('data_df')\n",
        "        if df is None or df.empty:\n",
        "            return \"ç„¡æœ‰æ•ˆæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\"\n",
        "\n",
        "        if 'MA5' in df.columns and 'MA20' in df.columns:\n",
        "            summary.append(\"ç§»å‹•å¹³å‡ç·š: çœ‹æ¼²\" if df['MA5'].iloc[-1] > df['MA20'].iloc[-1] else \"ç§»å‹•å¹³å‡ç·š: ä¸­æ€§\")\n",
        "\n",
        "        if 'RSI' in df.columns:\n",
        "            rsi = df['RSI'].iloc[-1]\n",
        "            summary.append(f\"RSI: {'è¶…è²·' if rsi > 70 else 'è¶…è³£' if rsi < 30 else 'ä¸­æ€§'} ({round(rsi, 2)})\")\n",
        "\n",
        "        if 'MACD' in df.columns and 'Signal' in df.columns:\n",
        "            summary.append(\"MACD: æ­£å‘\" if df['MACD'].iloc[-1] > df['Signal'].iloc[-1] else \"MACD: è² å‘\")\n",
        "\n",
        "        if 'K' in df.columns and 'D' in df.columns:\n",
        "            summary.append(\"KD: çœ‹æ¼²\" if df['K'].iloc[-1] > df['D'].iloc[-1] else \"KD: çœ‹è·Œ\")\n",
        "\n",
        "        return \", \".join(summary) if summary else \"ç„¡å¯ç”¨æŠ€è¡“æŒ‡æ¨™\"\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”ŸæˆæŠ€è¡“æŒ‡æ¨™æ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return \"æŠ€è¡“æŒ‡æ¨™æ‘˜è¦ç”Ÿæˆå¤±æ•—\"\n",
        "\n",
        "\n",
        "def get_summary_report_html(data: dict):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆ HTML æ ¼å¼çš„çµ±è¨ˆå ±å‘Šã€‚\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for stock_id, stock_data in data.items():\n",
        "        try:\n",
        "            # æª¢æŸ¥æ­·å²è³‡æ–™æ¬„ä½\n",
        "            hist_data = stock_data.get(\"æ­·å²è³‡æ–™\")\n",
        "            if not hist_data:\n",
        "                hist_data = stock_data.get(\"data\", [])\n",
        "\n",
        "            if not hist_data:\n",
        "                raise ValueError(\"ç„¡æ­·å²è³‡æ–™\")\n",
        "\n",
        "            df = pd.DataFrame(hist_data)\n",
        "            if df.empty:\n",
        "                raise ValueError(\"æ­·å²è³‡æ–™ç‚ºç©º\")\n",
        "\n",
        "            # æª¢æŸ¥æ¬„ä½åç¨±ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡ï¼‰\n",
        "            close_col = None\n",
        "            volume_col = None\n",
        "\n",
        "            for col in ['æ”¶ç›¤', 'Close', 'close']:\n",
        "                if col in df.columns:\n",
        "                    close_col = col\n",
        "                    break\n",
        "\n",
        "            for col in ['æˆäº¤é‡', 'Volume', 'volume']:\n",
        "                if col in df.columns:\n",
        "                    volume_col = col\n",
        "                    break\n",
        "\n",
        "            if not close_col or not volume_col:\n",
        "                raise ValueError(\"ç¼ºå°‘å¿…è¦æ¬„ä½\")\n",
        "\n",
        "            summary = df[[close_col, volume_col]].describe().T\n",
        "\n",
        "            row = {\n",
        "                \"è‚¡ç¥¨ä»£ç¢¼\": stock_id,\n",
        "                \"æ”¶ç›¤å¹³å‡\": round(summary.loc[close_col, \"mean\"], 2),\n",
        "                \"æ”¶ç›¤æœ€ä½\": round(summary.loc[close_col, \"min\"], 2),\n",
        "                \"æ”¶ç›¤æœ€é«˜\": round(summary.loc[close_col, \"max\"], 2),\n",
        "                \"æˆäº¤é‡å¹³å‡\": round(summary.loc[volume_col, \"mean\"], 0),\n",
        "                \"æˆäº¤é‡æœ€ä½\": round(summary.loc[volume_col, \"min\"], 0),\n",
        "                \"æˆäº¤é‡æœ€é«˜\": round(summary.loc[volume_col, \"max\"], 0),\n",
        "            }\n",
        "            rows.append(row)\n",
        "        except Exception as e:\n",
        "            rows.append({\n",
        "                \"è‚¡ç¥¨ä»£ç¢¼\": stock_id,\n",
        "                \"æ”¶ç›¤å¹³å‡\": \"éŒ¯èª¤\",\n",
        "                \"æ”¶ç›¤æœ€ä½\": \"\",\n",
        "                \"æ”¶ç›¤æœ€é«˜\": \"\",\n",
        "                \"æˆäº¤é‡å¹³å‡\": str(e),\n",
        "                \"æˆäº¤é‡æœ€ä½\": \"\",\n",
        "                \"æˆäº¤é‡æœ€é«˜\": \"\"\n",
        "            })\n",
        "\n",
        "    result_df = pd.DataFrame(rows)\n",
        "    return result_df.to_html(index=False, border=1, justify=\"center\", escape=False)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# é€šçŸ¥å‡½æ•¸ (***é‡å¤§ä¿®æ­£å€***)\n",
        "# ==============================================================================\n",
        "def send_notifications(message: str, files: List[str] = None):\n",
        "    \"\"\"\n",
        "    ç°¡åŒ–ç‰ˆé€šçŸ¥å‡½æ•¸ - åƒ…è¼¸å‡ºåˆ°æ§åˆ¶å°ï¼Œä¸éœ€è¦å¤–éƒ¨é…ç½®\n",
        "    \"\"\"\n",
        "    print(\"\\n=== é€šçŸ¥è¨Šæ¯ ===\")\n",
        "    print(message)\n",
        "    if files:\n",
        "        print(f\"é™„åŠ æª”æ¡ˆ: {', '.join(files)}\")\n",
        "    print(\"===============\\n\")\n",
        "\n",
        "    # å¦‚æœæœ‰æ—¥èªŒè¨˜éŒ„å™¨ï¼Œä¹Ÿè¨˜éŒ„ä¸€ä¸‹\n",
        "    try:\n",
        "        logger.info(f\"é€šçŸ¥è¨Šæ¯å·²è¼¸å‡ºåˆ°æ§åˆ¶å° (å« {len(files) if files else 0} å€‹æª”æ¡ˆ)\")\n",
        "    except:\n",
        "        pass  # å¦‚æœæ²’æœ‰ logger æˆ–å‡ºéŒ¯ï¼Œå°±å¿½ç•¥\n",
        "\n",
        "    \"\"\"\n",
        "    ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord (åŒæ­¥ç‰ˆæœ¬)\n",
        "    \"\"\"\n",
        "    # --- Telegram ç™¼é€ ---\n",
        "    for chat_id in TELEGRAM_CHAT_ID:\n",
        "        try:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            requests.post(url_msg, json=payload, timeout=20)\n",
        "            logger.info(f\"Telegram æ‘˜è¦æˆåŠŸç™¼é€è‡³ chat_id: {chat_id}\")\n",
        "\n",
        "            # ç™¼é€åœ–ç‰‡æª”æ¡ˆ\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        with open(file_path, 'rb') as f:\n",
        "                            photo_files = {'photo': (os.path.basename(file_path), f)}\n",
        "                            data = {'chat_id': chat_id}\n",
        "                            requests.post(url_photo, data=data, files=photo_files, timeout=60)\n",
        "                logger.info(f\"Telegram åœ–æª”æˆåŠŸç™¼é€è‡³ chat_id: {chat_id} ({len(files)}å€‹)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Telegram é€šçŸ¥è‡³ {chat_id} æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # --- Discord ç™¼é€ ---\n",
        "    try:\n",
        "        # æ¸…ç†è¨Šæ¯ä¸­çš„ Markdown ç¬¦è™Ÿï¼Œä½¿å…¶åœ¨ Discord ä¸­æ­£å¸¸é¡¯ç¤º\n",
        "        discord_message = message.replace('*', '').replace('_', '')\n",
        "        webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{discord_message}\\n```\")\n",
        "        if files:\n",
        "            for file_path in files:\n",
        "                if os.path.exists(file_path):\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "        response = webhook.execute()\n",
        "        if response.ok:\n",
        "            logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "        else:\n",
        "            logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "def format_notification_message(\n",
        "    results_to_show: Dict,\n",
        "    successful_analysis: int,\n",
        "    failed_analysis: int,\n",
        "    total_after_volume_filter: int,\n",
        "    top_n=5\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯ (å‡ç´šç‰ˆ)ï¼ŒåŒ…å«åˆ†æçµ±è¨ˆæ•¸æ“šã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not results_to_show:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– *å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š*\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆé¡¯ç¤ºæ¢ä»¶çš„è‚¡ç¥¨ã€‚\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–ã€‚\n",
        "\"\"\"\n",
        "\n",
        "        # æŒ‰åˆ†æ•¸æ’åºï¼Œç¢ºä¿é¡¯ç¤ºçš„æ˜¯æœ€é«˜åˆ†çš„è‚¡ç¥¨\n",
        "        top_stocks = sorted(results_to_show.values(), key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– *å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š*\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "*ğŸ“ˆ åˆ†æçµ±è¨ˆ:*\n",
        "> â€¢ ç¬¦åˆæˆäº¤é‡æ¨™æº–: {total_after_volume_filter} æ”¯\n",
        "> â€¢ æˆåŠŸåˆ†æ: {successful_analysis} æ”¯\n",
        "> â€¢ åˆ†æå¤±æ•—: {failed_analysis} æ”¯\n",
        "\n",
        "ğŸ† *TOP {min(top_n, len(top_stocks))} æ¨è–¦è‚¡ç¥¨:*\n",
        "\"\"\"\n",
        "        for rank, result in enumerate(top_stocks[:top_n], 1):\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            message += f\"\"\"\n",
        "*{rank}. {result.get('stock_name', '')} ({result.get('stock_id', '')})*\n",
        "   ğŸ’° æœ€æ–°åƒ¹æ ¼: {result.get('last_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ ç¶œåˆè©•åˆ†: *{result.get('combined_score', 0):.1f} / 100*\n",
        "   ğŸ¯ æŠ•è³‡å»ºè­°: *{recommendation.get('action', 'è§€æœ›')}*\n",
        "\"\"\"\n",
        "\n",
        "        message += \"\"\"\n",
        "âš ï¸ *æŠ•è³‡æé†’:*\n",
        "â€¢ æœ¬åˆ†æåƒ…ç‚ºæŠ€è¡“æŒ‡æ¨™åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡å»ºè­°ã€‚\n",
        "â€¢ æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹çµåˆåŸºæœ¬é¢åˆ†æä¸¦åšå¥½é¢¨éšªæ§ç®¡ã€‚\n",
        "\"\"\"\n",
        "        return message.strip()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "\n",
        "# ç¼ºå°‘çš„å‡½æ•¸å®šç¾©\n",
        "def filter_by_volume(stocks_data, min_volume_shares=1000000):\n",
        "    \"\"\"\n",
        "    æ ¹æ“šæˆäº¤é‡éæ¿¾è‚¡ç¥¨\n",
        "    \"\"\"\n",
        "    filtered_data = {}\n",
        "\n",
        "    for stock_id, stock_data in stocks_data.items():\n",
        "        try:\n",
        "            if 'data' not in stock_data or not stock_data['data']:\n",
        "                continue\n",
        "\n",
        "            df = pd.DataFrame(stock_data['data'])\n",
        "            if 'Volume' not in df.columns:\n",
        "                continue\n",
        "\n",
        "            # è¨ˆç®—è¿‘30å¤©å¹³å‡æˆäº¤é‡\n",
        "            recent_volume = df['Volume'].tail(30).mean()\n",
        "\n",
        "            # è½‰æ›ç‚ºå¼µæ•¸ï¼ˆ1å¼µ = 1000è‚¡ï¼‰\n",
        "            avg_volume_lots = recent_volume / 1000\n",
        "\n",
        "            if avg_volume_lots >= (min_volume_shares / 1000):  # min_volume_shareså·²ç¶“æ˜¯è‚¡æ•¸\n",
        "                filtered_data[stock_id] = stock_data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"éæ¿¾è‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    logger.info(f\"æˆäº¤é‡éæ¿¾å®Œæˆ: {len(filtered_data)}/{len(stocks_data)} æ”¯è‚¡ç¥¨ç¬¦åˆæ¨™æº–\")\n",
        "    return filtered_data\n",
        "\n",
        "def top_percentile_filter(analysis_results, percentile=98):\n",
        "    \"\"\"\n",
        "    ç¯©é¸å‰ç™¾åˆ†ä½çš„è‚¡ç¥¨\n",
        "    \"\"\"\n",
        "    if not analysis_results:\n",
        "        return {}\n",
        "\n",
        "    scores = [result.get('combined_score', 0) for result in analysis_results.values()]\n",
        "    threshold = np.percentile(scores, percentile)\n",
        "\n",
        "    elite_results = {\n",
        "        stock_id: result for stock_id, result in analysis_results.items()\n",
        "        if result.get('combined_score', 0) >= threshold\n",
        "    }\n",
        "\n",
        "    logger.info(f\"å‰{100-percentile}%ç¯©é¸å®Œæˆ: {len(elite_results)}/{len(analysis_results)} æ”¯è‚¡ç¥¨\")\n",
        "    return elite_results\n",
        "\n",
        "def print_top_stocks(results, top_n=10):\n",
        "    \"\"\"\n",
        "    æ‰“å°æœ€ä½³è‚¡ç¥¨æ¸…å–®\n",
        "    \"\"\"\n",
        "    sorted_results = sorted(results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "    print(f\"\\nğŸ† å‰ {min(top_n, len(sorted_results))} åæ¨è–¦è‚¡ç¥¨:\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for i, result in enumerate(sorted_results[:top_n], 1):\n",
        "        stock_id = result.get('stock_id', 'N/A')\n",
        "        stock_name = result.get('stock_name', 'N/A')\n",
        "        score = result.get('combined_score', 0)\n",
        "        recommendation = result.get('recommendation', {})\n",
        "\n",
        "        print(f\"{i:2d}. {stock_id} {stock_name}\")\n",
        "        print(f\"    ç¶œåˆè©•åˆ†: {score}/100\")\n",
        "        print(f\"    æŠ•è³‡å»ºè­°: {recommendation.get('action', 'N/A')}\")\n",
        "        print(f\"    ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 0)}%\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "def export_html_report(analysis_results):\n",
        "    \"\"\"\n",
        "    åŒ¯å‡ºHTMLå ±å‘Š\n",
        "    \"\"\"\n",
        "    try:\n",
        "        html_content = f\"\"\"\n",
        "        <!DOCTYPE html>\n",
        "        <html>\n",
        "        <head>\n",
        "            <meta charset=\"UTF-8\">\n",
        "            <title>å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š</title>\n",
        "            <style>\n",
        "                body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
        "                table {{ border-collapse: collapse; width: 100%; }}\n",
        "                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
        "                th {{ background-color: #f2f2f2; }}\n",
        "                .high-score {{ background-color: #d4edda; }}\n",
        "                .medium-score {{ background-color: #fff3cd; }}\n",
        "                .low-score {{ background-color: #f8d7da; }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š</h1>\n",
        "            <p>ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "            <table>\n",
        "                <tr>\n",
        "                    <th>æ’å</th>\n",
        "                    <th>è‚¡ç¥¨ä»£è™Ÿ</th>\n",
        "                    <th>è‚¡ç¥¨åç¨±</th>\n",
        "                    <th>ç¶œåˆè©•åˆ†</th>\n",
        "                    <th>æŠ•è³‡å»ºè­°</th>\n",
        "                    <th>ä¿¡å¿ƒåº¦</th>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        sorted_results = sorted(analysis_results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        for i, result in enumerate(sorted_results[:50], 1):  # åªé¡¯ç¤ºå‰50å\n",
        "            score = result.get('combined_score', 0)\n",
        "            score_class = 'high-score' if score >= 70 else 'medium-score' if score >= 50 else 'low-score'\n",
        "\n",
        "            html_content += f\"\"\"\n",
        "                <tr class=\"{score_class}\">\n",
        "                    <td>{i}</td>\n",
        "                    <td>{result.get('stock_id', 'N/A')}</td>\n",
        "                    <td>{result.get('stock_name', 'N/A')}</td>\n",
        "                    <td>{score}</td>\n",
        "                    <td>{result.get('recommendation', {}).get('action', 'N/A')}</td>\n",
        "                    <td>{result.get('recommendation', {}).get('confidence', 0)}%</td>\n",
        "                </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        html_content += \"\"\"\n",
        "            </table>\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "        html_path = os.path.join(RESULTS_DIR, f\"stock_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\")\n",
        "        with open(html_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        logger.info(f\"âœ… HTMLå ±å‘Šå·²åŒ¯å‡º: {html_path}\")\n",
        "        return html_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"åŒ¯å‡ºHTMLå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# ä¿®æ­£çš„åœ–è¡¨ç”Ÿæˆå‡½æ•¸\n",
        "def generate_detailed_analysis_report(stock_id, analysis_result, output_dir='reports'):\n",
        "    \"\"\"\n",
        "    ç‚ºå–®ä¸€è‚¡ç¥¨ç”Ÿæˆè©³ç´°çš„æŠ€è¡“åˆ†æå ±å‘Šï¼ŒåŒ…å«åœ–è¡¨å’Œé—œéµæŒ‡æ¨™ã€‚\n",
        "\n",
        "    ä¿®æ­£äº† addplot åƒæ•¸çš„è™•ç†é‚è¼¯ï¼Œé¿å…å‚³é None å€¼ã€‚\n",
        "\n",
        "    åƒæ•¸:\n",
        "    stock_id (str): è‚¡ç¥¨ä»£è™Ÿ\n",
        "    analysis_result (dict): åŒ…å«åˆ†æçµæœçš„å­—å…¸\n",
        "    output_dir (str): è¼¸å‡ºç›®éŒ„è·¯å¾‘\n",
        "\n",
        "    è¿”å›:\n",
        "    str: å ±å‘Šæ–‡ä»¶çš„è·¯å¾‘ï¼Œå¦‚æœç”Ÿæˆå¤±æ•—å‰‡è¿”å› None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not analysis_result or not analysis_result.get('success'):\n",
        "            logger.warning(f\"ç„¡æ³•ç‚ºè‚¡ç¥¨ {stock_id} ç”Ÿæˆå ±å‘Šï¼šåˆ†æçµæœç„¡æ•ˆ\")\n",
        "            return None\n",
        "\n",
        "        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # ç²å–åˆ†ææ•¸æ“š\n",
        "        df = analysis_result['data_df'].copy()\n",
        "\n",
        "        # ç¢ºä¿ç´¢å¼•æ˜¯æ—¥æœŸæ™‚é–“é¡å‹\n",
        "        if not isinstance(df.index, pd.DatetimeIndex):\n",
        "            logger.warning(f\"è‚¡ç¥¨ {stock_id} çš„æ•¸æ“šç´¢å¼•ä¸æ˜¯æ—¥æœŸé¡å‹ï¼Œå˜—è©¦è½‰æ›\")\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "\n",
        "        # ç¢ºä¿æ•¸æ“šæŒ‰æ—¥æœŸæ’åº\n",
        "        df.sort_index(inplace=True)\n",
        "\n",
        "        # å°‡ DataFrame è½‰æ›ç‚º mplfinance å¯ç”¨çš„æ ¼å¼\n",
        "        df_mpf = df[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "\n",
        "        # å‰µå»ºé™„åŠ åœ–è¡¨\n",
        "        ap = []  # åˆå§‹åŒ–ç‚ºç©ºåˆ—è¡¨\n",
        "\n",
        "        # æ·»åŠ ç§»å‹•å¹³å‡ç·š\n",
        "        if 'ma20' in df.columns and 'ma60' in df.columns and 'ma120' in df.columns:\n",
        "            ap.append(mpf.make_addplot(df['ma20'], color='blue', width=0.7))\n",
        "            ap.append(mpf.make_addplot(df['ma60'], color='red', width=0.7))\n",
        "            ap.append(mpf.make_addplot(df['ma120'], color='green', width=0.7))\n",
        "\n",
        "        # æ·»åŠ  RSI æŒ‡æ¨™ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
        "        if 'rsi' in df.columns:\n",
        "            # å‰µå»ºä¸€å€‹æ–°çš„å­åœ–ç”¨æ–¼ RSI\n",
        "            ap.append(mpf.make_addplot(df['rsi'], panel=1, color='purple',\n",
        "                                       ylabel='RSI'))\n",
        "\n",
        "        # æ·»åŠ  MACD æŒ‡æ¨™ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
        "        if all(col in df.columns for col in ['macd', 'macdsignal']):\n",
        "            # å‰µå»ºä¸€å€‹æ–°çš„å­åœ–ç”¨æ–¼ MACD\n",
        "            ap.append(mpf.make_addplot(df['macd'], panel=2, color='blue',\n",
        "                                       ylabel='MACD'))\n",
        "            ap.append(mpf.make_addplot(df['macdsignal'], panel=2, color='red'))\n",
        "            ap.append(mpf.make_addplot(df['histogram'], panel=2, type='bar', color='dimgray'))\n",
        "\n",
        "        # è¨­ç½®åœ–è¡¨æ¨£å¼å’Œä½ˆå±€\n",
        "        style = mpf.make_mpf_style(base_mpf_style='charles', rc={'figure.figsize': (12, 10)})\n",
        "\n",
        "        # è¨­ç½®å­åœ–æ¯”ä¾‹\n",
        "        fig_kwargs = {\n",
        "            'figratio': (12, 8),\n",
        "            'panel_ratios': (6, 2, 2) if 'macd' in df.columns else (6, 2)\n",
        "        }\n",
        "\n",
        "        # è¨­ç½®åœ–è¡¨æ¨™é¡Œ\n",
        "        title = f\"{stock_id} {analysis_result.get('stock_name', '')} æŠ€è¡“åˆ†æ ({df.index[0].strftime('%Y-%m-%d')} è‡³ {df.index[-1].strftime('%Y-%m-%d')})\"\n",
        "\n",
        "        # ç”Ÿæˆåœ–è¡¨\n",
        "        plot_kwargs = {\n",
        "            'type': 'candle',\n",
        "            'style': style,\n",
        "            'volume': True,\n",
        "            'title': title,\n",
        "            'figscale': 1.5,\n",
        "            'tight_layout': True,\n",
        "            'savefig': f\"{output_dir}/{stock_id}_technical_analysis.png\",\n",
        "            'returnfig': True,\n",
        "            **fig_kwargs\n",
        "        }\n",
        "\n",
        "        # åªæœ‰åœ¨ ap åˆ—è¡¨éç©ºæ™‚æ‰æ·»åŠ  addplot åƒæ•¸\n",
        "        if ap:\n",
        "            plot_kwargs['addplot'] = ap\n",
        "\n",
        "        fig, axes = mpf.plot(df_mpf, **plot_kwargs)\n",
        "\n",
        "        # é—œé–‰åœ–è¡¨ä»¥é‡‹æ”¾è¨˜æ†¶é«”\n",
        "        plt.close(fig)\n",
        "\n",
        "        # è¿”å›å ±å‘Šæ–‡ä»¶è·¯å¾‘\n",
        "        return f\"{output_dir}/{stock_id}_technical_analysis.png\"\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç”Ÿæˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ ({stock_id}): {str(e)}\")\n",
        "        logger.debug(traceback.format_exc())\n",
        "        return None\n",
        "\n",
        "\n",
        "# æ‚¨åŸæœ¬çš„å…¶ä»–å‡½æ•¸ï¼ˆset_chinese_font, get_taiwan_stocks, etc.ï¼‰ä¿æŒä¸è®Š\n",
        "def set_chinese_font():\n",
        "    \"\"\"\n",
        "    è‡ªå‹•è¨­å®šé©åˆç•¶å‰ä½œæ¥­ç³»çµ±çš„ä¸­æ–‡å­—é«”ï¼Œç”¨æ–¼ Matplotlib é¡¯ç¤ºã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        system = platform.system()\n",
        "        font_name = \"\"\n",
        "\n",
        "        if system == 'Windows':\n",
        "            font_name = 'Microsoft YaHei'\n",
        "            plt.rcParams['font.sans-serif'] = [font_name]\n",
        "        elif system == 'Darwin':\n",
        "            font_name = 'PingFang HK'\n",
        "            plt.rcParams['font.sans-serif'] = [font_name]\n",
        "        else:\n",
        "            font_paths = [\n",
        "                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',\n",
        "            ]\n",
        "            found_font_path = next((path for path in font_paths if os.path.exists(path)), None)\n",
        "\n",
        "            if found_font_path:\n",
        "                font_manager.fontManager.addfont(found_font_path)\n",
        "                font_name = font_manager.FontProperties(fname=found_font_path).get_name()\n",
        "                plt.rcParams['font.sans-serif'] = [font_name]\n",
        "            else:\n",
        "                print(\"âš ï¸ æœªåœ¨å¸¸è¦‹è·¯å¾‘æ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚\")\n",
        "                plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "        if font_name:\n",
        "            print(f\"âœ… å·²è¨­å®šåœ–è¡¨å­—é«”ç‚º: {font_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å­—é«”é…ç½®éŒ¯èª¤: {e}ã€‚ä½¿ç”¨é è¨­å­—é«”ã€‚\")\n",
        "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. å‡ç´šï¼šæœ€çµ‚å ±å‘Šåˆ—å°å‡½æ•¸ (æ›¿æ›èˆŠçš„ print_top_stocks_with_patterns)\n",
        "# ==============================================================================\n",
        "def print_final_report(results):\n",
        "    \"\"\"\n",
        "    åˆ—å°æœ€çµ‚çš„é ‚å°–è‚¡ç¥¨åˆ†æå ±å‘Š (V3.0 æ™ºèƒ½ç‰ˆ)\n",
        "    - é¡¯ç¤ºä¸­æ–‡Kç·šè¶¨å‹¢æ‘˜è¦\n",
        "    - é¡¯ç¤ºæ™ºèƒ½äº¤æ˜“å»ºè­°\n",
        "    \"\"\"\n",
        "    report_lines = []\n",
        "    header = \"ğŸ†\" * 20\n",
        "    title = \" \" * 28 + \"æœ€çµ‚é ‚å°–å€‹è‚¡åˆ†æå ±å‘Š\"\n",
        "\n",
        "    report_lines.append(\"\\n\" + \"=\"*80)\n",
        "    report_lines.append(header)\n",
        "    report_lines.append(title)\n",
        "    report_lines.append(header)\n",
        "    report_lines.append(\"=\"*80)\n",
        "\n",
        "    if not results:\n",
        "        report_lines.append(\"\\nğŸ¤· æœªèƒ½ç¯©é¸å‡ºä»»ä½•ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ã€‚\")\n",
        "        final_report = \"\\n\".join(report_lines)\n",
        "        print(final_report)\n",
        "        return final_report\n",
        "\n",
        "    # æ ¹æ“šç¶œåˆè©•åˆ†å¾é«˜åˆ°ä½æ’åº\n",
        "    sorted_results = sorted(results.values(), key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "    for i, result in enumerate(sorted_results):\n",
        "        report_lines.append(f\"\\n--- æ’å {i+1} -----------------------------------------------------------\")\n",
        "\n",
        "        stock_id = result.get('stock_id', 'N/A')\n",
        "        stock_name = result.get('stock_name', 'N/A')\n",
        "        industry = result.get('industry', 'N/A')\n",
        "        last_price = result.get('last_price', 0.0)\n",
        "        combined_score = result.get('combined_score', 0)\n",
        "\n",
        "        # ç²å–å·²ç”Ÿæˆçš„æ™ºèƒ½å»ºè­°\n",
        "        recommendation = result.get('recommendation', {})\n",
        "        action = recommendation.get('action', 'åˆ†æä¸å®Œæ•´')\n",
        "        reason = recommendation.get('reason', 'ç„¡æ³•ç”Ÿæˆå»ºè­°')\n",
        "\n",
        "        # ç²å–å·²ç”Ÿæˆçš„Kç·šç²¾è¯æ‘˜è¦\n",
        "        pattern_report = result.get('pattern_report', 'Kç·šå‹æ…‹å ±å‘Šæœªç”Ÿæˆã€‚')\n",
        "\n",
        "        report_lines.append(f\"ğŸ“ˆ è‚¡ç¥¨: {stock_id} {stock_name} ({industry})\")\n",
        "        report_lines.append(f\"ğŸ’° æœ€æ–°è‚¡åƒ¹: {last_price:.2f}\")\n",
        "        report_lines.append(f\"â­ ç¶œåˆè©•åˆ†: {combined_score}/100\")\n",
        "        report_lines.append(f\"ğŸ’¡ äº¤æ˜“å»ºè­°: {action} - {reason}\")\n",
        "        report_lines.append(pattern_report) # ç›´æ¥ä½¿ç”¨å·²ç”Ÿæˆçš„å ±å‘Š\n",
        "\n",
        "        report_lines.append(\"-\" * 70)\n",
        "\n",
        "    report_lines.append(\"\\n\" + \"=\"*80)\n",
        "    report_lines.append(\"åˆ†æå ±å‘ŠçµæŸã€‚ç¥æ‚¨æŠ•è³‡é †åˆ©ï¼\")\n",
        "\n",
        "    final_report = \"\\n\".join(report_lines)\n",
        "    print(final_report)\n",
        "    return final_report\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # (å¯é¸) åœ¨æ­¤è™•åŠ å…¥å°‡å ±å‘Šç™¼é€åˆ° Telegram çš„é‚è¼¯\n",
        "    final_report_str = print_final_report(results_to_show)\n",
        "\n",
        "    send_notifications(final_report_str)\n",
        "\n",
        "# ä¿®æ­£ä¸¦å„ªåŒ–å¾Œçš„ä¸»é¸å–®å‡½æ•¸\n",
        "def main_menu():\n",
        "    \"\"\"\n",
        "    ä¸»ç¨‹å¼åŸ·è¡Œæµç¨‹ (æœ€çµ‚å„ªåŒ–ç‰ˆ)\n",
        "    \"\"\"\n",
        "    print(\"=\"*40)\n",
        "    print(\"==== å°è‚¡å¤šè‚¡æŠ€è¡“åˆ†æèˆ‡ç¯©é¸å·¥å…· ====\")\n",
        "    print(\"=\"*40)\n",
        "    print(\"ğŸš€ é–‹å§‹è‡ªå‹•åˆ†ææ‰€æœ‰è‚¡ç¥¨...\")\n",
        "\n",
        "    try:\n",
        "        # [éšæ®µ1/7] ç²å–è‚¡ç¥¨åŸºæœ¬è³‡æ–™\n",
        "        print(\"\\n[éšæ®µ1/7] ç²å–æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬è³‡æ–™...\")\n",
        "        stocks_info = get_stock_basic_info()\n",
        "        if not stocks_info:\n",
        "            error_msg = \"âŒ ç„¡æ³•ç²å–è‚¡ç¥¨åŸºæœ¬è³‡æ–™ï¼Œæµç¨‹ä¸­æ­¢ã€‚\"\n",
        "            print(error_msg)\n",
        "            send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æå¤±æ•—*\\n\\n{error_msg}\")\n",
        "            return\n",
        "        print(f\"âœ… æˆåŠŸç²å– {len(stocks_info)} æ”¯è‚¡ç¥¨è³‡æ–™\")\n",
        "\n",
        "        # [éšæ®µ2/7] æ‰¹æ¬¡ä¸‹è¼‰æ­·å²è³‡æ–™\n",
        "        print(\"\\n[éšæ®µ2/7] æ‰¹æ¬¡ä¸‹è¼‰æ­·å²è³‡æ–™...\")\n",
        "        all_stocks_data = fetch_multiple_stocks_data(stocks_info, period='1y')\n",
        "        if not all_stocks_data:\n",
        "            error_msg = \"âŒ ç„¡æ³•å–å¾—ä»»ä½•è‚¡ç¥¨æ­·å²è³‡æ–™ï¼Œæµç¨‹ä¸­æ­¢ã€‚\"\n",
        "            print(error_msg)\n",
        "            send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æå¤±æ•—*\\n\\n{error_msg}\")\n",
        "            return\n",
        "\n",
        "        # [éšæ®µ3/7] éæ¿¾ä½æˆäº¤é‡è‚¡ç¥¨\n",
        "        print(\"\\n[éšæ®µ3/7] éæ¿¾ä½æˆäº¤é‡è‚¡ç¥¨...\")\n",
        "        filtered_data = filter_by_volume(all_stocks_data, min_volume_shares=1000000)\n",
        "        if not filtered_data:\n",
        "            error_msg = \"âŒ æ²’æœ‰ä»»ä½•å€‹è‚¡ç¬¦åˆæˆäº¤é‡æ¨™æº– (è¿‘ä¸€å€‹æœˆæ¯æ—¥æˆäº¤é‡ > 1000å¼µ)ã€‚\"\n",
        "            print(error_msg)\n",
        "            send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æçµæœ*\\n\\n{error_msg}\")\n",
        "            return\n",
        "\n",
        "        progress_msg = f\"ğŸ“Š *è‚¡ç¥¨åˆ†æé€²åº¦å ±å‘Š*\\n\\nâœ… å·²ç²å– {len(stocks_info)} æ”¯è‚¡ç¥¨è³‡æ–™\\nâœ… ç¬¦åˆæˆäº¤é‡æ¨™æº–: {len(filtered_data)} æ”¯\\nğŸ”„ é–‹å§‹é€²è¡ŒæŠ€è¡“åˆ†æ...\"\n",
        "        send_notifications(progress_msg)\n",
        "\n",
        "        # [éšæ®µ4/7] æ ¸å¿ƒåˆ†æèˆ‡è©•åˆ†\n",
        "        print(f\"\\n[éšæ®µ4/7] é€²è¡Œæ ¸å¿ƒåˆ†æèˆ‡ç¶œåˆè©•åˆ† ({len(filtered_data)} æ”¯)...\")\n",
        "        all_analysis_results = {}\n",
        "        successful_analysis, failed_analysis = 0, 0\n",
        "\n",
        "        for i, (stock_id, stock_data) in enumerate(filtered_data.items()):\n",
        "            print(f\"  åˆ†æä¸­ ({i+1}/{len(filtered_data)}): {stock_id} {stock_data.get('stock_name', '')}\")\n",
        "            try:\n",
        "                analysis_result = analyze_stock(stock_id, stock_data)\n",
        "                if analysis_result.get('success'):\n",
        "                    scores, final_score = calculate_comprehensive_score(analysis_result)\n",
        "                    analysis_result.update({\n",
        "                        'scores': {k: int(round(v)) for k, v in scores.items()},\n",
        "                        'combined_score': int(round(final_score))\n",
        "                        # å»ºè­°å…ˆä¸åœ¨æ­¤ç”¢ç”Ÿï¼Œå¾…Kç·šåˆ†æå¾Œçµ±ä¸€ç”¢ç”Ÿ\n",
        "                    })\n",
        "                    all_analysis_results[stock_id] = analysis_result\n",
        "                    successful_analysis += 1\n",
        "                else:\n",
        "                    failed_analysis += 1\n",
        "                    logger.warning(f\"è·³éè‚¡ç¥¨ {stock_id}ï¼Œåˆ†æå¤±æ•—: {analysis_result.get('message', 'æœªçŸ¥éŒ¯èª¤')}\")\n",
        "            except Exception as e:\n",
        "                failed_analysis += 1\n",
        "                logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”Ÿç„¡æ³•é æœŸçš„ç•°å¸¸: {str(e)}\")\n",
        "\n",
        "        print(f\"\\nåˆ†æå®Œæˆ: æˆåŠŸ {successful_analysis} æ”¯ï¼Œå¤±æ•— {failed_analysis} æ”¯\")\n",
        "\n",
        "        if not all_analysis_results:\n",
        "            error_msg = \"âŒ åˆ†æå®Œæˆï¼Œä½†æ²’æœ‰ä»»ä½•æœ‰æ•ˆçš„åˆ†æçµæœã€‚\"\n",
        "            print(error_msg)\n",
        "            send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æçµæœ*\\n\\n{error_msg}\")\n",
        "            return\n",
        "\n",
        "        # [éšæ®µ5/7] ç¯©é¸é ‚å°–å€‹è‚¡ä¸¦ç”ŸæˆKç·šå ±å‘Šèˆ‡å»ºè­° (åˆä½µåŸ5, 7, 8éšæ®µ)\n",
        "        print(\"\\n[éšæ®µ5/7] ç¯©é¸é ‚å°–å€‹è‚¡ä¸¦ç”Ÿæˆå ±å‘Šèˆ‡å»ºè­°...\")\n",
        "\n",
        "        # ç›´æ¥å¾æ‰€æœ‰åˆ†æçµæœä¸­ï¼ŒæŒ‰åˆ†æ•¸æ’åºï¼Œå–å‰10åä½œç‚ºé ‚å°–å€‹è‚¡\n",
        "        top_10_stocks = sorted(\n",
        "            all_analysis_results.items(),\n",
        "            key=lambda item: item[1].get('combined_score', 0),\n",
        "            reverse=True\n",
        "        )[:10]\n",
        "        results_to_show = dict(top_10_stocks)\n",
        "\n",
        "        if not results_to_show:\n",
        "             print(\"ğŸ¤· æœªç¯©é¸å‡ºä»»ä½•é ‚å°–å€‹è‚¡ã€‚\")\n",
        "        else:\n",
        "            print(f\"âœ… å·²ç¯©é¸å‡ºåˆ†æ•¸æœ€é«˜çš„ {len(results_to_show)} æ”¯è‚¡ç¥¨é€²è¡Œæœ€çµ‚å ±å‘Šã€‚\")\n",
        "\n",
        "        success_count, error_count = 0, 0\n",
        "        for stock_id, result in results_to_show.items():\n",
        "            print(f\"  è™•ç†ä¸­ ({success_count + error_count + 1}/{len(results_to_show)}): {stock_id}\")\n",
        "            df_for_patterns = result.get('data_df')\n",
        "\n",
        "            if df_for_patterns is not None and not df_for_patterns.empty:\n",
        "                try:\n",
        "                    df_copy = df_for_patterns.copy()\n",
        "                    df_copy.columns = [col.lower() for col in df_copy.columns]\n",
        "\n",
        "                    date_col = next((col for col in ['date', 'datetime', 'time'] if col in df_copy.columns), None)\n",
        "\n",
        "                    if date_col:\n",
        "                        try:\n",
        "                            df_copy[date_col] = pd.to_datetime(df_copy[date_col])\n",
        "                            df_copy.set_index(date_col, inplace=True)\n",
        "                        except Exception as e:\n",
        "                            #print(f\"    è­¦å‘Š: ç„¡æ³•å°‡ {date_col} è¨­ç‚ºç´¢å¼•: {e}ã€‚å‰µå»ºè‡¨æ™‚ç´¢å¼•ã€‚\")\n",
        "                            df_copy.set_index(pd.date_range(start='2023-01-01', periods=len(df_copy)), inplace=True)\n",
        "                    else:\n",
        "                        #print(\"    è­¦å‘Š: æœªæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œå‰µå»ºè‡¨æ™‚æ—¥æœŸç´¢å¼•ã€‚\")\n",
        "                        df_copy.set_index(pd.date_range(start='2023-01-01', periods=len(df_copy)), inplace=True)\n",
        "\n",
        "                    required_cols = ['open', 'high', 'low', 'close']\n",
        "                    if all(col in df_copy.columns for col in required_cols):\n",
        "                        full_pattern_report = generate_pattern_report(df_copy, periods=['daily', 'weekly', 'monthly'])\n",
        "                        condensed_report, report_summary = generate_condensed_pattern_report_and_summary(full_pattern_report)\n",
        "\n",
        "                        # *** ä¿®æ­£é»ï¼šåŠ å…¥èª¿è©¦ä¿¡æ¯ ***\n",
        "                        result['pattern_report'] = condensed_report\n",
        "                        combined_score = result.get('combined_score', 0)\n",
        "\n",
        "                        # ğŸ” èª¿è©¦ä¿¡æ¯ï¼šåœ¨èª¿ç”¨å‰æª¢æŸ¥åƒæ•¸\n",
        "                        #print(f\"    ğŸ” èª¿ç”¨ generate_recommendation:\")\n",
        "                        #print(f\"        stock_id: {stock_id}\")\n",
        "                        #print(f\"        combined_score: {combined_score} (type: {type(combined_score)})\")\n",
        "                        #print(f\"        report_summary å­˜åœ¨: {report_summary is not None}\")\n",
        "                        #if report_summary:\n",
        "                            #print(f\"        report_summary keys: {list(report_summary.keys())}\")\n",
        "\n",
        "                        recommendation = generate_recommendation(combined_score, report_summary)\n",
        "                        result['recommendation'] = recommendation\n",
        "\n",
        "                        # ğŸ” èª¿è©¦ä¿¡æ¯ï¼šæª¢æŸ¥è¿”å›çµæœ\n",
        "                        #print(f\"    ğŸ” generate_recommendation è¿”å›:\")\n",
        "                        #print(f\"        action: {recommendation.get('action', 'N/A')}\")\n",
        "                        #print(f\"        confidence: {recommendation.get('confidence', 'N/A')}\")\n",
        "\n",
        "                        #print(f\"    å ±å‘Šå·²ç”Ÿæˆ: æ‘˜è¦é•·åº¦ {len(condensed_report)} å­—ç¬¦\")\n",
        "                        #success_count += 1\n",
        "                    else:\n",
        "                        missing_cols = [col for col in required_cols if col not in df_copy.columns]\n",
        "                        logger.warning(f\"ç„¡æ³•ç‚ºè‚¡ç¥¨ {stock_id} ç”Ÿæˆå ±å‘Šï¼Œç¼ºå°‘æ¬„ä½: {missing_cols}\")\n",
        "                        result['pattern_report'] = f\"Kç·šå ±å‘Šç”Ÿæˆå¤±æ•—ï¼šç¼ºå°‘æ¬„ä½ã€‚\"\n",
        "                        result['recommendation'] = {\"action\": \"éŒ¯èª¤\", \"reason\": \"æ•¸æ“šä¸å®Œæ•´\", \"confidence\": 0}\n",
        "                        error_count += 1\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"ç‚ºè‚¡ç¥¨ {stock_id} ç”ŸæˆKç·šå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    result['pattern_report'] = \"Kç·šå ±å‘Šç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚\"\n",
        "                    result['recommendation'] = {\"action\": \"éŒ¯èª¤\", \"reason\": \"åˆ†æéç¨‹ç•°å¸¸\", \"confidence\": 0}\n",
        "                    error_count += 1\n",
        "            else:\n",
        "                logger.warning(f\"è‚¡ç¥¨ {stock_id} çš„æ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆå ±å‘Šã€‚\")\n",
        "                result['pattern_report'] = \"æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•ç”ŸæˆKç·šå ±å‘Šã€‚\"\n",
        "                result['recommendation'] = {\"action\": \"éŒ¯èª¤\", \"reason\": \"æ•¸æ“šä¸è¶³\", \"confidence\": 0}\n",
        "                error_count += 1\n",
        "\n",
        "        print_top_stocks(results_to_show, top_n=10)\n",
        "        print(f\"\\nå ±å‘Šç”Ÿæˆçµæœ: æˆåŠŸ {success_count} æ”¯ï¼Œå¤±æ•— {error_count} æ”¯\")\n",
        "        print(\"âœ… æ‰€æœ‰é ‚å°–å€‹è‚¡å ±å‘Šèˆ‡å»ºè­°å·²ç”Ÿæˆã€‚\")\n",
        "\n",
        "        # [éšæ®µ6/7] ç”Ÿæˆå ±å‘Šèˆ‡ç™¼é€é€šçŸ¥\n",
        "        print(\"\\n[éšæ®µ6/7] ç”Ÿæˆå ±å‘Šã€åœ–è¡¨èˆ‡ç™¼é€é€šçŸ¥...\")\n",
        "\n",
        "        summary_msg = format_notification_message(\n",
        "            results_to_show,\n",
        "            successful_analysis,\n",
        "            failed_analysis,\n",
        "            len(filtered_data)\n",
        "        )\n",
        "\n",
        "        report_dir = 'reports'\n",
        "        os.makedirs(report_dir, exist_ok=True)\n",
        "        generated_images = []\n",
        "\n",
        "        # åªç‚ºåˆ†æ•¸æœ€é«˜çš„å‰5åç”Ÿæˆåœ–è¡¨\n",
        "        for stock_id, stock_info in list(results_to_show.items())[:5]:\n",
        "            print(f\"  ç”Ÿæˆåœ–è¡¨: {stock_id}\")\n",
        "            image_path = generate_detailed_analysis_report(\n",
        "                stock_id=stock_id,\n",
        "                analysis_result=stock_info,\n",
        "                output_dir=report_dir\n",
        "            )\n",
        "            if image_path and os.path.exists(image_path):\n",
        "                generated_images.append(image_path)\n",
        "\n",
        "        export_html_report(all_analysis_results)\n",
        "\n",
        "        final_message = summary_msg + f\"\\n\\nğŸ“Š å·²ç”Ÿæˆ {len(generated_images)} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\\nğŸ“‹ HTML è©³ç´°å ±å‘Šå·²åŒ¯å‡º\"\n",
        "        send_notifications(final_message, generated_images)\n",
        "\n",
        "        # [éšæ®µ7/7] æ‰“å°æœ€çµ‚å ±å‘Š\n",
        "        if results_to_show:\n",
        "            print(\"\\n\\n========== ğŸ† é ‚å°–å€‹è‚¡åˆ†æå ±å‘Š ğŸ† ==========\\n\")\n",
        "            for stock_id, result in results_to_show.items():\n",
        "                try:\n",
        "                    stock_name = result.get('stock_name', '') or get_stock_name(stock_id)\n",
        "                    print(f\"ã€{stock_id} {stock_name}ã€‘\")\n",
        "                    print(f\"ç¶œåˆè©•åˆ†: {result.get('combined_score', 0)}\")\n",
        "\n",
        "                    pattern_report = result.get('pattern_report', 'ç„¡Kç·šå‹æ…‹å ±å‘Š')\n",
        "                    print(f\"Kç·šåˆ†æ:\\n{pattern_report}\")\n",
        "\n",
        "                    recommendation = result.get('recommendation', {})\n",
        "                    action = recommendation.get('action', 'ç„¡å»ºè­°')\n",
        "                    reason = recommendation.get('reason', 'ç„¡ç†ç”±')\n",
        "                    confidence = recommendation.get('confidence', 0)\n",
        "                    print(f\"\\næŠ•è³‡å»ºè­°: {action}\")\n",
        "                    print(f\"å»ºè­°ç†ç”±: {reason}\")\n",
        "                    print(f\"ä¿¡å¿ƒåº¦: {confidence}%\")\n",
        "\n",
        "                    if 'pattern_details' in recommendation:\n",
        "                        print(\"å‹æ…‹è©³æƒ…:\")\n",
        "                        for detail in recommendation['pattern_details']:\n",
        "                            print(f\"  â€¢ {detail}\")\n",
        "\n",
        "                    print(\"\\né—œéµæŒ‡æ¨™:\")\n",
        "                    indicators = result.get('indicators', {})\n",
        "                    for key in ['rsi', 'macd', 'bb_width', 'atr']:\n",
        "                        if key in indicators:\n",
        "                            print(f\"  {key.upper()}: {indicators[key]:.2f}\")\n",
        "\n",
        "                    print(\"-\" * 50 + \"\\n\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ æ‰“å°è‚¡ç¥¨ {stock_id} çš„å ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        else:\n",
        "            print(\"\\nâš ï¸ æ²’æœ‰é ‚å°–å€‹è‚¡å¯ä¾›é¡¯ç¤ºã€‚\")\n",
        "\n",
        "        print(\"\\nğŸ‰ å…¨éƒ¨æµç¨‹åŸ·è¡Œå®Œç•¢ï¼\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ä¸»ç¨‹åºç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}\"\n",
        "        print(error_msg)\n",
        "        logger.error(error_msg)\n",
        "        logger.debug(traceback.format_exc())\n",
        "        send_notifications(f\"ğŸš¨ *è‚¡ç¥¨åˆ†æåš´é‡å¤±æ•—*\\n\\n{error_msg}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    check_environment()\n",
        "    set_chinese_font()\n",
        "    main_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7gqIWGS8w_s"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "å°è‚¡æŠ€è¡“ + æƒ…ç·’ + æ©Ÿå™¨å­¸ç¿’å¼·åŒ– è©•åˆ†ç³»çµ± (å®Œæ•´æ•´åˆç‰ˆ)\n",
        "=================================================\n",
        "åŠŸèƒ½åŒ…å«ï¼š\n",
        "1. å–å¾—å°è‚¡æ¸…å–®èˆ‡å‚™æ´\n",
        "2. yfinance æŠ“å–æ­·å²æ—¥ç·š\n",
        "3. æŠ€è¡“æŒ‡æ¨™ï¼šRSI / MACD / KD / å¸ƒæ—å¸¶ / å‡ç·š\n",
        "4. æ–°èæ¨™é¡Œæƒ…ç·’ + ç†±åº¦çµ±è¨ˆï¼ˆå¤šä¾†æºï¼›ç°¡æ˜“å­—å…¸æƒ…ç·’ï¼‰\n",
        "5. å°ç£å¸‚å ´ Fear & Greed æŒ‡æ•¸ï¼ˆåƒ¹å‹•èƒ½ã€æ³¢å‹•æ¯”ã€é›†ä¸­å¸‚å ´æˆäº¤é‡ã€é¸æ“‡æ¬Š Put/Call Ratioï¼‰\n",
        "6. ç¶œåˆè©•åˆ†ï¼šè¶¨å‹¢ / æˆäº¤é‡ / æŠ€è¡“ / æƒ…ç·’ / MLé æ¸¬ï¼ˆå¯é¸ï¼‰\n",
        "7. Telegram / Discord é€šçŸ¥\n",
        "8. çµ‚ç«¯/æ–‡å­—è¼¸å‡ºæ ¼å¼åŒ–\n",
        "9. (æ›´æ–°) ä½¿ç”¨ TWSE å…¬é–‹ API çœŸå¯¦å–å¾—ï¼šæœ¬ç›Šæ¯”(PE)ã€ä¸‰å¤§æ³•äººè²·è³£è¶…(ç±Œç¢¼)ï¼Œæ›¿æ›éå»éš¨æ©Ÿç‰¹å¾µ\n",
        "=================================================\n",
        "å®‰è£éœ€æ±‚ï¼š\n",
        "pip install pandas numpy yfinance requests beautifulsoup4 jieba aiohttp nest_asyncio scikit-learn discord-webhook\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import logging\n",
        "import traceback\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import jieba\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from collections import Counter\n",
        "from io import StringIO\n",
        "from functools import lru_cache\n",
        "\n",
        "# ML\n",
        "try:\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    SKLEARN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SKLEARN_AVAILABLE = False\n",
        "\n",
        "# Discord\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# nest_asyncioï¼ˆåœ¨ Jupyter ç­‰éœ€è¦ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ========= æ—¥èªŒè¨­å®š =========\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
        ")\n",
        "logger = logging.getLogger(\"StockSentimentSystem\")\n",
        "\n",
        "# ========= æ™‚å€ =========\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# ========= é€šè¨Šè¨­å®š (è«‹è‡ªè¡Œæ›´æ›) =========\n",
        "TELEGRAM_BOT_TOKEN = os.getenv(\"TELEGRAM_BOT_TOKEN\", \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\")\n",
        "TELEGRAM_CHAT_IDS = [int(x) for x in os.getenv(\"TELEGRAM_CHAT_IDS\", [879781796, 8113868436]).split(\",\")]\n",
        "DISCORD_WEBHOOK_URL = os.getenv(\"DISCORD_WEBHOOK_URL\", \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\")\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "\n",
        "# ========= æ©Ÿå™¨å­¸ç¿’ç›¸é—œï¼ˆå¯é¸ï¼‰ =========\n",
        "def adaptive_weights(market_condition: str) -> Dict[str, float]:\n",
        "    if market_condition == \"bull\":\n",
        "        return {\"pe\": 0.2, \"volume\": 0.3, \"ma\": 0.3, \"chips\": 0.2}\n",
        "    elif market_condition == \"bear\":\n",
        "        return {\"pe\": 0.4, \"volume\": 0.2, \"ma\": 0.2, \"chips\": 0.2}\n",
        "    else:\n",
        "        return {\"pe\": 0.3, \"volume\": 0.25, \"ma\": 0.25, \"chips\": 0.2}\n",
        "\n",
        "def build_ml_model(historical_data: pd.DataFrame) -> Optional[RandomForestRegressor]:\n",
        "    if not SKLEARN_AVAILABLE:\n",
        "        logger.warning(\"scikit-learn æœªå®‰è£ï¼Œè·³é ML æ¨¡å‹å»ºç«‹\")\n",
        "        return None\n",
        "    required_cols = ['pe_ratio', 'volume', 'ma_signal', 'chips_score', 'future_return']\n",
        "    for c in required_cols:\n",
        "        if c not in historical_data.columns:\n",
        "            logger.warning(f\"æ­·å²è³‡æ–™ç¼ºå°‘æ¬„ä½: {c}ï¼Œè·³é ML\")\n",
        "            return None\n",
        "    try:\n",
        "        model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "        model.fit(historical_data[['pe_ratio', 'volume', 'ma_signal', 'chips_score']], historical_data['future_return'])\n",
        "        logger.info(\"ML æ¨¡å‹è¨“ç·´å®Œæˆ\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ML æ¨¡å‹è¨“ç·´å¤±æ•—: {e}\")\n",
        "        return None\n",
        "\n",
        "def ml_predict_current(model: RandomForestRegressor,\n",
        "                       pe_ratio: float,\n",
        "                       volume: float,\n",
        "                       ma_signal: int,\n",
        "                       chips_score: int) -> float:\n",
        "    if model is None:\n",
        "        return 0.0\n",
        "    try:\n",
        "        df_feat = pd.DataFrame([{\n",
        "            'pe_ratio': pe_ratio,\n",
        "            'volume': volume,\n",
        "            'ma_signal': ma_signal,\n",
        "            'chips_score': chips_score\n",
        "        }])\n",
        "        pred = float(model.predict(df_feat)[0])\n",
        "        return pred\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ML é æ¸¬å¤±æ•—: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "# ========= çœŸå¯¦ç‰¹å¾µæŠ“å–å™¨ =========\n",
        "class RealFeatureFetcher:\n",
        "    \"\"\"\n",
        "    å¾å°ç£è­‰äº¤æ‰€å…¬é–‹ API å–å¾—ï¼š\n",
        "    1. æœ¬ç›Šæ¯”ã€æ®–åˆ©ç‡ã€è‚¡åƒ¹æ·¨å€¼æ¯” (BWIBBU_d)\n",
        "    2. ä¸‰å¤§æ³•äººè²·è³£è¶… (T86)\n",
        "    (å…·å‚™æ—¥æœŸå›é€€ã€å¿«å–ã€è½‰æ›/æ¸…ç†)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        self._fundamental_cache: Dict[str, Dict[str, Any]] = {}\n",
        "        self._chips_cache: Dict[str, Dict[str, Any]] = {}\n",
        "        self._last_date_used = None\n",
        "\n",
        "    @staticmethod\n",
        "    def _date_str_list(days_back=7) -> List[str]:\n",
        "        today = datetime.now(taipei_tz).date()\n",
        "        dates = []\n",
        "        for i in range(days_back):\n",
        "            d = today - timedelta(days=i)\n",
        "            dates.append(d.strftime(\"%Y%m%d\"))\n",
        "        return dates\n",
        "\n",
        "    def _fetch_json(self, url: str, params: Dict[str, Any] = None, retry=3) -> Optional[Dict[str, Any]]:\n",
        "        for attempt in range(retry):\n",
        "            try:\n",
        "                r = self.session.get(url, params=params, headers=self.headers, timeout=15)\n",
        "                if r.status_code == 200:\n",
        "                    return r.json()\n",
        "                else:\n",
        "                    logger.debug(f\"URL {url} ç‹€æ…‹ç¢¼ {r.status_code}\")\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"è«‹æ±‚å¤±æ•— {url}: {e}\")\n",
        "            time.sleep(1 + attempt)\n",
        "        return None\n",
        "\n",
        "    def _load_fundamental_for_date(self, date_str: str) -> bool:\n",
        "        \"\"\"\n",
        "        å–å¾—å–®ä¸€æ—¥æœŸæœ¬ç›Šæ¯”è³‡æ–™\n",
        "        API: https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d?date=YYYYMMDD&selectType=ALL\n",
        "        \"\"\"\n",
        "        url = \"https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d\"\n",
        "        params = {\"date\": date_str, \"selectType\": \"ALL\", \"response\": \"json\"}\n",
        "        js = self._fetch_json(url, params=params)\n",
        "        if not js or js.get(\"data\") is None:\n",
        "            return False\n",
        "        fields = js.get(\"fields\", [])\n",
        "        data = js.get(\"data\", [])\n",
        "        # å…¸å‹æ¬„ä½ï¼ˆå¯èƒ½è®Šå‹•ï¼‰ï¼š['è­‰åˆ¸ä»£è™Ÿ','è­‰åˆ¸åç¨±','æ®–åˆ©ç‡(%)','è‚¡åˆ©å¹´åº¦','æœ¬ç›Šæ¯”','è‚¡åƒ¹æ·¨å€¼æ¯”','è²¡å ±å¹´/å­£']\n",
        "        try:\n",
        "            col_index = {name: idx for idx, name in enumerate(fields)}\n",
        "            for row in data:\n",
        "                try:\n",
        "                    code = row[col_index['è­‰åˆ¸ä»£è™Ÿ']].strip()\n",
        "                    pe_raw = row[col_index.get('æœ¬ç›Šæ¯”', -1)]\n",
        "                    pb_raw = row[col_index.get('è‚¡åƒ¹æ·¨å€¼æ¯”', -1)]\n",
        "                    dy_raw = row[col_index.get('æ®–åˆ©ç‡(%)', -1)]\n",
        "                    # æ¸…ç†\n",
        "                    def to_float(v):\n",
        "                        try:\n",
        "                            v = str(v).replace(',', '').strip()\n",
        "                            if v in ['-', 'N/A', 'nan', '']:\n",
        "                                return float('nan')\n",
        "                            return float(v)\n",
        "                        except:\n",
        "                            return float('nan')\n",
        "                    pe = to_float(pe_raw)\n",
        "                    pb = to_float(pb_raw)\n",
        "                    dy = to_float(dy_raw)\n",
        "                    self._fundamental_cache[code] = {\n",
        "                        'pe_ratio': pe,\n",
        "                        'pb_ratio': pb,\n",
        "                        'div_yield': dy,\n",
        "                        'date': date_str\n",
        "                    }\n",
        "                except Exception:\n",
        "                    continue\n",
        "            logger.info(f\"å–å¾—æœ¬ç›Šæ¯”è³‡æ–™æ—¥æœŸ {date_str} å…± {len(self._fundamental_cache)} ç­† (ç´¯ç©)\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.debug(f\"è§£ææœ¬ç›Šæ¯”è³‡æ–™å¤±æ•— {date_str}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _load_chips_for_date(self, date_str: str) -> bool:\n",
        "        \"\"\"\n",
        "        å–å¾—ä¸‰å¤§æ³•äººè³‡æ–™\n",
        "        API: https://www.twse.com.tw/rwd/zh/fund/T86?date=YYYYMMDD&selectType=ALL\n",
        "        é‡é»æ¬„ä½ï¼š'è­‰åˆ¸ä»£è™Ÿ','è­‰åˆ¸åç¨±','ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸'\n",
        "        \"\"\"\n",
        "        url = \"https://www.twse.com.tw/rwd/zh/fund/T86\"\n",
        "        params = {\"date\": date_str, \"selectType\": \"ALL\", \"response\": \"json\"}\n",
        "        js = self._fetch_json(url, params=params)\n",
        "        if not js or js.get(\"data\") is None:\n",
        "            return False\n",
        "        fields = js.get(\"fields\", [])\n",
        "        data = js.get(\"data\", [])\n",
        "        try:\n",
        "            col_index = {name: idx for idx, name in enumerate(fields)}\n",
        "            if 'ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸' not in col_index:\n",
        "                # çµæ§‹è®Šå‹• fallback\n",
        "                return False\n",
        "            for row in data:\n",
        "                try:\n",
        "                    code = row[col_index['è­‰åˆ¸ä»£è™Ÿ']].strip()\n",
        "                    net_raw = row[col_index['ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸']]\n",
        "                    net_raw = str(net_raw).replace(',', '').strip()\n",
        "                    if net_raw in ['-', '']:\n",
        "                        net_val = 0\n",
        "                    else:\n",
        "                        net_val = int(net_raw)\n",
        "                    self._chips_cache[code] = {\n",
        "                        'chips_net': net_val,\n",
        "                        'date': date_str\n",
        "                    }\n",
        "                except Exception:\n",
        "                    continue\n",
        "            logger.info(f\"å–å¾—ä¸‰å¤§æ³•äººè³‡æ–™æ—¥æœŸ {date_str} å…± {len(self._chips_cache)} ç­† (ç´¯ç©)\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.debug(f\"è§£æä¸‰å¤§æ³•äººè³‡æ–™å¤±æ•— {date_str}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def prepare_latest(self, max_back_days: int = 7):\n",
        "        \"\"\"\n",
        "        ä¾åºå¾€å‰å›é€€æ—¥æœŸç›´åˆ°æŠ“åˆ°è³‡æ–™æˆ–é”ä¸Šé™\n",
        "        \"\"\"\n",
        "        if self._last_date_used is not None:\n",
        "            return  # å·²ç¶“æŠ“éç•¶æ—¥/æœ€è¿‘ä¸€æ¬¡\n",
        "        for d in self._date_str_list(max_back_days):\n",
        "            f_ok = self._load_fundamental_for_date(d)\n",
        "            c_ok = self._load_chips_for_date(d)\n",
        "            if f_ok or c_ok:\n",
        "                self._last_date_used = d\n",
        "                break\n",
        "        if self._last_date_used is None:\n",
        "            logger.warning(\"ç„¡æ³•å–å¾—æœ€è¿‘ 7 æ—¥å…§ä»»ä½•æœ¬ç›Šæ¯” / ç±Œç¢¼è³‡æ–™ï¼Œå°‡ä½¿ç”¨é è¨­å€¼\")\n",
        "\n",
        "    def get_features(self, stock_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        å›å‚³æŒ‡å®šè‚¡ç¥¨çš„ç‰¹å¾µï¼š\n",
        "        pe_ratio, pb_ratio, div_yield, chips_net, chips_score\n",
        "        chips_score è¨ˆç®—é‚è¼¯ï¼š\n",
        "            - ä¾æ‰€æœ‰æœ‰è³‡æ–™è‚¡ç¥¨çš„ chips_net æ’å (åˆ†ä½æ•¸)\n",
        "            - åˆ†ä½æ•¸ > 0.66 â‡’ 2\n",
        "            - 0.33 ~ 0.66 â‡’ 1\n",
        "            - <= 0.33 â‡’ 0\n",
        "            - è‹¥ç‚ºé¡¯è‘—è² å€¼ä¸”å°æ–¼ 20% åˆ†ä½å¯çµ¦ -1ï¼ˆä¾› ML ä½¿ç”¨ï¼Œä¸é€²å…¥åŸæœ¬çš„çµ„åˆè©•åˆ†ï¼‰\n",
        "        \"\"\"\n",
        "        # ç¢ºä¿è³‡æ–™å·²è¼‰å…¥\n",
        "        if self._last_date_used is None:\n",
        "            self.prepare_latest()\n",
        "\n",
        "        feat = {\n",
        "            'pe_ratio': float('nan'),\n",
        "            'pb_ratio': float('nan'),\n",
        "            'div_yield': float('nan'),\n",
        "            'chips_net': 0,\n",
        "            'chips_score': 0\n",
        "        }\n",
        "        if stock_id in self._fundamental_cache:\n",
        "            f = self._fundamental_cache[stock_id]\n",
        "            feat['pe_ratio'] = f.get('pe_ratio', float('nan'))\n",
        "            feat['pb_ratio'] = f.get('pb_ratio', float('nan'))\n",
        "            feat['div_yield'] = f.get('div_yield', float('nan'))\n",
        "        if stock_id in self._chips_cache:\n",
        "            feat['chips_net'] = self._chips_cache[stock_id]['chips_net']\n",
        "\n",
        "        # è¨ˆç®—ç±Œç¢¼åˆ†ä½æ•¸ï¼ˆåªåšä¸€æ¬¡å…¨åŸŸæ’åºï¼‰\n",
        "        if not hasattr(self, '_chips_rank_prepared'):\n",
        "            all_nets = [v['chips_net'] for v in self._chips_cache.values() if isinstance(v.get('chips_net'), int)]\n",
        "            if len(all_nets) > 10:\n",
        "                arr = np.array(all_nets)\n",
        "                self._chips_p33 = np.percentile(arr, 33)\n",
        "                self._chips_p66 = np.percentile(arr, 66)\n",
        "                self._chips_p20 = np.percentile(arr, 20)\n",
        "            else:\n",
        "                self._chips_p33 = self._chips_p66 = self._chips_p20 = 0\n",
        "            self._chips_rank_prepared = True\n",
        "\n",
        "        try:\n",
        "            cn = feat['chips_net']\n",
        "            if ' _chips_p33' in dir(self):\n",
        "                # ç›´æ¥ç”¨å±¬æ€§\n",
        "                pass\n",
        "            if cn <= self._chips_p20:\n",
        "                feat['chips_score'] = -1  # é¡¯è‘—åç©º\n",
        "            if cn > self._chips_p66:\n",
        "                feat['chips_score'] = 2\n",
        "            elif cn > self._chips_p33:\n",
        "                feat['chips_score'] = 1\n",
        "            # <= p33 ä¸”å°šæœªæ¨™è¨˜ -1 æ™‚ä¿æŒ 0\n",
        "        except Exception:\n",
        "            feat['chips_score'] = 0\n",
        "\n",
        "        # fallback: pe_ratio è‹¥ç‚º nan çµ¦å¹³å‡å€¼ 15~20\n",
        "        if math.isnan(feat['pe_ratio']):\n",
        "            feat['pe_ratio'] = 18.0\n",
        "        return feat\n",
        "\n",
        "# ========= å¸‚å ´æƒ…ç·’åˆ†æå™¨ =========\n",
        "class MarketSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.config = {\n",
        "            'news_weight': 0.4,\n",
        "            'fear_greed_weight': 0.6,\n",
        "            'news_sources': [\n",
        "                'https://news.cnyes.com/news/cat/tw_stock',\n",
        "                'https://www.moneydj.com/kmdj/news/newsreallist.aspx?a=5',\n",
        "                'https://www.cnbc.com/world/?region=world',\n",
        "            ],\n",
        "            'positive_keywords': ['ä¸Šæ¼²', 'çªç ´', 'åˆ©å¤š', 'æˆé•·', 'ç²åˆ©', 'çœ‹å¥½', 'å¼·å‹¢', 'æ¼²åœ', 'çªåœ', 'è²·é€²', 'å‰µé«˜', 'è¶…é æœŸ'],\n",
        "            'negative_keywords': ['ä¸‹è·Œ', 'è·Œç ´', 'åˆ©ç©º', 'è¡°é€€', 'è™§æ', 'çœ‹æ·¡', 'å¼±å‹¢', 'è·Œåœ', 'é‡æŒ«', 'è³£å‡º', 'èª¿é™', 'è£å“¡'],\n",
        "            'cache_duration': 1800\n",
        "        }\n",
        "        self.news_cache: Dict[str, Any] = {}\n",
        "        self.fear_greed_cache: Dict[str, Any] = {'timestamp': 0, 'value': 50, 'components': {}}\n",
        "\n",
        "    def get_stock_news_sentiment(self, stock_id: str, stock_name: str) -> Tuple[float, int]:\n",
        "        cache_key = f\"{stock_id}_{stock_name}\"\n",
        "        now_ts = time.time()\n",
        "        if cache_key in self.news_cache and (now_ts - self.news_cache[cache_key]['timestamp'] < self.config['cache_duration']):\n",
        "            return self.news_cache[cache_key]['sentiment_score'], self.news_cache[cache_key]['news_count']\n",
        "        search_terms = [stock_id, stock_name]\n",
        "        news_count = 0\n",
        "        sentiment_scores = []\n",
        "        for url in self.config['news_sources']:\n",
        "            try:\n",
        "                headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "                resp = requests.get(url, headers=headers, timeout=12)\n",
        "                soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "                candidates = soup.select('a, h2, h3, div')\n",
        "                for c in candidates:\n",
        "                    text = c.get_text(strip=True)\n",
        "                    if not text or len(text) > 60:\n",
        "                        continue\n",
        "                    if any(term in text for term in search_terms):\n",
        "                        news_count += 1\n",
        "                        words = jieba.lcut(text)\n",
        "                        pos = sum(1 for w in words if w in self.config['positive_keywords'])\n",
        "                        neg = sum(1 for w in words if w in self.config['negative_keywords'])\n",
        "                        if pos + neg > 0:\n",
        "                            s = (pos - neg) / (pos + neg)\n",
        "                            sentiment_scores.append(s)\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"æ–°èä¾†æºå¤±æ•— {url}: {e}\")\n",
        "        if sentiment_scores:\n",
        "            avg = float(np.mean(sentiment_scores))\n",
        "            score_0_100 = (avg + 1) * 50\n",
        "        else:\n",
        "            score_0_100 = 50.0\n",
        "        self.news_cache[cache_key] = {\n",
        "            'timestamp': now_ts,\n",
        "            'sentiment_score': score_0_100,\n",
        "            'news_count': news_count\n",
        "        }\n",
        "        return score_0_100, news_count\n",
        "\n",
        "    def get_fear_greed_index(self) -> Tuple[float, Dict[str, Any]]:\n",
        "        now_ts = time.time()\n",
        "        if now_ts - self.fear_greed_cache['timestamp'] < self.config['cache_duration']:\n",
        "            return self.fear_greed_cache['value'], self.fear_greed_cache['components']\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        components = {\n",
        "            'price_momentum': None,\n",
        "            'price_score': 50,\n",
        "            'volatility_ratio': None,\n",
        "            'volatility_score': 50,\n",
        "            'volume_change_pct': None,\n",
        "            'volume_score': 50,\n",
        "            'pc_ratio': None,\n",
        "            'pc_ratio_score': 50\n",
        "        }\n",
        "        try:\n",
        "            taiex_url = \"https://query1.finance.yahoo.com/v8/finance/chart/%5ETWII?interval=1d&range=60d\"\n",
        "            r = requests.get(taiex_url, headers=headers, timeout=12).json()\n",
        "            closes = r['chart']['result'][0]['indicators']['quote'][0]['close']\n",
        "            closes = [c for c in closes if c is not None]\n",
        "            if len(closes) >= 20:\n",
        "                ma10 = np.mean(closes[-10:])\n",
        "                last = closes[-1]\n",
        "                price_momentum = (last / ma10 - 1) * 100 if ma10 else 0\n",
        "                components['price_momentum'] = price_momentum\n",
        "                price_score = 50 + price_momentum * 5\n",
        "                components['price_score'] = max(0, min(100, price_score))\n",
        "                ret = np.diff(closes) / closes[:-1]\n",
        "                if len(ret) >= 21:\n",
        "                    vol_5 = np.std(ret[-5:]) * 100\n",
        "                    vol_20 = np.std(ret[-20:]) * 100\n",
        "                    vol_ratio = vol_5 / vol_20 if vol_20 else 1\n",
        "                    components['volatility_ratio'] = vol_ratio\n",
        "                    volatility_score = 100 - (vol_ratio - 0.5) * 100\n",
        "                    components['volatility_score'] = max(0, min(100, volatility_score))\n",
        "            volume_url = \"https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK?date=20230101&response=json\"\n",
        "            try:\n",
        "                rv = requests.get(volume_url, headers=headers, timeout=12).json()\n",
        "                vol_list = []\n",
        "                if 'data' in rv:\n",
        "                    for row in rv['data'][-8:]:\n",
        "                        try:\n",
        "                            val = row[1].replace(',', '')\n",
        "                            vol_list.append(float(val))\n",
        "                        except:\n",
        "                            pass\n",
        "                if len(vol_list) >= 5:\n",
        "                    recent = np.mean(vol_list[-5:])\n",
        "                    prev = np.mean(vol_list[-10:-5]) if len(vol_list) >= 10 else recent\n",
        "                    volume_change = (recent / prev - 1) * 100 if prev else 0\n",
        "                    components['volume_change_pct'] = volume_change\n",
        "                    components['volume_score'] = max(0, min(100, 50 + volume_change))\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"FearGreed æˆäº¤é‡æŠ“å–å¤±æ•—: {e}\")\n",
        "            try:\n",
        "                pc_url = \"https://www.taifex.com.tw/cht/3/pcRatio\"\n",
        "                pr = requests.get(pc_url, headers=headers, timeout=12)\n",
        "                soup = BeautifulSoup(pr.text, 'html.parser')\n",
        "                tables = soup.find_all('table')\n",
        "                pc_ratio = None\n",
        "                for tbl in tables:\n",
        "                    tds = tbl.find_all('td')\n",
        "                    for td in tds:\n",
        "                        txt = td.get_text(strip=True)\n",
        "                        if re.match(r'^\\d+(\\.\\d+)?$', txt):\n",
        "                            val = float(txt)\n",
        "                            if 0.3 < val < 5:\n",
        "                                pc_ratio = val\n",
        "                                break\n",
        "                    if pc_ratio:\n",
        "                        break\n",
        "                if pc_ratio:\n",
        "                    components['pc_ratio'] = pc_ratio\n",
        "                    pc_score = 50 + (pc_ratio - 1) * 40\n",
        "                    components['pc_ratio_score'] = max(0, min(100, pc_score))\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"FearGreed P/C å¤±æ•—: {e}\")\n",
        "            final_value = (\n",
        "                components['price_score'] * 0.5 +\n",
        "                components['volatility_score'] * 0.2 +\n",
        "                components['volume_score'] * 0.15 +\n",
        "                components['pc_ratio_score'] * 0.15\n",
        "            )\n",
        "            final_value = max(0, min(100, final_value))\n",
        "            market_mood = \"æ¥µåº¦ææ…Œ\" if final_value < 20 else \\\n",
        "                          \"ææ…Œ\" if final_value < 40 else \\\n",
        "                          \"ä¸­æ€§\" if final_value < 60 else \\\n",
        "                          \"è²ªå©ª\" if final_value < 80 else \"æ¥µåº¦è²ªå©ª\"\n",
        "            components['market_mood'] = market_mood\n",
        "            self.fear_greed_cache = {\n",
        "                'timestamp': now_ts,\n",
        "                'value': final_value,\n",
        "                'components': components\n",
        "            }\n",
        "            return final_value, components\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Fear & Greed è¨ˆç®—å¤±æ•—: {e}\")\n",
        "            return self.fear_greed_cache['value'], self.fear_greed_cache['components']\n",
        "\n",
        "    def calculate_sentiment_score(self, stock_id: str, stock_name: str) -> Dict[str, Any]:\n",
        "        news_sentiment, news_count = self.get_stock_news_sentiment(stock_id, stock_name)\n",
        "        fear_greed_value, fg_components = self.get_fear_greed_index()\n",
        "        if fear_greed_value < 20 or fear_greed_value > 80:\n",
        "            adj_fg_w = self.config['fear_greed_weight'] * 1.3\n",
        "        else:\n",
        "            adj_fg_w = self.config['fear_greed_weight']\n",
        "        adj_news_w = self.config['news_weight'] * min(1.0, news_count / 5)\n",
        "        total_w = adj_news_w + adj_fg_w\n",
        "        if total_w == 0:\n",
        "            total_w = 1\n",
        "        adj_news_w /= total_w\n",
        "        adj_fg_w /= total_w\n",
        "        sentiment_score = news_sentiment * adj_news_w + fear_greed_value * adj_fg_w\n",
        "        return {\n",
        "            'sentiment_score': sentiment_score,\n",
        "            'news_sentiment': news_sentiment,\n",
        "            'news_count': news_count,\n",
        "            'fear_greed_index': fear_greed_value,\n",
        "            'market_mood': fg_components.get('market_mood', ''),\n",
        "            'fear_greed_components': fg_components,\n",
        "            'weight_news': adj_news_w,\n",
        "            'weight_fear_greed': adj_fg_w\n",
        "        }\n",
        "\n",
        "# ========= è‚¡ç¥¨åˆ†æå™¨ =========\n",
        "class StockAnalyzer:\n",
        "    def __init__(self, ml_model: Optional[RandomForestRegressor] = None):\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,\n",
        "            'sentiment_weights': {\n",
        "                'trend': 0.25,\n",
        "                'volume': 0.10,\n",
        "                'technical': 0.35,\n",
        "                'sentiment': 0.20,\n",
        "                'ml': 0.10\n",
        "            }\n",
        "        }\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "        self.taiwan_stocks: Optional[pd.DataFrame] = None\n",
        "        self.sentiment_analyzer = MarketSentimentAnalyzer()\n",
        "        self.ml_model = ml_model\n",
        "        self.feature_fetcher = RealFeatureFetcher()  # æ–°å¢çœŸå¯¦ç‰¹å¾µæŠ“å–å™¨ï¼ˆæœ¬ç›Šæ¯” / ç±Œç¢¼ï¼‰\n",
        "\n",
        "    # --------- è‚¡ç¥¨åˆ—è¡¨å–å¾— ---------\n",
        "    def get_taiwan_stocks(self, force_update: bool = True) -> pd.DataFrame:\n",
        "        if (not force_update) and os.path.exists(self.stock_list_path):\n",
        "            if time.time() - os.path.getmtime(self.stock_list_path) < 86400:\n",
        "                try:\n",
        "                    return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "                except Exception:\n",
        "                    pass\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_dfs = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                resp = requests.get(url, headers=headers, timeout=30)\n",
        "                resp.encoding = 'big5'\n",
        "                tables = pd.read_html(StringIO(resp.text))\n",
        "                df = tables[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df['market'] = market_name\n",
        "                all_dfs.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"å–å¾— {market_name} æ¸…å–®å¤±æ•—: {e}\")\n",
        "        if not all_dfs:\n",
        "            return self._get_backup_stock_list()\n",
        "        try:\n",
        "            df = pd.concat(all_dfs, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)]\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)]\n",
        "            df['yahoo_symbol'] = df.apply(\n",
        "                lambda r: f\"{r['stock_id']}.TW\" if 'ä¸Šå¸‚' in r['market'] else f\"{r['stock_id']}.TWO\", axis=1\n",
        "            )\n",
        "            final = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final = final.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"å–å¾—è‚¡ç¥¨æ¸…å–® {len(final)} æ”¯\")\n",
        "            return final\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†æ¸…å–®éŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        data = [\n",
        "            {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "            {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "            {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "            {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "            {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "            {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "            {'stock_id': '3008', 'stock_name': 'å¤§ç«‹å…‰', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3008.TW', 'industry': 'å…‰å­¸'},\n",
        "            {'stock_id': '3711', 'stock_name': 'æ—¥æœˆå…‰æŠ•æ§', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3711.TW', 'industry': 'åŠå°é«”'},\n",
        "            {'stock_id': '2884', 'stock_name': 'ç‰å±±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2884.TW', 'industry': 'é‡‘è'},\n",
        "            {'stock_id': '2002', 'stock_name': 'ä¸­é‹¼', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2002.TW', 'industry': 'é‹¼éµ'}\n",
        "        ]\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    # --------- æ•¸æ“šå–å¾—èˆ‡æŒ‡æ¨™ ---------\n",
        "    def fetch_yfinance_data(self, symbol: str,\n",
        "                            period: str = \"1y\",\n",
        "                            interval: str = \"1d\",\n",
        "                            retries: int = 3) -> pd.DataFrame:\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(symbol, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"{symbol} ç„¡è³‡æ–™\")\n",
        "                    return pd.DataFrame()\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "                df = df[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "                df.reset_index(inplace=True)\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    wait = 0.5 * (2 ** attempt) + random.random()\n",
        "                    time.sleep(wait)\n",
        "                else:\n",
        "                    logger.error(f\"{symbol} æŠ“å–å¤±æ•—: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        delta = prices.diff()\n",
        "        gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(period).mean()\n",
        "        rs = gain / loss\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "        return rsi\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast=12, slow=26, signal=9):\n",
        "        ema_fast = prices.ewm(span=fast).mean()\n",
        "        ema_slow = prices.ewm(span=slow).mean()\n",
        "        macd_line = ema_fast - ema_slow\n",
        "        macd_signal = macd_line.ewm(span=signal).mean()\n",
        "        macd_hist = macd_line - macd_signal\n",
        "        return macd_line, macd_signal, macd_hist\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period=20, std_dev=2):\n",
        "        mid = prices.rolling(period).mean()\n",
        "        std = prices.rolling(period).std()\n",
        "        upper = mid + std_dev * std\n",
        "        lower = mid - std_dev * std\n",
        "        return upper, mid, lower\n",
        "\n",
        "    def calculate_kd(self, high: pd.Series, low: pd.Series, close: pd.Series, period=14):\n",
        "        ll = low.rolling(period).min()\n",
        "        hh = high.rolling(period).max()\n",
        "        rsv = (close - ll) / (hh - ll) * 100\n",
        "        k = rsv.ewm(alpha=1/3).mean()\n",
        "        d = k.ewm(alpha=1/3).mean()\n",
        "        return k, d\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if df.empty:\n",
        "            return df\n",
        "        df = df.copy()\n",
        "        df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "        macd_line, macd_signal, macd_hist = self.calculate_macd(\n",
        "            df['Close'], self.config['macd_fast'], self.config['macd_slow'], self.config['macd_signal']\n",
        "        )\n",
        "        df['MACD'] = macd_line\n",
        "        df['MACD_Signal'] = macd_signal\n",
        "        df['MACD_Hist'] = macd_hist\n",
        "        upper, mid, lower = self.calculate_bollinger_bands(df['Close'], self.config['bb_period'], self.config['bb_std'])\n",
        "        df['BB_Upper'] = upper\n",
        "        df['BB_Middle'] = mid\n",
        "        df['BB_Lower'] = lower\n",
        "        k, d = self.calculate_kd(df['High'], df['Low'], df['Close'], self.config['kd_period'])\n",
        "        df['K_Percent'] = k\n",
        "        df['D_Percent'] = d\n",
        "        df['MA5'] = df['Close'].rolling(5).mean()\n",
        "        df['MA10'] = df['Close'].rolling(10).mean()\n",
        "        df['MA20'] = df['Close'].rolling(20).mean()\n",
        "        df['Volume_MA'] = df['Volume'].rolling(self.config['volume_ma_period']).mean()\n",
        "        return df\n",
        "\n",
        "    # --------- åŸºç¤åˆ†æ ---------\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        if df.empty:\n",
        "            return False\n",
        "        if 'Volume' not in df.columns:\n",
        "            return False\n",
        "        avg20 = df['Volume'].tail(20).mean()\n",
        "        lots = avg20 / 1000.0\n",
        "        return lots >= self.config['min_volume_lots']\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty or len(df) < 20:\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "        cp = float(df['Close'].iloc[-1])\n",
        "        p5 = float(df['Close'].iloc[-6]) if len(df) >= 6 else cp\n",
        "        p20 = float(df['Close'].iloc[-21]) if len(df) >= 21 else cp\n",
        "        ch5 = (cp / p5 - 1) * 100 if p5 else 0\n",
        "        ch20 = (cp / p20 - 1) * 100 if p20 else 0\n",
        "        ma5 = df['MA5'].iloc[-1]\n",
        "        ma20 = df['MA20'].iloc[-1]\n",
        "        trend = 'ç›¤æ•´'\n",
        "        strength = 0\n",
        "        if ch5 > 3 and ch20 > 5 and cp > ma5 > ma20:\n",
        "            trend = 'å¼·å‹¢ä¸Šæ¼²'; strength = 3\n",
        "        elif ch5 > 1 and ch20 > 2 and cp > ma5:\n",
        "            trend = 'ä¸Šæ¼²'; strength = 2\n",
        "        elif ch5 < -3 and ch20 < -5 and cp < ma5 < ma20:\n",
        "            trend = 'å¼·å‹¢ä¸‹è·Œ'; strength = -3\n",
        "        elif ch5 < -1 and ch20 < -2 and cp < ma5:\n",
        "            trend = 'ä¸‹è·Œ'; strength = -2\n",
        "        return {\n",
        "            'trend': trend,\n",
        "            'strength': strength,\n",
        "            'price_change_5d': ch5,\n",
        "            'price_change_20d': ch20,\n",
        "            'ma5_position': ma5,\n",
        "            'ma20_position': ma20\n",
        "        }\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty or len(df) < 20:\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "        curr_vol = df['Volume'].iloc[-1]\n",
        "        avg20 = df['Volume'].rolling(20).mean().iloc[-1]\n",
        "        ratio = curr_vol / avg20 if avg20 else 1.0\n",
        "        avg_lots = avg20 / 1000\n",
        "        if ratio > 2:\n",
        "            vt, vs = 'çˆ†é‡', 'å¼·çƒˆ'\n",
        "        elif ratio > 1.5:\n",
        "            vt, vs = 'æ”¾é‡', 'ç©æ¥µ'\n",
        "        elif ratio < 0.5:\n",
        "            vt, vs = 'ç¸®é‡', 'æ¶ˆæ¥µ'\n",
        "        else:\n",
        "            vt, vs = 'æ­£å¸¸', 'ä¸­æ€§'\n",
        "        return {\n",
        "            'volume_trend': vt,\n",
        "            'volume_ratio': ratio,\n",
        "            'volume_signal': vs,\n",
        "            'avg_volume_lots': avg_lots\n",
        "        }\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty:\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "        score = 50\n",
        "        out = {}\n",
        "        rsi_v = df['RSI'].iloc[-1]\n",
        "        if math.isnan(rsi_v):\n",
        "            rsi_v = 50\n",
        "        out['rsi_value'] = rsi_v\n",
        "        if rsi_v > 80:\n",
        "            out['rsi_signal'] = 'è¶…è²·'; score -= 15\n",
        "        elif rsi_v > 70:\n",
        "            out['rsi_signal'] = 'åé«˜'; score -= 5\n",
        "        elif rsi_v < 20:\n",
        "            out['rsi_signal'] = 'è¶…è³£'; score += 15\n",
        "        elif rsi_v < 30:\n",
        "            out['rsi_signal'] = 'åä½'; score += 5\n",
        "        else:\n",
        "            out['rsi_signal'] = 'ä¸­æ€§'\n",
        "        macd_c = df['MACD'].iloc[-1]; macd_s = df['MACD_Signal'].iloc[-1]\n",
        "        macd_p = df['MACD'].iloc[-2] if len(df) >= 2 else macd_c\n",
        "        macd_sp = df['MACD_Signal'].iloc[-2] if len(df) >= 2 else macd_s\n",
        "        out['macd_value'] = macd_c\n",
        "        if macd_p <= macd_sp and macd_c > macd_s:\n",
        "            out['macd_signal'] = 'é»ƒé‡‘äº¤å‰'; score += 20\n",
        "        elif macd_p >= macd_sp and macd_c < macd_s:\n",
        "            out['macd_signal'] = 'æ­»äº¡äº¤å‰'; score -= 20\n",
        "        elif macd_c > macd_s:\n",
        "            out['macd_signal'] = 'å¤šé ­'; score += 5\n",
        "        elif macd_c < macd_s:\n",
        "            out['macd_signal'] = 'ç©ºé ­'; score -= 5\n",
        "        else:\n",
        "            out['macd_signal'] = 'ä¸­æ€§'\n",
        "        k_v = df['K_Percent'].iloc[-1]; d_v = df['D_Percent'].iloc[-1]\n",
        "        if math.isnan(k_v): k_v = 50\n",
        "        if math.isnan(d_v): d_v = 50\n",
        "        out['k_value'] = k_v; out['d_value'] = d_v\n",
        "        if k_v > 80 and d_v > 80:\n",
        "            out['kd_signal'] = 'è¶…è²·'; score -= 10\n",
        "        elif k_v < 20 and d_v < 20:\n",
        "            out['kd_signal'] = 'è¶…è³£'; score += 10\n",
        "        elif k_v > d_v:\n",
        "            out['kd_signal'] = 'åå¤š'; score += 3\n",
        "        elif k_v < d_v:\n",
        "            out['kd_signal'] = 'åç©º'; score -= 3\n",
        "        else:\n",
        "            out['kd_signal'] = 'ä¸­æ€§'\n",
        "        upper = df['BB_Upper'].iloc[-1]; lower = df['BB_Lower'].iloc[-1]; cp = df['Close'].iloc[-1]\n",
        "        if not (math.isnan(upper) or math.isnan(lower)) and upper != lower:\n",
        "            pos = (cp - lower) / (upper - lower)\n",
        "            out['bb_position'] = pos\n",
        "            if pos > 0.8:\n",
        "                out['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'; score -= 5\n",
        "            elif pos < 0.2:\n",
        "                out['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'; score += 5\n",
        "            else:\n",
        "                out['bb_signal'] = 'ä¸­æ€§'\n",
        "        else:\n",
        "            out['bb_signal'] = 'ä¸­æ€§'; out['bb_position'] = 0.5\n",
        "        out['score'] = max(0, min(100, score))\n",
        "        return out\n",
        "\n",
        "    # --------- ç¶œåˆè©•åˆ†å«æƒ…ç·’ & ML ---------\n",
        "    def calculate_combined_score(self,\n",
        "                                 trend_analysis: Dict[str, Any],\n",
        "                                 volume_analysis: Dict[str, Any],\n",
        "                                 technical_analysis: Dict[str, Any],\n",
        "                                 sentiment_analysis: Optional[Dict[str, Any]] = None,\n",
        "                                 ml_pred: Optional[float] = None) -> Dict[str, Any]:\n",
        "        w = self.config['sentiment_weights']\n",
        "        base = 50\n",
        "        trend_strength = trend_analysis.get('strength', 0)\n",
        "        trend_component = max(-30, min(30, trend_strength * 10))\n",
        "        vr = volume_analysis.get('volume_ratio', 1.0)\n",
        "        if vr > 1.8:\n",
        "            vol_comp = 12\n",
        "        elif vr > 1.5:\n",
        "            vol_comp = 8\n",
        "        elif vr > 1.2:\n",
        "            vol_comp = 5\n",
        "        elif vr < 0.6:\n",
        "            vol_comp = -8\n",
        "        elif vr < 0.8:\n",
        "            vol_comp = -4\n",
        "        else:\n",
        "            vol_comp = 0\n",
        "        tech_score = technical_analysis.get('score', 50) - 50\n",
        "        tech_score = max(-50, min(50, tech_score))\n",
        "        sent_score = (sentiment_analysis.get('sentiment_score', 50) - 50) if sentiment_analysis else 0\n",
        "        if ml_pred is not None:\n",
        "            ml_scaled = max(-30, min(30, ml_pred))\n",
        "        else:\n",
        "            ml_scaled = 0\n",
        "        composite = (base +\n",
        "                     trend_component * w['trend'] +\n",
        "                     vol_comp * w['volume'] +\n",
        "                     tech_score * w['technical'] +\n",
        "                     sent_score * w['sentiment'] +\n",
        "                     ml_scaled * w['ml'])\n",
        "        composite = max(0, min(100, composite))\n",
        "        return {\n",
        "            'combined_score': composite,\n",
        "            'components': {\n",
        "                'trend_component': trend_component,\n",
        "                'volume_component': vol_comp,\n",
        "                'technical_component': tech_score,\n",
        "                'sentiment_component': sent_score,\n",
        "                'ml_component': ml_scaled\n",
        "            },\n",
        "            'weights': w\n",
        "        }\n",
        "\n",
        "    def generate_recommendation(self,\n",
        "                                combined_score: float,\n",
        "                                trend_analysis: Dict[str, Any],\n",
        "                                technical_analysis: Dict[str, Any],\n",
        "                                sentiment_analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        if combined_score >= 80:\n",
        "            rec, conf = \"å¼·åŠ›è²·é€²\", \"é«˜\"\n",
        "        elif combined_score >= 65:\n",
        "            rec, conf = \"è²·é€²\", \"ä¸­é«˜\"\n",
        "        elif combined_score >= 45:\n",
        "            rec, conf = \"æŒæœ‰\", \"ä¸­ç­‰\"\n",
        "        elif combined_score >= 30:\n",
        "            rec, conf = \"è³£å‡º\", \"ä¸­\"\n",
        "        else:\n",
        "            rec, conf = \"å¼·åŠ›è³£å‡º\", \"é«˜\"\n",
        "        reasons = []\n",
        "        trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "        if 'ä¸Šæ¼²' in trend:\n",
        "            reasons.append(f\"è¶¨å‹¢ï¼š{trend}\")\n",
        "        elif 'ä¸‹è·Œ' in trend:\n",
        "            reasons.append(f\"è¶¨å‹¢ï¼š{trend}\")\n",
        "        rsi_sig = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "        if rsi_sig in ['è¶…è³£', 'åä½']:\n",
        "            reasons.append(f\"RSI {rsi_sig}\")\n",
        "        elif rsi_sig in ['è¶…è²·', 'åé«˜']:\n",
        "            reasons.append(f\"RSI {rsi_sig}\")\n",
        "        macd_sig = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "        if macd_sig == 'é»ƒé‡‘äº¤å‰':\n",
        "            reasons.append(\"MACD é»ƒé‡‘äº¤å‰\")\n",
        "        elif macd_sig == 'æ­»äº¡äº¤å‰':\n",
        "            reasons.append(\"MACD æ­»äº¡äº¤å‰\")\n",
        "        if sentiment_analysis:\n",
        "            mood = sentiment_analysis.get('market_mood', '')\n",
        "            if mood:\n",
        "                reasons.append(f\"å¸‚å ´æƒ…ç·’ï¼š{mood}\")\n",
        "        return {\n",
        "            'recommendation': rec,\n",
        "            'confidence': conf,\n",
        "            'score': combined_score,\n",
        "            'reasons': reasons[:5]\n",
        "        }\n",
        "\n",
        "    # --------- å–®æ”¯è‚¡ç¥¨åˆ†æ (å«æƒ…ç·’ + çœŸå¯¦ç‰¹å¾µ + ML) ---------\n",
        "    async def analyze_stock_async(self,\n",
        "                                  session: aiohttp.ClientSession,\n",
        "                                  stock_info: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "        stock_id = stock_info['stock_id']\n",
        "        try:\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'stock_id': stock_id,\n",
        "                    'success': False,\n",
        "                    'error': 'æ•¸æ“šä¸è¶³'\n",
        "                }\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'stock_id': stock_id,\n",
        "                    'success': False,\n",
        "                    'error': 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶'\n",
        "                }\n",
        "            df_ind = self.calculate_technical_indicators(df)\n",
        "            trend_analysis = self.analyze_trend(df_ind)\n",
        "            volume_analysis = self.analyze_volume(df_ind)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_ind)\n",
        "            sentiment_analysis = self.sentiment_analyzer.calculate_sentiment_score(stock_id, stock_name)\n",
        "\n",
        "            # ====== (æ›´æ–°) çœŸå¯¦ç‰¹å¾µå–å¾— (å–ä»£åŸæ¨¡æ“¬éš¨æ©Ÿ) ======\n",
        "            real_feats = self.feature_fetcher.get_features(stock_id)\n",
        "            pe_ratio = real_feats['pe_ratio']\n",
        "            # ç•¶ä¸‹æˆäº¤é‡ä½¿ç”¨æœ€å¾Œä¸€æ ¹ Volumeï¼ˆèˆ‡ model åŒé‡ç´šï¼‰\n",
        "            volume_value = float(df_ind['Volume'].iloc[-1])\n",
        "            # ma_signalï¼šåˆ©ç”¨å‡ç·šå¤šç©ºçµæ§‹\n",
        "            cp = df_ind['Close'].iloc[-1]\n",
        "            ma5 = df_ind['MA5'].iloc[-1]\n",
        "            ma20 = df_ind['MA20'].iloc[-1]\n",
        "            if cp > ma5 > ma20:\n",
        "                ma_signal = 2\n",
        "            elif cp > ma5:\n",
        "                ma_signal = 1\n",
        "            else:\n",
        "                ma_signal = 0\n",
        "            chips_score = real_feats['chips_score']\n",
        "            # ====== ML é æ¸¬ ======\n",
        "            ml_pred = None\n",
        "            if self.ml_model:\n",
        "                ml_pred = ml_predict_current(self.ml_model, pe_ratio, volume_value, ma_signal, chips_score)\n",
        "\n",
        "            combined = self.calculate_combined_score(\n",
        "                trend_analysis, volume_analysis, technical_analysis, sentiment_analysis, ml_pred\n",
        "            )\n",
        "            combined_score = combined['combined_score']\n",
        "            recommendation = self.generate_recommendation(\n",
        "                combined_score, trend_analysis, technical_analysis, sentiment_analysis\n",
        "            )\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_id,\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': float(df_ind['Close'].iloc[-1]),\n",
        "                'price_change_5d': trend_analysis.get('price_change_5d', 0),\n",
        "                'combined_score': combined_score,\n",
        "                'combined_components': combined.get('components', {}),\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'sentiment_analysis': sentiment_analysis,\n",
        "                'ml_predicted_return': ml_pred,\n",
        "                'real_features': {\n",
        "                    'pe_ratio': pe_ratio,\n",
        "                    'chips_net': real_feats['chips_net'],\n",
        "                    'chips_score': chips_score,\n",
        "                    'pb_ratio': real_feats['pb_ratio'],\n",
        "                    'div_yield': real_feats['div_yield'],\n",
        "                    'ma_signal': ma_signal,\n",
        "                    'volume_feature': volume_value\n",
        "                },\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            logger.error(f\"{symbol} åˆ†æéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_id,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    # --------- æ‰¹é‡åˆ†æ ---------\n",
        "    async def analyze_all_stocks(self, limit: Optional[int] = None) -> Dict[str, Any]:\n",
        "        if self.taiwan_stocks is None:\n",
        "            self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "        df_list = self.taiwan_stocks\n",
        "        if df_list.empty:\n",
        "            logger.error(\"ç„¡è‚¡ç¥¨æ¸…å–®\")\n",
        "            return {}\n",
        "        if limit:\n",
        "            df_list = df_list.head(limit)\n",
        "\n",
        "        # é å…ˆè¼‰å…¥æœ€æ–°æœ¬ç›Šæ¯” / ç±Œç¢¼è³‡æ–™ï¼Œé¿å…æ¯æª”é‡è¤‡å›é€€\n",
        "        self.feature_fetcher.prepare_latest()\n",
        "\n",
        "        results = {}\n",
        "        tasks = []\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            for _, row in df_list.iterrows():\n",
        "                tasks.append(self.analyze_stock_async(session, row.to_dict()))\n",
        "            batch_size = 12\n",
        "            for i in range(0, len(tasks), batch_size):\n",
        "                batch = tasks[i:i+batch_size]\n",
        "                batch_results = await asyncio.gather(*batch, return_exceptions=True)\n",
        "                for r in batch_results:\n",
        "                    if isinstance(r, dict) and 'symbol' in r:\n",
        "                        results[r['symbol']] = r\n",
        "                await asyncio.sleep(1)\n",
        "        return results\n",
        "\n",
        "# ========= è¼¸å‡ºæ ¼å¼åŒ– =========\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    ok = [r for r in results.values() if r.get('success')]\n",
        "    ok.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "    lines = []\n",
        "    now_str = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "    lines.append(\"ğŸ† å°è‚¡ç¶œåˆæŠ€è¡“ + æƒ…ç·’ + ML (çœŸå¯¦ç‰¹å¾µ) åˆ†æ\")\n",
        "    lines.append(f\"ğŸ•’ åˆ†ææ™‚é–“: {now_str}\")\n",
        "    lines.append(f\"âœ… æˆåŠŸåˆ†æ: {len(ok)} æ”¯\")\n",
        "    lines.append(f\"ğŸ“Š è©•åˆ†çµ„æˆ: è¶¨å‹¢/æˆäº¤é‡/æŠ€è¡“/æƒ…ç·’/ML\")\n",
        "    lines.append(\"=\" * 60)\n",
        "    if not ok:\n",
        "        lines.append(\"âŒ ç„¡å¯ç”¨çµæœ\")\n",
        "        return \"\\n\".join(lines)\n",
        "    top = ok[:limit]\n",
        "    for idx, r in enumerate(top, 1):\n",
        "        sa = r.get('sentiment_analysis', {})\n",
        "        news_cnt = sa.get('news_count', 0)\n",
        "        fear_greed = sa.get('fear_greed_index', 50)\n",
        "        mood = sa.get('market_mood', '')\n",
        "        fg_emoji = \"ğŸ˜¨\" if fear_greed < 30 else \"ğŸ˜\" if fear_greed < 70 else \"ğŸ¤‘\"\n",
        "        rec = r.get('recommendation', {}).get('recommendation', '')\n",
        "        feats = r.get('real_features', {})\n",
        "        lines.append(f\"{idx}. {r.get('stock_name')} ({r.get('stock_id')})\")\n",
        "        lines.append(f\"   ğŸ’° åƒ¹æ ¼: {r.get('current_price', 0):.2f} | 5æ—¥: {r.get('price_change_5d', 0):+.2f}% | å»ºè­°: {rec}\")\n",
        "        lines.append(f\"   â­ ç¶œåˆè©•åˆ†: {r.get('combined_score', 0):.1f}  | PE:{feats.get('pe_ratio','-'):.2f} | ç±Œç¢¼åˆ†æ•¸:{feats.get('chips_score','-')}\")\n",
        "        lines.append(f\"   ğŸ“° æ–°èç†±åº¦: {news_cnt} | æ–°èæƒ…ç·’: {sa.get('news_sentiment',50):.1f}\")\n",
        "        lines.append(f\"   {fg_emoji} å¸‚å ´æƒ…ç·’(F&G): {fear_greed:.1f} ({mood})\")\n",
        "        tech = r.get('technical_analysis', {})\n",
        "        lines.append(f\"   ğŸ” RSI {tech.get('rsi_value',50):.1f}({tech.get('rsi_signal','ä¸­æ€§')}), MACD:{tech.get('macd_signal','ä¸­æ€§')}, KD:{tech.get('k_value',50):.1f}/{tech.get('d_value',50):.1f}\")\n",
        "        lines.append(\"-\" * 60)\n",
        "    avg_score = np.mean([x.get('combined_score', 0) for x in ok]) if ok else 0\n",
        "    high_cnt = sum(1 for x in ok if x.get('combined_score', 0) >= 70)\n",
        "    lines.append(f\"ğŸ“ˆ å¹³å‡åˆ†æ•¸: {avg_score:.1f} | é«˜åˆ†(>=70): {high_cnt}\")\n",
        "    lines.append(\"âš ï¸ é¢¨éšªè²æ˜ï¼šåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªã€‚\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    msg = format_analysis_message(results, limit)\n",
        "    print(msg)\n",
        "\n",
        "# ========= é€šçŸ¥ =========\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "    if not files:\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        if os.path.exists(chart_dir):\n",
        "            # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "            files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                    if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            if files:\n",
        "                logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "            else:\n",
        "                logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                if response.status == 200:\n",
        "                    logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                else:\n",
        "                    response_text = await response.text()\n",
        "                    logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                sent_count = 0\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            data = aiohttp.FormData()\n",
        "                            data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                            # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                            caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                            data.add_field('caption', caption)\n",
        "\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                    if response.status == 200:\n",
        "                                        sent_count += 1\n",
        "                                    else:\n",
        "                                        response_text = await response.text()\n",
        "                                        logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                            # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                            await asyncio.sleep(0.5)\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "        message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "        for chunk in message_chunks:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response and response.ok:\n",
        "                logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                content = response.content if response else \"æœªçŸ¥\"\n",
        "                logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "        # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "        if files:\n",
        "            batch_size = 10\n",
        "            for i in range(0, len(files), batch_size):\n",
        "                batch_files = files[i:i+batch_size]\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                for file_path in batch_files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        # ç²å–åœ–è¡¨æª”æ¡ˆæ•¸é‡\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        chart_count = 0\n",
        "        if os.path.exists(chart_dir):\n",
        "            chart_files = [f for f in os.listdir(chart_dir) if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            chart_count = len(chart_files)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ“Š ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ“ˆ TOP {min(5, len(filtered_results))} æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            # ç²å–æ›´å¤šæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\n",
        "            macd = tech.get('macd_value', 0)\n",
        "            signal = tech.get('signal_value', 0)\n",
        "            macd_status = \"å¤šé ­\" if macd > signal else \"ç©ºé ­\" if macd < signal else \"ä¸­æ€§\"\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_status', 'ä¸­æ€§')})\n",
        "   ğŸ“‰ MACD: {macd_status}\n",
        "\"\"\"\n",
        "\n",
        "        # æ·»åŠ åœ–è¡¨è³‡è¨Š\n",
        "        if chart_count > 0:\n",
        "            message += f\"\"\"\n",
        "ğŸ“Š è©³ç´°åˆ†æåœ–è¡¨:\n",
        "â€¢ å·²ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "â€¢ åœ–è¡¨åŒ…å«Kç·šã€å‡ç·šã€æˆäº¤é‡ã€MACDåŠRSIæŒ‡æ¨™\n",
        "â€¢ åœ–è¡¨å°‡åœ¨æ­¤è¨Šæ¯å¾Œç™¼é€\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "# ========= ä¸»ç¨‹å¼å…¥å£ =========\n",
        "async def main():\n",
        "    print(\"ğŸš€ å•Ÿå‹• å°è‚¡æŠ€è¡“ + æƒ…ç·’ + ML (çœŸå¯¦ç‰¹å¾µ) åˆ†æç³»çµ±\")\n",
        "    ml_model = None\n",
        "    # è‹¥è¦å•Ÿç”¨ MLï¼Œè«‹æä¾›çœŸå¯¦ historical_dataï¼š\n",
        "    # historical_data = pd.read_csv('historical_features.csv')  # éœ€åŒ…å« pe_ratio, volume, ma_signal, chips_score, future_return\n",
        "    # ml_model = build_ml_model(historical_data)\n",
        "\n",
        "    analyzer = StockAnalyzer(ml_model=ml_model)\n",
        "    print(\"ğŸ“Š æ­£åœ¨åˆ†æè‚¡ç¥¨ï¼ˆå¯èƒ½éœ€æ•¸åˆ†é˜ï¼‰...\")\n",
        "    results = await analyzer.analyze_all_stocks(limit=2000)  # å¯èª¿æ•´åˆ†ææ•¸é‡\n",
        "    if not results:\n",
        "        print(\"âŒ ç„¡åˆ†æçµæœ\")\n",
        "        return\n",
        "    display_terminal_results(results, limit=15)\n",
        "    message = format_analysis_message(results, limit=15)\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        await send_notification(session, message)\n",
        "\n",
        "    print(\"âœ… å®Œæˆã€‚\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        asyncio.run(main())\n",
        "    except RuntimeError:\n",
        "        loop = asyncio.get_event_loop()\n",
        "        loop.run_until_complete(main())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPWpoPDH7u9_"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "#  å°è‚¡ç¶œåˆåˆ†æç³»çµ± (èåˆç‰ˆ)\n",
        "#  åŠŸèƒ½ï¼š\n",
        "#   1. è‚¡ç¥¨æ¸…å–®æŠ“å– + å¿«å– (å«å‚™æ´)\n",
        "#   2. yfinance æŠ“ OHLCV\n",
        "#   3. æŠ€è¡“æŒ‡æ¨™ï¼šv1 (ç°¡ç‰ˆ) / v2 (å®Œæ•´æ“´å……)\n",
        "#   4. æ–°èæƒ…ç·’ + å°ç£ Fear & Greed æŒ‡æ•¸\n",
        "#   5. ç¶œåˆè©•åˆ† (è¶¨å‹¢ / æˆäº¤é‡ / æŠ€è¡“ / æƒ…ç·’)\n",
        "#   6. èƒŒé›¢åµæ¸¬ (RSI vs Price)ï¼šå¸¸è¦ / éš±è—\n",
        "#   7. æˆäº¤é‡æ¢ä»¶éæ¿¾ (æ—¥/é€±)\n",
        "#   8. åœ–è¡¨è¼¸å‡º (mplfinance)\n",
        "#   9. Telegram / Discord é€šçŸ¥ (å¤šæ®µè¨Šæ¯ + Retry/Backoff)\n",
        "#  ä½œè€…ï¼šæ•´åˆç‰ˆï¼ˆç’°å¢ƒè®Šæ•¸å¼·åŒ– + æ”¹è‰¯é‡æ§‹ï¼‰\n",
        "# ===============================\n",
        "\n",
        "# ===============================\n",
        "# (å¯é¸) å®‰è£éœ€æ±‚ (Jupyter æ¸¬è©¦)\n",
        "# ===============================\n",
        "# !pip install --upgrade pip\n",
        "# !pip install pandas numpy yfinance requests lxml html5lib seaborn matplotlib mplfinance chineseize-matplotlib -q\n",
        "# !pip install twstock shioaji aiohttp nest-asyncio discord-webhook python-dotenv jieba -q\n",
        "\n",
        "# ===============================\n",
        "# Imports\n",
        "# ===============================\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import gc\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import signal\n",
        "import warnings\n",
        "import logging\n",
        "import traceback\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import requests\n",
        "import platform\n",
        "import dateutil.parser\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import jieba\n",
        "\n",
        "from io import StringIO\n",
        "from functools import wraps\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, Any, List, Optional, Tuple, Union\n",
        "from collections import Counter\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError\n",
        "\n",
        "# åœ–è¡¨\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import mplfinance as mpf\n",
        "\n",
        "# BeautifulSoup\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# nest_asyncioï¼ˆåœ¨ Jupyter é‡å…¥ï¼‰\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Discord Webhook (å¯é¸)\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# dotenv (å¯é¸)\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ===============================\n",
        "# å…¨åŸŸè¨­å®š\n",
        "# ===============================\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.switch_backend('Agg')\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"stock_analysis.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(\"FusionAnalyzer\")\n",
        "\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# ===============================\n",
        "# ç’°å¢ƒè®Šæ•¸è¨­å®šï¼ˆç„¡å‰‡ç•™ç©º -> ä¸ç™¼é€ï¼‰\n",
        "# ===============================\n",
        "\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# ===============================\n",
        "# ç›®éŒ„çµæ§‹\n",
        "# ===============================\n",
        "for d in ['data', 'data/stocks', 'cache', 'analysis_charts', 'analysis_reports', 'stock_reports']:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# å­—é«”è¨­å®šï¼ˆé¿å…ä¸­æ–‡å­—äº‚ç¢¼ï¼‰\n",
        "# ===============================\n",
        "def set_chinese_font():\n",
        "    system = platform.system()\n",
        "    if system == 'Windows':\n",
        "        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
        "    elif system == 'Darwin':\n",
        "        plt.rcParams['font.sans-serif'] = ['PingFang TC', 'PingFang HK', 'Heiti TC']\n",
        "    else:\n",
        "        plt.rcParams['font.sans-serif'] = ['Noto Sans CJK TC', 'WenQuanYi Micro Hei', 'SimHei']\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "set_chinese_font()\n",
        "\n",
        "# ===============================\n",
        "# é€šç”¨å·¥å…·\n",
        "# ===============================\n",
        "def parse_date(date_str):\n",
        "    try:\n",
        "        return dateutil.parser.parse(date_str)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def ensure_date_column(df: pd.DataFrame):\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    date_candidates = ['Date', 'date', 'æ—¥æœŸ', 'TradeDate', 'time', 'datetime']\n",
        "    for c in date_candidates:\n",
        "        if c in df.columns:\n",
        "            df = df.rename(columns={c: 'Date'})\n",
        "            try:\n",
        "                df['Date'] = pd.to_datetime(df['Date'])\n",
        "            except:\n",
        "                return None\n",
        "            return df\n",
        "    return None\n",
        "\n",
        "# ===============================\n",
        "# Timeout æ©Ÿåˆ¶\n",
        "# ===============================\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "def timeout_handler(signum, frame):\n",
        "    raise TimeoutException(\"åŸ·è¡Œæ™‚é–“éé•·ï¼Œå·²ä¸­æ­¢\")\n",
        "\n",
        "def timeout(seconds):\n",
        "    def decorator(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            if platform.system() == \"Windows\":\n",
        "                with ThreadPoolExecutor(max_workers=1) as executor:\n",
        "                    future = executor.submit(func, *args, **kwargs)\n",
        "                    try:\n",
        "                        return future.result(timeout=seconds)\n",
        "                    except FuturesTimeoutError:\n",
        "                        raise TimeoutException(f\"æ“ä½œè¶…æ™‚ ({seconds} ç§’)\")\n",
        "            else:\n",
        "                try:\n",
        "                    signal.signal(signal.SIGALRM, timeout_handler)\n",
        "                    signal.alarm(seconds)\n",
        "                    try:\n",
        "                        return func(*args, **kwargs)\n",
        "                    finally:\n",
        "                        signal.alarm(0)\n",
        "                except Exception:\n",
        "                    with ThreadPoolExecutor(max_workers=1) as executor:\n",
        "                        future = executor.submit(func, *args, **kwargs)\n",
        "                        try:\n",
        "                            return future.result(timeout=seconds)\n",
        "                        except FuturesTimeoutError:\n",
        "                            raise TimeoutException(f\"æ“ä½œè¶…æ™‚ ({seconds} ç§’)\")\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# ===============================\n",
        "# å¿«å–å·¥å…·\n",
        "# ===============================\n",
        "def _save_cache(cache_file, data):\n",
        "    try:\n",
        "        os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n",
        "        with open(cache_file, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ä¿å­˜å¿«å–å¤±æ•—: {e}\")\n",
        "\n",
        "def _load_backup_cache(cache_file):\n",
        "    try:\n",
        "        if os.path.exists(cache_file):\n",
        "            with open(cache_file, 'rb') as f:\n",
        "                return pickle.load(f)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"è¼‰å…¥å‚™ä»½å¿«å–å¤±æ•—: {e}\")\n",
        "    return {}\n",
        "\n",
        "# ===============================\n",
        "# é©—è­‰è‚¡ç¥¨è³‡æ–™\n",
        "# ===============================\n",
        "def validate_stock_data(df: pd.DataFrame, min_points=20):\n",
        "    if df is None or df.empty:\n",
        "        return False\n",
        "    if 'Date' not in df.columns:\n",
        "        return False\n",
        "    close_col = 'Close' if 'Close' in df.columns else ('close' if 'close' in df.columns else None)\n",
        "    if close_col is None:\n",
        "        return False\n",
        "    if df[close_col].isnull().all():\n",
        "        return False\n",
        "    if len(df) < min_points:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# ===============================\n",
        "# å¸‚å ´æƒ…ç·’åˆ†æå™¨\n",
        "# ===============================\n",
        "class MarketSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.config = {\n",
        "            'news_weight': 0.4,\n",
        "            'fear_greed_weight': 0.6,\n",
        "            'news_sources': [\n",
        "                'https://news.cnyes.com/news/cat/tw_stock',\n",
        "                'https://www.moneydj.com/kmdj/news/newsreallist.aspx?a=5',\n",
        "                'https://www.cnbc.com/world/?region=world',\n",
        "            ],\n",
        "            'positive_keywords': ['ä¸Šæ¼²', 'çªç ´', 'åˆ©å¤š', 'æˆé•·', 'ç²åˆ©', 'çœ‹å¥½', 'å¼·å‹¢', 'æ¼²åœ', 'çªåœ', 'è²·é€²', 'å‰µé«˜', 'è¶…é æœŸ'],\n",
        "            'negative_keywords': ['ä¸‹è·Œ', 'è·Œç ´', 'åˆ©ç©º', 'è¡°é€€', 'è™§æ', 'çœ‹æ·¡', 'å¼±å‹¢', 'è·Œåœ', 'é‡æŒ«', 'è³£å‡º', 'èª¿é™', 'è£å“¡'],\n",
        "            'cache_duration': 1800\n",
        "        }\n",
        "        self.news_cache = {}\n",
        "        self.fear_greed_cache = {'timestamp': 0, 'value': 50, 'components': {}}\n",
        "\n",
        "    def get_stock_news_sentiment(self, stock_id: str, stock_name: str) -> Tuple[float, int]:\n",
        "        cache_key = f\"{stock_id}_{stock_name}\"\n",
        "        now_ts = time.time()\n",
        "        if cache_key in self.news_cache and (now_ts - self.news_cache[cache_key]['timestamp'] < self.config['cache_duration']):\n",
        "            return self.news_cache[cache_key]['sentiment_score'], self.news_cache[cache_key]['news_count']\n",
        "        search_terms = [stock_id, stock_name]\n",
        "        news_count = 0\n",
        "        sentiment_scores = []\n",
        "        for url in self.config['news_sources']:\n",
        "            try:\n",
        "                headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "                resp = requests.get(url, headers=headers, timeout=12)\n",
        "                soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "                candidates = soup.select('a, h2, h3, div')\n",
        "                for c in candidates:\n",
        "                    text = c.get_text(strip=True)\n",
        "                    if not text or len(text) > 60:\n",
        "                        continue\n",
        "                    if any(term in text for term in search_terms):\n",
        "                        news_count += 1\n",
        "                        words = jieba.lcut(text)\n",
        "                        pos = sum(1 for w in words if w in self.config['positive_keywords'])\n",
        "                        neg = sum(1 for w in words if w in self.config['negative_keywords'])\n",
        "                        if pos + neg > 0:\n",
        "                            s = (pos - neg) / (pos + neg)\n",
        "                            sentiment_scores.append(s)\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"æ–°èä¾†æºå¤±æ•— {url}: {e}\")\n",
        "        if sentiment_scores:\n",
        "            avg = float(np.mean(sentiment_scores))\n",
        "            score_0_100 = (avg + 1) * 50\n",
        "        else:\n",
        "            score_0_100 = 50.0\n",
        "        self.news_cache[cache_key] = {\n",
        "            'timestamp': now_ts,\n",
        "            'sentiment_score': score_0_100,\n",
        "            'news_count': news_count\n",
        "        }\n",
        "        return score_0_100, news_count\n",
        "\n",
        "    def get_fear_greed_index(self) -> Tuple[float, Dict[str, Any]]:\n",
        "        now_ts = time.time()\n",
        "        if now_ts - self.fear_greed_cache['timestamp'] < self.config['cache_duration']:\n",
        "            return self.fear_greed_cache['value'], self.fear_greed_cache['components']\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        components = {\n",
        "            'price_momentum': None,\n",
        "            'price_score': 50,\n",
        "            'volatility_ratio': None,\n",
        "            'volatility_score': 50,\n",
        "            'volume_change_pct': None,\n",
        "            'volume_score': 50,\n",
        "            'pc_ratio': None,\n",
        "            'pc_ratio_score': 50\n",
        "        }\n",
        "        try:\n",
        "            taiex_url = \"https://query1.finance.yahoo.com/v8/finance/chart/%5ETWII?interval=1d&range=60d\"\n",
        "            r = requests.get(taiex_url, headers=headers, timeout=12).json()\n",
        "            closes = r['chart']['result'][0]['indicators']['quote'][0]['close']\n",
        "            closes = [c for c in closes if c is not None]\n",
        "            if len(closes) >= 20:\n",
        "                ma10 = np.mean(closes[-10:])\n",
        "                last = closes[-1]\n",
        "                price_momentum = (last / ma10 - 1) * 100 if ma10 else 0\n",
        "                components['price_momentum'] = price_momentum\n",
        "                price_score = 50 + price_momentum * 5\n",
        "                components['price_score'] = max(0, min(100, price_score))\n",
        "                ret = np.diff(closes) / closes[:-1]\n",
        "                if len(ret) >= 21:\n",
        "                    vol_5 = np.std(ret[-5:]) * 100\n",
        "                    vol_20 = np.std(ret[-20:]) * 100\n",
        "                    vol_ratio = vol_5 / vol_20 if vol_20 else 1\n",
        "                    components['volatility_ratio'] = vol_ratio\n",
        "                    volatility_score = 100 - (vol_ratio - 0.5) * 100\n",
        "                    components['volatility_score'] = max(0, min(100, volatility_score))\n",
        "            volume_url = \"https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK?date=20230101&response=json\"\n",
        "            try:\n",
        "                rv = requests.get(volume_url, headers=headers, timeout=12).json()\n",
        "                vol_list = []\n",
        "                if 'data' in rv:\n",
        "                    for row in rv['data'][-8:]:\n",
        "                        try:\n",
        "                            val = row[1].replace(',', '')\n",
        "                            vol_list.append(float(val))\n",
        "                        except:\n",
        "                            pass\n",
        "                if len(vol_list) >= 5:\n",
        "                    recent = np.mean(vol_list[-5:])\n",
        "                    prev = np.mean(vol_list[-10:-5]) if len(vol_list) >= 10 else recent\n",
        "                    volume_change = (recent / prev - 1) * 100 if prev else 0\n",
        "                    components['volume_change_pct'] = volume_change\n",
        "                    components['volume_score'] = max(0, min(100, 50 + volume_change))\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"æˆäº¤é‡æŠ“å–å¤±æ•—: {e}\")\n",
        "            try:\n",
        "                pc_url = \"https://www.taifex.com.tw/cht/3/pcRatio\"\n",
        "                pr = requests.get(pc_url, headers=headers, timeout=12)\n",
        "                soup = BeautifulSoup(pr.text, 'html.parser')\n",
        "                tables = soup.find_all('table')\n",
        "                pc_ratio = None\n",
        "                for tbl in tables:\n",
        "                    tds = tbl.find_all('td')\n",
        "                    for td in tds:\n",
        "                        txt = td.get_text(strip=True)\n",
        "                        if re.match(r'^\\d+(\\.\\d+)?$', txt):\n",
        "                            val = float(txt)\n",
        "                            if 0.3 < val < 5:\n",
        "                                pc_ratio = val\n",
        "                                break\n",
        "                    if pc_ratio:\n",
        "                        break\n",
        "                if pc_ratio:\n",
        "                    components['pc_ratio'] = pc_ratio\n",
        "                    pc_score = 50 + (pc_ratio - 1) * 40\n",
        "                    components['pc_ratio_score'] = max(0, min(100, pc_score))\n",
        "            except Exception as e:\n",
        "                logger.debug(f\"P/C æŠ“å–å¤±æ•—: {e}\")\n",
        "            final_value = (\n",
        "                components['price_score'] * 0.5 +\n",
        "                components['volatility_score'] * 0.2 +\n",
        "                components['volume_score'] * 0.15 +\n",
        "                components['pc_ratio_score'] * 0.15\n",
        "            )\n",
        "            final_value = max(0, min(100, final_value))\n",
        "            mood = \"æ¥µåº¦ææ…Œ\" if final_value < 20 else \\\n",
        "                   \"ææ…Œ\" if final_value < 40 else \\\n",
        "                   \"ä¸­æ€§\" if final_value < 60 else \\\n",
        "                   \"è²ªå©ª\" if final_value < 80 else \"æ¥µåº¦è²ªå©ª\"\n",
        "            components['market_mood'] = mood\n",
        "            self.fear_greed_cache = {\n",
        "                'timestamp': now_ts,\n",
        "                'value': final_value,\n",
        "                'components': components\n",
        "            }\n",
        "            return final_value, components\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Fear & Greed è¨ˆç®—å¤±æ•—: {e}\")\n",
        "            return self.fear_greed_cache['value'], self.fear_greed_cache['components']\n",
        "\n",
        "    def calculate_sentiment_score(self, stock_id: str, stock_name: str) -> Dict[str, Any]:\n",
        "        news_sentiment, news_count = self.get_stock_news_sentiment(stock_id, stock_name)\n",
        "        fg_value, fg_components = self.get_fear_greed_index()\n",
        "        if fg_value < 20 or fg_value > 80:\n",
        "            adj_fg_w = self.config['fear_greed_weight'] * 1.3\n",
        "        else:\n",
        "            adj_fg_w = self.config['fear_greed_weight']\n",
        "        adj_news_w = self.config['news_weight'] * min(1.0, news_count / 5)\n",
        "        total_w = adj_news_w + adj_fg_w\n",
        "        if total_w == 0:\n",
        "            total_w = 1\n",
        "        adj_news_w /= total_w\n",
        "        adj_fg_w /= total_w\n",
        "        sentiment_score = news_sentiment * adj_news_w + fg_value * adj_fg_w\n",
        "        return {\n",
        "            'sentiment_score': sentiment_score,\n",
        "            'news_sentiment': news_sentiment,\n",
        "            'news_count': news_count,\n",
        "            'fear_greed_index': fg_value,\n",
        "            'market_mood': fg_components.get('market_mood', ''),\n",
        "            'fear_greed_components': fg_components,\n",
        "            'weight_news': adj_news_w,\n",
        "            'weight_fear_greed': adj_fg_w\n",
        "        }\n",
        "\n",
        "# ===============================\n",
        "# æŠ€è¡“åˆ†æä¸»é¡åˆ¥\n",
        "# ===============================\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,\n",
        "            'sentiment_weights': {\n",
        "                'trend': 0.25,\n",
        "                'volume': 0.10,\n",
        "                'technical': 0.40,\n",
        "                'sentiment': 0.25\n",
        "            }\n",
        "        }\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "        self.taiwan_stocks: Optional[pd.DataFrame] = None\n",
        "        self.sentiment_analyzer = MarketSentimentAnalyzer()\n",
        "\n",
        "    # è‚¡ç¥¨æ¸…å–®\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if time.time() - os.path.getmtime(self.stock_list_path) < 86400:\n",
        "                try:\n",
        "                    return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "                except:\n",
        "                    pass\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df['market'] = market_name\n",
        "                all_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} æ¸…å–®å¤±æ•—: {e}\")\n",
        "        if not all_df:\n",
        "            return self._backup_list()\n",
        "        try:\n",
        "            df = pd.concat(all_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)]\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)]\n",
        "            df['yahoo_symbol'] = df.apply(\n",
        "                lambda r: f\"{r['stock_id']}.TW\" if r['market'] == 'ä¸Šå¸‚' else f\"{r['stock_id']}.TWO\",\n",
        "                axis=1\n",
        "            )\n",
        "            final = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final = final.drop_duplicates(subset=['stock_id'])\n",
        "            final.to_csv(self.stock_list_path, index=False)\n",
        "            return final\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®éŒ¯èª¤: {e}\")\n",
        "            return self._backup_list()\n",
        "\n",
        "    def _backup_list(self):\n",
        "        data = [\n",
        "            {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'industry': 'åŠå°é«”', 'yahoo_symbol': '2330.TW'},\n",
        "            {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'industry': 'é›»å­', 'yahoo_symbol': '2317.TW'},\n",
        "            {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'industry': 'åŠå°é«”', 'yahoo_symbol': '2454.TW'},\n",
        "            {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'industry': 'é‡‘è', 'yahoo_symbol': '2881.TW'},\n",
        "            {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'industry': 'é‡‘è', 'yahoo_symbol': '2882.TW'},\n",
        "        ]\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    # æŠ“è³‡æ–™\n",
        "    def fetch_yfinance_data(self, symbol: str, period=\"1y\", interval=\"1d\", retries=3):\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(symbol, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    return pd.DataFrame()\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "                df = df[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "                df.reset_index(inplace=True)\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(0.5 * (2 ** attempt))\n",
        "                else:\n",
        "                    logger.error(f\"{symbol} æ•¸æ“šæŠ“å–å¤±æ•—: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # ç°¡ç‰ˆæŒ‡æ¨™ v1\n",
        "    def calculate_technical_indicators_v1(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if df.empty:\n",
        "            return df\n",
        "        df = df.copy()\n",
        "        delta = df['Close'].diff()\n",
        "        gain = delta.where(delta > 0, 0)\n",
        "        loss = -delta.where(delta < 0, 0)\n",
        "        avg_gain = gain.rolling(self.config['rsi_period']).mean()\n",
        "        avg_loss = loss.rolling(self.config['rsi_period']).mean()\n",
        "        rs = avg_gain / avg_loss\n",
        "        df['RSI'] = 100 - (100 / (1 + rs))\n",
        "        ema_fast = df['Close'].ewm(span=self.config['macd_fast']).mean()\n",
        "        ema_slow = df['Close'].ewm(span=self.config['macd_slow']).mean()\n",
        "        macd_line = ema_fast - ema_slow\n",
        "        macd_signal = macd_line.ewm(span=self.config['macd_signal']).mean()\n",
        "        df['MACD'] = macd_line\n",
        "        df['MACD_Signal'] = macd_signal\n",
        "        df['MACD_Histogram'] = macd_line - macd_signal\n",
        "        mid = df['Close'].rolling(self.config['bb_period']).mean()\n",
        "        std = df['Close'].rolling(self.config['bb_period']).std()\n",
        "        df['BB_Upper'] = mid + self.config['bb_std'] * std\n",
        "        df['BB_Middle'] = mid\n",
        "        df['BB_Lower'] = mid - self.config['bb_std'] * std\n",
        "        ll = df['Low'].rolling(self.config['kd_period']).min()\n",
        "        hh = df['High'].rolling(self.config['kd_period']).max()\n",
        "        k = (df['Close'] - ll) / (hh - ll + 1e-9) * 100\n",
        "        k = k.rolling(3).mean()\n",
        "        d = k.rolling(3).mean()\n",
        "        df['K_Percent'] = k\n",
        "        df['D_Percent'] = d\n",
        "        df['MA5'] = df['Close'].rolling(5).mean()\n",
        "        df['MA10'] = df['Close'].rolling(10).mean()\n",
        "        df['MA20'] = df['Close'].rolling(20).mean()\n",
        "        df['Volume_MA'] = df['Volume'].rolling(self.config['volume_ma_period']).mean()\n",
        "        return df\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        if df.empty:\n",
        "            return False\n",
        "        avg20 = df['Volume'].tail(20).mean()\n",
        "        lots = avg20 / 1000\n",
        "        return lots >= self.config['min_volume_lots']\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty or len(df) < 20:\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "        cp = df['Close'].iloc[-1]\n",
        "        p5 = df['Close'].iloc[-6] if len(df) >= 6 else cp\n",
        "        p20 = df['Close'].iloc[-21] if len(df) >= 21 else cp\n",
        "        ch5 = (cp / p5 - 1) * 100 if p5 else 0\n",
        "        ch20 = (cp / p20 - 1) * 100 if p20 else 0\n",
        "        ma5 = df['MA5'].iloc[-1]\n",
        "        ma20 = df['MA20'].iloc[-1]\n",
        "        trend = 'ç›¤æ•´'\n",
        "        strength = 0\n",
        "        if ch5 > 3 and ch20 > 5 and cp > ma5 > ma20:\n",
        "            trend = 'å¼·å‹¢ä¸Šæ¼²'; strength = 3\n",
        "        elif ch5 > 1 and ch20 > 2 and cp > ma5:\n",
        "            trend = 'ä¸Šæ¼²'; strength = 2\n",
        "        elif ch5 < -3 and ch20 < -5 and cp < ma5 < ma20:\n",
        "            trend = 'å¼·å‹¢ä¸‹è·Œ'; strength = -3\n",
        "        elif ch5 < -1 and ch20 < -2 and cp < ma5:\n",
        "            trend = 'ä¸‹è·Œ'; strength = -2\n",
        "        return {\n",
        "            'trend': trend,\n",
        "            'strength': strength,\n",
        "            'price_change_5d': ch5,\n",
        "            'price_change_20d': ch20\n",
        "        }\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty or len(df) < 20:\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "        curr = df['Volume'].iloc[-1]\n",
        "        avg20 = df['Volume'].rolling(20).mean().iloc[-1]\n",
        "        ratio = curr / avg20 if avg20 else 1\n",
        "        lots = avg20 / 1000\n",
        "        if ratio > 2: vt, vs = 'çˆ†é‡', 'å¼·çƒˆ'\n",
        "        elif ratio > 1.5: vt, vs = 'æ”¾é‡', 'ç©æ¥µ'\n",
        "        elif ratio < 0.5: vt, vs = 'ç¸®é‡', 'æ¶ˆæ¥µ'\n",
        "        else: vt, vs = 'æ­£å¸¸', 'ä¸­æ€§'\n",
        "        return {\n",
        "            'volume_trend': vt, 'volume_ratio': ratio, 'volume_signal': vs, 'avg_volume_lots': lots\n",
        "        }\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        if df.empty:\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "        score = 50\n",
        "        out = {}\n",
        "        rsi_v = df['RSI'].iloc[-1] if 'RSI' in df.columns else 50\n",
        "        if math.isnan(rsi_v): rsi_v = 50\n",
        "        out['rsi_value'] = rsi_v\n",
        "        if rsi_v > 80: out['rsi_signal'] = 'è¶…è²·'; score -= 15\n",
        "        elif rsi_v > 70: out['rsi_signal'] = 'åé«˜'; score -= 5\n",
        "        elif rsi_v < 20: out['rsi_signal'] = 'è¶…è³£'; score += 15\n",
        "        elif rsi_v < 30: out['rsi_signal'] = 'åä½'; score += 5\n",
        "        else: out['rsi_signal'] = 'ä¸­æ€§'\n",
        "        macd_c = df['MACD'].iloc[-1] if 'MACD' in df.columns else 0\n",
        "        macd_s = df['MACD_Signal'].iloc[-1] if 'MACD_Signal' in df.columns else 0\n",
        "        macd_p = df['MACD'].iloc[-2] if 'MACD' in df.columns and len(df) >= 2 else macd_c\n",
        "        macd_sp = df['MACD_Signal'].iloc[-2] if 'MACD_Signal' in df.columns and len(df) >= 2 else macd_s\n",
        "        out['macd_value'] = macd_c\n",
        "        if macd_p <= macd_sp and macd_c > macd_s:\n",
        "            out['macd_signal'] = 'é»ƒé‡‘äº¤å‰'; score += 20\n",
        "        elif macd_p >= macd_sp and macd_c < macd_s:\n",
        "            out['macd_signal'] = 'æ­»äº¡äº¤å‰'; score -= 20\n",
        "        elif macd_c > macd_s:\n",
        "            out['macd_signal'] = 'å¤šé ­'; score += 5\n",
        "        elif macd_c < macd_s:\n",
        "            out['macd_signal'] = 'ç©ºé ­'; score -= 5\n",
        "        else:\n",
        "            out['macd_signal'] = 'ä¸­æ€§'\n",
        "        k_col = 'K_Percent' if 'K_Percent' in df.columns else ('K' if 'K' in df.columns else None)\n",
        "        d_col = 'D_Percent' if 'D_Percent' in df.columns else ('D' if 'D' in df.columns else None)\n",
        "        k_v = df[k_col].iloc[-1] if k_col else 50\n",
        "        d_v = df[d_col].iloc[-1] if d_col else 50\n",
        "        if math.isnan(k_v): k_v = 50\n",
        "        if math.isnan(d_v): d_v = 50\n",
        "        out['k_value'] = k_v; out['d_value'] = d_v\n",
        "        if k_v > 80 and d_v > 80: out['kd_signal'] = 'è¶…è²·'; score -= 10\n",
        "        elif k_v < 20 and d_v < 20: out['kd_signal'] = 'è¶…è³£'; score += 10\n",
        "        elif k_v > d_v: out['kd_signal'] = 'åå¤š'; score += 3\n",
        "        elif k_v < d_v: out['kd_signal'] = 'åç©º'; score -= 3\n",
        "        else: out['kd_signal'] = 'ä¸­æ€§'\n",
        "        if 'BB_Upper' in df.columns and 'BB_Lower' in df.columns and 'Close' in df.columns:\n",
        "            bb_u = df['BB_Upper'].iloc[-1]; bb_l = df['BB_Lower'].iloc[-1]; cp = df['Close'].iloc[-1]\n",
        "            if not (math.isnan(bb_u) or math.isnan(bb_l)) and bb_u != bb_l:\n",
        "                pos = (cp - bb_l) / (bb_u - bb_l)\n",
        "                out['bb_position'] = pos\n",
        "                if pos > 0.8: out['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'; score -= 5\n",
        "                elif pos < 0.2: out['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'; score += 5\n",
        "                else: out['bb_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                out['bb_signal'] = 'ä¸­æ€§'; out['bb_position'] = 0.5\n",
        "        else:\n",
        "            out['bb_signal'] = 'ä¸­æ€§'; out['bb_position'] = 0.5\n",
        "        out['score'] = max(0, min(100, score))\n",
        "        return out\n",
        "\n",
        "    def calculate_combined_score(self,\n",
        "                                 trend_analysis: Dict[str, Any],\n",
        "                                 volume_analysis: Dict[str, Any],\n",
        "                                 technical_analysis: Dict[str, Any],\n",
        "                                 sentiment_analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        w = self.config['sentiment_weights']\n",
        "        base = 50\n",
        "        trend_strength = trend_analysis.get('strength', 0)\n",
        "        trend_component = max(-30, min(30, trend_strength * 10))\n",
        "        vr = volume_analysis.get('volume_ratio', 1.0)\n",
        "        if vr > 1.8: vol_comp = 12\n",
        "        elif vr > 1.5: vol_comp = 8\n",
        "        elif vr > 1.2: vol_comp = 5\n",
        "        elif vr < 0.6: vol_comp = -8\n",
        "        elif vr < 0.8: vol_comp = -4\n",
        "        else: vol_comp = 0\n",
        "        tech_score = max(-50, min(50, technical_analysis.get('score', 50) - 50))\n",
        "        sent_score = (sentiment_analysis.get('sentiment_score', 50) - 50) if sentiment_analysis else 0\n",
        "        composite = (base +\n",
        "                     trend_component * w['trend'] +\n",
        "                     vol_comp * w['volume'] +\n",
        "                     tech_score * w['technical'] +\n",
        "                     sent_score * w['sentiment'])\n",
        "        composite = max(0, min(100, composite))\n",
        "        return {\n",
        "            'combined_score': composite,\n",
        "            'components': {\n",
        "                'trend_component': trend_component,\n",
        "                'volume_component': vol_comp,\n",
        "                'technical_component': tech_score,\n",
        "                'sentiment_component': sent_score\n",
        "            },\n",
        "            'weights': w\n",
        "        }\n",
        "\n",
        "    def generate_recommendation(self,\n",
        "                                combined_score: float,\n",
        "                                trend_analysis: Dict[str, Any],\n",
        "                                technical_analysis: Dict[str, Any],\n",
        "                                sentiment_analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        if combined_score >= 80: rec, conf = \"å¼·åŠ›è²·é€²\", \"é«˜\"\n",
        "        elif combined_score >= 65: rec, conf = \"è²·é€²\", \"ä¸­é«˜\"\n",
        "        elif combined_score >= 45: rec, conf = \"æŒæœ‰\", \"ä¸­ç­‰\"\n",
        "        elif combined_score >= 30: rec, conf = \"è³£å‡º\", \"ä¸­\"\n",
        "        else: rec, conf = \"å¼·åŠ›è³£å‡º\", \"é«˜\"\n",
        "        reasons = []\n",
        "        trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "        if 'ä¸Šæ¼²' in trend or 'ä¸‹è·Œ' in trend:\n",
        "            reasons.append(f\"è¶¨å‹¢ï¼š{trend}\")\n",
        "        rsi_sig = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "        if rsi_sig in ['è¶…è³£', 'åä½', 'è¶…è²·', 'åé«˜']:\n",
        "            reasons.append(f\"RSI {rsi_sig}\")\n",
        "        macd_sig = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "        if macd_sig in ['é»ƒé‡‘äº¤å‰', 'æ­»äº¡äº¤å‰']:\n",
        "            reasons.append(f\"MACD {macd_sig}\")\n",
        "        if sentiment_analysis:\n",
        "            mood = sentiment_analysis.get('market_mood', '')\n",
        "            if mood:\n",
        "                reasons.append(f\"å¸‚å ´æƒ…ç·’ï¼š{mood}\")\n",
        "        return {\n",
        "            'recommendation': rec,\n",
        "            'confidence': conf,\n",
        "            'score': combined_score,\n",
        "            'reasons': reasons[:5]\n",
        "        }\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "        stock_id = stock_info['stock_id']\n",
        "        try:\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df.empty or len(df) < 60:\n",
        "                return {'symbol': symbol, 'stock_name': stock_name, 'stock_id': stock_id, 'success': False, 'error': 'æ•¸æ“šä¸è¶³'}\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {'symbol': symbol, 'stock_name': stock_name, 'stock_id': stock_id, 'success': False, 'error': 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶'}\n",
        "            df_ind = self.calculate_technical_indicators_v1(df)\n",
        "            trend_analysis = self.analyze_trend(df_ind)\n",
        "            volume_analysis = self.analyze_volume(df_ind)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_ind)\n",
        "            sentiment_analysis = self.sentiment_analyzer.calculate_sentiment_score(stock_id, stock_name)\n",
        "            combined = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis, sentiment_analysis)\n",
        "            recommendation = self.generate_recommendation(combined['combined_score'], trend_analysis, technical_analysis, sentiment_analysis)\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_id,\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': float(df_ind['Close'].iloc[-1]),\n",
        "                'price_change_5d': trend_analysis.get('price_change_5d', 0),\n",
        "                'combined_score': combined['combined_score'],\n",
        "                'combined_components': combined.get('components', {}),\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'sentiment_analysis': sentiment_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"{symbol} åˆ†æéŒ¯èª¤: {e}\")\n",
        "            return {'symbol': symbol, 'stock_name': stock_name, 'stock_id': stock_id, 'success': False, 'error': str(e)}\n",
        "\n",
        "    async def analyze_all_stocks(self, limit: Optional[int] = None) -> Dict[str, Any]:\n",
        "        if self.taiwan_stocks is None:\n",
        "            self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "        if self.taiwan_stocks.empty:\n",
        "            return {}\n",
        "        df_list = self.taiwan_stocks if not limit else self.taiwan_stocks.head(limit)\n",
        "        tasks = []\n",
        "        results = {}\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            for _, row in df_list.iterrows():\n",
        "                tasks.append(self.analyze_stock_async(session, row.to_dict()))\n",
        "            batch_size = 12\n",
        "            for i in range(0, len(tasks), batch_size):\n",
        "                batch = tasks[i:i+batch_size]\n",
        "                batch_results = await asyncio.gather(*batch, return_exceptions=True)\n",
        "                for r in batch_results:\n",
        "                    if isinstance(r, dict) and 'symbol' in r:\n",
        "                        results[r['symbol']] = r\n",
        "                await asyncio.sleep(1)\n",
        "        return results\n",
        "\n",
        "# ===============================\n",
        "# æ ¼å¼åŒ–è¼¸å‡º\n",
        "# ===============================\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    ok = [r for r in results.values() if r.get('success')]\n",
        "    ok.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "    lines = []\n",
        "    now_str = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "    lines.append(\"ğŸ† å°è‚¡ç¶œåˆæŠ€è¡“ + æƒ…ç·’ åˆ†æ\")\n",
        "    lines.append(f\"ğŸ•’ åˆ†ææ™‚é–“: {now_str}\")\n",
        "    lines.append(f\"âœ… æˆåŠŸåˆ†æ: {len(ok)} æ”¯\")\n",
        "    lines.append(\"=\" * 50)\n",
        "    if not ok:\n",
        "        lines.append(\"âŒ ç„¡å¯ç”¨çµæœ\")\n",
        "        return \"\\n\".join(lines)\n",
        "    top = ok[:limit]\n",
        "    for idx, r in enumerate(top, 1):\n",
        "        sa = r.get('sentiment_analysis', {})\n",
        "        news_cnt = sa.get('news_count', 0)\n",
        "        fear_greed = sa.get('fear_greed_index', 50)\n",
        "        mood = sa.get('market_mood', '')\n",
        "        fg_emoji = \"ğŸ˜¨\" if fear_greed < 30 else \"ğŸ˜\" if fear_greed < 70 else \"ğŸ¤‘\"\n",
        "        rec = r.get('recommendation', {}).get('recommendation', '')\n",
        "        lines.append(f\"{idx}. {r.get('stock_name')} ({r.get('stock_id')})\")\n",
        "        lines.append(f\"   ğŸ’° åƒ¹æ ¼: {r.get('current_price', 0):.2f} | 5æ—¥: {r.get('price_change_5d', 0):+.2f}%\")\n",
        "        lines.append(f\"   â­ ç¶œåˆè©•åˆ†: {r.get('combined_score', 0):.1f} | å»ºè­°: {rec}\")\n",
        "        lines.append(f\"   ğŸ“° æ–°èç†±åº¦: {news_cnt} | æ–°èæƒ…ç·’: {sa.get('news_sentiment',50):.1f}\")\n",
        "        lines.append(f\"   {fg_emoji} å¸‚å ´æƒ…ç·’(F&G): {fear_greed:.1f} ({mood})\")\n",
        "        tech = r.get('technical_analysis', {})\n",
        "        lines.append(f\"   ğŸ” RSI {tech.get('rsi_value',50):.1f}({tech.get('rsi_signal','ä¸­æ€§')}), MACD:{tech.get('macd_signal','ä¸­æ€§')}, KD:{tech.get('k_value',50):.1f}/{tech.get('d_value',50):.1f}\")\n",
        "        lines.append(\"-\" * 50)\n",
        "    avg_score = np.mean([x.get('combined_score', 0) for x in ok]) if ok else 0\n",
        "    high_cnt = sum(1 for x in ok if x.get('combined_score', 0) >= 70)\n",
        "    lines.append(f\"ğŸ“ˆ å¹³å‡åˆ†æ•¸: {avg_score:.1f} | é«˜åˆ†(>=70): {high_cnt}\")\n",
        "    lines.append(\"âš ï¸ é¢¨éšªè²æ˜ï¼šåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªã€‚\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# ===============================\n",
        "# é€šçŸ¥ï¼ˆå« Retry / Backoffï¼‰\n",
        "# ===============================\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "    if not files:\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        if os.path.exists(chart_dir):\n",
        "            # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "            files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                    if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            if files:\n",
        "                logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "            else:\n",
        "                logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                if response.status == 200:\n",
        "                    logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                else:\n",
        "                    response_text = await response.text()\n",
        "                    logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                sent_count = 0\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            data = aiohttp.FormData()\n",
        "                            data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                            # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                            caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                            data.add_field('caption', caption)\n",
        "\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                    if response.status == 200:\n",
        "                                        sent_count += 1\n",
        "                                    else:\n",
        "                                        response_text = await response.text()\n",
        "                                        logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                            # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                            await asyncio.sleep(0.5)\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "        message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "        for chunk in message_chunks:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response and response.ok:\n",
        "                logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                content = response.content if response else \"æœªçŸ¥\"\n",
        "                logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "        # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "        if files:\n",
        "            batch_size = 10\n",
        "            for i in range(0, len(files), batch_size):\n",
        "                batch_files = files[i:i+batch_size]\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                for file_path in batch_files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        # ç²å–åœ–è¡¨æª”æ¡ˆæ•¸é‡\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        chart_count = 0\n",
        "        if os.path.exists(chart_dir):\n",
        "            chart_files = [f for f in os.listdir(chart_dir) if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            chart_count = len(chart_files)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ“Š ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ“ˆ TOP {min(5, len(filtered_results))} æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            # ç²å–æ›´å¤šæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\n",
        "            macd = tech.get('macd_value', 0)\n",
        "            signal = tech.get('signal_value', 0)\n",
        "            macd_status = \"å¤šé ­\" if macd > signal else \"ç©ºé ­\" if macd < signal else \"ä¸­æ€§\"\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_status', 'ä¸­æ€§')})\n",
        "   ğŸ“‰ MACD: {macd_status}\n",
        "\"\"\"\n",
        "\n",
        "        # æ·»åŠ åœ–è¡¨è³‡è¨Š\n",
        "        if chart_count > 0:\n",
        "            message += f\"\"\"\n",
        "ğŸ“Š è©³ç´°åˆ†æåœ–è¡¨:\n",
        "â€¢ å·²ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "â€¢ åœ–è¡¨åŒ…å«Kç·šã€å‡ç·šã€æˆäº¤é‡ã€MACDåŠRSIæŒ‡æ¨™\n",
        "â€¢ åœ–è¡¨å°‡åœ¨æ­¤è¨Šæ¯å¾Œç™¼é€\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def detect_divergence(df, rsi_threshold=30, rsi_overbought=70, window=20, min_divergence_points=2):\n",
        "    \"\"\"\n",
        "    æª¢æ¸¬ RSI èˆ‡åƒ¹æ ¼ä¹‹é–“çš„èƒŒé›¢\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): åŒ…å«åƒ¹æ ¼å’Œ RSI çš„ DataFrame\n",
        "        rsi_threshold (int): RSI è¶…è³£é–¾å€¼\n",
        "        rsi_overbought (int): RSI è¶…è²·é–¾å€¼\n",
        "        window (int): æª¢æ¸¬çª—å£å¤§å°\n",
        "        min_divergence_points (int): æœ€å°èƒŒé›¢é»æ•¸é‡\n",
        "\n",
        "    Returns:\n",
        "        dict: åŒ…å«èƒŒé›¢é¡å‹å’Œåˆ†æ•¸çš„å­—å…¸\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨\n",
        "        required_cols = ['Close', 'RSI']\n",
        "        for col in required_cols:\n",
        "            if col not in df.columns:\n",
        "                # å˜—è©¦æŸ¥æ‰¾å°å¯«ç‰ˆæœ¬\n",
        "                if col.lower() in df.columns:\n",
        "                    df[col] = df[col.lower()]\n",
        "                    logger.info(f\"å·²å°‡ {col.lower()} æ¬„ä½è¤‡è£½ç‚º {col}\")\n",
        "                else:\n",
        "                    logger.warning(f\"detect_divergence: ç¼ºå°‘å¿…è¦æ¬„ä½ {col}\")\n",
        "                    return {\n",
        "                        'type': 'ç„¡',                        'bullish_regular': 0,\n",
        "                        'bullish_hidden': 0,\n",
        "                        'bearish_regular': 0,\n",
        "                        'bearish_hidden': 0,\n",
        "                        'details': f\"ç¼ºå°‘å¿…è¦æ¬„ä½: {col}\"\n",
        "                        }\n",
        "\n",
        "        # åˆå§‹åŒ–è¿”å›çµæœ\n",
        "        result = {\n",
        "        'type': 'ç„¡',\n",
        "        'bullish_regular': 0,\n",
        "        'bullish_hidden': 0,\n",
        "        'bearish_regular': 0,\n",
        "        'bearish_hidden': 0,\n",
        "        'details': None\n",
        "        }\n",
        "\n",
        "        if df is None or df.empty:\n",
        "            return result\n",
        "        if 'Close' not in df.columns or 'RSI' not in df.columns:\n",
        "            return result\n",
        "        lookback = 30\n",
        "        if len(df) < lookback:\n",
        "            return result\n",
        "        recent = df.tail(lookback)\n",
        "        price_highs, price_lows, rsi_highs, rsi_lows = [], [], [], []\n",
        "        for i in range(1, len(recent)-1):\n",
        "            if recent['Close'].iloc[i] > recent['Close'].iloc[i-1] and recent['Close'].iloc[i] > recent['Close'].iloc[i+1]:\n",
        "                price_highs.append((i, recent['Close'].iloc[i]))\n",
        "            if recent['Close'].iloc[i] < recent['Close'].iloc[i-1] and recent['Close'].iloc[i] < recent['Close'].iloc[i+1]:\n",
        "                price_lows.append((i, recent['Close'].iloc[i]))\n",
        "            if recent['RSI'].iloc[i] > recent['RSI'].iloc[i-1] and recent['RSI'].iloc[i] > recent['RSI'].iloc[i+1]:\n",
        "                rsi_highs.append((i, recent['RSI'].iloc[i]))\n",
        "            if recent['RSI'].iloc[i] < recent['RSI'].iloc[i-1] and recent['RSI'].iloc[i] < recent['RSI'].iloc[i+1]:\n",
        "                rsi_lows.append((i, recent['RSI'].iloc[i]))\n",
        "        if len(price_highs) >= 2 and len(rsi_highs) >= 2:\n",
        "            lp = price_highs[-1]; pp = price_highs[-2]\n",
        "            lr = rsi_highs[-1]; pr = rsi_highs[-2]\n",
        "            if lp[1] > pp[1] and lr[1] < pr[1]:\n",
        "                result['bearish_regular'] += 1\n",
        "                result['type'] = 'é ‚èƒŒé›¢'\n",
        "                result['details'] = {'price_high1': pp[1], 'price_high2': lp[1], 'rsi_high1': pr[1], 'rsi_high2': lr[1]}\n",
        "            if lp[1] < pp[1] and lr[1] > pr[1]:\n",
        "                result['bearish_hidden'] += 1\n",
        "        if len(price_lows) >= 2 and len(rsi_lows) >= 2:\n",
        "            lp = price_lows[-1]; pp = price_lows[-2]\n",
        "            lr = rsi_lows[-1]; pr = rsi_lows[-2]\n",
        "            if lp[1] < pp[1] and lr[1] > pr[1]:\n",
        "                result['bullish_regular'] += 1\n",
        "                result['type'] = 'åº•èƒŒé›¢'\n",
        "                result['details'] = {'price_low1': pp[1], 'price_low2': lp[1], 'rsi_low1': pr[1], 'rsi_low2': lr[1]}\n",
        "            if lp[1] > pp[1] and lr[1] < pr[1]:\n",
        "                result['bullish_hidden'] += 1\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logger.error(f\"èƒŒé›¢æª¢æ¸¬éŒ¯èª¤: {e}\")\n",
        "        return result\n",
        "\n",
        "def check_volume_condition(df, min_volume=1000, weeks=3):\n",
        "    try:\n",
        "        if 'Volume' not in df.columns or df.empty:\n",
        "            return False\n",
        "        if not isinstance(df.index, pd.DatetimeIndex):\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "        if len(df) < weeks * 5:\n",
        "            return False\n",
        "        weekly_volume = df['Volume'].resample('W').mean() / 1000\n",
        "        if len(weekly_volume) < weeks:\n",
        "            return False\n",
        "        is_high_volume = weekly_volume.tail(weeks) > min_volume\n",
        "        return all(is_high_volume)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æª¢æŸ¥æˆäº¤é‡æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return False\n",
        "\n",
        "# ===============================\n",
        "# v2 æŠ€è¡“æŒ‡æ¨™ï¼ˆå®Œæ•´ï¼‰\n",
        "# ===============================\n",
        "def calculate_technical_indicators_v2(df: pd.DataFrame, debug: bool = False):\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    if debug:\n",
        "        print(\"=== DEBUG BEFORE INDICATOR ===\")\n",
        "        print(df.columns.tolist())\n",
        "        print(df.head(3))\n",
        "        print(df.dtypes)\n",
        "        for i, c in enumerate(df.columns):\n",
        "            print(i, repr(c), \"-> stripped:\", repr(str(c).strip()))\n",
        "    try:\n",
        "        df = df.copy()\n",
        "        if not isinstance(df.index, pd.DatetimeIndex):\n",
        "            if 'Date' in df.columns:\n",
        "                try:\n",
        "                    df['Date'] = pd.to_datetime(df['Date'])\n",
        "                    df.set_index('Date', inplace=True)\n",
        "                except:\n",
        "                    pass\n",
        "        cols = []\n",
        "        for c in df.columns:\n",
        "            if isinstance(c, tuple):\n",
        "                parts = [str(x) for x in c if x is not None and str(x) != \"\"]\n",
        "                cols.append(\"_\".join(parts))\n",
        "            else:\n",
        "                cols.append(str(c))\n",
        "        df.columns = cols\n",
        "        def normalize(col: str):\n",
        "            col2 = str(col).strip().replace('\\u3000', ' ')\n",
        "            col2 = re.sub(r'\\s+', '', col2)\n",
        "            return col2.lower()\n",
        "        norm_map = {}\n",
        "        for original in df.columns:\n",
        "            n = normalize(original)\n",
        "            if n not in norm_map:\n",
        "                norm_map[n] = original\n",
        "        if debug:\n",
        "            print(\"== Column Normalization Map ==\")\n",
        "            for k, v in norm_map.items():\n",
        "                print(f\"{k} -> {v}\")\n",
        "        def find_first_by_keywords(keywords):\n",
        "            for kw in keywords:\n",
        "                kw_n = normalize(kw)\n",
        "                if kw_n in norm_map:\n",
        "                    return norm_map[kw_n]\n",
        "            for norm_key, orig in norm_map.items():\n",
        "                if any(kw in norm_key for kw in keywords):\n",
        "                    return orig\n",
        "            return None\n",
        "        col_close = find_first_by_keywords(['close', 'adjclose', 'closeprice', 'price'])\n",
        "        col_high  = find_first_by_keywords(['high', 'max'])\n",
        "        col_low   = find_first_by_keywords(['low', 'min'])\n",
        "        col_open  = find_first_by_keywords(['open'])\n",
        "        col_vol   = find_first_by_keywords(['volume', 'vol'])\n",
        "        missing = [n for n, v in [('Close', col_close), ('High', col_high), ('Low', col_low)] if v is None]\n",
        "        if missing:\n",
        "            if debug:\n",
        "                print(\"åŸå§‹æ¬„ä½åˆ—è¡¨:\", df.columns.tolist())\n",
        "            return None\n",
        "        rename_map = {}\n",
        "        if col_close and col_close != 'Close': rename_map[col_close] = 'Close'\n",
        "        if col_high  and col_high  != 'High':  rename_map[col_high]  = 'High'\n",
        "        if col_low   and col_low   != 'Low':   rename_map[col_low]   = 'Low'\n",
        "        if col_open  and col_open  != 'Open':  rename_map[col_open]  = 'Open'\n",
        "        if col_vol   and col_vol   != 'Volume':rename_map[col_vol]   = 'Volume'\n",
        "        if rename_map:\n",
        "            df.rename(columns=rename_map, inplace=True)\n",
        "        def series_only(frame, col):\n",
        "            s = frame[col]\n",
        "            if isinstance(s, pd.DataFrame):\n",
        "                for sub in s.columns:\n",
        "                    if not s[sub].isna().all():\n",
        "                        return s[sub]\n",
        "                return s.iloc[:, 0]\n",
        "            return s\n",
        "        close = series_only(df, 'Close')\n",
        "        high  = series_only(df, 'High')\n",
        "        low   = series_only(df, 'Low')\n",
        "        volume = series_only(df, 'Volume') if 'Volume' in df.columns else pd.Series(0, index=df.index)\n",
        "        core = pd.concat([close, high, low], axis=1)\n",
        "        df = df.loc[~core.isna().all(axis=1)].copy()\n",
        "        for win in [5, 10, 20, 60, 120]:\n",
        "            df[f\"MA{win}\"] = close.rolling(win, min_periods=1).mean()\n",
        "        ema12 = close.ewm(span=12, adjust=False).mean()\n",
        "        ema26 = close.ewm(span=26, adjust=False).mean()\n",
        "        macd_line = ema12 - ema26\n",
        "        macd_signal = macd_line.ewm(span=9, adjust=False).mean()\n",
        "        df['MACD'] = macd_line\n",
        "        df['MACD_Signal'] = macd_signal\n",
        "        df['MACD_Hist'] = macd_line - macd_signal\n",
        "        delta = close.diff()\n",
        "        gain = delta.clip(lower=0)\n",
        "        loss = (-delta.clip(upper=0)).abs()\n",
        "        avg_gain = gain.rolling(14, min_periods=14).mean()\n",
        "        avg_loss = loss.rolling(14, min_periods=14).mean()\n",
        "        rs = avg_gain / (avg_loss.replace(0, np.nan))\n",
        "        df['RSI'] = 100 - (100 / (1 + rs))\n",
        "        mid = close.rolling(20, min_periods=15).mean()\n",
        "        std = close.rolling(20, min_periods=15).std()\n",
        "        df['BB_Middle'] = mid\n",
        "        df['BB_Upper'] = mid + 2 * std\n",
        "        df['BB_Lower'] = mid - 2 * std\n",
        "        n = 14\n",
        "        ll = low.rolling(n, min_periods=5).min()\n",
        "        hh = high.rolling(n, min_periods=5).max()\n",
        "        rng = (hh - ll).replace(0, np.nan)\n",
        "        k_raw = 100 * (close - ll) / (rng + 1e-9)\n",
        "        df['%K_raw'] = k_raw\n",
        "        df['K'] = k_raw.rolling(3, min_periods=1).mean()\n",
        "        df['D'] = df['K'].rolling(3, min_periods=1).mean()\n",
        "        pc = close.diff()\n",
        "        obv_step = np.where(pc > 0, volume,\n",
        "                            np.where(pc < 0, -volume, 0))\n",
        "        df['OBV'] = pd.Series(obv_step, index=df.index).cumsum()\n",
        "        tr1 = (high - low).abs()\n",
        "        tr2 = (high - close.shift()).abs()\n",
        "        tr3 = (low - close.shift()).abs()\n",
        "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "        df['ATR'] = tr.rolling(14, min_periods=5).mean()\n",
        "        plus_dm_raw = (high - high.shift())\n",
        "        minus_dm_raw = (low.shift() - low)\n",
        "        plus_dm = plus_dm_raw.where((plus_dm_raw > minus_dm_raw) & (plus_dm_raw > 0), 0.0)\n",
        "        minus_dm = minus_dm_raw.where((minus_dm_raw > plus_dm_raw) & (minus_dm_raw > 0), 0.0)\n",
        "        tr_14 = tr.rolling(14, min_periods=5).sum()\n",
        "        plus_di = 100 * (plus_dm.rolling(14, min_periods=5).sum() / (tr_14 + 1e-9))\n",
        "        minus_di = 100 * (minus_dm.rolling(14, min_periods=5).sum() / (tr_14 + 1e-9))\n",
        "        dx = 100 * ((plus_di - minus_di).abs() / (plus_di + minus_di + 1e-9))\n",
        "        df['Plus_DI'] = plus_di\n",
        "        df['Minus_DI'] = minus_di\n",
        "        df['ADX'] = dx.rolling(14, min_periods=5).mean()\n",
        "        tp = (high + low + close) / 3\n",
        "        tp_ma = tp.rolling(20, min_periods=15).mean()\n",
        "        mean_dev = (tp - tp_ma).abs().rolling(20, min_periods=15).mean()\n",
        "        df['CCI'] = (tp - tp_ma) / (0.015 * (mean_dev + 1e-9))\n",
        "        df['ROC'] = (close / close.shift(10) - 1) * 100\n",
        "        typical_price = tp\n",
        "        money_flow = typical_price * volume\n",
        "        pos_mf = money_flow.where(typical_price > typical_price.shift(), 0.0)\n",
        "        neg_mf = money_flow.where(typical_price < typical_price.shift(), 0.0)\n",
        "        pmf_sum = pos_mf.rolling(14, min_periods=5).sum()\n",
        "        nmf_sum = neg_mf.rolling(14, min_periods=5).sum()\n",
        "        mfr = pmf_sum / (nmf_sum + 1e-9)\n",
        "        df['MFI'] = 100 - (100 / (1 + mfr))\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"[calculate_technical_indicators_v2] ä¾‹å¤–: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "# ===============================\n",
        "# èƒŒé›¢åˆ†ææµç¨‹\n",
        "# ===============================\n",
        "async def run_divergence_analysis(\n",
        "        stocks: List[Dict[str, Any]],\n",
        "        min_score=3,\n",
        "        period='1y',\n",
        "        volume_weeks=3,\n",
        "        require_volume=1000,\n",
        "        include_sentiment=True):\n",
        "    results = []\n",
        "    total = len(stocks)\n",
        "    logger.info(f\"èƒŒé›¢åˆ†æé–‹å§‹: å…± {total} æ”¯è‚¡ç¥¨\")\n",
        "    sent_analyzer = MarketSentimentAnalyzer() if include_sentiment else None\n",
        "    for idx, s in enumerate(stocks, 1):\n",
        "        try:\n",
        "            stock_id = s.get('stock_id')\n",
        "            yahoo_symbol = s.get('yahoo_symbol', f\"{stock_id}.TW\")\n",
        "            raw = yf.download(yahoo_symbol, period=period, interval=\"1d\", auto_adjust=True, progress=False)\n",
        "            if raw.empty or len(raw) < 200:\n",
        "                continue\n",
        "            raw.reset_index(inplace=True)\n",
        "            if 'Date' not in raw.columns or 'Close' not in raw.columns:\n",
        "                continue\n",
        "            raw['Date'] = pd.to_datetime(raw['Date'])\n",
        "            raw.set_index('Date', inplace=True)\n",
        "            ind_df = calculate_technical_indicators_v2(raw)\n",
        "            if ind_df is None or ind_df.empty:\n",
        "                continue\n",
        "            div = detect_divergence(ind_df)\n",
        "            bull_score = div['bullish_regular'] + div['bullish_hidden']\n",
        "            bear_score = div['bearish_regular'] + div['bearish_hidden']\n",
        "            if bull_score == 0 and bear_score == 0:\n",
        "                continue\n",
        "            direction = None\n",
        "            final_score = 0\n",
        "            if bull_score > bear_score and bull_score >= min_score:\n",
        "                direction = 'bullish'; final_score = bull_score\n",
        "            elif bear_score > bull_score and bear_score >= min_score:\n",
        "                direction = 'bearish'; final_score = bear_score\n",
        "            else:\n",
        "                continue\n",
        "            if not check_volume_condition(ind_df[['Volume']].copy(), min_volume=require_volume, weeks=volume_weeks):\n",
        "                continue\n",
        "            sentiment_block = {}\n",
        "            if include_sentiment and sent_analyzer:\n",
        "                sentiment_block = sent_analyzer.calculate_sentiment_score(stock_id, s.get('stock_name', ''))\n",
        "            results.append({\n",
        "                'stock_id': stock_id,\n",
        "                'stock_name': s.get('stock_name', ''),\n",
        "                'type': div['type'],\n",
        "                'score': final_score,\n",
        "                'direction': direction,\n",
        "                'close': ind_df['Close'].iloc[-1],\n",
        "                'date': ind_df.index[-1].strftime('%Y-%m-%d'),\n",
        "                'rsi': ind_df['RSI'].iloc[-1] if 'RSI' in ind_df.columns else None,\n",
        "                'volume_condition': True,\n",
        "                'sentiment': sentiment_block,\n",
        "                'data': ind_df\n",
        "            })\n",
        "            logger.info(f\"[{idx}/{total}] {stock_id} èƒŒé›¢ç¬¦åˆ: {direction} åˆ†æ•¸={final_score}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"èƒŒé›¢åˆ†æéŒ¯èª¤ {s}: {e}\")\n",
        "    if results:\n",
        "        results.sort(key=lambda x: x['score'], reverse=True)\n",
        "    return results\n",
        "\n",
        "# ===============================\n",
        "# èƒŒé›¢åœ–è¡¨\n",
        "# ===============================\n",
        "def plot_divergence_chart(entry: Dict[str, Any], save_dir='analysis_charts'):\n",
        "    try:\n",
        "        df = entry.get('data')\n",
        "        if df is None or df.empty:\n",
        "            return None\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        title = f\"{entry['stock_id']} {entry['stock_name']} {entry['type']} åˆ†æ•¸:{entry['score']}\"\n",
        "        ap = []\n",
        "        if 'MA20' in df.columns:\n",
        "            ap.append(mpf.make_addplot(df['MA20'], color='blue', width=1))\n",
        "        if 'MA60' in df.columns:\n",
        "            ap.append(mpf.make_addplot(df['MA60'], color='red', width=1))\n",
        "        if 'RSI' in df.columns:\n",
        "            ap.append(mpf.make_addplot(df['RSI'], panel=1, color='purple', ylabel='RSI'))\n",
        "            ap.append(mpf.make_addplot([70]*len(df), panel=1, color='red', linestyle='--'))\n",
        "            ap.append(mpf.make_addplot([30]*len(df), panel=1, color='green', linestyle='--'))\n",
        "        path = os.path.join(save_dir, f\"{entry['stock_id']}_{datetime.now().strftime('%Y%m%d')}_div.png\")\n",
        "        mpf.plot(df, type='candle', title=title, addplot=ap, volume=True, figsize=(14,8),\n",
        "                 panel_ratios=(6,2), style='yahoo', savefig=path)\n",
        "        return path\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç¹ªè£½èƒŒé›¢åœ–éŒ¯èª¤: {e}\")\n",
        "        return None\n",
        "\n",
        "# ===============================\n",
        "# èƒŒé›¢é€šçŸ¥\n",
        "# ===============================\n",
        "async def notify_divergence_results(entries: List[Dict[str, Any]], limit=10):\n",
        "    if not entries:\n",
        "        await send_notification_text(\"ğŸ“‰ èƒŒé›¢åˆ†æï¼šæ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "        return\n",
        "    text_lines = []\n",
        "    text_lines.append(\"ğŸ” èƒŒé›¢åˆ†æçµæœ\")\n",
        "    text_lines.append(f\"ğŸ•’ {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    text_lines.append(\"=\"*40)\n",
        "    top = entries[:limit]\n",
        "    for i, e in enumerate(top, 1):\n",
        "        sent = e.get('sentiment', {})\n",
        "        fg = sent.get('fear_greed_index', 50)\n",
        "        mood = sent.get('market_mood', '')\n",
        "        text_lines.append(f\"{i}. {e['stock_id']} {e['stock_name']} {e['type']} åˆ†æ•¸:{e['score']} åƒ¹:{e['close']:.2f}\")\n",
        "        if sent:\n",
        "            text_lines.append(f\"   æƒ…ç·’:{sent.get('sentiment_score',50):.1f} F&G:{fg:.1f}({mood}) æ–°è:{sent.get('news_count',0)}\")\n",
        "    await send_notification_text(\"\\n\".join(text_lines))\n",
        "    for e in top:\n",
        "        try:\n",
        "            chart = plot_divergence_chart(e)\n",
        "            if chart:\n",
        "                logger.info(f\"èƒŒé›¢åœ–å·²ç”Ÿæˆ: {chart}\")\n",
        "        except Exception as ex:\n",
        "            logger.error(f\"ç”ŸæˆèƒŒé›¢åœ–å¤±æ•—: {ex}\")\n",
        "\n",
        "# ===============================\n",
        "# ä¸»æµç¨‹\n",
        "# ===============================\n",
        "async def main_all():\n",
        "    logger.info(\"===== ç¶œåˆåˆ†æå•Ÿå‹• (æŠ€è¡“+æƒ…ç·’ + èƒŒé›¢) =====\")\n",
        "    analyzer = StockAnalyzer()\n",
        "    results = await analyzer.analyze_all_stocks(limit=2000)\n",
        "    msg = format_analysis_message(results, limit=10)\n",
        "    print(msg)\n",
        "    await send_notification_text(msg)\n",
        "    if analyzer.taiwan_stocks is None or analyzer.taiwan_stocks.empty:\n",
        "        logger.warning(\"ç„¡æ³•å–å¾—è‚¡ç¥¨æ¸…å–®é€²è¡ŒèƒŒé›¢åˆ†æ\")\n",
        "        return\n",
        "    stocks_list = analyzer.taiwan_stocks.to_dict('records')\n",
        "    divergence_entries = await run_divergence_analysis(\n",
        "        stocks=stocks_list,\n",
        "        min_score=3,\n",
        "        period='1y',\n",
        "        volume_weeks=3,\n",
        "        require_volume=1000,\n",
        "        include_sentiment=True\n",
        "    )\n",
        "    await notify_divergence_results(divergence_entries, limit=10)\n",
        "    logger.info(\"===== ç¶œåˆåˆ†æå®Œæˆ =====\")\n",
        "\n",
        "# ===============================\n",
        "# Debug æ¸¬è©¦ï¼šæŒ‡æ¨™ v2\n",
        "# ===============================\n",
        "def debug_indicator_test(symbol=\"2330.TW\"):\n",
        "    t = yf.download(symbol, period=\"3mo\", interval=\"1d\", auto_adjust=True, progress=False)\n",
        "    if t.empty:\n",
        "        print(\"ä¸‹è¼‰æ¸¬è©¦è³‡æ–™å¤±æ•—\")\n",
        "        return\n",
        "    t.columns = [c + ' ' if c == 'Close' else c for c in t.columns]  # æ¨¡æ“¬ Close æœ‰ç©ºç™½\n",
        "    ind = calculate_technical_indicators_v2(t, debug=True)\n",
        "    if ind is None:\n",
        "        print(\"æŒ‡æ¨™è¨ˆç®—å¤±æ•—ï¼Œè«‹è²¼ debug è¼¸å‡ºã€‚\")\n",
        "        return\n",
        "    cols_show = [c for c in ['Close', 'K', 'D', 'RSI', 'MACD', 'MFI'] if c in ind.columns]\n",
        "    print(ind.tail()[cols_show])\n",
        "\n",
        "# ===============================\n",
        "# åŸ·è¡Œå…¥å£\n",
        "# ===============================\n",
        "if __name__ == \"__main__\":\n",
        "    RUN_MAIN = True\n",
        "    RUN_DEBUG_INDICATOR = False\n",
        "    if RUN_MAIN:\n",
        "        try:\n",
        "            asyncio.run(main_all())\n",
        "        except RuntimeError:\n",
        "            loop = asyncio.get_event_loop()\n",
        "            loop.run_until_complete(main_all())\n",
        "    if RUN_DEBUG_INDICATOR:\n",
        "        debug_indicator_test(\"2330.TW\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUm-I-mRgO7R"
      },
      "outputs": [],
      "source": [
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "class StrongMomentumStockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–å¼·å‹¢è‚¡åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 500,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'price_change_threshold': 5.0,  # åƒ¹æ ¼è®ŠåŒ–é–¾å€¼(%)\n",
        "            'volume_ratio_threshold': 1.5,  # æˆäº¤é‡æ¯”ç‡é–¾å€¼\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.5,\n",
        "                'volume_trend': 0.3,\n",
        "                'technical_score': 0.2\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df.loc[:, 'market'] = market_name\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)].copy()\n",
        "\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨è‚¡ç¥¨æ¸…å–®\")\n",
        "\n",
        "            # å¾åœ–ç‰‡ä¸­è­˜åˆ¥çš„è‚¡ç¥¨åŠ å…¥å‚™ç”¨åˆ—è¡¨\n",
        "            image_stocks = [\n",
        "                {'stock_id': '6134', 'stock_name': 'è¬æ—­', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '6134.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '6133', 'stock_name': 'é‡‘æ©‹', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '6133.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '3163', 'stock_name': 'æ³¢è‹¥å¨', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3163.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '5475', 'stock_name': 'å¾·å®', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '5475.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '3605', 'stock_name': 'å®è‡´', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3605.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '1815', 'stock_name': 'å¯Œé¦™', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1815.TW', 'industry': 'é£Ÿå“'},\n",
        "                {'stock_id': '1802', 'stock_name': 'å°ç»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1802.TW', 'industry': 'ç»ç’ƒ'},\n",
        "                {'stock_id': '3297', 'stock_name': 'æ­ç‰¹', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3297.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '6895', 'stock_name': 'å®ç¢©ç³»çµ±', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '6895.TW', 'industry': 'è³‡è¨Šæœå‹™'},\n",
        "                {'stock_id': '4989', 'stock_name': 'æ¦®ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '4989.TW', 'industry': 'ç”ŸæŠ€é†«ç™‚'},\n",
        "                {'stock_id': '3332', 'stock_name': 'åœ­åº·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3332.TW', 'industry': 'ç”ŸæŠ€é†«ç™‚'},\n",
        "                {'stock_id': '6197', 'stock_name': 'ä½³å¿…çª', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '6197.TW', 'industry': 'é›»å­'},\n",
        "            ]\n",
        "\n",
        "            # æ·»åŠ å…¶ä»–çŸ¥åè‚¡ç¥¨\n",
        "            famous_stocks = [\n",
        "                {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2412', 'stock_name': 'ä¸­è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2412.TW', 'industry': 'é€šä¿¡'},\n",
        "                {'stock_id': '1301', 'stock_name': 'å°å¡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1301.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "            ]\n",
        "\n",
        "            # åˆä½µå…©å€‹åˆ—è¡¨\n",
        "            all_stocks = image_stocks + famous_stocks\n",
        "\n",
        "            df = pd.DataFrame(all_stocks)\n",
        "            logger.info(f\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1mo\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“š\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return df\n",
        "\n",
        "            df = df.copy()\n",
        "\n",
        "            # RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'], self.config['rsi_period'])\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·š\n",
        "            df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "            df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "            df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "            # æˆäº¤é‡ç§»å‹•å¹³å‡\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "                # è¨ˆç®—æˆäº¤é‡æ¯”ç‡ (ç•¶æ—¥æˆäº¤é‡/20æ—¥å¹³å‡)\n",
        "                df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']\n",
        "\n",
        "            # è¨ˆç®—æ—¥æ¼²å¹…\n",
        "            df['Daily_Return'] = df['Close'].pct_change() * 100\n",
        "\n",
        "            # è¨ˆç®—5æ—¥æ¼²å¹…\n",
        "            df['5D_Return'] = df['Close'].pct_change(5) * 100\n",
        "\n",
        "            # è¨ˆç®—10æ—¥æ¼²å¹…\n",
        "            df['10D_Return'] = df['Close'].pct_change(10) * 100\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def check_volume_surge(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡çªå¢\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or 'Volume_Ratio' not in df.columns:\n",
        "                return {'volume_surge': False, 'volume_ratio': 1.0}\n",
        "\n",
        "            # ç²å–æœ€è¿‘ä¸€æ—¥çš„æˆäº¤é‡æ¯”ç‡\n",
        "            latest_volume_ratio = df['Volume_Ratio'].iloc[-1]\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦æœ‰æˆäº¤é‡çªå¢\n",
        "            volume_surge = latest_volume_ratio >= self.config['volume_ratio_threshold']\n",
        "\n",
        "            return {\n",
        "                'volume_surge': volume_surge,\n",
        "                'volume_ratio': latest_volume_ratio\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡çªå¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_surge': False, 'volume_ratio': 1.0}\n",
        "\n",
        "    def check_price_momentum(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æª¢æŸ¥åƒ¹æ ¼å‹•èƒ½\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Daily_Return' not in df.columns:\n",
        "                return {'strong_momentum': False, 'daily_return': 0, '5d_return': 0}\n",
        "\n",
        "            # ç²å–æœ€è¿‘ä¸€æ—¥çš„æ¼²å¹…\n",
        "            daily_return = df['Daily_Return'].iloc[-1]\n",
        "\n",
        "            # ç²å–5æ—¥æ¼²å¹…\n",
        "            five_day_return = df['5D_Return'].iloc[-1] if '5D_Return' in df.columns else 0\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦æœ‰å¼·å‹¢å‹•èƒ½ (æ—¥æ¼²å¹…è¶…éé–¾å€¼)\n",
        "            strong_momentum = daily_return >= self.config['price_change_threshold']\n",
        "\n",
        "            # æª¢æŸ¥æ˜¯å¦æ¥è¿‘æ¼²åœ (å°ç£è‚¡å¸‚æ¼²åœé€šå¸¸ç‚º10%)\n",
        "            near_limit_up = daily_return >= 8.0\n",
        "\n",
        "            return {\n",
        "                'strong_momentum': strong_momentum,\n",
        "                'near_limit_up': near_limit_up,\n",
        "                'daily_return': daily_return,\n",
        "                '5d_return': five_day_return\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥åƒ¹æ ¼å‹•èƒ½æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'strong_momentum': False, 'daily_return': 0, '5d_return': 0}\n",
        "\n",
        "    def check_ma_crossover(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æª¢æŸ¥å‡ç·šäº¤å‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'MA5' not in df.columns or 'MA20' not in df.columns or len(df) < 2:\n",
        "                return {'ma_crossover': False, 'ma_support': False}\n",
        "\n",
        "            # æª¢æŸ¥5æ—¥å‡ç·šæ˜¯å¦ä¸Šç©¿20æ—¥å‡ç·š\n",
        "            prev_ma5 = df['MA5'].iloc[-2]\n",
        "            prev_ma20 = df['MA20'].iloc[-2]\n",
        "            curr_ma5 = df['MA5'].iloc[-1]\n",
        "            curr_ma20 = df['MA20'].iloc[-1]\n",
        "\n",
        "            ma_crossover = (prev_ma5 <= prev_ma20) and (curr_ma5 > curr_ma20)\n",
        "\n",
        "            # æª¢æŸ¥åƒ¹æ ¼æ˜¯å¦ç«™ä¸Šå‡ç·š (åƒ¹æ ¼ > 5æ—¥å‡ç·š > 20æ—¥å‡ç·š)\n",
        "            current_price = df['Close'].iloc[-1]\n",
        "            ma_support = (current_price > curr_ma5) and (curr_ma5 > curr_ma20)\n",
        "\n",
        "            return {\n",
        "                'ma_crossover': ma_crossover,\n",
        "                'ma_support': ma_support,\n",
        "                'price_above_ma5': current_price > curr_ma5,\n",
        "                'price_above_ma20': current_price > curr_ma20\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥å‡ç·šäº¤å‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'ma_crossover': False, 'ma_support': False}\n",
        "\n",
        "    def calculate_strong_momentum_score(self, price_momentum: Dict, volume_surge: Dict, ma_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—å¼·å‹¢å‹•èƒ½åˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # åƒ¹æ ¼å‹•èƒ½åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            price_score = 0\n",
        "            if price_momentum.get('near_limit_up', False):\n",
        "                price_score = 30  # æ¥è¿‘æ¼²åœçµ¦äºˆé«˜åˆ†\n",
        "            elif price_momentum.get('strong_momentum', False):\n",
        "                price_score = 20  # å¼·å‹¢å‹•èƒ½çµ¦äºˆä¸­é«˜åˆ†\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_surge.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 2.5:\n",
        "                volume_score = 20  # çˆ†é‡\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_score = 15  # æ”¾é‡\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 10  # å°å¹…æ”¾é‡\n",
        "\n",
        "            # å‡ç·šåˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            ma_score = 0\n",
        "            if ma_analysis.get('ma_crossover', False):\n",
        "                ma_score = 15  # å‡ç·šäº¤å‰\n",
        "            elif ma_analysis.get('ma_support', False):\n",
        "                ma_score = 10  # å‡ç·šæ”¯æ’\n",
        "            elif ma_analysis.get('price_above_ma5', False):\n",
        "                ma_score = 5   # åƒ¹æ ¼ç«™ä¸Š5æ—¥å‡ç·š\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            weights = self.config['trend_weights']\n",
        "            total_score = base_score + (price_score * weights['price_trend']) + (volume_score * weights['volume_trend']) + (ma_score * weights['technical_score'])\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¼·å‹¢å‹•èƒ½åˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_momentum_label(self, price_momentum: Dict, volume_surge: Dict, ma_analysis: Dict, score: float) -> str:\n",
        "        \"\"\"ç”Ÿæˆå‹•èƒ½æ¨™ç±¤\"\"\"\n",
        "        try:\n",
        "            # æ ¹æ“šå„é …æŒ‡æ¨™ç”Ÿæˆæ¨™ç±¤\n",
        "            labels = []\n",
        "\n",
        "            # åƒ¹æ ¼å‹•èƒ½æ¨™ç±¤\n",
        "            if price_momentum.get('near_limit_up', False):\n",
        "                labels.append(\"æ¼²åœè‚¡\")\n",
        "            elif price_momentum.get('daily_return', 0) >= 7.0:\n",
        "                labels.append(\"å¼·æ¼²è‚¡\")\n",
        "            elif price_momentum.get('strong_momentum', False):\n",
        "                labels.append(\"æ¼²å‹¢è‚¡\")\n",
        "\n",
        "            # æˆäº¤é‡æ¨™ç±¤\n",
        "            if volume_surge.get('volume_ratio', 1.0) > 2.5:\n",
        "                labels.append(\"çˆ†é‡\")\n",
        "            elif volume_surge.get('volume_ratio', 1.0) > 1.5:\n",
        "                labels.append(\"æ”¾é‡\")\n",
        "\n",
        "            # å‡ç·šæ¨™ç±¤\n",
        "            if ma_analysis.get('ma_crossover', False):\n",
        "                labels.append(\"å‡ç·šäº¤å‰\")\n",
        "            elif ma_analysis.get('ma_support', False):\n",
        "                labels.append(\"å‡ç·šå¤šé ­\")\n",
        "\n",
        "            # å¦‚æœæ²’æœ‰ç‰¹å®šæ¨™ç±¤ï¼Œæ ¹æ“šåˆ†æ•¸çµ¦äºˆä¸€èˆ¬æ¨™ç±¤\n",
        "            if not labels:\n",
        "                if score >= 80:\n",
        "                    labels.append(\"å¼·å‹¢è‚¡\")\n",
        "                elif score >= 65:\n",
        "                    labels.append(\"ç†±é–€è‚¡\")\n",
        "                elif score >= 50:\n",
        "                    labels.append(\"æ´»èºè‚¡\")\n",
        "\n",
        "            # è¿”å›æœ€å¤šå…©å€‹æ¨™ç±¤\n",
        "            return \" + \".join(labels[:2]) if labels else \"ä¸€èˆ¬è‚¡\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‹•èƒ½æ¨™ç±¤æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return \"ä¸€èˆ¬è‚¡\"\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "        stock_id = stock_info['stock_id']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol, period=\"1mo\")\n",
        "            if df is None or df.empty or len(df) < 5:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_id': stock_id,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡çªå¢\n",
        "            volume_surge = self.check_volume_surge(df_with_indicators)\n",
        "\n",
        "            # æª¢æŸ¥åƒ¹æ ¼å‹•èƒ½\n",
        "            price_momentum = self.check_price_momentum(df_with_indicators)\n",
        "\n",
        "            # æª¢æŸ¥å‡ç·šäº¤å‰\n",
        "            ma_analysis = self.check_ma_crossover(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—å¼·å‹¢å‹•èƒ½åˆ†æ•¸\n",
        "            momentum_score = self.calculate_strong_momentum_score(price_momentum, volume_surge, ma_analysis)\n",
        "\n",
        "            # ç”Ÿæˆå‹•èƒ½æ¨™ç±¤\n",
        "            momentum_label = self.generate_momentum_label(price_momentum, volume_surge, ma_analysis, momentum_score)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            daily_return = price_momentum.get('daily_return', 0)\n",
        "            five_day_return = price_momentum.get('5d_return', 0)\n",
        "\n",
        "            # ç²å–æˆäº¤é‡è³‡è¨Š (è½‰æ›ç‚ºå¼µæ•¸)\n",
        "            current_volume = float(df['Volume'].iloc[-1]) if 'Volume' in df.columns else 0\n",
        "            volume_lots = current_volume / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_id': stock_id,\n",
        "                'stock_name': stock_name,\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'daily_return': daily_return,\n",
        "                '5d_return': five_day_return,\n",
        "                'volume_lots': volume_lots,\n",
        "                'volume_ratio': volume_surge.get('volume_ratio', 1.0),\n",
        "                'momentum_score': momentum_score,\n",
        "                'momentum_label': momentum_label,\n",
        "                'price_momentum': price_momentum,\n",
        "                'volume_surge': volume_surge,\n",
        "                'ma_analysis': ma_analysis,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {momentum_score:.1f} - æ¨™ç±¤: {momentum_label} - æ—¥æ¼²å¹…: {daily_return:.2f}%\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_id': stock_id,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "def format_momentum_stocks_message(results: Dict[str, Any], limit: int = 15) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–å¼·å‹¢è‚¡åˆ†æçµæœç‚ºè¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰å‹•èƒ½åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('momentum_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        # å…ˆæŒ‰æ—¥æ¼²å¹…æ’åº\n",
        "        successful_results.sort(key=lambda x: x.get('daily_return', 0), reverse=True)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        total_analyzed = len(results)\n",
        "        successful_count = len(successful_results)\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message_parts = []\n",
        "        message_parts.append(\"ğŸš€ å°è‚¡å¼·å‹¢è‚¡åˆ†æ\")\n",
        "        message_parts.append(\"=\" * 40)\n",
        "        message_parts.append(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        message_parts.append(f\"ğŸ“Š æˆåŠŸåˆ†æ: {successful_count} æ”¯è‚¡ç¥¨\")\n",
        "        message_parts.append(\"\")\n",
        "\n",
        "        if not successful_results:\n",
        "            message_parts.append(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢è‚¡\")\n",
        "            return \"\\n\".join(message_parts)\n",
        "\n",
        "        # é¡¯ç¤ºæ¼²å¹…å‰Nåçš„å¼·å‹¢è‚¡\n",
        "        top_stocks = successful_results[:limit]\n",
        "        message_parts.append(f\"ğŸ”¥ ä»Šæ—¥å¼·å‹¢è‚¡ TOP {len(top_stocks)}:\")\n",
        "        message_parts.append(\"-\" * 40)\n",
        "\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            daily_return = result.get('daily_return', 0)\n",
        "            five_day_return = result.get('5d_return', 0)\n",
        "            momentum_score = result.get('momentum_score', 0)\n",
        "            momentum_label = result.get('momentum_label', 'ä¸€èˆ¬è‚¡')\n",
        "            current_price = result.get('current_price', 0)\n",
        "            volume_lots = result.get('volume_lots', 0)\n",
        "            volume_ratio = result.get('volume_ratio', 1.0)\n",
        "\n",
        "            # æ¼²å¹…ç¬¦è™Ÿ\n",
        "            change_symbol = \"ğŸ”´\" if daily_return > 0 else \"ğŸ”µ\" if daily_return < 0 else \"âšª\"\n",
        "\n",
        "            # æˆäº¤é‡ç¬¦è™Ÿ\n",
        "            volume_symbol = \"ğŸ’¥\" if volume_ratio > 2.5 else \"ğŸ“ˆ\" if volume_ratio > 1.5 else \"ğŸ“Š\"\n",
        "\n",
        "            message_parts.append(f\"{i}. {stock_name} ({stock_id}) - {momentum_label}\")\n",
        "            message_parts.append(f\"   {change_symbol} æ¼²å¹…: {daily_return:+.2f}% | 5æ—¥: {five_day_return:+.2f}%\")\n",
        "            message_parts.append(f\"   ğŸ’° åƒ¹æ ¼: {current_price:.2f} | {volume_symbol} æˆäº¤é‡: {volume_lots:.0f}å¼µ (x{volume_ratio:.1f})\")\n",
        "            message_parts.append(f\"   â­ å‹•èƒ½è©•åˆ†: {momentum_score:.1f}/100\")\n",
        "            message_parts.append(\"\")\n",
        "\n",
        "        # æ·»åŠ æ¼²åœè‚¡çµ±è¨ˆ\n",
        "        limit_up_stocks = [r for r in successful_results if r.get('daily_return', 0) >= 9.5]\n",
        "        strong_up_stocks = [r for r in successful_results if 7.0 <= r.get('daily_return', 0) < 9.5]\n",
        "\n",
        "        message_parts.append(\"ğŸ“Š å¸‚å ´å¼·å‹¢è‚¡çµ±è¨ˆ:\")\n",
        "        message_parts.append(f\"   ğŸ”¥ æ¼²åœè‚¡æ•¸: {len(limit_up_stocks)} æ”¯\")\n",
        "        message_parts.append(f\"   ğŸ“ˆ å¼·æ¼²è‚¡æ•¸ (7-9.5%): {len(strong_up_stocks)} æ”¯\")\n",
        "\n",
        "        # æ·»åŠ ç”¢æ¥­åˆ†å¸ƒ\n",
        "        industry_counts = {}\n",
        "        for result in limit_up_stocks + strong_up_stocks:\n",
        "            industry = result.get('industry', 'å…¶ä»–')\n",
        "            industry_counts[industry] = industry_counts.get(industry, 0) + 1\n",
        "\n",
        "        if industry_counts:\n",
        "            message_parts.append(\"   ğŸ­ å¼·å‹¢ç”¢æ¥­åˆ†å¸ƒ:\")\n",
        "            for industry, count in sorted(industry_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "                message_parts.append(f\"      {industry}: {count} æ”¯\")\n",
        "\n",
        "        message_parts.append(\"\")\n",
        "        message_parts.append(\"âš ï¸ æŠ•è³‡æé†’:\")\n",
        "        message_parts.append(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\")\n",
        "        message_parts.append(\"â€¢ å¼·å‹¢è‚¡å¸¸æœ‰å¤§å¹…æ³¢å‹•ï¼Œè«‹è¬¹æ…äº¤æ˜“\")\n",
        "        message_parts.append(\"â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æ±ºç­–\")\n",
        "\n",
        "        return \"\\n\".join(message_parts)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 15):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰å‹•èƒ½åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('momentum_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        # å…ˆæŒ‰æ—¥æ¼²å¹…æ’åº\n",
        "        successful_results.sort(key=lambda x: x.get('daily_return', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸš€ å°è‚¡å¼·å‹¢è‚¡åˆ†æçµæœ\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å¼·å‹¢è‚¡\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'æ¼²å¹…%':<8}{'5æ—¥%':<8}{'åƒ¹æ ¼':<10}{'æˆäº¤é‡(å¼µ)':<12}{'é‡æ¯”':<6}{'å‹•èƒ½è©•åˆ†':<8}{'æ¨™ç±¤':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰Nå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            daily_return = result.get('daily_return', 0)\n",
        "            five_day_return = result.get('5d_return', 0)\n",
        "            momentum_score = result.get('momentum_score', 0)\n",
        "            momentum_label = result.get('momentum_label', 'ä¸€èˆ¬è‚¡')[:10]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            volume_lots = result.get('volume_lots', 0)\n",
        "            volume_ratio = result.get('volume_ratio', 1.0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{daily_return:<+8.2f}{five_day_return:<+8.2f}{current_price:<10.2f}{volume_lots:<12.0f}{volume_ratio:<6.1f}{momentum_score:<8.1f}{momentum_label:<12}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # çµ±è¨ˆè³‡è¨Š\n",
        "        limit_up_stocks = [r for r in successful_results if r.get('daily_return', 0) >= 9.5]\n",
        "        strong_up_stocks = [r for r in successful_results if 7.0 <= r.get('daily_return', 0) < 9.5]\n",
        "\n",
        "        print(f\"\\nğŸ“Š å¸‚å ´å¼·å‹¢è‚¡çµ±è¨ˆ:\")\n",
        "        print(f\"   ğŸ”¥ æ¼²åœè‚¡æ•¸: {len(limit_up_stocks)} æ”¯\")\n",
        "        print(f\"   ğŸ“ˆ å¼·æ¼²è‚¡æ•¸ (7-9.5%): {len(strong_up_stocks)} æ”¯\")\n",
        "\n",
        "        # ç”¢æ¥­åˆ†å¸ƒ\n",
        "        industry_counts = {}\n",
        "        for result in limit_up_stocks + strong_up_stocks:\n",
        "            industry = result.get('industry', 'å…¶ä»–')\n",
        "            industry_counts[industry] = industry_counts.get(industry, 0) + 1\n",
        "\n",
        "        if industry_counts:\n",
        "            print(\"   ğŸ­ å¼·å‹¢ç”¢æ¥­åˆ†å¸ƒ:\")\n",
        "            for industry, count in sorted(industry_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "                print(f\"      {industry}: {count} æ”¯\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å¼·å‹¢è‚¡å¸¸æœ‰å¤§å¹…æ³¢å‹•ï¼Œè«‹è¬¹æ…äº¤æ˜“\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # å¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆï¼Œå˜—è©¦å¾é è¨­ç›®éŒ„ç²å–\n",
        "    if not files:\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        if os.path.exists(chart_dir):\n",
        "            # ç²å–ç›®éŒ„ä¸­çš„æ‰€æœ‰ PNG æª”æ¡ˆ\n",
        "            files = [os.path.join(chart_dir, f) for f in os.listdir(chart_dir)\n",
        "                    if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            if files:\n",
        "                logger.info(f\"æ‰¾åˆ° {len(files)} å€‹åœ–è¡¨æª”æ¡ˆåœ¨ {chart_dir}\")\n",
        "            else:\n",
        "                logger.warning(f\"åœ¨ {chart_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• PNG æª”æ¡ˆ\")\n",
        "\n",
        "    # Telegram\n",
        "    try:\n",
        "        # éæ­·æ‰€æœ‰ Telegram Chat ID\n",
        "        for chat_id in TELEGRAM_CHAT_ID:\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯\n",
        "            url_msg = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "            payload = {\"chat_id\": chat_id, \"text\": message, \"parse_mode\": \"Markdown\"}\n",
        "            async with session.post(url_msg, json=payload, timeout=20) as response:\n",
        "                if response.status == 200:\n",
        "                    logger.info(f\"Telegram æ‘˜è¦å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id}ã€‚\")\n",
        "                else:\n",
        "                    response_text = await response.text()\n",
        "                    logger.error(f\"Telegram æ‘˜è¦ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "            # å¦‚æœæœ‰æª”æ¡ˆï¼Œä¹Ÿéæ­·ç™¼é€\n",
        "            if files:\n",
        "                url_photo = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                sent_count = 0\n",
        "                for file_path in files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            data = aiohttp.FormData()\n",
        "                            data.add_field('chat_id', str(chat_id))  # ç¢ºä¿ chat_id æ˜¯å­—ä¸²\n",
        "                            # æ·»åŠ å¯é¸çš„åœ–ç‰‡èªªæ˜\n",
        "                            caption = os.path.basename(file_path).replace('_report.png', '').replace('_', ' ')\n",
        "                            data.add_field('caption', caption)\n",
        "\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                data.add_field('photo', f, filename=os.path.basename(file_path))\n",
        "                                async with session.post(url_photo, data=data, timeout=60) as response:\n",
        "                                    if response.status == 200:\n",
        "                                        sent_count += 1\n",
        "                                    else:\n",
        "                                        response_text = await response.text()\n",
        "                                        logger.error(f\"Telegram åœ–æª”ç™¼é€å¤±æ•—: {response.status} - {response_text}\")\n",
        "\n",
        "                            # æ·»åŠ å°å»¶é²ä»¥é¿å… Telegram API é™åˆ¶\n",
        "                            await asyncio.sleep(0.5)\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"ç™¼é€æª”æ¡ˆ {file_path} æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                logger.info(f\"Telegram åœ–æª”å·²æˆåŠŸç™¼é€åˆ° chat_id: {chat_id} ({sent_count}/{len(files)}å€‹)ã€‚\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Discord\n",
        "    try:\n",
        "        # å°‡è¨Šæ¯åˆ†æ®µç™¼é€ï¼Œé¿å…è¶…é Discord çš„é™åˆ¶\n",
        "        message_chunks = [message[i:i+1900] for i in range(0, len(message), 1900)]\n",
        "\n",
        "        for chunk in message_chunks:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{chunk}\\n```\")\n",
        "            response = webhook.execute()\n",
        "            if response and response.ok:\n",
        "                logger.info(\"Discord æ–‡å­—é€šçŸ¥ç™¼é€æˆåŠŸã€‚\")\n",
        "            else:\n",
        "                status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                content = response.content if response else \"æœªçŸ¥\"\n",
        "                logger.error(f\"Discord æ–‡å­—é€šçŸ¥å¤±æ•—: {status_code} {content}\")\n",
        "\n",
        "        # åˆ†æ‰¹ç™¼é€æª”æ¡ˆï¼Œæ¯æ‰¹æœ€å¤š 10 å€‹æª”æ¡ˆ\n",
        "        if files:\n",
        "            batch_size = 10\n",
        "            for i in range(0, len(files), batch_size):\n",
        "                batch_files = files[i:i+batch_size]\n",
        "                webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"åœ–è¡¨æ‰¹æ¬¡ {i//batch_size + 1}/{(len(files)-1)//batch_size + 1}\")\n",
        "\n",
        "                for file_path in batch_files:\n",
        "                    if os.path.exists(file_path):\n",
        "                        try:\n",
        "                            with open(file_path, 'rb') as f:\n",
        "                                webhook.add_file(file=f.read(), filename=os.path.basename(file_path))\n",
        "                        except Exception as file_error:\n",
        "                            logger.error(f\"æ·»åŠ æª”æ¡ˆ {file_path} åˆ° Discord webhook æ™‚å‡ºéŒ¯: {file_error}\")\n",
        "\n",
        "                response = webhook.execute()\n",
        "                if response and response.ok:\n",
        "                    logger.info(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€æˆåŠŸã€‚\")\n",
        "                else:\n",
        "                    status_code = response.status_code if response else \"æœªçŸ¥\"\n",
        "                    content = response.content if response else \"æœªçŸ¥\"\n",
        "                    logger.error(f\"Discord åœ–æª”æ‰¹æ¬¡ {i//batch_size + 1} ç™¼é€å¤±æ•—: {status_code} {content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def format_notification_message(filtered_results: Dict) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        current_time = datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        if not filtered_results:\n",
        "            return f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "\n",
        "âŒ æœ¬æ¬¡åˆ†ææœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ’¡ å»ºè­°èª¿æ•´ç¯©é¸æ¢ä»¶æˆ–é—œæ³¨å¸‚å ´è®ŠåŒ–\n",
        "\"\"\"\n",
        "\n",
        "        # ç²å–åœ–è¡¨æª”æ¡ˆæ•¸é‡\n",
        "        chart_dir = \"/content/results/charts/\"\n",
        "        chart_count = 0\n",
        "        if os.path.exists(chart_dir):\n",
        "            chart_files = [f for f in os.listdir(chart_dir) if f.endswith('.png') and os.path.isfile(os.path.join(chart_dir, f))]\n",
        "            chart_count = len(chart_files)\n",
        "\n",
        "        message = f\"\"\"\n",
        "ğŸ¤– å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\n",
        "ğŸ“… åˆ†ææ™‚é–“: {current_time}\n",
        "ğŸ¯ æ‰¾åˆ° {len(filtered_results)} æ”¯å„ªè³ªè‚¡ç¥¨\n",
        "ğŸ“Š ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ“ˆ TOP {min(5, len(filtered_results))} æ¨è–¦è‚¡ç¥¨:\n",
        "\"\"\"\n",
        "\n",
        "        for rank, (stock_id, result) in enumerate(list(filtered_results.items())[:5], 1):\n",
        "            trend = result.get('trend_analysis', {})\n",
        "            tech = result.get('technical_analysis', {})\n",
        "            recommendation = result.get('recommendation', {})\n",
        "\n",
        "            # ç²å–æ›´å¤šæŠ€è¡“æŒ‡æ¨™æ•¸æ“š\n",
        "            macd = tech.get('macd_value', 0)\n",
        "            signal = tech.get('signal_value', 0)\n",
        "            macd_status = \"å¤šé ­\" if macd > signal else \"ç©ºé ­\" if macd < signal else \"ä¸­æ€§\"\n",
        "\n",
        "            message += f\"\"\"\n",
        "{rank}. {result.get('stock_name', '')} ({stock_id})\n",
        "   ğŸ’° åƒ¹æ ¼: {result.get('current_price', 0):.2f} TWD\n",
        "   ğŸ“ˆ è©•åˆ†: {result.get('combined_score', 0):.1f}/100\n",
        "   ğŸ¯ å»ºè­°: {recommendation.get('action', 'è§€æœ›')}\n",
        "   ğŸ“Š è¶¨å‹¢: {trend.get('trend', 'ç›¤æ•´')}\n",
        "   ğŸ” RSI: {tech.get('rsi_value', 50):.1f} ({tech.get('rsi_status', 'ä¸­æ€§')})\n",
        "   ğŸ“‰ MACD: {macd_status}\n",
        "\"\"\"\n",
        "\n",
        "        # æ·»åŠ åœ–è¡¨è³‡è¨Š\n",
        "        if chart_count > 0:\n",
        "            message += f\"\"\"\n",
        "ğŸ“Š è©³ç´°åˆ†æåœ–è¡¨:\n",
        "â€¢ å·²ç”Ÿæˆ {chart_count} å¼µæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "â€¢ åœ–è¡¨åŒ…å«Kç·šã€å‡ç·šã€æˆäº¤é‡ã€MACDåŠRSIæŒ‡æ¨™\n",
        "â€¢ åœ–è¡¨å°‡åœ¨æ­¤è¨Šæ¯å¾Œç™¼é€\n",
        "\"\"\"\n",
        "\n",
        "        message += f\"\"\"\n",
        "âš ï¸  æŠ•è³‡æé†’:\n",
        "â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶\n",
        "\"\"\"\n",
        "\n",
        "        return message.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return f\"å°è‚¡åˆ†æå®Œæˆï¼Œä½†è¨Šæ¯æ ¼å¼åŒ–å¤±æ•—: {str(e)}\"\n",
        "\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ å°è‚¡å¼·å‹¢è‚¡åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†æç›®æ¨™: å°‹æ‰¾å¸‚å ´å¼·å‹¢è‚¡\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StrongMomentumStockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=15)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_momentum_stocks_message(results, limit=15)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆ\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # åŸ·è¡Œä¸»ç¨‹å¼\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCbUcnP8rm87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ar0GtM0XrsGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLyj04YtrwNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aGW55prbShh"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from typing import Dict, List, Any, Optional\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from io import StringIO\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "# è™•ç†ä¸­æ–‡å­—é«”å’Œè­¦å‘Š\n",
        "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Jupyter Notebook æ”¯æ´\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "# é€šçŸ¥è¨­å®š (è«‹æ ¹æ“šéœ€è¦ä¿®æ”¹)\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]  # æ”¯æ´å¤šç”¨æˆ¶é€šçŸ¥\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "# å˜—è©¦å°å…¥é€šçŸ¥ç›¸é—œæ¨¡çµ„\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "class StockAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–è‚¡ç¥¨åˆ†æå™¨\"\"\"\n",
        "        self.config = {\n",
        "            'rsi_period': 14,\n",
        "            'macd_fast': 12,\n",
        "            'macd_slow': 26,\n",
        "            'macd_signal': 9,\n",
        "            'bb_period': 20,\n",
        "            'bb_std': 2,\n",
        "            'kd_period': 14,\n",
        "            'volume_ma_period': 20,\n",
        "            'min_volume_lots': 1000,  # æœ€å°æˆäº¤é‡ï¼ˆå¼µï¼‰\n",
        "            'screen_conditions': {\n",
        "                'min_price_change': 5.0,      # æœ€å°æ¼²å¹…5%\n",
        "                'min_volume_lots': 5000,      # æœ€å°æˆäº¤é‡5000å¼µ\n",
        "                'max_volume_ratio': 3.0,      # æœ€å¤§æˆäº¤é‡æ¯”ç‡3å€\n",
        "                'macd_diff_min': 0.0,         # MACDå·®å€¼æœ€å°å€¼\n",
        "                'macd_diff_max': 1.5,         # MACDå·®å€¼æœ€å¤§å€¼\n",
        "            },\n",
        "            'trend_weights': {\n",
        "                'price_trend': 0.3,\n",
        "                'volume_trend': 0.2,\n",
        "                'technical_score': 0.5\n",
        "            }\n",
        "        }\n",
        "        self.taiwan_stocks = None\n",
        "        self.stock_list_path = \"taiwan_stocks_cache.csv\"\n",
        "\n",
        "    def get_taiwan_stocks(self, force_update=True):\n",
        "        \"\"\"ç²å–å°ç£è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        if not force_update and os.path.exists(self.stock_list_path):\n",
        "            if (time.time() - os.path.getmtime(self.stock_list_path)) < 86400:\n",
        "                logger.info(\"å¾å¿«å–è¼‰å…¥è‚¡ç¥¨åˆ—è¡¨ã€‚\")\n",
        "                return pd.read_csv(self.stock_list_path, dtype={'stock_id': str})\n",
        "\n",
        "        logger.info(\"å¾å°ç£è­‰äº¤æ‰€ç¶²ç«™ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...\")\n",
        "        urls = {\n",
        "            \"ä¸Šå¸‚\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
        "            \"ä¸Šæ«ƒ\": \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
        "        }\n",
        "        all_stocks_df = []\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        for market_name, url in urls.items():\n",
        "            try:\n",
        "                res = requests.get(url, headers=headers, timeout=30)\n",
        "                res.encoding = 'big5'\n",
        "                html_dfs = pd.read_html(StringIO(res.text))\n",
        "                df = html_dfs[0].copy()\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df.iloc[1:].copy()\n",
        "                df.loc[:, 'market'] = market_name\n",
        "                all_stocks_df.append(df)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"ç²å– {market_name} è‚¡ç¥¨åˆ—è¡¨å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not all_stocks_df:\n",
        "            logger.error(\"ç„¡æ³•å¾ç¶²ç«™ç²å–ä»»ä½•è‚¡ç¥¨æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®ã€‚\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "        try:\n",
        "            df = pd.concat(all_stocks_df, ignore_index=True)\n",
        "            df[['stock_id', 'stock_name']] = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split(r'\\s+', n=1, expand=True)\n",
        "            df = df[df['stock_id'].str.match(r'^\\d{4}$', na=False)].copy()\n",
        "            exclude = ['ETF', 'ETN', 'TDR', 'å—ç›Š', 'æŒ‡æ•¸', 'è³¼', 'ç‰›', 'ç†Š', 'å­˜è¨—æ†‘è­‰']\n",
        "            df = df[~df['stock_name'].str.contains('|'.join(exclude), na=False)].copy()\n",
        "\n",
        "            df.loc[:, 'yahoo_symbol'] = df.apply(\n",
        "                lambda row: f\"{row['stock_id']}.TW\" if 'ä¸Šå¸‚' in row['market'] else f\"{row['stock_id']}.TWO\", axis=1)\n",
        "\n",
        "            final_df = df[['stock_id', 'stock_name', 'market', 'ç”¢æ¥­åˆ¥', 'yahoo_symbol']].rename(columns={'ç”¢æ¥­åˆ¥': 'industry'})\n",
        "            final_df = final_df.drop_duplicates(subset=['stock_id']).reset_index(drop=True)\n",
        "            final_df.to_csv(self.stock_list_path, index=False)\n",
        "            logger.info(f\"æˆåŠŸç²å– {len(final_df)} æ”¯è‚¡ç¥¨æ¸…å–®ä¸¦ä¿å­˜å¿«å–ã€‚\")\n",
        "            return final_df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è™•ç†è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return self._get_backup_stock_list()\n",
        "\n",
        "    def _get_backup_stock_list(self) -> pd.DataFrame:\n",
        "        \"\"\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®\"\"\"\n",
        "        try:\n",
        "            logger.info(\"ä½¿ç”¨å‚™ç”¨è‚¡ç¥¨æ¸…å–®\")\n",
        "            famous_stocks = [\n",
        "                {'stock_id': '2330', 'stock_name': 'å°ç©é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2330.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2317', 'stock_name': 'é´»æµ·', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2317.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2454.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2881.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2882.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2412', 'stock_name': 'ä¸­è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2412.TW', 'industry': 'é€šä¿¡'},\n",
        "                {'stock_id': '1301', 'stock_name': 'å°å¡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1301.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '1303', 'stock_name': 'å—äº', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '1303.TW', 'industry': 'å¡‘è† '},\n",
        "                {'stock_id': '2308', 'stock_name': 'å°é”é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2308.TW', 'industry': 'é›»å­'},\n",
        "                {'stock_id': '2303', 'stock_name': 'è¯é›»', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2303.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2002', 'stock_name': 'ä¸­é‹¼', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2002.TW', 'industry': 'é‹¼éµ'},\n",
        "                {'stock_id': '2886', 'stock_name': 'å…†è±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2886.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2891.TW', 'industry': 'é‡‘è'},\n",
        "                {'stock_id': '3008', 'stock_name': 'å¤§ç«‹å…‰', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3008.TW', 'industry': 'å…‰å­¸'},\n",
        "                {'stock_id': '2357', 'stock_name': 'è¯ç¢©', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2357.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2382', 'stock_name': 'å»£é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2382.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '2395', 'stock_name': 'ç ”è¯', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2395.TW', 'industry': 'é›»è…¦'},\n",
        "                {'stock_id': '3711', 'stock_name': 'æ—¥æœˆå…‰æŠ•æ§', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '3711.TW', 'industry': 'åŠå°é«”'},\n",
        "                {'stock_id': '2409', 'stock_name': 'å‹é”', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2409.TW', 'industry': 'é¢æ¿'},\n",
        "                {'stock_id': '2884', 'stock_name': 'ç‰å±±é‡‘', 'market': 'ä¸Šå¸‚', 'yahoo_symbol': '2884.TW', 'industry': 'é‡‘è'},\n",
        "            ]\n",
        "            df = pd.DataFrame(famous_stocks)\n",
        "            logger.info(f\"å‚™ç”¨è‚¡ç¥¨æ¸…å–®åŒ…å« {len(df)} æ”¯è‚¡ç¥¨\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”Ÿæˆå‚™ç”¨è‚¡ç¥¨æ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def check_volume_filter(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æˆäº¤é‡æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶ï¼ˆæ¯æ—¥è‡³å°‘1000å¼µï¼‰\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns:\n",
        "                return False\n",
        "            recent_volume = df['Volume'].tail(20).mean()\n",
        "            volume_lots = recent_volume / 1000\n",
        "            meets_volume = volume_lots >= self.config['min_volume_lots']\n",
        "            return meets_volume\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return False\n",
        "\n",
        "    def fetch_yfinance_data(self, stock_id: str, period: str = \"1y\", interval: str = \"1d\", retries: int = 3):\n",
        "        \"\"\"ç²å–è‚¡ç¥¨æ•¸æ“šï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰\"\"\"\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                df = yf.download(tickers=stock_id, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "                if df.empty:\n",
        "                    logger.warning(f\"[{stock_id}] ç„¡æ•¸æ“šè¿”å›\")\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "                required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "                for col in required_cols:\n",
        "                    if col in df.columns:\n",
        "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df = df.dropna(subset=required_cols)\n",
        "                return df.reset_index()\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = 0.5 * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    logger.warning(f\"[{stock_id}] ç¬¬ {attempt + 1}/{retries} æ¬¡å˜—è©¦å¤±æ•—: {e}ã€‚ç­‰å¾… {sleep_time:.2f} ç§’å¾Œé‡è©¦...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    logger.error(f\"[{stock_id}] ç²å–æ•¸æ“šå¤±æ•—ã€‚\")\n",
        "                    return pd.DataFrame()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # åŸºç¤æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å‡½æ•¸\n",
        "    def calculate_sma(self, data, period):\n",
        "        \"\"\"è¨ˆç®—SMA (ç°¡å–®ç§»å‹•å¹³å‡ç·š)\"\"\"\n",
        "        return data.rolling(window=period).mean()\n",
        "\n",
        "    def calculate_ema(self, data, period):\n",
        "        \"\"\"è¨ˆç®—EMA (æŒ‡æ•¸ç§»å‹•å¹³å‡ç·š)\"\"\"\n",
        "        return data.ewm(span=period, adjust=False).mean()\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = None) -> pd.Series:\n",
        "        \"\"\"è¨ˆç®—RSI\"\"\"\n",
        "        try:\n",
        "            if period is None:\n",
        "                period = self.config['rsi_period']\n",
        "            delta = prices.diff()\n",
        "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "            rs = gain / loss\n",
        "            rsi = 100 - (100 / (1 + rs))\n",
        "            return rsi\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—RSIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return pd.Series(index=prices.index, data=50)\n",
        "\n",
        "    def calculate_macd(self, prices: pd.Series, fast: int = None, slow: int = None, signal: int = None):\n",
        "        \"\"\"è¨ˆç®—MACD\"\"\"\n",
        "        try:\n",
        "            if fast is None:\n",
        "                fast = self.config['macd_fast']\n",
        "            if slow is None:\n",
        "                slow = self.config['macd_slow']\n",
        "            if signal is None:\n",
        "                signal = self.config['macd_signal']\n",
        "\n",
        "            ema_fast = self.calculate_ema(prices, fast)\n",
        "            ema_slow = self.calculate_ema(prices, slow)\n",
        "            macd_line = ema_fast - ema_slow\n",
        "            macd_signal = self.calculate_ema(macd_line, signal)\n",
        "            macd_histogram = macd_line - macd_signal\n",
        "            return macd_line, macd_signal, macd_histogram\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—MACDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_stoch(self, high, low, close, k_period=None, d_period=3):\n",
        "        \"\"\"è¨ˆç®—KDæŒ‡æ¨™\"\"\"\n",
        "        try:\n",
        "            if k_period is None:\n",
        "                k_period = self.config['kd_period']\n",
        "\n",
        "            # è¨ˆç®—%K\n",
        "            lowest_low = low.rolling(window=k_period).min()\n",
        "            highest_high = high.rolling(window=k_period).max()\n",
        "\n",
        "            # é˜²æ­¢é™¤ä»¥é›¶\n",
        "            denom = highest_high - lowest_low\n",
        "            denom = denom.replace(0, 0.000001)\n",
        "\n",
        "            k = 100 * ((close - lowest_low) / denom)\n",
        "            # è¨ˆç®—%D (Kçš„ç§»å‹•å¹³å‡)\n",
        "            d = k.rolling(window=d_period).mean()\n",
        "            return k, d\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—KDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            fifty_series = pd.Series(index=high.index, data=50)\n",
        "            return fifty_series, fifty_series\n",
        "\n",
        "    def calculate_bollinger_bands(self, prices: pd.Series, period: int = None, std_dev: int = None):\n",
        "        \"\"\"è¨ˆç®—å¸ƒæ—å¸¶\"\"\"\n",
        "        try:\n",
        "            if period is None:\n",
        "                period = self.config['bb_period']\n",
        "            if std_dev is None:\n",
        "                std_dev = self.config['bb_std']\n",
        "\n",
        "            middle = prices.rolling(window=period).mean()\n",
        "            std = prices.rolling(window=period).std()\n",
        "            upper = middle + (std * std_dev)\n",
        "            lower = middle - (std * std_dev)\n",
        "            return upper, middle, lower\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—å¸ƒæ—å¸¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            zero_series = pd.Series(index=prices.index, data=0)\n",
        "            return zero_series, zero_series, zero_series\n",
        "\n",
        "    def calculate_indicators(self, data):\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ï¼ˆæ•´åˆç‰ˆï¼‰\"\"\"\n",
        "        if data is None or len(data) < 30:\n",
        "            return None\n",
        "\n",
        "        # è¤‡è£½æ•¸æ“šä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š\n",
        "        df = data.copy()\n",
        "\n",
        "        try:\n",
        "            # è¨ˆç®—MACD\n",
        "            df['MACD'], df['MACD_Signal'], df['MACD_Hist'] = self.calculate_macd(df['Close'])\n",
        "\n",
        "            # è¨ˆç®—å‡ç·š\n",
        "            df['MA5'] = self.calculate_sma(df['Close'], 5)\n",
        "            df['MA10'] = self.calculate_sma(df['Close'], 10)\n",
        "            df['MA20'] = self.calculate_sma(df['Close'], 20)\n",
        "            df['MA30'] = self.calculate_sma(df['Close'], 30)\n",
        "\n",
        "            # è¨ˆç®—RSI\n",
        "            df['RSI'] = self.calculate_rsi(df['Close'])\n",
        "\n",
        "            # è¨ˆç®—KD\n",
        "            df['K'], df['D'] = self.calculate_stoch(df['High'], df['Low'], df['Close'])\n",
        "            df['K_Percent'] = df['K']  # ä¿æŒä¸€è‡´æ€§\n",
        "            df['D_Percent'] = df['D']  # ä¿æŒä¸€è‡´æ€§\n",
        "\n",
        "            # è¨ˆç®—å¸ƒæ—å¸¶\n",
        "            bb_upper, bb_middle, bb_lower = self.calculate_bollinger_bands(df['Close'])\n",
        "            df['BB_Upper'] = bb_upper\n",
        "            df['BB_Middle'] = bb_middle\n",
        "            df['BB_Lower'] = bb_lower\n",
        "\n",
        "            # è¨ˆç®—æ¼²å¹…\n",
        "            df['Change'] = df['Close'].pct_change() * 100\n",
        "\n",
        "            # è¨ˆç®—æˆäº¤é‡å‡ç·š\n",
        "            if 'Volume' in df.columns:\n",
        "                df['Volume_MA'] = df['Volume'].rolling(window=self.config['volume_ma_period']).mean()\n",
        "                df['Volume_MA30'] = self.calculate_sma(df['Volume'], 30)\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ï¼ˆèˆ‡calculate_indicatorsä¿æŒä¸€è‡´ï¼‰\"\"\"\n",
        "        return self.calculate_indicators(df)\n",
        "\n",
        "    def perform_quadrant_analysis(self, data):\n",
        "        \"\"\"å››è±¡é™åˆ†æ\"\"\"\n",
        "        if data is None or len(data) < 30:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # ç²å–æœ€æ–°æ•¸æ“š\n",
        "            latest = data.iloc[-1]\n",
        "\n",
        "            # å››è±¡é™åˆ¤æ–·\n",
        "            macd_above_signal = latest['MACD'] > latest['MACD_Signal']\n",
        "            macd_rising = data['MACD'].iloc[-1] > data['MACD'].iloc[-2] if len(data) >= 2 else False\n",
        "\n",
        "            rsi_above_50 = latest['RSI'] > 50\n",
        "            rsi_rising = data['RSI'].iloc[-1] > data['RSI'].iloc[-2] if len(data) >= 2 else False\n",
        "\n",
        "            # åˆ¤æ–·è±¡é™\n",
        "            if macd_above_signal and rsi_above_50:\n",
        "                quadrant = 1  # å¼·å‹¢å¤šé ­\n",
        "            elif not macd_above_signal and rsi_above_50:\n",
        "                quadrant = 2  # å¤šé ­è­¦æˆ’\n",
        "            elif not macd_above_signal and not rsi_above_50:\n",
        "                quadrant = 3  # å¼·å‹¢ç©ºé ­\n",
        "            else:  # macd_above_signal and not rsi_above_50\n",
        "                quadrant = 4  # ç©ºé ­åè½‰\n",
        "\n",
        "            # è¶¨å‹¢æ–¹å‘\n",
        "            if macd_rising and rsi_rising:\n",
        "                trend = \"ä¸Šå‡\"\n",
        "            elif not macd_rising and not rsi_rising:\n",
        "                trend = \"ä¸‹é™\"\n",
        "            else:\n",
        "                trend = \"ç›¤æ•´\"\n",
        "\n",
        "            # è¿”å›åˆ†æçµæœ\n",
        "            return {\n",
        "                'quadrant': quadrant,\n",
        "                'trend': trend,\n",
        "                'macd_above_signal': macd_above_signal,\n",
        "                'macd_rising': macd_rising,\n",
        "                'rsi_above_50': rsi_above_50,\n",
        "                'rsi_rising': rsi_rising,\n",
        "                'macd': latest['MACD'],\n",
        "                'macd_signal': latest['MACD_Signal'],\n",
        "                'macd_hist': latest['MACD_Hist'],\n",
        "                'rsi': latest['RSI'],\n",
        "                'k': latest['K'],\n",
        "                'd': latest['D']\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å››è±¡é™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_resample_frequency(self, freq_type: str) -> str:\n",
        "        \"\"\"ç²å–é©ç•¶çš„é‡æ¡æ¨£é »ç‡å­—ç¬¦ä¸²\"\"\"\n",
        "        try:\n",
        "            import pandas as pd\n",
        "\n",
        "            # æª¢æŸ¥ pandas ç‰ˆæœ¬\n",
        "            pd_version = pd.__version__\n",
        "            major_version = int(pd_version.split('.')[0])\n",
        "            minor_version = int(pd_version.split('.')[1])\n",
        "\n",
        "            # pandas 2.2.0+ ä½¿ç”¨æ–°çš„é »ç‡å­—ç¬¦ä¸²\n",
        "            if major_version > 2 or (major_version == 2 and minor_version >= 2):\n",
        "                freq_mapping = {\n",
        "                    'M': 'ME',  # Month End\n",
        "                    'Q': 'QE',  # Quarter End\n",
        "                    'Y': 'YE',  # Year End\n",
        "                    'W': 'W',   # Week (unchanged)\n",
        "                    'D': 'D',   # Day (unchanged)\n",
        "                }\n",
        "                return freq_mapping.get(freq_type, freq_type)\n",
        "            else:\n",
        "                return freq_type\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"æª¢æŸ¥ pandas ç‰ˆæœ¬æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return freq_type\n",
        "\n",
        "    def perform_multi_timeframe_analysis(self, stock_id, start_date=None, end_date=None):\n",
        "        \"\"\"å¤šæ™‚é–“é€±æœŸåˆ†æï¼ˆä¿®æ­£ç‰ˆï¼‰\"\"\"\n",
        "        try:\n",
        "            if start_date is None:\n",
        "                start_date = (datetime.now() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "            if end_date is None:\n",
        "                end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            # ç²å–è¼ƒé•·æ™‚é–“çš„æ•¸æ“šä»¥ä¾¿é‡æ¡æ¨£\n",
        "            extended_start = (datetime.strptime(start_date, \"%Y-%m-%d\") - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            # å¦‚æœæ˜¯yahoo symbolæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦å‰‡è½‰æ›\n",
        "            if not stock_id.endswith(('.TW', '.TWO')):\n",
        "                yahoo_symbol = f\"{stock_id}.TW\"\n",
        "            else:\n",
        "                yahoo_symbol = stock_id\n",
        "\n",
        "            data = self.fetch_yfinance_data(yahoo_symbol, period=\"2y\")\n",
        "\n",
        "            if data is None or data.empty:\n",
        "                return None\n",
        "\n",
        "            # è¨­å®šæ—¥æœŸç‚ºç´¢å¼•\n",
        "            if 'Date' in data.columns:\n",
        "                data.set_index('Date', inplace=True)\n",
        "            elif data.index.name != 'Date':\n",
        "                data.index = pd.to_datetime(data.index)\n",
        "\n",
        "            # ä¸åŒæ™‚é–“é€±æœŸçš„æ•¸æ“š\n",
        "            daily_data = self.calculate_indicators(data)\n",
        "\n",
        "            # é€±ç·šæ•¸æ“š\n",
        "            try:\n",
        "                weekly_freq = self.get_resample_frequency('W')\n",
        "                weekly_data = data.resample(weekly_freq).agg({\n",
        "                    'Open': 'first',\n",
        "                    'High': 'max',\n",
        "                    'Low': 'min',\n",
        "                    'Close': 'last',\n",
        "                    'Volume': 'sum'\n",
        "                }).dropna()\n",
        "                weekly_data = self.calculate_indicators(weekly_data)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"é€±ç·šæ•¸æ“šé‡æ¡æ¨£å¤±æ•—: {e}\")\n",
        "                weekly_data = None\n",
        "\n",
        "            # æœˆç·šæ•¸æ“š\n",
        "            try:\n",
        "                monthly_freq = self.get_resample_frequency('M')\n",
        "\n",
        "                # ä½¿ç”¨è­¦å‘ŠæŠ‘åˆ¶ä¾†è™•ç†èˆŠç‰ˆæœ¬çš„æ£„ç”¨è­¦å‘Š\n",
        "                import warnings\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*'M' is deprecated.*\")\n",
        "\n",
        "                    monthly_data = data.resample(monthly_freq).agg({\n",
        "                        'Open': 'first',\n",
        "                        'High': 'max',\n",
        "                        'Low': 'min',\n",
        "                        'Close': 'last',\n",
        "                        'Volume': 'sum'\n",
        "                    }).dropna()\n",
        "\n",
        "                monthly_data = self.calculate_indicators(monthly_data)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"æœˆç·šæ•¸æ“šé‡æ¡æ¨£å¤±æ•—: {e}\")\n",
        "                monthly_data = None\n",
        "\n",
        "            # é€²è¡Œå››è±¡é™åˆ†æ\n",
        "            daily_analysis = self.perform_quadrant_analysis(daily_data) if daily_data is not None else None\n",
        "            weekly_analysis = self.perform_quadrant_analysis(weekly_data) if weekly_data is not None else None\n",
        "            monthly_analysis = self.perform_quadrant_analysis(monthly_data) if monthly_data is not None else None\n",
        "\n",
        "            result = {\n",
        "                'daily': {\n",
        "                    'data': daily_data,\n",
        "                    'analysis': daily_analysis\n",
        "                }\n",
        "            }\n",
        "\n",
        "            if weekly_data is not None:\n",
        "                result['weekly'] = {\n",
        "                    'data': weekly_data,\n",
        "                    'analysis': weekly_analysis\n",
        "                }\n",
        "\n",
        "            if monthly_data is not None:\n",
        "                result['monthly'] = {\n",
        "                    'data': monthly_data,\n",
        "                    'analysis': monthly_analysis\n",
        "                }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å¤šæ™‚é–“é€±æœŸåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_multi_timeframe_summary(self, results, stock_id):\n",
        "        \"\"\"ç”Ÿæˆå¤šæ™‚é–“é€±æœŸåˆ†æå ±å‘Š\"\"\"\n",
        "        if not results:\n",
        "            print(\"ç„¡åˆ†æçµæœå¯é¡¯ç¤º\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(f\"è‚¡ç¥¨ä»£ç¢¼: {stock_id} å¤šæ™‚é–“é€±æœŸå››è±¡é™åˆ†æçµæœ\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        timeframes = {\n",
        "            'daily': 'æ—¥ç·š',\n",
        "            'weekly': 'é€±ç·š',\n",
        "            'monthly': 'æœˆç·š'\n",
        "        }\n",
        "\n",
        "        quadrant_names = {\n",
        "            1: \"å¼·å‹¢å¤šé ­ (ç¬¬ä¸€è±¡é™)\",\n",
        "            2: \"å¤šé ­è­¦æˆ’ (ç¬¬äºŒè±¡é™)\",\n",
        "            3: \"å¼·å‹¢ç©ºé ­ (ç¬¬ä¸‰è±¡é™)\",\n",
        "            4: \"ç©ºé ­åè½‰ (ç¬¬å››è±¡é™)\"\n",
        "        }\n",
        "\n",
        "        for tf, tf_name in timeframes.items():\n",
        "            if tf in results and results[tf]['analysis']:\n",
        "                analysis = results[tf]['analysis']\n",
        "                data = results[tf]['data']\n",
        "                latest = data.iloc[-1]\n",
        "\n",
        "                print(f\"\\nã€{tf_name}åˆ†æã€‘\")\n",
        "                print(f\"è±¡é™: {quadrant_names[analysis['quadrant']]}\")\n",
        "                print(f\"è¶¨å‹¢: {analysis['trend']}\")\n",
        "                print(f\"MACD: {analysis['macd']:.4f}, è¨Šè™Ÿç·š: {analysis['macd_signal']:.4f}, æŸ±ç‹€: {analysis['macd_hist']:.4f}\")\n",
        "                print(f\"RSI: {analysis['rsi']:.2f}\")\n",
        "                print(f\"KDæŒ‡æ¨™: K={analysis['k']:.2f}, D={analysis['d']:.2f}\")\n",
        "                print(f\"æ”¶ç›¤åƒ¹: {latest['Close']:.2f}, 10æ—¥å‡ç·š: {latest['MA10']:.2f}, 30æ—¥å‡ç·š: {latest['MA30']:.2f}\")\n",
        "\n",
        "                # é¡¯ç¤ºç›¸å°ä½ç½®\n",
        "                print(\"æŠ€è¡“æŒ‡æ¨™ç›¸å°ä½ç½®:\")\n",
        "                if latest['Close'] > latest['MA10']:\n",
        "                    print(\"- åƒ¹æ ¼ä½æ–¼10æ—¥å‡ç·šä¹‹ä¸Š\")\n",
        "                else:\n",
        "                    print(\"- åƒ¹æ ¼ä½æ–¼10æ—¥å‡ç·šä¹‹ä¸‹\")\n",
        "\n",
        "                if latest['Close'] > latest['MA30']:\n",
        "                    print(\"- åƒ¹æ ¼ä½æ–¼30æ—¥å‡ç·šä¹‹ä¸Š\")\n",
        "                else:\n",
        "                    print(\"- åƒ¹æ ¼ä½æ–¼30æ—¥å‡ç·šä¹‹ä¸‹\")\n",
        "\n",
        "                if analysis['macd'] > analysis['macd_signal']:\n",
        "                    print(\"- MACDä½æ–¼è¨Šè™Ÿç·šä¹‹ä¸Š (å¤šé ­)\")\n",
        "                else:\n",
        "                    print(\"- MACDä½æ–¼è¨Šè™Ÿç·šä¹‹ä¸‹ (ç©ºé ­)\")\n",
        "\n",
        "                if analysis['k'] > analysis['d']:\n",
        "                    print(\"- Kç·šä½æ–¼Dç·šä¹‹ä¸Š (å¤šé ­)\")\n",
        "                else:\n",
        "                    print(\"- Kç·šä½æ–¼Dç·šä¹‹ä¸‹ (ç©ºé ­)\")\n",
        "\n",
        "                print(f\"\\nã€{tf_name}åˆ†æã€‘: æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•åˆ†æ\")\n",
        "\n",
        "        # ç¶œåˆå»ºè­°\n",
        "        print(\"\\nã€ç¶œåˆåˆ†æã€‘\")\n",
        "\n",
        "        # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰æ™‚é–“é€±æœŸéƒ½æœ‰åˆ†æçµæœ\n",
        "        if all(tf in results and results[tf]['analysis'] for tf in timeframes):\n",
        "            daily_q = results['daily']['analysis']['quadrant']\n",
        "            weekly_q = results['weekly']['analysis']['quadrant']\n",
        "            monthly_q = results['monthly']['analysis']['quadrant']\n",
        "\n",
        "            # å¤šé ­æ’åˆ—\n",
        "            if monthly_q in [1, 4] and weekly_q in [1, 4] and daily_q in [1, 4]:\n",
        "                print(\"å¤šé ­æ’åˆ—: æœˆç·šã€é€±ç·šå’Œæ—¥ç·šå‡å‘ˆç¾å¤šé ­è¶¨å‹¢ï¼Œå¯è€ƒæ…®é€¢ä½è²·å…¥\")\n",
        "            # ç©ºé ­æ’åˆ—\n",
        "            elif monthly_q in [2, 3] and weekly_q in [2, 3] and daily_q in [2, 3]:\n",
        "                print(\"ç©ºé ­æ’åˆ—: æœˆç·šã€é€±ç·šå’Œæ—¥ç·šå‡å‘ˆç¾ç©ºé ­è¶¨å‹¢ï¼Œå»ºè­°è§€æœ›æˆ–æ¸›å€‰\")\n",
        "            # å¤šç©ºè½‰æ›\n",
        "            else:\n",
        "                if daily_q in [1, 4] and (weekly_q in [2, 3] or monthly_q in [2, 3]):\n",
        "                    print(\"çŸ­ç·šåå½ˆ: æ—¥ç·šå‘ˆç¾å¤šé ­ï¼Œä½†ä¸­é•·æœŸä»åœ¨ç©ºé ­ï¼Œå¯èƒ½æ˜¯åå½ˆè¡Œæƒ…\")\n",
        "                elif daily_q in [2, 3] and (weekly_q in [1, 4] or monthly_q in [1, 4]):\n",
        "                    print(\"çŸ­ç·šå›èª¿: æ—¥ç·šå‘ˆç¾ç©ºé ­ï¼Œä½†ä¸­é•·æœŸä»åœ¨å¤šé ­ï¼Œå¯èƒ½æ˜¯å›èª¿è¡Œæƒ…\")\n",
        "                else:\n",
        "                    print(\"å¤šç©ºäº¤éŒ¯: å„æ™‚é–“é€±æœŸèµ°å‹¢ä¸ä¸€è‡´ï¼Œå»ºè­°è§€æœ›æˆ–ä¾ä¸»è¦æ™‚é–“é€±æœŸæ“ä½œ\")\n",
        "        else:\n",
        "            print(\"éƒ¨åˆ†æ™‚é–“é€±æœŸæ•¸æ“šä¸è¶³ï¼Œç„¡æ³•æä¾›å®Œæ•´ç¶œåˆåˆ†æ\")\n",
        "\n",
        "    def analyze_trend(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"è¶¨å‹¢åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or len(df) < 20:\n",
        "                return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_5d_ago = float(df['Close'].iloc[-6]) if len(df) >= 6 else current_price\n",
        "            price_20d_ago = float(df['Close'].iloc[-21]) if len(df) >= 21 else current_price\n",
        "\n",
        "            change_5d = ((current_price - price_5d_ago) / price_5d_ago * 100) if price_5d_ago != 0 else 0\n",
        "            change_20d = ((current_price - price_20d_ago) / price_20d_ago * 100) if price_20d_ago != 0 else 0\n",
        "\n",
        "            # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢\n",
        "            ma5_current = float(df['MA5'].iloc[-1]) if 'MA5' in df.columns and not pd.isna(df['MA5'].iloc[-1]) else current_price\n",
        "            ma20_current = float(df['MA20'].iloc[-1]) if 'MA20' in df.columns and not pd.isna(df['MA20'].iloc[-1]) else current_price\n",
        "\n",
        "            # åˆ¤æ–·è¶¨å‹¢\n",
        "            if change_5d > 3 and change_20d > 5 and current_price > ma5_current > ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸Šæ¼²'\n",
        "                strength = 3\n",
        "            elif change_5d > 1 and change_20d > 2 and current_price > ma5_current:\n",
        "                trend = 'ä¸Šæ¼²'\n",
        "                strength = 2\n",
        "            elif change_5d < -3 and change_20d < -5 and current_price < ma5_current < ma20_current:\n",
        "                trend = 'å¼·å‹¢ä¸‹è·Œ'\n",
        "                strength = -3\n",
        "            elif change_5d < -1 and change_20d < -2 and current_price < ma5_current:\n",
        "                trend = 'ä¸‹è·Œ'\n",
        "                strength = -2\n",
        "            else:\n",
        "                trend = 'ç›¤æ•´'\n",
        "                strength = 0\n",
        "\n",
        "            return {\n",
        "                'trend': trend,\n",
        "                'strength': strength,\n",
        "                'price_change_5d': change_5d,\n",
        "                'price_change_20d': change_20d,\n",
        "                'ma5_position': ma5_current,\n",
        "                'ma20_position': ma20_current\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¶¨å‹¢åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'trend': 'ç›¤æ•´', 'strength': 0, 'price_change_5d': 0, 'price_change_20d': 0}\n",
        "\n",
        "    def analyze_volume(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æˆäº¤é‡åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty or 'Volume' not in df.columns or len(df) < 20:\n",
        "                return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "            current_volume = float(df['Volume'].iloc[-1])\n",
        "            avg_volume_20d = float(df['Volume'].rolling(window=20).mean().iloc[-1])\n",
        "\n",
        "            volume_ratio = current_volume / avg_volume_20d if avg_volume_20d > 0 else 1.0\n",
        "            avg_volume_lots = avg_volume_20d / 1000  # è½‰æ›ç‚ºå¼µæ•¸\n",
        "\n",
        "            if volume_ratio > 2.0:\n",
        "                volume_trend = 'çˆ†é‡'\n",
        "                volume_signal = 'å¼·çƒˆ'\n",
        "            elif volume_ratio > 1.5:\n",
        "                volume_trend = 'æ”¾é‡'\n",
        "                volume_signal = 'ç©æ¥µ'\n",
        "            elif volume_ratio < 0.5:\n",
        "                volume_trend = 'ç¸®é‡'\n",
        "                volume_signal = 'æ¶ˆæ¥µ'\n",
        "            else:\n",
        "                volume_trend = 'æ­£å¸¸'\n",
        "                volume_signal = 'ä¸­æ€§'\n",
        "\n",
        "            return {\n",
        "                'volume_trend': volume_trend,\n",
        "                'volume_ratio': volume_ratio,\n",
        "                'volume_signal': volume_signal,\n",
        "                'avg_volume_lots': avg_volume_lots\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æˆäº¤é‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {'volume_trend': 'æ­£å¸¸', 'volume_ratio': 1.0, 'volume_signal': 'ä¸­æ€§', 'avg_volume_lots': 0}\n",
        "\n",
        "    def analyze_technical_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"æŠ€è¡“æŒ‡æ¨™åˆ†æ\"\"\"\n",
        "        try:\n",
        "            if df.empty:\n",
        "                return {\n",
        "                    'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                    'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                    'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                    'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                    'score': 50\n",
        "                }\n",
        "\n",
        "            signals = {}\n",
        "            score = 50\n",
        "\n",
        "            # RSI åˆ†æ\n",
        "            if 'RSI' in df.columns and not df['RSI'].empty:\n",
        "                rsi_value = float(df['RSI'].iloc[-1]) if not pd.isna(df['RSI'].iloc[-1]) else 50\n",
        "                signals['rsi_value'] = rsi_value\n",
        "\n",
        "                if rsi_value > 80:\n",
        "                    signals['rsi_signal'] = 'è¶…è²·'\n",
        "                    score -= 15\n",
        "                elif rsi_value > 70:\n",
        "                    signals['rsi_signal'] = 'åé«˜'\n",
        "                    score -= 5\n",
        "                elif rsi_value < 20:\n",
        "                    signals['rsi_signal'] = 'è¶…è³£'\n",
        "                    score += 15\n",
        "                elif rsi_value < 30:\n",
        "                    signals['rsi_signal'] = 'åä½'\n",
        "                    score += 5\n",
        "                else:\n",
        "                    signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['rsi_signal'] = 'ä¸­æ€§'\n",
        "                signals['rsi_value'] = 50\n",
        "\n",
        "            # MACD åˆ†æ\n",
        "            if all(col in df.columns for col in ['MACD', 'MACD_Signal']) and len(df) >= 2:\n",
        "                macd_current = float(df['MACD'].iloc[-1]) if not pd.isna(df['MACD'].iloc[-1]) else 0\n",
        "                macd_signal_current = float(df['MACD_Signal'].iloc[-1]) if not pd.isna(df['MACD_Signal'].iloc[-1]) else 0\n",
        "                macd_prev = float(df['MACD'].iloc[-2]) if not pd.isna(df['MACD'].iloc[-2]) else 0\n",
        "                macd_signal_prev = float(df['MACD_Signal'].iloc[-2]) if not pd.isna(df['MACD_Signal'].iloc[-2]) else 0\n",
        "\n",
        "                signals['macd_value'] = macd_current\n",
        "\n",
        "                if macd_prev <= macd_signal_prev and macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'é»ƒé‡‘äº¤å‰'\n",
        "                    score += 20\n",
        "                elif macd_prev >= macd_signal_prev and macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'æ­»äº¡äº¤å‰'\n",
        "                    score -= 20\n",
        "                elif macd_current > macd_signal_current:\n",
        "                    signals['macd_signal'] = 'å¤šé ­'\n",
        "                    score += 5\n",
        "                elif macd_current < macd_signal_current:\n",
        "                    signals['macd_signal'] = 'ç©ºé ­'\n",
        "                    score -= 5\n",
        "                else:\n",
        "                    signals['macd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['macd_signal'] = 'ä¸­æ€§'\n",
        "                signals['macd_value'] = 0\n",
        "\n",
        "            # KD åˆ†æ\n",
        "            if all(col in df.columns for col in ['K_Percent', 'D_Percent']):\n",
        "                k_value = float(df['K_Percent'].iloc[-1]) if not pd.isna(df['K_Percent'].iloc[-1]) else 50\n",
        "                d_value = float(df['D_Percent'].iloc[-1]) if not pd.isna(df['D_Percent'].iloc[-1]) else 50\n",
        "\n",
        "                signals['k_value'] = k_value\n",
        "                signals['d_value'] = d_value\n",
        "\n",
        "                if k_value > 80 and d_value > 80:\n",
        "                    signals['kd_signal'] = 'è¶…è²·'\n",
        "                    score -= 10\n",
        "                elif k_value < 20 and d_value < 20:\n",
        "                    signals['kd_signal'] = 'è¶…è³£'\n",
        "                    score += 10\n",
        "                elif k_value > d_value:\n",
        "                    signals['kd_signal'] = 'åå¤š'\n",
        "                    score += 3\n",
        "                elif k_value < d_value:\n",
        "                    signals['kd_signal'] = 'åç©º'\n",
        "                    score -= 3\n",
        "                else:\n",
        "                    signals['kd_signal'] = 'ä¸­æ€§'\n",
        "            else:\n",
        "                signals['kd_signal'] = 'ä¸­æ€§'\n",
        "                signals['k_value'] = 50\n",
        "                signals['d_value'] = 50\n",
        "\n",
        "            # å¸ƒæ—å¸¶åˆ†æ\n",
        "            if all(col in df.columns for col in ['BB_Upper', 'BB_Lower', 'Close']):\n",
        "                current_price = float(df['Close'].iloc[-1])\n",
        "                bb_upper = float(df['BB_Upper'].iloc[-1]) if not pd.isna(df['BB_Upper'].iloc[-1]) else current_price\n",
        "                bb_lower = float(df['BB_Lower'].iloc[-1]) if not pd.isna(df['BB_Lower'].iloc[-1]) else current_price\n",
        "\n",
        "                if bb_upper != bb_lower:\n",
        "                    bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)\n",
        "                    signals['bb_position'] = bb_position\n",
        "\n",
        "                    if bb_position > 0.8:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸Šè»Œ'\n",
        "                        score -= 5\n",
        "                    elif bb_position < 0.2:\n",
        "                        signals['bb_signal'] = 'æ¥è¿‘ä¸‹è»Œ'\n",
        "                        score += 5\n",
        "                    else:\n",
        "                        signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                else:\n",
        "                    signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                    signals['bb_position'] = 0.5\n",
        "            else:\n",
        "                signals['bb_signal'] = 'ä¸­æ€§'\n",
        "                signals['bb_position'] = 0.5\n",
        "\n",
        "            score = max(0, min(100, score))\n",
        "            signals['score'] = score\n",
        "\n",
        "            return signals\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æŠ€è¡“æŒ‡æ¨™åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'rsi_signal': 'ä¸­æ€§', 'rsi_value': 50,\n",
        "                'macd_signal': 'ä¸­æ€§', 'macd_value': 0,\n",
        "                'kd_signal': 'ä¸­æ€§', 'k_value': 50, 'd_value': 50,\n",
        "                'bb_signal': 'ä¸­æ€§', 'bb_position': 0.5,\n",
        "                'score': 50\n",
        "            }\n",
        "\n",
        "    def calculate_combined_score(self, trend_analysis: Dict, volume_analysis: Dict, technical_analysis: Dict) -> float:\n",
        "        \"\"\"è¨ˆç®—ç¶œåˆåˆ†æ•¸\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            # è¶¨å‹¢åˆ†æ•¸ (æ¬Šé‡: 30%)\n",
        "            trend_score = 0\n",
        "            trend_strength = trend_analysis.get('strength', 0)\n",
        "            if trend_strength > 0:\n",
        "                trend_score = min(30, trend_strength * 10)\n",
        "            elif trend_strength < 0:\n",
        "                trend_score = max(-30, trend_strength * 10)\n",
        "\n",
        "            # æˆäº¤é‡åˆ†æ•¸ (æ¬Šé‡: 20%)\n",
        "            volume_score = 0\n",
        "            volume_ratio = volume_analysis.get('volume_ratio', 1.0)\n",
        "            if volume_ratio > 1.5:\n",
        "                volume_score = 10\n",
        "            elif volume_ratio > 1.2:\n",
        "                volume_score = 5\n",
        "            elif volume_ratio < 0.7:\n",
        "                volume_score = -5\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™åˆ†æ•¸ (æ¬Šé‡: 50%)\n",
        "            tech_score = technical_analysis.get('score', 50) - 50\n",
        "\n",
        "            # è¨ˆç®—åŠ æ¬Šç¸½åˆ†\n",
        "            total_score = base_score + (trend_score * 0.3) + (volume_score * 0.2) + (tech_score * 0.5)\n",
        "\n",
        "            return max(0, min(100, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"è¨ˆç®—ç¶œåˆåˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return 50.0\n",
        "\n",
        "    def generate_recommendation(self, combined_score: float, trend_analysis: Dict, technical_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "        try:\n",
        "            recommendation = \"æŒæœ‰\"\n",
        "            confidence = \"ä¸­ç­‰\"\n",
        "            reasons = []\n",
        "\n",
        "            if combined_score >= 75:\n",
        "                recommendation = \"å¼·åŠ›è²·é€²\"\n",
        "                confidence = \"é«˜\"\n",
        "            elif combined_score >= 60:\n",
        "                recommendation = \"è²·é€²\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            elif combined_score >= 40:\n",
        "                recommendation = \"æŒæœ‰\"\n",
        "                confidence = \"ä¸­ç­‰\"\n",
        "            elif combined_score >= 25:\n",
        "                recommendation = \"è³£å‡º\"\n",
        "                confidence = \"ä¸­é«˜\"\n",
        "            else:\n",
        "                recommendation = \"å¼·åŠ›è³£å‡º\"\n",
        "                confidence = \"é«˜\"\n",
        "\n",
        "            # ç”Ÿæˆå»ºè­°åŸå› \n",
        "            trend = trend_analysis.get('trend', 'ç›¤æ•´')\n",
        "            if 'ä¸Šæ¼²' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "            elif 'ä¸‹è·Œ' in trend:\n",
        "                reasons.append(f\"åƒ¹æ ¼è¶¨å‹¢ï¼š{trend}\")\n",
        "\n",
        "            rsi_signal = technical_analysis.get('rsi_signal', 'ä¸­æ€§')\n",
        "            if rsi_signal in ['è¶…è³£', 'åä½']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œå¯èƒ½åå½ˆ\")\n",
        "            elif rsi_signal in ['è¶…è²·', 'åé«˜']:\n",
        "                reasons.append(f\"RSIæŒ‡æ¨™ï¼š{rsi_signal}ï¼Œæ³¨æ„å›èª¿\")\n",
        "\n",
        "            macd_signal = technical_analysis.get('macd_signal', 'ä¸­æ€§')\n",
        "            if macd_signal == 'é»ƒé‡‘äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾é»ƒé‡‘äº¤å‰\")\n",
        "            elif macd_signal == 'æ­»äº¡äº¤å‰':\n",
        "                reasons.append(\"MACDå‡ºç¾æ­»äº¡äº¤å‰\")\n",
        "\n",
        "            return {\n",
        "                'recommendation': recommendation,\n",
        "                'confidence': confidence,\n",
        "                'score': combined_score,\n",
        "                'reasons': reasons\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç”ŸæˆæŠ•è³‡å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'recommendation': 'æŒæœ‰',\n",
        "                'confidence': 'ä½',\n",
        "                'score': 50,\n",
        "                'reasons': ['åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤']\n",
        "            }\n",
        "\n",
        "    def screen_stocks(self, start_date=None, end_date=None) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        è‚¡ç¥¨ç¯©é¸åŠŸèƒ½\n",
        "        ç¯©é¸æ¢ä»¶ï¼š\n",
        "        1. æŠ€è¡“é¢\n",
        "           - MACD: 0 < D-M < 1.5\n",
        "           - æœ¬æ—¥æ”¶ç›¤åƒ¹é«˜æ–¼10æ—¥å‡åƒ¹ä¸”é«˜æ–¼30æ—¥å‡åƒ¹\n",
        "           - æœ¬æ—¥è‚¡åƒ¹æ¼²å¹…5%ä»¥ä¸Š\n",
        "        2. ç±Œç¢¼é¢\n",
        "           - æœ¬æ—¥æˆäº¤é‡5000å¼µä»¥ä¸Šä½†ä¸è¶…é30æ—¥å‡é‡çš„3å€\n",
        "           - ç”±ç¬¦åˆç¯©é¸æ¢ä»¶ä¸­å–æˆäº¤é‡å‰ä¸‰å¤§ç‚ºæ¨™çš„\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"é–‹å§‹è‚¡ç¥¨ç¯©é¸...\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if start_date is None:\n",
        "            start_date = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
        "        if end_date is None:\n",
        "            end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        # å»¶é•·é–‹å§‹æ—¥æœŸä»¥ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“šè¨ˆç®—æŒ‡æ¨™\n",
        "        extended_start = (datetime.strptime(start_date, \"%Y-%m-%d\") - timedelta(days=60)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        # ç²å–è‚¡ç¥¨æ¸…å–®\n",
        "        if self.taiwan_stocks is None:\n",
        "            self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "        if self.taiwan_stocks.empty:\n",
        "            print(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "            return []\n",
        "\n",
        "        results = []\n",
        "        stock_list = [(row['stock_id'], row['stock_name'], row['yahoo_symbol']) for _, row in self.taiwan_stocks.iterrows()]\n",
        "\n",
        "        # éæ­·è‚¡ç¥¨åˆ—è¡¨\n",
        "        for i, (stock_id, stock_name, yahoo_symbol) in enumerate(stock_list):\n",
        "            print(f\"è™•ç† {i+1}/{len(stock_list)}: {stock_id} - {stock_name}\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            data = self.fetch_yfinance_data(yahoo_symbol, period=\"3mo\")\n",
        "            if data is None or len(data) < 30:\n",
        "                continue\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df = self.calculate_indicators(data)\n",
        "            if df is None:\n",
        "                continue\n",
        "\n",
        "            # ç²å–æœ€æ–°ä¸€å¤©çš„æ•¸æ“š\n",
        "            latest = df.iloc[-1]\n",
        "\n",
        "            try:\n",
        "                # ç¯©é¸æ¢ä»¶æª¢æŸ¥\n",
        "                # 1. MACD: 0 < D-M < 1.5\n",
        "                macd_diff = latest['MACD_Signal'] - latest['MACD']\n",
        "                macd_condition = (self.config['screen_conditions']['macd_diff_min'] <\n",
        "                                macd_diff < self.config['screen_conditions']['macd_diff_max'])\n",
        "\n",
        "                # 2. æœ¬æ—¥æ”¶ç›¤åƒ¹é«˜æ–¼10æ—¥å‡åƒ¹ä¸”é«˜æ–¼30æ—¥å‡åƒ¹\n",
        "                price_above_ma = (latest['Close'] > latest['MA10']) and (latest['Close'] > latest['MA30'])\n",
        "\n",
        "                # 3. æœ¬æ—¥è‚¡åƒ¹æ¼²å¹…5%ä»¥ä¸Š\n",
        "                price_change = latest['Change']\n",
        "                price_change_condition = price_change >= self.config['screen_conditions']['min_price_change']\n",
        "\n",
        "                # 4. æœ¬æ—¥æˆäº¤é‡5000å¼µä»¥ä¸Šä½†ä¸è¶…é30æ—¥å‡é‡çš„3å€\n",
        "                # å°è‚¡ä¸€å¼µæ˜¯1000è‚¡ï¼Œæ‰€ä»¥5000å¼µæ˜¯5,000,000è‚¡\n",
        "                min_volume = self.config['screen_conditions']['min_volume_lots'] * 1000\n",
        "                max_volume_ratio = self.config['screen_conditions']['max_volume_ratio']\n",
        "                volume_condition = (latest['Volume'] >= min_volume and\n",
        "                                  latest['Volume'] <= latest['Volume_MA30'] * max_volume_ratio)\n",
        "\n",
        "                # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæ‰€æœ‰æ¢ä»¶\n",
        "                if macd_condition and price_above_ma and price_change_condition and volume_condition:\n",
        "                    # é€²è¡Œå››è±¡é™åˆ†æ\n",
        "                    quadrant_analysis = self.perform_quadrant_analysis(df)\n",
        "\n",
        "                    results.append({\n",
        "                        'stock_id': stock_id,\n",
        "                        'stock_name': stock_name,\n",
        "                        'yahoo_symbol': yahoo_symbol,\n",
        "                        'close': latest['Close'],\n",
        "                        'change': price_change,\n",
        "                        'volume': latest['Volume'],\n",
        "                        'volume_lots': latest['Volume'] / 1000,\n",
        "                        'macd_diff': macd_diff,\n",
        "                        'quadrant_analysis': quadrant_analysis,\n",
        "                        'data': df\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ç¯©é¸ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                continue\n",
        "\n",
        "        # æŒ‰æˆäº¤é‡æ’åº\n",
        "        if results:\n",
        "            results.sort(key=lambda x: x['volume'], reverse=True)\n",
        "\n",
        "            # å–å‰ä¸‰å¤§æˆäº¤é‡\n",
        "            top_results = results[:min(3, len(results))]\n",
        "\n",
        "            print(\"\\n\" + \"=\" * 80)\n",
        "            print(f\"ç¯©é¸çµæœ: ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨æœ‰ {len(results)} æª”ï¼Œå–æˆäº¤é‡å‰ {len(top_results)} å¤§\")\n",
        "            print(\"=\" * 80)\n",
        "\n",
        "            for i, result in enumerate(top_results):\n",
        "                print(f\"\\næ’å {i+1}: {result['stock_id']} - {result['stock_name']}\")\n",
        "                print(f\"æ”¶ç›¤åƒ¹: {result['close']:.2f}, æ¼²å¹…: {result['change']:.2f}%\")\n",
        "                print(f\"æˆäº¤é‡: {result['volume']:,.0f} è‚¡ (ç´„ {result['volume_lots']:.0f} å¼µ)\")\n",
        "                print(f\"MACDå·®å€¼ (D-M): {result['macd_diff']:.4f}\")\n",
        "\n",
        "                # å››è±¡é™åˆ†æ\n",
        "                if result['quadrant_analysis']:\n",
        "                    analysis = result['quadrant_analysis']\n",
        "                    print(f\"å››è±¡é™åˆ†æ: ç¬¬ {analysis['quadrant']} è±¡é™ ({analysis['trend']}è¶¨å‹¢)\")\n",
        "\n",
        "            return top_results\n",
        "        else:\n",
        "            print(\"\\næ²’æœ‰ç¬¦åˆç¯©é¸æ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "            return []\n",
        "\n",
        "    def create_stock_chart(self, stock_data: Dict[str, Any], save_path: str = None) -> str:\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨æŠ€è¡“åˆ†æåœ–è¡¨\"\"\"\n",
        "        try:\n",
        "            df = stock_data.get('data')\n",
        "            if df is None or df.empty:\n",
        "                return None\n",
        "\n",
        "            stock_name = stock_data.get('stock_name', 'Unknown')\n",
        "            stock_id = stock_data.get('stock_id', 'Unknown')\n",
        "\n",
        "            # å‰µå»ºåœ–è¡¨\n",
        "            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "            fig.suptitle(f'{stock_name} ({stock_id}) æŠ€è¡“åˆ†æåœ–è¡¨', fontsize=16, fontweight='bold')\n",
        "\n",
        "            # ç¢ºä¿æ—¥æœŸæ ¼å¼æ­£ç¢º\n",
        "            if 'Date' not in df.columns:\n",
        "                df = df.reset_index()\n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "            # å–æœ€è¿‘60å¤©çš„æ•¸æ“šç”¨æ–¼ç¹ªåœ–\n",
        "            plot_df = df.tail(60).copy()\n",
        "\n",
        "            # åœ–1: åƒ¹æ ¼å’Œç§»å‹•å¹³å‡ç·š\n",
        "            ax1.plot(plot_df['Date'], plot_df['Close'], label='æ”¶ç›¤åƒ¹', linewidth=2, color='black')\n",
        "            ax1.plot(plot_df['Date'], plot_df['MA5'], label='MA5', color='red', alpha=0.7)\n",
        "            ax1.plot(plot_df['Date'], plot_df['MA10'], label='MA10', color='blue', alpha=0.7)\n",
        "            ax1.plot(plot_df['Date'], plot_df['MA20'], label='MA20', color='green', alpha=0.7)\n",
        "            ax1.plot(plot_df['Date'], plot_df['MA30'], label='MA30', color='purple', alpha=0.7)\n",
        "\n",
        "            # å¸ƒæ—å¸¶\n",
        "            ax1.fill_between(plot_df['Date'], plot_df['BB_Upper'], plot_df['BB_Lower'],\n",
        "                           alpha=0.1, color='gray', label='å¸ƒæ—å¸¶')\n",
        "\n",
        "            ax1.set_title('åƒ¹æ ¼èµ°å‹¢èˆ‡ç§»å‹•å¹³å‡ç·š')\n",
        "            ax1.legend()\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "\n",
        "            # åœ–2: MACD\n",
        "            ax2.plot(plot_df['Date'], plot_df['MACD'], label='MACD', color='blue')\n",
        "            ax2.plot(plot_df['Date'], plot_df['MACD_Signal'], label='Signal', color='red')\n",
        "            ax2.bar(plot_df['Date'], plot_df['MACD_Hist'], label='Histogram', alpha=0.3, color='green')\n",
        "            ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
        "            ax2.set_title('MACDæŒ‡æ¨™')\n",
        "            ax2.legend()\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "\n",
        "            # åœ–3: RSIå’ŒKD\n",
        "            ax3_twin = ax3.twinx()\n",
        "            ax3.plot(plot_df['Date'], plot_df['RSI'], label='RSI', color='purple', linewidth=2)\n",
        "            ax3.axhline(y=70, color='red', linestyle='--', alpha=0.5, label='è¶…è²·ç·š')\n",
        "            ax3.axhline(y=30, color='green', linestyle='--', alpha=0.5, label='è¶…è³£ç·š')\n",
        "            ax3.set_ylim(0, 100)\n",
        "            ax3.set_ylabel('RSI', color='purple')\n",
        "\n",
        "            ax3_twin.plot(plot_df['Date'], plot_df['K'], label='K', color='orange')\n",
        "            ax3_twin.plot(plot_df['Date'], plot_df['D'], label='D', color='brown')\n",
        "            ax3_twin.set_ylim(0, 100)\n",
        "            ax3_twin.set_ylabel('KD', color='orange')\n",
        "\n",
        "            ax3.set_title('RSIèˆ‡KDæŒ‡æ¨™')\n",
        "            ax3.legend(loc='upper left')\n",
        "            ax3_twin.legend(loc='upper right')\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "            ax3.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "\n",
        "            # åœ–4: æˆäº¤é‡\n",
        "            ax4.bar(plot_df['Date'], plot_df['Volume']/1000, alpha=0.6, color='skyblue', label='æˆäº¤é‡(åƒè‚¡)')\n",
        "            ax4.plot(plot_df['Date'], plot_df['Volume_MA']/1000, color='red', label='20æ—¥å‡é‡', linewidth=2)\n",
        "            ax4.set_title('æˆäº¤é‡åˆ†æ')\n",
        "            ax4.legend()\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "\n",
        "            # èª¿æ•´æ—¥æœŸæ¨™ç±¤\n",
        "            for ax in [ax1, ax2, ax3, ax4]:\n",
        "                ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # ä¿å­˜åœ–è¡¨\n",
        "            if save_path is None:\n",
        "                save_path = f\"charts/{stock_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "\n",
        "            # ç¢ºä¿ç›®éŒ„å­˜åœ¨\n",
        "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "            logger.info(f\"åœ–è¡¨å·²ä¿å­˜: {save_path}\")\n",
        "            return save_path\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"å‰µå»ºåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return None\n",
        "\n",
        "    async def analyze_stock_async(self, session: aiohttp.ClientSession, stock_info: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"ç•°æ­¥åˆ†æå–®æ”¯è‚¡ç¥¨\"\"\"\n",
        "        symbol = stock_info['yahoo_symbol']\n",
        "        stock_name = stock_info['stock_name']\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_name} ({symbol})\")\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': symbol,\n",
        "                    'stock_name': stock_name,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "                        # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # å››è±¡é™åˆ†æ\n",
        "            quadrant_analysis = self.perform_quadrant_analysis(df_with_indicators)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'stock_id': stock_info.get('stock_id', ''),\n",
        "                'market': stock_info.get('market', ''),\n",
        "                'industry': stock_info.get('industry', ''),\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'quadrant_analysis': quadrant_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'data': df_with_indicators,  # æ·»åŠ æ•¸æ“šç”¨æ–¼åœ–è¡¨ç”Ÿæˆ\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_name} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']} - è±¡é™: {quadrant_analysis.get('quadrant', 'N/A') if quadrant_analysis else 'N/A'}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': symbol,\n",
        "                'stock_name': stock_name,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    async def analyze_all_stocks(self) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼ˆåŠ å…¥æˆäº¤é‡ç¯©é¸ï¼‰\"\"\"\n",
        "        try:\n",
        "            # ç²å–å®Œæ•´è‚¡ç¥¨æ¸…å–®\n",
        "            if self.taiwan_stocks is None:\n",
        "                self.taiwan_stocks = self.get_taiwan_stocks()\n",
        "\n",
        "            if self.taiwan_stocks.empty:\n",
        "                logger.error(\"ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                return {}\n",
        "\n",
        "            logger.info(f\"æº–å‚™åˆ†æ {len(self.taiwan_stocks)} æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰\")\n",
        "\n",
        "            results = {}\n",
        "            failed_count = 0\n",
        "            volume_filtered_count = 0\n",
        "\n",
        "            # ä½¿ç”¨ aiohttp é€²è¡Œç•°æ­¥åˆ†æ\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # å‰µå»ºåˆ†æä»»å‹™\n",
        "                tasks = []\n",
        "                for _, stock_info in self.taiwan_stocks.iterrows():\n",
        "                    task = self.analyze_stock_async(session, stock_info.to_dict())\n",
        "                    tasks.append(task)\n",
        "\n",
        "                # åˆ†æ‰¹åŸ·è¡Œä»»å‹™ä»¥é¿å…éè¼‰\n",
        "                batch_size = 10\n",
        "                for i in range(0, len(tasks), batch_size):\n",
        "                    batch_tasks = tasks[i:i+batch_size]\n",
        "                    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n",
        "\n",
        "                    # è™•ç†æ‰¹æ¬¡çµæœ\n",
        "                    for result in batch_results:\n",
        "                        if isinstance(result, Exception):\n",
        "                            logger.error(f\"åˆ†æä»»å‹™ç•°å¸¸: {result}\")\n",
        "                            failed_count += 1\n",
        "                            continue\n",
        "\n",
        "                        if isinstance(result, dict) and 'symbol' in result:\n",
        "                            if result.get('success', False):\n",
        "                                results[result['symbol']] = result\n",
        "                            else:\n",
        "                                error_msg = result.get('error', '')\n",
        "                                if 'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶' in error_msg:\n",
        "                                    volume_filtered_count += 1\n",
        "                                else:\n",
        "                                    failed_count += 1\n",
        "\n",
        "                    # æ‰¹æ¬¡é–“æš«åœé¿å…éè¼‰\n",
        "                    if i + batch_size < len(tasks):\n",
        "                        await asyncio.sleep(2)\n",
        "\n",
        "            logger.info(f\"åˆ†æå®Œæˆçµ±è¨ˆï¼š\")\n",
        "            logger.info(f\"  - æˆåŠŸåˆ†æ: {len(results)} æ”¯\")\n",
        "            logger.info(f\"  - æˆäº¤é‡ç¯©é¸æ·˜æ±°: {volume_filtered_count} æ”¯\")\n",
        "            logger.info(f\"  - å…¶ä»–å¤±æ•—: {failed_count} æ”¯\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"æ‰¹é‡åˆ†æè‚¡ç¥¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def analyze_single_stock_with_multi_timeframe(self, stock_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"åˆ†æå–®æ”¯è‚¡ç¥¨ä¸¦åŒ…å«å¤šæ™‚é–“é€±æœŸåˆ†æ\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æè‚¡ç¥¨: {stock_id}\")\n",
        "\n",
        "            # å¦‚æœä¸æ˜¯yahoo symbolæ ¼å¼ï¼Œè½‰æ›ç‚ºyahoo symbol\n",
        "            if not stock_id.endswith(('.TW', '.TWO')):\n",
        "                yahoo_symbol = f\"{stock_id}.TW\"\n",
        "            else:\n",
        "                yahoo_symbol = stock_id\n",
        "                stock_id = stock_id.split('.')[0]\n",
        "\n",
        "            # ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            df = self.fetch_yfinance_data(yahoo_symbol)\n",
        "            if df is None or df.empty or len(df) < 60:\n",
        "                return {\n",
        "                    'symbol': yahoo_symbol,\n",
        "                    'stock_id': stock_id,\n",
        "                    'success': False,\n",
        "                    'error': 'ç„¡æ³•ç²å–è¶³å¤ çš„è‚¡ç¥¨æ•¸æ“š'\n",
        "                }\n",
        "\n",
        "            # æª¢æŸ¥æˆäº¤é‡ç¯©é¸æ¢ä»¶\n",
        "            if not self.check_volume_filter(df):\n",
        "                return {\n",
        "                    'symbol': yahoo_symbol,\n",
        "                    'stock_id': stock_id,\n",
        "                    'success': False,\n",
        "                    'error': f'æˆäº¤é‡ä¸ç¬¦åˆæ¢ä»¶ï¼ˆéœ€â‰¥{self.config[\"min_volume_lots\"]}å¼µ/æ—¥ï¼‰'\n",
        "                }\n",
        "\n",
        "            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™\n",
        "            df_with_indicators = self.calculate_technical_indicators(df)\n",
        "\n",
        "            # é€²è¡Œå„é …åˆ†æ\n",
        "            trend_analysis = self.analyze_trend(df_with_indicators)\n",
        "            volume_analysis = self.analyze_volume(df_with_indicators)\n",
        "            technical_analysis = self.analyze_technical_indicators(df_with_indicators)\n",
        "\n",
        "            # å››è±¡é™åˆ†æ\n",
        "            quadrant_analysis = self.perform_quadrant_analysis(df_with_indicators)\n",
        "\n",
        "            # å¤šæ™‚é–“é€±æœŸåˆ†æ\n",
        "            multi_timeframe_analysis = self.perform_multi_timeframe_analysis(yahoo_symbol)\n",
        "\n",
        "            # è¨ˆç®—ç¶œåˆåˆ†æ•¸\n",
        "            combined_score = self.calculate_combined_score(trend_analysis, volume_analysis, technical_analysis)\n",
        "\n",
        "            # ç”ŸæˆæŠ•è³‡å»ºè­°\n",
        "            recommendation = self.generate_recommendation(combined_score, trend_analysis, technical_analysis)\n",
        "\n",
        "            # ç²å–ç•¶å‰åƒ¹æ ¼è³‡è¨Š\n",
        "            current_price = float(df['Close'].iloc[-1])\n",
        "            price_change = trend_analysis.get('price_change_5d', 0)\n",
        "\n",
        "            result = {\n",
        "                'symbol': yahoo_symbol,\n",
        "                'stock_id': stock_id,\n",
        "                'success': True,\n",
        "                'current_price': current_price,\n",
        "                'price_change_5d': price_change,\n",
        "                'combined_score': combined_score,\n",
        "                'trend_analysis': trend_analysis,\n",
        "                'volume_analysis': volume_analysis,\n",
        "                'technical_analysis': technical_analysis,\n",
        "                'quadrant_analysis': quadrant_analysis,\n",
        "                'multi_timeframe_analysis': multi_timeframe_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'data': df_with_indicators,\n",
        "                'analysis_time': datetime.now(taipei_tz).isoformat()\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ: {stock_id} - åˆ†æ•¸: {combined_score:.1f} - å»ºè­°: {recommendation['recommendation']}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æè‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            return {\n",
        "                'symbol': yahoo_symbol if 'yahoo_symbol' in locals() else stock_id,\n",
        "                'stock_id': stock_id,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "# é¡¯ç¤ºå’Œé€šçŸ¥åŠŸèƒ½\n",
        "def display_terminal_results(results: Dict[str, Any], limit: int = 10):\n",
        "    \"\"\"åœ¨çµ‚ç«¯é¡¯ç¤ºåˆ†æçµæœ\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            print(\"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\")\n",
        "            return\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æçµæœ - å‰ååå„ªè³ªè‚¡ç¥¨\".center(80))\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\")\n",
        "        print(f\"ğŸ” æˆäº¤é‡ç¯©é¸æ¢ä»¶: â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if not successful_results:\n",
        "            print(\"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # è¡¨æ ¼æ¨™é¡Œ\n",
        "        print(f\"{'æ’å':<4}{'ä»£ç¢¼':<8}{'è‚¡ç¥¨åç¨±':<12}{'è©•åˆ†':<8}{'åƒ¹æ ¼':<10}{'æ¼²è·Œ%':<8}{'å»ºè­°':<10}{'æˆäº¤é‡(å¼µ)':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # é¡¯ç¤ºå‰åå\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')[:10]  # é™åˆ¶é•·åº¦\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            rec_text = recommendation.get('recommendation', 'æŒæœ‰')[:8]  # é™åˆ¶é•·åº¦\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            volume_info = result.get('volume_analysis', {})\n",
        "            avg_volume_lots = volume_info.get('avg_volume_lots', 0)\n",
        "\n",
        "            print(f\"{i:<4}{stock_id:<8}{stock_name:<12}{score:<8.1f}{current_price:<10.2f}{price_change:<+8.2f}{rec_text:<10}{avg_volume_lots:<12.0f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰äº”å\n",
        "        print(\"\\nğŸ“Š è©³ç´°åˆ†æå ±å‘Š (å‰äº”å):\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:5], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {})\n",
        "            trend_analysis = result.get('trend_analysis', {})\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            volume_analysis = result.get('volume_analysis', {})\n",
        "\n",
        "            print(f\"\\n{i}. {stock_name} ({stock_id}) - è©•åˆ†: {score:.1f}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"ğŸ’° ç•¶å‰åƒ¹æ ¼: {result.get('current_price', 0):.2f}\")\n",
        "            print(f\"ğŸ“ˆ 5æ—¥æ¼²è·Œ: {result.get('price_change_5d', 0):+.2f}%\")\n",
        "            print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {recommendation.get('recommendation', 'æŒæœ‰')}\")\n",
        "            print(f\"ğŸ“Š ä¿¡å¿ƒåº¦: {recommendation.get('confidence', 'ä¸­ç­‰')}\")\n",
        "\n",
        "            # æŠ€è¡“æŒ‡æ¨™è©³æƒ…\n",
        "            print(f\"ğŸ” æŠ€è¡“æŒ‡æ¨™:\")\n",
        "            print(f\"   RSI: {technical_analysis.get('rsi_value', 50):.1f} ({technical_analysis.get('rsi_signal', 'ä¸­æ€§')})\")\n",
        "            print(f\"   MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\")\n",
        "            print(f\"   KD: K={technical_analysis.get('k_value', 50):.1f}, D={technical_analysis.get('d_value', 50):.1f}\")\n",
        "\n",
        "            # è¶¨å‹¢å’Œæˆäº¤é‡\n",
        "            print(f\"ğŸ“Š è¶¨å‹¢åˆ†æ: {trend_analysis.get('trend', 'ç›¤æ•´')}\")\n",
        "            print(f\"ğŸ“ˆ æˆäº¤é‡: {volume_analysis.get('avg_volume_lots', 0):.0f}å¼µ/æ—¥ ({volume_analysis.get('volume_trend', 'æ­£å¸¸')})\")\n",
        "\n",
        "            # å»ºè­°åŸå› \n",
        "            reasons = recommendation.get('reasons', [])\n",
        "            if reasons:\n",
        "                print(f\"ğŸ’¡ å»ºè­°åŸå› : {', '.join(reasons[:2])}\")  # é¡¯ç¤ºå‰å…©å€‹åŸå› \n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"âš ï¸  æŠ•è³‡æé†’:\")\n",
        "        print(\"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡ä¸€å®šæœ‰é¢¨éšª\")\n",
        "        print(\"â€¢ å·²ç¯©é¸æˆäº¤é‡â‰¥1000å¼µ/æ—¥çš„æ´»èºè‚¡ç¥¨\")\n",
        "        print(\"â€¢ è«‹å‹™å¿…çµåˆåŸºæœ¬é¢åˆ†æåšæœ€çµ‚æŠ•è³‡æ±ºç­–\")\n",
        "        print(\"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"é¡¯ç¤ºçµ‚ç«¯çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        print(f\"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºé€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        if not successful_results:\n",
        "            return \"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\"\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message = f\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æå ±å‘Š\\n\"\n",
        "        message += f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "        message += f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\\n\"\n",
        "        message += f\"ğŸ” æˆäº¤é‡ç¯©é¸: â‰¥1000å¼µ/æ—¥\\n\\n\"\n",
        "\n",
        "        message += \"ğŸ… å‰ååå„ªè³ªè‚¡ç¥¨:\\n\"\n",
        "        message += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            current_price = result.get('current_price', 0)\n",
        "            price_change = result.get('price_change_5d', 0)\n",
        "            recommendation = result.get('recommendation', {}).get('recommendation', 'æŒæœ‰')\n",
        "\n",
        "            message += f\"{i:2d}. {stock_name} ({stock_id})\\n\"\n",
        "            message += f\"    ğŸ’° åƒ¹æ ¼: {current_price:.2f} ({price_change:+.1f}%)\\n\"\n",
        "            message += f\"    ğŸ“Š è©•åˆ†: {score:.1f} | ğŸ¯ {recommendation}\\n\\n\"\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰ä¸‰å\n",
        "        message += \"\\nğŸ“Š è©³ç´°åˆ†æ (å‰ä¸‰å):\\n\"\n",
        "        message += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:3], 1):\n",
        "            stock_name = result.get('stock_name', 'Unknown')\n",
        "            stock_id = result.get('stock_id', 'Unknown')\n",
        "            technical_analysis = result.get('technical_analysis', {})\n",
        "            quadrant_analysis = result.get('quadrant_analysis', {})\n",
        "\n",
        "            message += f\"\\n{i}. {stock_name} ({stock_id})\\n\"\n",
        "            message += f\"ğŸ” RSI: {technical_analysis.get('rsi_value', 50):.1f}\\n\"\n",
        "            message += f\"ğŸ“ˆ MACD: {technical_analysis.get('macd_signal', 'ä¸­æ€§')}\\n\"\n",
        "            if quadrant_analysis:\n",
        "                message += f\"ğŸ¯ å››è±¡é™: ç¬¬{quadrant_analysis.get('quadrant', 'N/A')}è±¡é™\\n\"\n",
        "\n",
        "        message += \"\\nâš ï¸ æŠ•è³‡æé†’:\\n\"\n",
        "        message += \"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\\n\"\n",
        "        message += \"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæ±ºç­–\\n\"\n",
        "        message += \"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\"\n",
        "\n",
        "        return message\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, chart_files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        # æª¢æŸ¥ Telegram è¨­å®š\n",
        "        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_IDS or TELEGRAM_BOT_TOKEN == \"YOUR_BOT_TOKEN_HERE\":\n",
        "            logger.warning(\"Telegram è¨­å®šæœªå®Œæˆï¼Œè·³éç™¼é€é€šçŸ¥\")\n",
        "            print(\"ğŸ“± Telegram è¨­å®šæœªå®Œæˆï¼Œè«‹è¨­å®š TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS\")\n",
        "        else:\n",
        "            # åˆ†å‰²é•·è¨Šæ¯\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            # å¦‚æœå–®è¡Œå¤ªé•·ï¼Œç›´æ¥æˆªæ–·\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            # ç™¼é€æ–‡å­—è¨Šæ¯çµ¦æ‰€æœ‰ chat_id\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_IDS:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† å°è‚¡åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {\n",
        "                        'chat_id': chat_id,\n",
        "                        'text': part\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id} (ç¬¬ {i+1}/{len(parts)} éƒ¨åˆ†)\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤åˆ° {chat_id} (ç¬¬ {i+1} éƒ¨åˆ†): {e}\")\n",
        "\n",
        "                    # é¿å…ç™¼é€å¤ªå¿«\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "                # ç™¼é€åœ–è¡¨æ–‡ä»¶\n",
        "                if chart_files:\n",
        "                    telegram_photo_url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto\"\n",
        "                    for chart_file in chart_files:\n",
        "                        if os.path.exists(chart_file):\n",
        "                            try:\n",
        "                                with open(chart_file, 'rb') as photo:\n",
        "                                    files = {'photo': photo}\n",
        "                                    data = {'chat_id': chat_id}\n",
        "\n",
        "                                    # ä½¿ç”¨ requests åŒæ­¥ç™¼é€åœ–ç‰‡ï¼ˆå› ç‚º aiohttp è™•ç†æ–‡ä»¶ä¸Šå‚³è¼ƒè¤‡é›œï¼‰\n",
        "                                    import requests\n",
        "                                    response = requests.post(telegram_photo_url, files=files, data=data, timeout=30)\n",
        "\n",
        "                                    if response.status_code == 200:\n",
        "                                        logger.info(f\"æˆåŠŸç™¼é€åœ–è¡¨åˆ° Telegram: {chart_file}\")\n",
        "                                    else:\n",
        "                                        logger.error(f\"ç™¼é€åœ–è¡¨å¤±æ•—: {response.status_code} - {response.text}\")\n",
        "                            except Exception as e:\n",
        "                                logger.error(f\"ç™¼é€åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥ (å¦‚æœå¯ç”¨)\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL and DISCORD_WEBHOOK_URL != \"YOUR_DISCORD_WEBHOOK_URL\":\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "\n",
        "            # æ·»åŠ åœ–è¡¨æ–‡ä»¶\n",
        "            if chart_files:\n",
        "                for chart_file in chart_files:\n",
        "                    if os.path.exists(chart_file):\n",
        "                        with open(chart_file, \"rb\") as f:\n",
        "                            webhook.add_file(file=f.read(), filename=os.path.basename(chart_file))\n",
        "\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code} {response.content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "def run_stock_screening():\n",
        "    \"\"\"åŸ·è¡Œè‚¡ç¥¨ç¯©é¸åŠŸèƒ½\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"å°è‚¡ç¯©é¸ç³»çµ±\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nç¯©é¸æ¢ä»¶:\")\n",
        "    print(\"1. æŠ€è¡“é¢\")\n",
        "    print(\"   - MACD: 0 < D-M < 1.5\")\n",
        "    print(\"   - æœ¬æ—¥æ”¶ç›¤åƒ¹é«˜æ–¼10æ—¥å‡åƒ¹ä¸”é«˜æ–¼30æ—¥å‡åƒ¹\")\n",
        "    print(\"   - æœ¬æ—¥è‚¡åƒ¹æ¼²å¹…5%ä»¥ä¸Š\")\n",
        "    print(\"2. ç±Œç¢¼é¢\")\n",
        "    print(\"   - æœ¬æ—¥æˆäº¤é‡5000å¼µä»¥ä¸Šä½†ä¸è¶…é30æ—¥å‡é‡çš„3å€\")\n",
        "    print(\"   - ç”±ç¬¦åˆç¯©é¸æ¢ä»¶ä¸­å–æˆäº¤é‡å‰ä¸‰å¤§ç‚ºæ¨™çš„\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    analyzer = StockAnalyzer()\n",
        "\n",
        "    # åŸ·è¡Œç¯©é¸\n",
        "    screened_stocks = analyzer.screen_stocks()\n",
        "\n",
        "    if screened_stocks:\n",
        "        print(f\"\\nğŸ¯ ç¯©é¸å®Œæˆï¼Œå…±æ‰¾åˆ° {len(screened_stocks)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "\n",
        "        # ç‚ºç¯©é¸å‡ºçš„è‚¡ç¥¨ç”Ÿæˆåœ–è¡¨\n",
        "        chart_files = []\n",
        "        for stock_data in screened_stocks:\n",
        "            chart_path = analyzer.create_stock_chart(stock_data)\n",
        "            if chart_path:\n",
        "                chart_files.append(chart_path)\n",
        "\n",
        "        return screened_stocks, chart_files\n",
        "    else:\n",
        "        print(\"\\nâŒ æœªæ‰¾åˆ°ç¬¦åˆç¯©é¸æ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "        return [], []\n",
        "\n",
        "async def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸš€ å°è‚¡æŠ€è¡“åˆ†æç¨‹å¼å•Ÿå‹•\")\n",
        "        print(f\"â° é–‹å§‹æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"ğŸ” åˆ†ææ¢ä»¶: æˆäº¤é‡â‰¥1000å¼µ/æ—¥\")\n",
        "        print(\"ğŸ† ç›®æ¨™: æ‰¾å‡ºå‰ååå„ªè³ªè‚¡ç¥¨\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # åˆå§‹åŒ–åˆ†æå™¨\n",
        "        analyzer = StockAnalyzer()\n",
        "\n",
        "        # åŸ·è¡Œå…¨éƒ¨è‚¡ç¥¨åˆ†æ\n",
        "        print(\"ğŸ“Š é–‹å§‹åˆ†ææ‰€æœ‰å°è‚¡ï¼ˆåŒ…å«æˆäº¤é‡ç¯©é¸ï¼‰...\")\n",
        "        results = await analyzer.analyze_all_stocks()\n",
        "\n",
        "        if not results:\n",
        "            error_message = \"âŒ åˆ†æå¤±æ•—ï¼Œæœªèƒ½ç²å–ä»»ä½•çµæœ\"\n",
        "            print(error_message)\n",
        "\n",
        "            # ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, error_message)\n",
        "            return\n",
        "\n",
        "        # åœ¨çµ‚ç«¯é¡¯ç¤ºçµæœ\n",
        "        display_terminal_results(results, limit=10)\n",
        "\n",
        "        # ç‚ºå‰ä¸‰åè‚¡ç¥¨ç”Ÿæˆåœ–è¡¨\n",
        "        print(\"\\nğŸ“Š æ­£åœ¨ç‚ºå‰ä¸‰åè‚¡ç¥¨ç”ŸæˆæŠ€è¡“åˆ†æåœ–è¡¨...\")\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        chart_files = []\n",
        "        for i, result in enumerate(successful_results[:3]):\n",
        "            print(f\"ç”Ÿæˆåœ–è¡¨ {i+1}/3: {result.get('stock_name', 'Unknown')}\")\n",
        "            chart_path = analyzer.create_stock_chart(result)\n",
        "            if chart_path:\n",
        "                chart_files.append(chart_path)\n",
        "\n",
        "        # æ ¼å¼åŒ–é€šçŸ¥è¨Šæ¯\n",
        "        print(\"\\nğŸ“± æ­£åœ¨æº–å‚™ç™¼é€é€šçŸ¥...\")\n",
        "        message = format_analysis_message(results, limit=10)\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        print(\"ğŸ“± æ­£åœ¨ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, message, chart_files)\n",
        "\n",
        "        print(f\"\\nâ° ç¨‹å¼åŸ·è¡Œå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"âœ… åˆ†æå ±å‘Šå·²å®Œæˆä¸¦ç™¼é€\")\n",
        "        print(\"ğŸ† å‰ååå„ªè³ªè‚¡ç¥¨å·²é¡¯ç¤ºåœ¨ä¸Šæ–¹\")\n",
        "        print(\"ğŸ“Š æŠ€è¡“åˆ†æåœ–è¡¨å·²ç”Ÿæˆä¸¦ç™¼é€\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"âŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\\n\\nè©³ç´°éŒ¯èª¤:\\n{traceback.format_exc()}\"\n",
        "        logger.error(error_message)\n",
        "        print(error_message)\n",
        "\n",
        "        # å˜—è©¦ç™¼é€éŒ¯èª¤é€šçŸ¥\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                await send_notification(session, f\"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\")\n",
        "        except Exception as notify_error:\n",
        "            logger.error(f\"ç™¼é€éŒ¯èª¤é€šçŸ¥å¤±æ•—: {notify_error}\")\n",
        "\n",
        "# ä½¿ç”¨ç¯„ä¾‹\n",
        "def example_usage():\n",
        "    \"\"\"ä½¿ç”¨ç¯„ä¾‹\"\"\"\n",
        "    analyzer = StockAnalyzer()\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"å°è‚¡æŠ€è¡“åˆ†æç³»çµ± - ä½¿ç”¨ç¯„ä¾‹\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # ç¯„ä¾‹1: åˆ†æå–®æ”¯è‚¡ç¥¨ï¼ˆåŒ…å«å¤šæ™‚é–“é€±æœŸåˆ†æï¼‰\n",
        "    print(\"\\n=== ç¯„ä¾‹1: å–®æ”¯è‚¡ç¥¨å®Œæ•´åˆ†æ ===\")\n",
        "    result = analyzer.analyze_single_stock_with_multi_timeframe(\"2330\")\n",
        "    if result['success']:\n",
        "        print(f\"è‚¡ç¥¨: {result['stock_id']} - {result.get('stock_name', 'Unknown')}\")\n",
        "        print(f\"ç•¶å‰åƒ¹æ ¼: {result['current_price']:.2f}\")\n",
        "        print(f\"ç¶œåˆåˆ†æ•¸: {result['combined_score']:.1f}\")\n",
        "        print(f\"æŠ•è³‡å»ºè­°: {result['recommendation']['recommendation']}\")\n",
        "\n",
        "        # é¡¯ç¤ºå››è±¡é™åˆ†æ\n",
        "        if result['quadrant_analysis']:\n",
        "            quad = result['quadrant_analysis']\n",
        "            print(f\"å››è±¡é™: ç¬¬{quad['quadrant']}è±¡é™ ({quad['trend']})\")\n",
        "\n",
        "        # é¡¯ç¤ºå¤šæ™‚é–“é€±æœŸåˆ†æ\n",
        "        if result['multi_timeframe_analysis']:\n",
        "            analyzer.generate_multi_timeframe_summary(result['multi_timeframe_analysis'], result['stock_id'])\n",
        "\n",
        "                # ç”Ÿæˆåœ–è¡¨\n",
        "        chart_path = analyzer.create_stock_chart(result)\n",
        "        if chart_path:\n",
        "            print(f\"æŠ€è¡“åˆ†æåœ–è¡¨å·²ç”Ÿæˆ: {chart_path}\")\n",
        "    else:\n",
        "        print(f\"åˆ†æå¤±æ•—: {result['error']}\")\n",
        "\n",
        "    # ç¯„ä¾‹2: è‚¡ç¥¨ç¯©é¸åŠŸèƒ½\n",
        "    print(\"\\n=== ç¯„ä¾‹2: è‚¡ç¥¨ç¯©é¸åŠŸèƒ½ ===\")\n",
        "    screened_stocks, chart_files = run_stock_screening()\n",
        "\n",
        "    # ç¯„ä¾‹3: æ‰¹é‡åˆ†æï¼ˆæ³¨æ„ï¼šé€™æœƒåˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼Œå¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“ï¼‰\n",
        "    print(\"\\n=== ç¯„ä¾‹3: æ‰¹é‡åˆ†æ ===\")\n",
        "    print(\"æ³¨æ„ï¼šæ‰¹é‡åˆ†ææœƒåˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼Œå¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“\")\n",
        "    user_input = input(\"æ˜¯å¦åŸ·è¡Œæ‰¹é‡åˆ†æï¼Ÿ(y/N): \")\n",
        "    if user_input.lower() == 'y':\n",
        "        results = asyncio.run(analyzer.analyze_all_stocks())\n",
        "        print(f\"æˆåŠŸåˆ†æ {len(results)} æ”¯è‚¡ç¥¨\")\n",
        "        display_terminal_results(results, limit=5)\n",
        "    else:\n",
        "        print(\"è·³éæ‰¹é‡åˆ†æ\")\n",
        "\n",
        "# å®šæ™‚åŸ·è¡ŒåŠŸèƒ½\n",
        "def schedule_analysis():\n",
        "    \"\"\"å®šæ™‚åŸ·è¡Œåˆ†æ\"\"\"\n",
        "    import schedule\n",
        "    import time\n",
        "\n",
        "    def job():\n",
        "        \"\"\"å®šæ™‚ä»»å‹™\"\"\"\n",
        "        print(f\"\\nğŸ• å®šæ™‚åˆ†æé–‹å§‹: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        asyncio.run(main())\n",
        "        print(f\"ğŸ• å®šæ™‚åˆ†æå®Œæˆ: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "    # è¨­å®šæ’ç¨‹ï¼šæ¯å¤©æ—©ä¸Š9é»å’Œä¸‹åˆ2é»åŸ·è¡Œ\n",
        "    schedule.every().day.at(\"09:00\").do(job)\n",
        "    schedule.every().day.at(\"14:00\").do(job)\n",
        "\n",
        "    print(\"ğŸ“… å®šæ™‚åˆ†æå·²å•Ÿå‹•\")\n",
        "    print(\"â° åŸ·è¡Œæ™‚é–“: æ¯å¤© 09:00 å’Œ 14:00\")\n",
        "    print(\"æŒ‰ Ctrl+C åœæ­¢å®šæ™‚åŸ·è¡Œ\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            schedule.run_pending()\n",
        "            time.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nğŸ“… å®šæ™‚åˆ†æå·²åœæ­¢\")\n",
        "\n",
        "# äº’å‹•å¼é¸å–®\n",
        "def interactive_menu():\n",
        "    \"\"\"äº’å‹•å¼é¸å–®\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"ğŸ† å°è‚¡æŠ€è¡“åˆ†æç³»çµ±\".center(60))\n",
        "        print(\"=\" * 60)\n",
        "        print(\"1. ğŸ“Š åˆ†æå–®æ”¯è‚¡ç¥¨ï¼ˆå«å¤šæ™‚é–“é€±æœŸï¼‰\")\n",
        "        print(\"2. ğŸ” è‚¡ç¥¨ç¯©é¸åŠŸèƒ½\")\n",
        "        print(\"3. ğŸ“ˆ æ‰¹é‡åˆ†ææ‰€æœ‰è‚¡ç¥¨\")\n",
        "        print(\"4. ğŸ“± ç™¼é€æ¸¬è©¦é€šçŸ¥\")\n",
        "        print(\"5. ğŸ“… å•Ÿå‹•å®šæ™‚åˆ†æ\")\n",
        "        print(\"6. ğŸ”§ è¨­å®šç®¡ç†\")\n",
        "        print(\"7. â“ ä½¿ç”¨èªªæ˜\")\n",
        "        print(\"0. ğŸšª é€€å‡ºç¨‹å¼\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        choice = input(\"è«‹é¸æ“‡åŠŸèƒ½ (0-7): \").strip()\n",
        "\n",
        "        if choice == \"1\":\n",
        "            stock_id = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ (ä¾‹: 2330): \").strip()\n",
        "            if stock_id:\n",
        "                analyzer = StockAnalyzer()\n",
        "                result = analyzer.analyze_single_stock_with_multi_timeframe(stock_id)\n",
        "                if result['success']:\n",
        "                    print(f\"\\nâœ… åˆ†æå®Œæˆ: {result.get('stock_name', 'Unknown')} ({result['stock_id']})\")\n",
        "                    print(f\"ğŸ“Š ç¶œåˆè©•åˆ†: {result['combined_score']:.1f}\")\n",
        "                    print(f\"ğŸ¯ æŠ•è³‡å»ºè­°: {result['recommendation']['recommendation']}\")\n",
        "\n",
        "                    # ç”Ÿæˆåœ–è¡¨\n",
        "                    chart_path = analyzer.create_stock_chart(result)\n",
        "                    if chart_path:\n",
        "                        print(f\"ğŸ“Š åœ–è¡¨å·²ç”Ÿæˆ: {chart_path}\")\n",
        "\n",
        "                    # é¡¯ç¤ºå¤šæ™‚é–“é€±æœŸåˆ†æ\n",
        "                    if result.get('multi_timeframe_analysis'):\n",
        "                        show_detail = input(\"æ˜¯å¦é¡¯ç¤ºè©³ç´°å¤šæ™‚é–“é€±æœŸåˆ†æï¼Ÿ(y/N): \")\n",
        "                        if show_detail.lower() == 'y':\n",
        "                            analyzer.generate_multi_timeframe_summary(\n",
        "                                result['multi_timeframe_analysis'], result['stock_id'])\n",
        "                else:\n",
        "                    print(f\"âŒ åˆ†æå¤±æ•—: {result['error']}\")\n",
        "            else:\n",
        "                print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            screened_stocks, chart_files = run_stock_screening()\n",
        "            if chart_files:\n",
        "                print(f\"ğŸ“Š å·²ç”Ÿæˆ {len(chart_files)} å€‹æŠ€è¡“åˆ†æåœ–è¡¨\")\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            confirm = input(\"âš ï¸  æ‰¹é‡åˆ†æéœ€è¦è¼ƒé•·æ™‚é–“ï¼Œç¢ºå®šåŸ·è¡Œï¼Ÿ(y/N): \")\n",
        "            if confirm.lower() == 'y':\n",
        "                asyncio.run(main())\n",
        "            else:\n",
        "                print(\"âŒ å·²å–æ¶ˆæ‰¹é‡åˆ†æ\")\n",
        "\n",
        "        elif choice == \"4\":\n",
        "            test_message = f\"ğŸ§ª æ¸¬è©¦é€šçŸ¥\\nâ° æ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\\nâœ… é€šçŸ¥ç³»çµ±é‹ä½œæ­£å¸¸\"\n",
        "            asyncio.run(send_test_notification(test_message))\n",
        "\n",
        "        elif choice == \"5\":\n",
        "            confirm = input(\"âš ï¸  é€™å°‡å•Ÿå‹•å®šæ™‚åˆ†æï¼ˆæ¯å¤©09:00å’Œ14:00åŸ·è¡Œï¼‰ï¼Œç¢ºå®šå•Ÿå‹•ï¼Ÿ(y/N): \")\n",
        "            if confirm.lower() == 'y':\n",
        "                schedule_analysis()\n",
        "            else:\n",
        "                print(\"âŒ å·²å–æ¶ˆå®šæ™‚åˆ†æ\")\n",
        "\n",
        "        elif choice == \"6\":\n",
        "            settings_menu()\n",
        "\n",
        "        elif choice == \"7\":\n",
        "            show_help()\n",
        "\n",
        "        elif choice == \"0\":\n",
        "            print(\"ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨å°è‚¡æŠ€è¡“åˆ†æç³»çµ±ï¼\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥\")\n",
        "\n",
        "async def send_test_notification(message: str):\n",
        "    \"\"\"ç™¼é€æ¸¬è©¦é€šçŸ¥\"\"\"\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        await send_notification(session, message)\n",
        "    print(\"ğŸ“± æ¸¬è©¦é€šçŸ¥å·²ç™¼é€\")\n",
        "\n",
        "def settings_menu():\n",
        "    \"\"\"è¨­å®šé¸å–®\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"ğŸ”§ è¨­å®šç®¡ç†\".center(50))\n",
        "    print(\"=\" * 50)\n",
        "    print(\"1. ğŸ“± Telegram é€šçŸ¥è¨­å®š\")\n",
        "    print(\"2. ğŸ’¬ Discord é€šçŸ¥è¨­å®š\")\n",
        "    print(\"3. ğŸ“Š åˆ†æåƒæ•¸è¨­å®š\")\n",
        "    print(\"4. ğŸ” ç¯©é¸æ¢ä»¶è¨­å®š\")\n",
        "    print(\"0. ğŸ”™ è¿”å›ä¸»é¸å–®\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    choice = input(\"è«‹é¸æ“‡è¨­å®šé …ç›® (0-4): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        print(f\"\\nğŸ“± ç•¶å‰ Telegram è¨­å®š:\")\n",
        "        print(f\"Bot Token: {'å·²è¨­å®š' if TELEGRAM_BOT_TOKEN != 'YOUR_BOT_TOKEN_HERE' else 'æœªè¨­å®š'}\")\n",
        "        print(f\"Chat IDs: {TELEGRAM_CHAT_IDS if TELEGRAM_CHAT_IDS != ['YOUR_CHAT_ID_HERE'] else 'æœªè¨­å®š'}\")\n",
        "        print(\"\\nğŸ’¡ è«‹åœ¨ç¨‹å¼ç¢¼ä¸­ä¿®æ”¹ TELEGRAM_BOT_TOKEN å’Œ TELEGRAM_CHAT_IDS è®Šæ•¸\")\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        print(f\"\\nğŸ’¬ ç•¶å‰ Discord è¨­å®š:\")\n",
        "        print(f\"Webhook URL: {'å·²è¨­å®š' if DISCORD_WEBHOOK_URL != 'YOUR_DISCORD_WEBHOOK_URL' else 'æœªè¨­å®š'}\")\n",
        "        print(f\"Discord æ¨¡çµ„: {'å·²å®‰è£' if MESSAGING_AVAILABLE else 'æœªå®‰è£'}\")\n",
        "        print(\"\\nğŸ’¡ è«‹åœ¨ç¨‹å¼ç¢¼ä¸­ä¿®æ”¹ DISCORD_WEBHOOK_URL è®Šæ•¸\")\n",
        "\n",
        "    elif choice == \"3\":\n",
        "        analyzer = StockAnalyzer()\n",
        "        print(f\"\\nğŸ“Š ç•¶å‰åˆ†æåƒæ•¸:\")\n",
        "        print(f\"RSI é€±æœŸ: {analyzer.config['rsi_period']}\")\n",
        "        print(f\"MACD å¿«ç·š: {analyzer.config['macd_fast']}\")\n",
        "        print(f\"MACD æ…¢ç·š: {analyzer.config['macd_slow']}\")\n",
        "        print(f\"MACD ä¿¡è™Ÿç·š: {analyzer.config['macd_signal']}\")\n",
        "        print(f\"æœ€å°æˆäº¤é‡: {analyzer.config['min_volume_lots']} å¼µ/æ—¥\")\n",
        "        print(\"\\nğŸ’¡ å¦‚éœ€ä¿®æ”¹è«‹ç·¨è¼¯ StockAnalyzer.__init__ ä¸­çš„ config\")\n",
        "\n",
        "    elif choice == \"4\":\n",
        "        analyzer = StockAnalyzer()\n",
        "        print(f\"\\nğŸ” ç•¶å‰ç¯©é¸æ¢ä»¶:\")\n",
        "        conditions = analyzer.config['screen_conditions']\n",
        "        print(f\"æœ€å°æ¼²å¹…: {conditions['min_price_change']}%\")\n",
        "        print(f\"æœ€å°æˆäº¤é‡: {conditions['min_volume_lots']} å¼µ\")\n",
        "        print(f\"æœ€å¤§æˆäº¤é‡å€æ•¸: {conditions['max_volume_ratio']} å€\")\n",
        "        print(f\"MACDå·®å€¼ç¯„åœ: {conditions['macd_diff_min']} ~ {conditions['macd_diff_max']}\")\n",
        "        print(\"\\nğŸ’¡ å¦‚éœ€ä¿®æ”¹è«‹ç·¨è¼¯ StockAnalyzer.__init__ ä¸­çš„ screen_conditions\")\n",
        "\n",
        "def show_help():\n",
        "    \"\"\"é¡¯ç¤ºä½¿ç”¨èªªæ˜\"\"\"\n",
        "    help_text = \"\"\"\n",
        "ğŸ“– å°è‚¡æŠ€è¡“åˆ†æç³»çµ± - ä½¿ç”¨èªªæ˜\n",
        "\n",
        "ğŸ¯ ç³»çµ±åŠŸèƒ½:\n",
        "1. ğŸ“Š å–®è‚¡åˆ†æ: æä¾›å®Œæ•´æŠ€è¡“æŒ‡æ¨™åˆ†æï¼ŒåŒ…å«å¤šæ™‚é–“é€±æœŸåˆ†æ\n",
        "2. ğŸ” è‚¡ç¥¨ç¯©é¸: æ ¹æ“šæŠ€è¡“é¢å’Œç±Œç¢¼é¢æ¢ä»¶ç¯©é¸å„ªè³ªè‚¡ç¥¨\n",
        "3. ğŸ“ˆ æ‰¹é‡åˆ†æ: åˆ†ææ‰€æœ‰å°è‚¡ï¼Œæ‰¾å‡ºè©•åˆ†æœ€é«˜çš„å‰åå\n",
        "4. ğŸ“± é€šçŸ¥åŠŸèƒ½: è‡ªå‹•ç™¼é€åˆ†æçµæœåˆ° Telegram å’Œ Discord\n",
        "5. ğŸ“Š åœ–è¡¨ç”Ÿæˆ: è‡ªå‹•ç”ŸæˆæŠ€è¡“åˆ†æåœ–è¡¨\n",
        "\n",
        "ğŸ”§ æŠ€è¡“æŒ‡æ¨™:\n",
        "â€¢ RSI: ç›¸å°å¼·å¼±æŒ‡æ¨™ï¼Œåˆ¤æ–·è¶…è²·è¶…è³£\n",
        "â€¢ MACD: æŒ‡æ•¸å¹³æ»‘ç§»å‹•å¹³å‡ç·šï¼Œåˆ¤æ–·è¶¨å‹¢è½‰æŠ˜\n",
        "â€¢ KD: éš¨æ©ŸæŒ‡æ¨™ï¼ŒçŸ­æœŸè²·è³£æ™‚æ©Ÿ\n",
        "â€¢ å¸ƒæ—å¸¶: åƒ¹æ ¼é€šé“ï¼Œåˆ¤æ–·åƒ¹æ ¼ç›¸å°ä½ç½®\n",
        "â€¢ ç§»å‹•å¹³å‡ç·š: MA5, MA10, MA20, MA30\n",
        "\n",
        "ğŸ¯ å››è±¡é™åˆ†æ:\n",
        "â€¢ ç¬¬ä¸€è±¡é™: å¼·å‹¢å¤šé ­ (MACD>Signal, RSI>50)\n",
        "â€¢ ç¬¬äºŒè±¡é™: å¤šé ­è­¦æˆ’ (MACD<Signal, RSI>50)\n",
        "â€¢ ç¬¬ä¸‰è±¡é™: å¼·å‹¢ç©ºé ­ (MACD<Signal, RSI<50)\n",
        "â€¢ ç¬¬å››è±¡é™: ç©ºé ­åè½‰ (MACD>Signal, RSI<50)\n",
        "\n",
        "ğŸ” ç¯©é¸æ¢ä»¶:\n",
        "â€¢ æŠ€è¡“é¢: MACDå·®å€¼0-1.5, åƒ¹æ ¼é«˜æ–¼å‡ç·š, æ¼²å¹…â‰¥5%\n",
        "â€¢ ç±Œç¢¼é¢: æˆäº¤é‡â‰¥5000å¼µä¸”â‰¤30æ—¥å‡é‡3å€\n",
        "\n",
        "ğŸ“± é€šçŸ¥è¨­å®š:\n",
        "1. ç”³è«‹ Telegram Bot Token\n",
        "2. ç²å– Chat ID\n",
        "3. åœ¨ç¨‹å¼ç¢¼ä¸­è¨­å®šç›¸é—œè®Šæ•¸\n",
        "4. å¯é¸: è¨­å®š Discord Webhook\n",
        "\n",
        "âš ï¸  é¢¨éšªæé†’:\n",
        "â€¢ æœ¬ç³»çµ±åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°\n",
        "â€¢ æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°\n",
        "â€¢ å»ºè­°çµåˆåŸºæœ¬é¢åˆ†æ\n",
        "â€¢ è«‹åšå¥½é¢¨éšªæ§åˆ¶å’Œè³‡é‡‘ç®¡ç†\n",
        "\n",
        "ğŸ’¡ æŠ€è¡“æ”¯æ´:\n",
        "â€¢ ç¢ºä¿ç¶²è·¯é€£ç·šæ­£å¸¸\n",
        "â€¢ è‚¡ç¥¨æ•¸æ“šä¾†æº: Yahoo Finance\n",
        "â€¢ å»ºè­°åœ¨äº¤æ˜“æ™‚é–“å¤–åŸ·è¡Œæ‰¹é‡åˆ†æ\n",
        "â€¢ å¦‚é‡å•é¡Œè«‹æª¢æŸ¥æ—¥èªŒè¼¸å‡º\n",
        "\"\"\"\n",
        "    print(help_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸš€ å°è‚¡æŠ€è¡“åˆ†æç³»çµ±\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"é¸æ“‡åŸ·è¡Œæ¨¡å¼:\")\n",
        "    print(\"1. ğŸ–¥ï¸  äº’å‹•å¼é¸å–®\")\n",
        "    print(\"2. ğŸ”„ ç›´æ¥åŸ·è¡Œä¸»ç¨‹å¼\")\n",
        "    print(\"3. ğŸ“š æŸ¥çœ‹ä½¿ç”¨ç¯„ä¾‹\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    mode = input(\"è«‹é¸æ“‡æ¨¡å¼ (1-3): \").strip()\n",
        "\n",
        "    if mode == \"1\":\n",
        "        interactive_menu()\n",
        "    elif mode == \"2\":\n",
        "        asyncio.run(main())\n",
        "    elif mode == \"3\":\n",
        "        example_usage()\n",
        "    else:\n",
        "        print(\"âŒ ç„¡æ•ˆé¸æ“‡ï¼Œå•Ÿå‹•äº’å‹•å¼é¸å–®\")\n",
        "        interactive_menu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import seaborn as sns\n",
        "from io import StringIO\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import json\n",
        "import pickle\n",
        "from typing import Dict, List, Any, Optional\n",
        "import random\n",
        "\n",
        "# æ©Ÿå™¨å­¸ç¿’ç›¸é—œ\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# é€šçŸ¥ç›¸é—œ\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# Jupyter Notebook æ”¯æ´\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "    import ipywidgets as widgets\n",
        "    from ipywidgets import Layout, HTML, Button, HBox, VBox, Output\n",
        "    from IPython.display import display, clear_output\n",
        "    JUPYTER_AVAILABLE = True\n",
        "except ImportError:\n",
        "    JUPYTER_AVAILABLE = False\n",
        "\n",
        "# Shioaji æ”¯æ´\n",
        "try:\n",
        "    import shioaji as sj\n",
        "    SHIOAJI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SHIOAJI_AVAILABLE = False\n",
        "\n",
        "# =============================================================================\n",
        "# å…¨åŸŸè¨­å®š\n",
        "# =============================================================================\n",
        "\n",
        "# ç¦æ­¢ä¸­æ–‡éŒ¯èª¤è­¦å‘Š\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ä¸­æ–‡å­—é«”è¨­å®š\n",
        "plt.rcParams['font.sans-serif'] = [\n",
        "    'Microsoft JhengHei',  # ç¹é«”ä¸­æ–‡\n",
        "    'SimHei',              # ç°¡é«”ä¸­æ–‡\n",
        "    'Arial Unicode MS',    # Unicode å­—é«”\n",
        "    'DejaVu Sans'         # åŸºç¤å­—é«”\n",
        "]\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# é€šçŸ¥è¨­å®š\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# åœ–è¡¨å„²å­˜ç›®éŒ„\n",
        "CHARTS_DIR = 'charts'\n",
        "if not os.path.exists(CHARTS_DIR):\n",
        "    os.makedirs(CHARTS_DIR)\n",
        "\n",
        "print(\"ğŸš€ ç’°å¢ƒè¨­å®šå®Œæˆï¼Œé–‹å§‹å»ºç«‹åˆ†æç³»çµ±...\")\n",
        "\n",
        "# =============================================================================\n",
        "# 1. æ•¸æ“šç²å–æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def fetch_from_cnn():\n",
        "    \"\"\"å¾CNNç¶²ç«™ç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\"\"\"\n",
        "    url = \"https://money.cnn.com/data/fear-and-greed/\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for element in soup.find_all(['div', 'span']):\n",
        "            if \"Fear & Greed Now:\" in element.get_text():\n",
        "                number_match = re.search(r'(\\d+)', element.get_text())\n",
        "                if number_match:\n",
        "                    value = int(number_match.group(1))\n",
        "                    logger.info(f\"æˆåŠŸå¾CNNç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸: {value}\")\n",
        "                    return value\n",
        "        logger.warning(\"ç„¡æ³•å¾CNNæå–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾CNNç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_from_alternative_me(limit=1):\n",
        "    \"\"\"å¾alternative.me APIç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\"\"\"\n",
        "    try:\n",
        "        url = f\"https://api.alternative.me/fng/?limit={limit}&format=json\"\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if 'data' in data and len(data['data']) > 0:\n",
        "            if limit == 1:\n",
        "                value = int(data['data'][0]['value'])\n",
        "                logger.info(f\"æˆåŠŸå¾Alternative.me APIç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸: {value}\")\n",
        "                return value\n",
        "            else:\n",
        "                df = pd.DataFrame(data['data'])\n",
        "                df['value'] = pd.to_numeric(df['value'])\n",
        "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
        "                df = df.rename(columns={'timestamp': 'Date', 'value': 'FearGreedIndex'})\n",
        "                df['Date'] = pd.to_datetime(df['Date'])\n",
        "                logger.info(f\"æˆåŠŸç²å– {len(df)} å¤©çš„æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“š\")\n",
        "                return df[['Date', 'FearGreedIndex']]\n",
        "        else:\n",
        "            logger.warning(\"Alternative.me APIè¿”å›çš„æ•¸æ“šæ ¼å¼ä¸æ­£ç¢º\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾Alternative.meç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_fear_and_greed_data(days):\n",
        "    \"\"\"ç²å–å³æ™‚èˆ‡æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“š\"\"\"\n",
        "    logger.info(\"æ­£åœ¨ç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸...\")\n",
        "\n",
        "    current_value = fetch_from_cnn()\n",
        "    if current_value is None:\n",
        "        current_value = fetch_from_alternative_me(limit=1)\n",
        "\n",
        "    historical_df = fetch_from_alternative_me(limit=days)\n",
        "\n",
        "    if historical_df is not None:\n",
        "        logger.info(\"å·²æˆåŠŸç²å–çœŸå¯¦æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“šã€‚\")\n",
        "        if current_value is not None:\n",
        "            today = pd.to_datetime(datetime.now().date())\n",
        "            if today not in historical_df['Date'].values:\n",
        "                new_row = pd.DataFrame([{'Date': today, 'FearGreedIndex': current_value}])\n",
        "                historical_df = pd.concat([historical_df, new_row], ignore_index=True)\n",
        "        return historical_df.drop_duplicates(subset=['Date'], keep='last')\n",
        "\n",
        "    logger.warning(\"ç„¡æ³•ç²å–çœŸå¯¦æ­·å²æ•¸æ“šï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šä½œç‚ºå‚™æ¡ˆã€‚\")\n",
        "    if current_value is None:\n",
        "        current_value = 50\n",
        "        logger.warning(f\"æ‰€æœ‰å³æ™‚ä¾†æºå‡å¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼ {current_value}\")\n",
        "\n",
        "    dates = pd.to_datetime([datetime.now() - timedelta(days=i) for i in range(days)]).sort_values()\n",
        "    scores = [current_value]\n",
        "    np.random.seed(42)\n",
        "    for _ in range(1, days):\n",
        "        mean_reversion = 0.1 * (50 - scores[-1])\n",
        "        random_change = np.random.normal(0, 3)\n",
        "        new_score = scores[-1] + mean_reversion + random_change\n",
        "        scores.append(max(0, min(100, new_score)))\n",
        "\n",
        "    return pd.DataFrame({'Date': dates, 'FearGreedIndex': scores})\n",
        "\n",
        "def fetch_stock_data(symbol, period='1y'):\n",
        "    \"\"\"å¾Yahoo Financeç²å–è‚¡ç¥¨æ•¸æ“šï¼Œè‡ªå‹•åˆ¤æ–·å°è‚¡/ç¾è‚¡\"\"\"\n",
        "    original_symbol = symbol\n",
        "\n",
        "    # å¦‚æœè¼¸å…¥çš„æ˜¯ç´”æ•¸å­—ï¼Œåˆ¤æ–·ç‚ºå°è‚¡ä»£ç¢¼\n",
        "    if re.match(r'^\\d{4,5}$', symbol):\n",
        "        symbol += \".TW\"\n",
        "        logger.info(f\"æª¢æ¸¬åˆ°å°è‚¡ä»£ç¢¼ï¼Œè½‰æ›ç‚º {symbol}\")\n",
        "\n",
        "    logger.info(f\"æ­£åœ¨å¾Yahoo Financeç²å– {symbol} ({period}) çš„æ•¸æ“š...\")\n",
        "    try:\n",
        "        stock = yf.Ticker(symbol)\n",
        "        df = stock.history(period=period, interval='1d')\n",
        "        if df.empty:\n",
        "            logger.error(f\"ç„¡æ³•ç²å– {symbol} çš„æ•¸æ“šï¼Œè«‹æª¢æŸ¥ä»£ç¢¼æ˜¯å¦æ­£ç¢ºã€‚\")\n",
        "            return None\n",
        "\n",
        "        df.reset_index(inplace=True)\n",
        "        df['Date'] = pd.to_datetime(df['Date'].dt.date)\n",
        "\n",
        "        logger.info(f\"æˆåŠŸç²å– {original_symbol} çš„ {len(df)} ç­†æ•¸æ“š\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾Yahoo Financeç²å– {symbol} çš„æ•¸æ“šæ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================\n",
        "# 2. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"è¨ˆç®—å®Œæ•´çš„æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "    # ç§»å‹•å¹³å‡ç·š\n",
        "    df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "    df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "    df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "    df['MA60'] = df['Close'].rolling(window=60).mean()\n",
        "\n",
        "    # EMA\n",
        "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "\n",
        "    # MACD\n",
        "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']\n",
        "\n",
        "    # RSI\n",
        "    delta = df['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean()\n",
        "    avg_loss = loss.rolling(window=14).mean().replace(0, np.nan)\n",
        "    rs = avg_gain / avg_loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # å¸ƒæ—å¸¶\n",
        "    df['BB_Middle'] = df['MA20']\n",
        "    std_dev = df['Close'].rolling(window=20).std()\n",
        "    df['BB_Upper'] = df['BB_Middle'] + (std_dev * 2)\n",
        "    df['BB_Lower'] = df['BB_Middle'] - (std_dev * 2)\n",
        "\n",
        "    # KDæŒ‡æ¨™\n",
        "    low_min = df['Low'].rolling(window=9).min()\n",
        "    high_max = df['High'].rolling(window=9).max()\n",
        "    rsv = (df['Close'] - low_min) / (high_max - low_min) * 100\n",
        "    df['K'] = rsv.ewm(com=2).mean()\n",
        "    df['D'] = df['K'].ewm(com=2).mean()\n",
        "\n",
        "    # å¨å»‰æŒ‡æ¨™\n",
        "    df['Williams_R'] = -100 * (high_max - df['Close']) / (high_max - low_min)\n",
        "\n",
        "    # æˆäº¤é‡æŒ‡æ¨™\n",
        "    df['Volume_MA'] = df['Volume'].rolling(window=20).mean()\n",
        "    df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']\n",
        "\n",
        "    # OBV\n",
        "    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()\n",
        "\n",
        "    # ADX (ç°¡åŒ–ç‰ˆ)\n",
        "    high_diff = df['High'].diff()\n",
        "    low_diff = df['Low'].diff()\n",
        "    plus_dm = np.where((high_diff > low_diff) & (high_diff > 0), high_diff, 0)\n",
        "    minus_dm = np.where((low_diff > high_diff) & (low_diff > 0), low_diff, 0)\n",
        "    tr1 = df['High'] - df['Low']\n",
        "    tr2 = abs(df['High'] - df['Close'].shift(1))\n",
        "    tr3 = abs(df['Low'] - df['Close'].shift(1))\n",
        "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "    atr = tr.ewm(alpha=1/14, adjust=False).mean()\n",
        "    plus_di = 100 * (pd.Series(plus_dm).ewm(alpha=1/14, adjust=False).mean() / atr)\n",
        "    minus_di = 100 * (pd.Series(minus_dm).ewm(alpha=1/14, adjust=False).mean() / atr)\n",
        "    dx = 100 * (abs(plus_di - minus_di) / (plus_di + minus_di).replace(0, np.nan))\n",
        "    df['ADX'] = dx.ewm(alpha=1/14, adjust=False).mean()\n",
        "\n",
        "    # CCI\n",
        "    typical_price = (df['High'] + df['Low'] + df['Close']) / 3\n",
        "    sma_tp = typical_price.rolling(window=20).mean()\n",
        "    mad = typical_price.rolling(window=20).apply(lambda x: np.mean(np.abs(x - np.mean(x))))\n",
        "    df['CCI'] = (typical_price - sma_tp) / (0.015 * mad)\n",
        "\n",
        "    # MFI\n",
        "    typical_price = (df['High'] + df['Low'] + df['Close']) / 3\n",
        "    money_flow = typical_price * df['Volume']\n",
        "    mf_sign = np.where(typical_price.diff() > 0, 1, -1)\n",
        "    signed_mf = money_flow * mf_sign\n",
        "    positive_mf = np.where(signed_mf > 0, signed_mf, 0)\n",
        "    negative_mf = np.where(signed_mf < 0, -signed_mf, 0)\n",
        "    mfr = pd.Series(positive_mf).rolling(14).sum() / pd.Series(negative_mf).rolling(14).sum().replace(0, np.nan)\n",
        "    df['MFI'] = 100 - (100 / (1 + mfr))\n",
        "\n",
        "    return df\n",
        "\n",
        "def feature_engineering(df):\n",
        "    \"\"\"å‰µå»ºè¡ç”Ÿç‰¹å¾µ\"\"\"\n",
        "    # åƒ¹æ ¼è®ŠåŒ–\n",
        "    df['Price_Change_1d'] = df['Close'].pct_change(1)\n",
        "    df['Price_Change_5d'] = df['Close'].pct_change(5)\n",
        "    df['Price_Change_20d'] = df['Close'].pct_change(20)\n",
        "\n",
        "    # æ³¢å‹•ç‡\n",
        "    df['Volatility_5d'] = df['Close'].rolling(5).std()\n",
        "    df['Volatility_20d'] = df['Close'].rolling(20).std()\n",
        "\n",
        "    # å¸ƒæ—å¸¶ç›¸é—œ\n",
        "    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']\n",
        "    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower']).replace(0, np.nan)\n",
        "\n",
        "    # å‹•é‡æŒ‡æ¨™\n",
        "    df['Momentum_14'] = df['Close'] - df['Close'].shift(14)\n",
        "\n",
        "    # ç›¸å°å¼·åº¦\n",
        "    df['Relative_Volume'] = df['Volume'] / df['Volume_MA']\n",
        "\n",
        "    # å¡«å……NaNå€¼\n",
        "    df.bfill(inplace=True)\n",
        "    df.ffill(inplace=True)\n",
        "    df.fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# =============================================================================\n",
        "# 3. Kç·šå‹æ…‹è­˜åˆ¥æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def identify_candlestick_patterns(df):\n",
        "    \"\"\"è­˜åˆ¥å¸¸è¦‹çš„Kç·šå‹æ…‹\"\"\"\n",
        "    result_df = df.copy()\n",
        "\n",
        "    # åŸºæœ¬è¨ˆç®—\n",
        "    result_df['body_size'] = abs(result_df['Close'] - result_df['Open'])\n",
        "    result_df['upper_shadow'] = result_df['High'] - result_df[['Open', 'Close']].max(axis=1)\n",
        "    result_df['lower_shadow'] = result_df[['Open', 'Close']].min(axis=1) - result_df['Low']\n",
        "    result_df['total_range'] = result_df['High'] - result_df['Low']\n",
        "\n",
        "    # å‰å¹¾å¤©æ•¸æ“š\n",
        "    for i in range(1, 4):\n",
        "        result_df[f'prev{i}_open'] = result_df['Open'].shift(i)\n",
        "        result_df[f'prev{i}_high'] = result_df['High'].shift(i)\n",
        "        result_df[f'prev{i}_low'] = result_df['Low'].shift(i)\n",
        "        result_df[f'prev{i}_close'] = result_df['Close'].shift(i)\n",
        "        result_df[f'prev{i}_body_size'] = result_df['body_size'].shift(i)\n",
        "\n",
        "    # Kç·šè¶¨å‹¢\n",
        "    result_df['is_bullish'] = result_df['Close'] > result_df['Open']\n",
        "    result_df['is_bearish'] = result_df['Close'] < result_df['Open']\n",
        "\n",
        "    for i in range(1, 4):\n",
        "        result_df[f'prev{i}_is_bullish'] = result_df[f'prev{i}_close'] > result_df[f'prev{i}_open']\n",
        "        result_df[f'prev{i}_is_bearish'] = result_df[f'prev{i}_close'] < result_df[f'prev{i}_open']\n",
        "\n",
        "    # ç§»å‹•å¹³å‡ç·šè¶¨å‹¢åˆ¤æ–·\n",
        "    result_df['uptrend'] = (result_df['MA5'] > result_df['MA20']) & (result_df['Close'] > result_df['MA20'])\n",
        "    result_df['downtrend'] = (result_df['MA5'] < result_df['MA20']) & (result_df['Close'] < result_df['MA20'])\n",
        "\n",
        "    # åˆå§‹åŒ–å‹æ…‹æ¬„ä½\n",
        "    pattern_columns = [\n",
        "        'åå­—æ˜Ÿ_ä¸­æ€§', 'éŒ˜å­ç·š_çœ‹æ¼²', 'éŒ˜å­ç·š_çœ‹è·Œ', 'æµæ˜Ÿç·š_çœ‹è·Œ',\n",
        "        'åå™¬_çœ‹æ¼²', 'åå™¬_çœ‹è·Œ', 'æ¯å­ç·š_çœ‹æ¼²', 'æ¯å­ç·š_çœ‹è·Œ',\n",
        "        'æ™¨æ˜Ÿ_çœ‹æ¼²', 'æš®æ˜Ÿ_çœ‹è·Œ', 'ä¸‰ç™½å…µ_çœ‹æ¼²', 'ä¸‰é»‘é´‰_çœ‹è·Œ',\n",
        "        'ç©¿åˆºç·š_çœ‹æ¼²', 'çƒé›²è“‹é ‚_çœ‹è·Œ', 'é•·è…¿åå­—ç·š_ä¸­æ€§', 'ä¸ŠåŠç·š_çœ‹è·Œ',\n",
        "        'ç´¡éŒ˜_ä¸­æ€§', 'åè½‰_çœ‹æ¼²', 'åè½‰_çœ‹è·Œ'\n",
        "    ]\n",
        "\n",
        "    for col in pattern_columns:\n",
        "        result_df[col] = 0\n",
        "\n",
        "    # åå­—æ˜Ÿ\n",
        "    doji_condition = result_df['body_size'] <= 0.1 * result_df['total_range']\n",
        "    result_df.loc[doji_condition, 'åå­—æ˜Ÿ_ä¸­æ€§'] = 1\n",
        "\n",
        "    # éŒ˜å­ç·š\n",
        "    hammer_condition = (\n",
        "        (result_df['lower_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['upper_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "    result_df.loc[hammer_condition & result_df['downtrend'], 'éŒ˜å­ç·š_çœ‹æ¼²'] = 1\n",
        "    result_df.loc[hammer_condition & result_df['uptrend'], 'éŒ˜å­ç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # æµæ˜Ÿç·š\n",
        "    shooting_star_condition = (\n",
        "        (result_df['upper_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['lower_shadow'] <= 0.1 * result_df['total_range']) &\n",
        "        (result_df['body_size'] <= 0.3 * result_df['total_range'])\n",
        "    )\n",
        "    result_df.loc[shooting_star_condition & result_df['uptrend'], 'æµæ˜Ÿç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # çœ‹æ¼²åå™¬\n",
        "    bullish_engulfing = (\n",
        "        (~result_df['prev1_is_bullish']) &\n",
        "        result_df['is_bullish'] &\n",
        "        (result_df['Open'] < result_df['prev1_close']) &\n",
        "        (result_df['Close'] > result_df['prev1_open'])\n",
        "    )\n",
        "    result_df.loc[bullish_engulfing & result_df['downtrend'], 'åå™¬_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # çœ‹è·Œåå™¬\n",
        "    bearish_engulfing = (\n",
        "        result_df['prev1_is_bullish'] &\n",
        "        (~result_df['is_bullish']) &\n",
        "        (result_df['Open'] > result_df['prev1_close']) &\n",
        "        (result_df['Close'] < result_df['prev1_open'])\n",
        "    )\n",
        "    result_df.loc[bearish_engulfing & result_df['uptrend'], 'åå™¬_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # çœ‹æ¼²æ¯å­ç·š\n",
        "    bullish_harami = (\n",
        "        (~result_df['prev1_is_bullish']) &\n",
        "        result_df['is_bullish'] &\n",
        "        (result_df['High'] < result_df['prev1_high']) &\n",
        "        (result_df['Low'] > result_df['prev1_low']) &\n",
        "        (result_df['body_size'] < result_df['prev1_body_size'])\n",
        "    )\n",
        "    result_df.loc[bullish_harami & result_df['downtrend'], 'æ¯å­ç·š_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # çœ‹è·Œæ¯å­ç·š\n",
        "    bearish_harami = (\n",
        "        result_df['prev1_is_bullish'] &\n",
        "        (~result_df['is_bullish']) &\n",
        "        (result_df['High'] < result_df['prev1_high']) &\n",
        "        (result_df['Low'] > result_df['prev1_low']) &\n",
        "        (result_df['body_size'] < result_df['prev1_body_size'])\n",
        "    )\n",
        "    result_df.loc[bearish_harami & result_df['uptrend'], 'æ¯å­ç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # æ™¨æ˜Ÿ\n",
        "    morning_star = (\n",
        "        (~result_df['prev2_is_bullish']) &\n",
        "        (result_df['prev1_body_size'] <= 0.3 * result_df['prev1_total_range']) &\n",
        "        result_df['is_bullish'] &\n",
        "        (result_df['Close'] > (result_df['prev2_open'] + result_df['prev2_close']) / 2)\n",
        "    )\n",
        "    result_df.loc[morning_star & result_df['downtrend'], 'æ™¨æ˜Ÿ_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # æš®æ˜Ÿ\n",
        "    evening_star = (\n",
        "        result_df['prev2_is_bullish'] &\n",
        "        (result_df['prev1_body_size'] <= 0.3 * result_df['prev1_total_range']) &\n",
        "        (~result_df['is_bullish']) &\n",
        "        (result_df['Close'] < (result_df['prev2_open'] + result_df['prev2_close']) / 2)\n",
        "    )\n",
        "    result_df.loc[evening_star & result_df['uptrend'], 'æš®æ˜Ÿ_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # ä¸‰ç™½å…µ\n",
        "    three_white_soldiers = (\n",
        "        result_df['is_bullish'] &\n",
        "        result_df['prev1_is_bullish'] &\n",
        "        result_df['prev2_is_bullish'] &\n",
        "        (result_df['Close'] > result_df['prev1_close']) &\n",
        "        (result_df['prev1_close'] > result_df['prev2_close']) &\n",
        "        (result_df['Open'] > result_df['prev1_open']) &\n",
        "        (result_df['prev1_open'] > result_df['prev2_open'])\n",
        "    )\n",
        "    result_df.loc[three_white_soldiers, 'ä¸‰ç™½å…µ_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # ä¸‰é»‘é´‰\n",
        "    three_black_crows = (\n",
        "        (~result_df['is_bullish']) &\n",
        "        (~result_df['prev1_is_bullish']) &\n",
        "        (~result_df['prev2_is_bullish']) &\n",
        "        (result_df['Close'] < result_df['prev1_close']) &\n",
        "        (result_df['prev1_close'] < result_df['prev2_close']) &\n",
        "        (result_df['Open'] < result_df['prev1_open']) &\n",
        "        (result_df['prev1_open'] < result_df['prev2_open'])\n",
        "    )\n",
        "    result_df.loc[three_black_crows, 'ä¸‰é»‘é´‰_çœ‹è·Œ'] = -1\n",
        "\n",
        "    return result_df\n",
        "\n",
        "def generate_pattern_report(df, periods=['daily']):\n",
        "    \"\"\"ç”ŸæˆKç·šå‹æ…‹åˆ†æå ±å‘Š\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šæ•¸æ“šç‚ºç©º\"\n",
        "\n",
        "    required_cols = ['Open', 'High', 'Low', 'Close']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šç¼ºå°‘å¿…è¦æ¬„ä½\"\n",
        "\n",
        "    def detect_patterns(ohlc_data):\n",
        "        patterns = {\"çœ‹æ¼²\": [], \"çœ‹è·Œ\": [], \"ä¸­æ€§\": []}\n",
        "\n",
        "        if len(ohlc_data) < 5:\n",
        "            return patterns\n",
        "\n",
        "        recent = ohlc_data.tail(10).copy()\n",
        "        recent['body_size'] = abs(recent['Close'] - recent['Open'])\n",
        "        recent['upper_shadow'] = recent['High'] - recent[['Open', 'Close']].max(axis=1)\n",
        "        recent['lower_shadow'] = recent[['Open', 'Close']].min(axis=1) - recent['Low']\n",
        "        recent['total_range'] = recent['High'] - recent['Low']\n",
        "        recent['is_bullish'] = recent['Close'] > recent['Open']\n",
        "        recent['is_bearish'] = recent['Close'] < recent['Open']\n",
        "\n",
        "        # è¨ˆç®—ç§»å‹•å¹³å‡ç·š\n",
        "        recent['ma5'] = recent['Close'].rolling(window=5).mean()\n",
        "        recent['ma10'] = recent['Close'].rolling(window=10).mean()\n",
        "\n",
        "        last3 = recent.tail(3)\n",
        "\n",
        "        # ä¸‰ç™½å…µ\n",
        "        if len(last3) == 3 and all(last3['is_bullish']) and \\\n",
        "           last3['Close'].iloc[0] < last3['Close'].iloc[1] < last3['Close'].iloc[2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"ä¸‰ç™½å…µ\")\n",
        "\n",
        "        # ä¸‰é»‘é´‰\n",
        "        if len(last3) == 3 and all(last3['is_bearish']) and \\\n",
        "           last3['Close'].iloc[0] > last3['Close'].iloc[1] > last3['Close'].iloc[2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ä¸‰é»‘é´‰\")\n",
        "\n",
        "        # å¤šé ­åå™¬\n",
        "        if len(last3) >= 2 and last3['is_bearish'].iloc[-2] and last3['is_bullish'].iloc[-1] and \\\n",
        "           last3['Open'].iloc[-1] <= last3['Close'].iloc[-2] and \\\n",
        "           last3['Close'].iloc[-1] >= last3['Open'].iloc[-2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"å¤šé ­åå™¬\")\n",
        "\n",
        "        # ç©ºé ­åå™¬\n",
        "        if len(last3) >= 2 and last3['is_bullish'].iloc[-2] and last3['is_bearish'].iloc[-1] and \\\n",
        "           last3['Open'].iloc[-1] >= last3['Close'].iloc[-2] and \\\n",
        "           last3['Close'].iloc[-1] <= last3['Open'].iloc[-2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ç©ºé ­åå™¬\")\n",
        "\n",
        "        # çœ‹æ¼²éŒ˜é ­\n",
        "        if any(last3['lower_shadow'] > 2 * last3['body_size']) and \\\n",
        "           any(last3['upper_shadow'] < 0.2 * last3['body_size']) and \\\n",
        "           any(last3['is_bullish']):\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"çœ‹æ¼²éŒ˜é ­\")\n",
        "\n",
        "        # çœ‹è·ŒåŠéŒ˜\n",
        "        if any(last3['upper_shadow'] > 2 * last3['body_size']) and \\\n",
        "           any(last3['lower_shadow'] < 0.2 * last3['body_size']) and \\\n",
        "           any(last3['is_bearish']):\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"çœ‹è·ŒåŠéŒ˜\")\n",
        "\n",
        "        # åå­—æ˜Ÿ\n",
        "        if any(last3['body_size'] < 0.1 * last3['total_range']):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"åå­—æ˜Ÿ\")\n",
        "\n",
        "        # é•·è…¿åå­—\n",
        "        if any((last3['body_size'] < 0.1 * last3['total_range']) &\n",
        "               (last3['upper_shadow'] > last3['body_size']) &\n",
        "               (last3['lower_shadow'] > last3['body_size'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"é•·è…¿åå­—\")\n",
        "\n",
        "        # ç´¡éŒ˜\n",
        "        if any((last3['body_size'] < 0.3 * last3['total_range']) &\n",
        "               (abs(last3['upper_shadow'] - last3['lower_shadow']) < 0.2 * last3['total_range'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"ç´¡éŒ˜\")\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    report_parts = []\n",
        "\n",
        "    for period in periods:\n",
        "        period_name = {'daily': 'æ—¥ç·š', 'weekly': 'é€±ç·š', 'monthly': 'æœˆç·š'}.get(period, period)\n",
        "\n",
        "        try:\n",
        "            patterns = detect_patterns(df)\n",
        "            period_report = [f\"{period_name}åˆ†æ:\"]\n",
        "\n",
        "            for pattern_type, detected_patterns in patterns.items():\n",
        "                if detected_patterns:\n",
        "                    pattern_str = \", \".join(detected_patterns)\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: {pattern_str}\")\n",
        "                else:\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: ç„¡\")\n",
        "\n",
        "            report_parts.append(\"\\n\".join(period_report))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {period_name} å‹æ…‹æ™‚å‡ºéŒ¯: {e}\")\n",
        "            report_parts.append(f\"{period_name}åˆ†æ:\\nåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤\")\n",
        "\n",
        "    return \"\\n\\n\".join(report_parts) if report_parts else \"æœªæª¢æ¸¬åˆ°æ˜é¡¯Kç·šå‹æ…‹\"\n",
        "\n",
        "# =============================================================================\n",
        "# 4. æ³¢æµªç†è«–åˆ†ææ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def wave_theory_analysis(df, stock_id):\n",
        "    \"\"\"å®Œæ•´çš„æ³¢æµªç†è«–åˆ†æ\"\"\"\n",
        "    close = df['Close'].values\n",
        "    high = df['High'].values\n",
        "    low = df['Low'].values\n",
        "\n",
        "    if len(close) < 30:\n",
        "        return False, \"æ•¸æ“šä¸è¶³\", None\n",
        "\n",
        "    # å°‹æ‰¾æœ€è¿‘çš„é¡¯è‘—é«˜é»ä½œç‚ºå¯èƒ½çš„3æµªé ‚é»\n",
        "    window = min(20, len(high) - 1)\n",
        "    peaks = []\n",
        "    troughs = []\n",
        "\n",
        "    # æ‰¾å‡ºæ‰€æœ‰å±€éƒ¨é«˜é»å’Œä½é»\n",
        "    for i in range(window, len(high) - window):\n",
        "        # æª¢æŸ¥æ˜¯å¦ç‚ºå±€éƒ¨é«˜é»\n",
        "        if high[i] == max(high[i-window:i+window+1]):\n",
        "            peaks.append((i, high[i]))\n",
        "        # æª¢æŸ¥æ˜¯å¦ç‚ºå±€éƒ¨ä½é»\n",
        "        if low[i] == min(low[i-window:i+window+1]):\n",
        "            troughs.append((i, low[i]))\n",
        "\n",
        "    # å¦‚æœæ²’æœ‰æ‰¾åˆ°è¶³å¤ çš„æ³¢å³°æ³¢è°·\n",
        "    if len(peaks) < 2 or len(troughs) < 2:\n",
        "        return False, \"ç„¡æ³•è­˜åˆ¥è¶³å¤ çš„æ³¢å³°æ³¢è°·\", None\n",
        "\n",
        "    # æŒ‰æ™‚é–“æ’åº\n",
        "    peaks.sort(key=lambda x: x[0])\n",
        "    troughs.sort(key=lambda x: x[0])\n",
        "\n",
        "    # å°‹æ‰¾å¯èƒ½çš„3æµªé«˜é»ï¼ˆæœ€å¾Œæˆ–å€’æ•¸ç¬¬äºŒå€‹é«˜é»ï¼‰\n",
        "    potential_wave3_peaks = []\n",
        "\n",
        "    # æª¢æŸ¥æœ€å¾Œä¸€å€‹é«˜é»\n",
        "    if peaks[-1][0] > troughs[-1][0]:  # æœ€å¾Œä¸€å€‹é«˜é»åœ¨æœ€å¾Œä¸€å€‹ä½é»ä¹‹å¾Œ\n",
        "        wave3_peak_idx, wave3_peak = peaks[-1]\n",
        "\n",
        "        # å°‹æ‰¾3æµªèµ·é»ï¼ˆå‰ä¸€å€‹ä½é»ï¼‰\n",
        "        for i in range(len(troughs) - 1, -1, -1):\n",
        "            if troughs[i][0] < wave3_peak_idx:\n",
        "                wave3_start_idx, wave3_start = troughs[i]\n",
        "                break\n",
        "        else:\n",
        "            wave3_start_idx, wave3_start = 0, low[0]\n",
        "\n",
        "        wave3_rise = wave3_peak - wave3_start\n",
        "        current_price = close[-1]\n",
        "        retracement = (wave3_peak - current_price) / wave3_rise if wave3_rise > 0 else 0\n",
        "\n",
        "        if 0.10 <= retracement <= 0.618:  # å›æ’¤æ¯”ä¾‹\n",
        "            potential_wave3_peaks.append((wave3_peak_idx, wave3_peak, wave3_start_idx, wave3_start, retracement))\n",
        "\n",
        "    # æª¢æŸ¥å€’æ•¸ç¬¬äºŒå€‹é«˜é»\n",
        "    if len(peaks) >= 2:\n",
        "        wave3_peak_idx, wave3_peak = peaks[-2]\n",
        "\n",
        "        # å°‹æ‰¾3æµªèµ·é»ï¼ˆå‰ä¸€å€‹ä½é»ï¼‰\n",
        "        for i in range(len(troughs) - 1, -1, -1):\n",
        "            if troughs[i][0] < wave3_peak_idx:\n",
        "                wave3_start_idx, wave3_start = troughs[i]\n",
        "                break\n",
        "        else:\n",
        "            wave3_start_idx, wave3_start = 0, low[0]\n",
        "\n",
        "        wave3_rise = wave3_peak - wave3_start\n",
        "        current_price = close[-1]\n",
        "        retracement = (wave3_peak - current_price) / wave3_rise if wave3_rise > 0 else 0\n",
        "\n",
        "        if 0.10 <= retracement <= 0.618:\n",
        "            potential_wave3_peaks.append((wave3_peak_idx, wave3_peak, wave3_start_idx, wave3_start, retracement))\n",
        "\n",
        "    # å¦‚æœæ²’æœ‰æ‰¾åˆ°å¯èƒ½çš„3æµªé«˜é»\n",
        "    if not potential_wave3_peaks:\n",
        "        return False, \"ç„¡æ³•è­˜åˆ¥ç¬¦åˆå›æ’¤æ¯”ä¾‹çš„3æµªé«˜é»\", None\n",
        "\n",
        "    # é¸æ“‡æœ€ä½³çš„3æµªé«˜é»ï¼ˆé¸æ“‡å›æ’¤æ¯”ä¾‹æœ€æ¥è¿‘0.382çš„ï¼‰\n",
        "    best_match = min(potential_wave3_peaks, key=lambda x: abs(x[4] - 0.382))\n",
        "    wave3_peak_idx, wave3_peak, wave3_start_idx, wave3_start, retracement = best_match\n",
        "\n",
        "    # æª¢æŸ¥æ˜¯å¦æœ‰1æµªé«˜é»\n",
        "    if wave3_start_idx > window:\n",
        "        # å°‹æ‰¾1æµªé«˜é»ï¼ˆåœ¨3æµªèµ·é»ä¹‹å‰çš„é«˜é»ï¼‰\n",
        "        wave1_candidates = [(i, h) for i, h in peaks if i < wave3_start_idx]\n",
        "        if wave1_candidates:\n",
        "            wave1_peak_idx, wave1_peak = max(wave1_candidates, key=lambda x: x[1])\n",
        "\n",
        "            # æª¢æŸ¥4æµªæ˜¯å¦èˆ‡1æµªé‡ç–Š\n",
        "            if close[-1] > wave1_peak:\n",
        "                wave_data = {\n",
        "                    'wave3_peak': wave3_peak,\n",
        "                    'wave3_start': wave3_start,\n",
        "                    'retracement': retracement,\n",
        "                    'current_price': close[-1],\n",
        "                    'wave1_peak': wave1_peak\n",
        "                }\n",
        "                return True, f\"4æµªå›æ’¤æ¯”ä¾‹: {retracement:.2%}, æœªèˆ‡1æµªé‡ç–Š\", wave_data\n",
        "            else:\n",
        "                return False, f\"4æµªèˆ‡1æµªé‡ç–Šï¼Œå›æ’¤æ¯”ä¾‹: {retracement:.2%}\", None\n",
        "        else:\n",
        "            # å¦‚æœæ‰¾ä¸åˆ°1æµªé«˜é»ï¼Œåƒ…ä¾æ“šå›æ’¤æ¯”ä¾‹åˆ¤æ–·\n",
        "            wave_data = {\n",
        "                'wave3_peak': wave3_peak,\n",
        "                'wave3_start': wave3_start,\n",
        "                'retracement': retracement,\n",
        "                'current_price': close[-1]\n",
        "            }\n",
        "            return True, f\"4æµªå›æ’¤æ¯”ä¾‹: {retracement:.2%}ï¼ˆç„¡æ³•ç¢ºèªèˆ‡1æµªé—œä¿‚ï¼‰\", wave_data\n",
        "    else:\n",
        "        wave_data = {\n",
        "            'wave3_peak': wave3_peak,\n",
        "            'wave3_start': wave3_start,\n",
        "            'retracement': retracement,\n",
        "            'current_price': close[-1]\n",
        "        }\n",
        "        return True, f\"4æµªå›æ’¤æ¯”ä¾‹: {retracement:.2%}ï¼ˆç„¡æ³•ç¢ºèªèˆ‡1æµªé—œä¿‚ï¼‰\", wave_data\n",
        "\n",
        "# =============================================================================\n",
        "# 5. æ©Ÿå™¨å­¸ç¿’é æ¸¬æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "class StockPredictor:\n",
        "    def __init__(self, target_days=7):\n",
        "        self.models = {\n",
        "            'ç·šæ€§è¿´æ­¸': LinearRegression(),\n",
        "            'éš¨æ©Ÿæ£®æ—': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "            'XGBoost': XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0),\n",
        "            'LightGBM': LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1)\n",
        "        }\n",
        "        self.scalers = {}\n",
        "        self.feature_names = None\n",
        "        self.target_days = target_days\n",
        "        self.backtest_results = {}\n",
        "        self.future_predictions = {}\n",
        "        self.feature_importances = None\n",
        "\n",
        "    def _prepare_data(self, df, predict_day):\n",
        "        \"\"\"æº–å‚™ç‰¹å¾µå’Œç›®æ¨™è®Šé‡\"\"\"\n",
        "        feature_columns = [\n",
        "            'MA5', 'MA10', 'MA20', 'MA60', 'MACD', 'MACD_Signal', 'RSI',\n",
        "            'BB_Width', 'BB_Position', 'K', 'D', 'Williams_R', 'ADX', 'CCI', 'MFI',\n",
        "            'Price_Change_1d', 'Price_Change_5d', 'Price_Change_20d',\n",
        "            'Volatility_5d', 'Volatility_20d', 'Momentum_14', 'Relative_Volume',\n",
        "            'FearGreedIndex'\n",
        "        ]\n",
        "        self.feature_names = [col for col in feature_columns if col in df.columns]\n",
        "\n",
        "        X = df[self.feature_names].copy()\n",
        "        y = df['Close'].shift(-predict_day)\n",
        "\n",
        "        valid_idx = ~y.isnull()\n",
        "        X = X[valid_idx]\n",
        "        y = y[valid_idx]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def run_backtest(self, df):\n",
        "        \"\"\"åŸ·è¡Œå›æ¸¬\"\"\"\n",
        "        logger.info(\"åŸ·è¡Œå›æ¸¬...\")\n",
        "        X, y = self._prepare_data(df, predict_day=1)\n",
        "\n",
        "        if len(X) < 50:\n",
        "            logger.warning(\"æ•¸æ“šé‡ä¸è¶³ï¼Œè·³éå›æ¸¬\")\n",
        "            return\n",
        "\n",
        "        split_index = int(len(X) * 0.8)\n",
        "        X_train, X_test = X[:split_index], X[split_index:]\n",
        "        y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            try:\n",
        "                model.fit(X_train_scaled, y_train)\n",
        "                y_pred = model.predict(X_test_scaled)\n",
        "                mse = mean_squared_error(y_test, y_pred)\n",
        "                r2 = r2_score(y_test, y_pred)\n",
        "                self.backtest_results[name] = {\n",
        "                    'y_test': y_test, 'y_pred': y_pred, 'mse': mse, 'r2': r2\n",
        "                }\n",
        "                logger.info(f\"[å›æ¸¬] {name} - RÂ²: {r2:.4f}, MSE: {mse:.4f}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"æ¨¡å‹ {name} è¨“ç·´å¤±æ•—: {e}\")\n",
        "\n",
        "        # ç‰¹å¾µé‡è¦æ€§\n",
        "        if 'éš¨æ©Ÿæ£®æ—' in self.models and hasattr(self.models['éš¨æ©Ÿæ£®æ—'], 'feature_importances_'):\n",
        "            self.feature_importances = pd.DataFrame({\n",
        "                'ç‰¹å¾µ': self.feature_names,\n",
        "                'é‡è¦æ€§': self.models['éš¨æ©Ÿæ£®æ—'].feature_importances_\n",
        "            }).sort_values('é‡è¦æ€§', ascending=False)\n",
        "\n",
        "    def predict_future(self, df):\n",
        "        \"\"\"é æ¸¬æœªä¾†åƒ¹æ ¼\"\"\"\n",
        "        logger.info(\"è¨“ç·´å®Œæ•´æ•¸æ“šé›†ä¸¦é æ¸¬æœªä¾†åƒ¹æ ¼...\")\n",
        "\n",
        "        for day in range(1, self.target_days + 1):\n",
        "            X, y = self._prepare_data(df, predict_day=day)\n",
        "\n",
        "            if X.empty or len(X) < 20:\n",
        "                logger.warning(f\"ç„¡æ³•ç‚ºé æ¸¬ç¬¬ {day} å¤©æº–å‚™æ•¸æ“šï¼Œè·³éã€‚\")\n",
        "                continue\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_scaled = scaler.fit_transform(X)\n",
        "            X_last = df[self.feature_names].iloc[-1:].copy()\n",
        "            X_last_scaled = scaler.transform(X_last)\n",
        "\n",
        "            daily_predictions = {}\n",
        "            for name, model in self.models.items():\n",
        "                try:\n",
        "                    model.fit(X_scaled, y)\n",
        "                    prediction = model.predict(X_last_scaled)[0]\n",
        "                    daily_predictions[name] = prediction\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"æ¨¡å‹ {name} é æ¸¬ç¬¬ {day} å¤©å¤±æ•—: {e}\")\n",
        "\n",
        "            if daily_predictions:\n",
        "                self.future_predictions[day] = daily_predictions\n",
        "\n",
        "# =============================================================================\n",
        "# 6. ç¶œåˆè©•åˆ†ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_combined_score(df):\n",
        "    \"\"\"è¨ˆç®—ç¶œåˆè©•åˆ†\"\"\"\n",
        "    if df.empty:\n",
        "        return 50\n",
        "\n",
        "    scores = []\n",
        "    latest = df.iloc[-1]\n",
        "\n",
        "    # æŠ€è¡“æŒ‡æ¨™è©•åˆ†\n",
        "    if 'RSI' in df.columns and not pd.isna(latest['RSI']):\n",
        "        rsi = latest['RSI']\n",
        "        if 30 <= rsi <= 50:\n",
        "            scores.append(70)  # æ½›åœ¨åå½ˆå€\n",
        "        elif 50 < rsi <= 70:\n",
        "            scores.append(60)  # å¼·å‹¢å€\n",
        "        elif rsi > 70:\n",
        "            scores.append(30)  # è¶…è²·\n",
        "        elif rsi < 30:\n",
        "            scores.append(80)  # è¶…è³£åå½ˆ\n",
        "        else:\n",
        "            scores.append(50)\n",
        "\n",
        "    # ç§»å‹•å¹³å‡ç·šè©•åˆ†\n",
        "    if all(col in df.columns for col in ['MA5', 'MA20', 'MA60']):\n",
        "        ma5, ma20, ma60 = latest['MA5'], latest['MA20'], latest['MA60']\n",
        "        if not any(pd.isna([ma5, ma20, ma60])):\n",
        "            if ma5 > ma20 > ma60:\n",
        "                scores.append(80)  # å¤šé ­æ’åˆ—\n",
        "            elif ma5 > ma20:\n",
        "                scores.append(65)  # çŸ­æœŸå¤šé ­\n",
        "            elif ma5 < ma20 < ma60:\n",
        "                scores.append(20)  # ç©ºé ­æ’åˆ—\n",
        "            else:\n",
        "                scores.append(45)\n",
        "\n",
        "    # MACDè©•åˆ†\n",
        "    if all(col in df.columns for col in ['MACD', 'MACD_Signal', 'MACD_Hist']):\n",
        "        macd, signal, hist = latest['MACD'], latest['MACD_Signal'], latest['MACD_Hist']\n",
        "        if not any(pd.isna([macd, signal, hist])):\n",
        "            if macd > signal and hist > 0:\n",
        "                scores.append(75)  # å¤šé ­ä¿¡è™Ÿ\n",
        "            elif macd > signal:\n",
        "                scores.append(60)  # æ½›åœ¨å¤šé ­\n",
        "            elif macd < signal and hist < 0:\n",
        "                scores.append(25)  # ç©ºé ­ä¿¡è™Ÿ\n",
        "            else:\n",
        "                scores.append(45)\n",
        "\n",
        "    # KDæŒ‡æ¨™è©•åˆ†\n",
        "    if all(col in df.columns for col in ['K', 'D']):\n",
        "        k, d = latest['K'], latest['D']\n",
        "        if not any(pd.isna([k, d])):\n",
        "            if k < 20 and d < 20:\n",
        "                scores.append(75)  # è¶…è³£\n",
        "            elif k > 80 and d > 80:\n",
        "                scores.append(25)  # è¶…è²·\n",
        "            elif k > d:\n",
        "                scores.append(60)  # é»ƒé‡‘äº¤å‰\n",
        "            else:\n",
        "                scores.append(40)  # æ­»äº¡äº¤å‰\n",
        "\n",
        "    # å¸ƒæ—å¸¶è©•åˆ†\n",
        "    if 'BB_Position' in df.columns and not pd.isna(latest['BB_Position']):\n",
        "        bb_pos = latest['BB_Position']\n",
        "        if bb_pos < 0.2:\n",
        "            scores.append(75)  # æ¥è¿‘ä¸‹è»Œ\n",
        "        elif bb_pos > 0.8:\n",
        "            scores.append(25)  # æ¥è¿‘ä¸Šè»Œ\n",
        "        else:\n",
        "            scores.append(50)\n",
        "\n",
        "    # åƒ¹æ ¼è¶¨å‹¢è©•åˆ†\n",
        "    if 'Price_Change_5d' in df.columns and not pd.isna(latest['Price_Change_5d']):\n",
        "        change = latest['Price_Change_5d']\n",
        "        if change > 0.1:\n",
        "            scores.append(80)  # å¼·å‹¢ä¸Šæ¼²\n",
        "        elif change > 0.05:\n",
        "            scores.append(65)  # æº«å’Œä¸Šæ¼²\n",
        "        elif change > 0:\n",
        "            scores.append(55)  # å¾®å¹…ä¸Šæ¼²\n",
        "        elif change > -0.05:\n",
        "            scores.append(45)  # å¾®å¹…ä¸‹è·Œ\n",
        "        elif change > -0.1:\n",
        "            scores.append(35)  # æº«å’Œä¸‹è·Œ\n",
        "        else:\n",
        "            scores.append(20)  # å¤§å¹…ä¸‹è·Œ\n",
        "\n",
        "    # æˆäº¤é‡è©•åˆ†\n",
        "    if 'Relative_Volume' in df.columns and not pd.isna(latest['Relative_Volume']):\n",
        "        vol_ratio = latest['Relative_Volume']\n",
        "        if vol_ratio > 2:\n",
        "            scores.append(70)  # çˆ†é‡\n",
        "        elif vol_ratio > 1.5:\n",
        "            scores.append(60)  # æ”¾é‡\n",
        "        elif vol_ratio < 0.5:\n",
        "            scores.append(40)  # ç¸®é‡\n",
        "        else:\n",
        "            scores.append(50)\n",
        "\n",
        "    # ææ‡¼è²ªå©ªæŒ‡æ•¸è©•åˆ†\n",
        "    if 'FearGreedIndex' in df.columns and not pd.isna(latest['FearGreedIndex']):\n",
        "        fgi = latest['FearGreedIndex']\n",
        "        if fgi < 25:\n",
        "            scores.append(75)  # æ¥µåº¦ææ‡¼ï¼Œåå½ˆæ©Ÿæœƒ\n",
        "        elif fgi < 45:\n",
        "            scores.append(65)  # ææ‡¼ï¼Œæ½›åœ¨æ©Ÿæœƒ\n",
        "        elif fgi > 75:\n",
        "            scores.append(30)  # æ¥µåº¦è²ªå©ªï¼Œé¢¨éšªé«˜\n",
        "        elif fgi > 55:\n",
        "            scores.append(40)  # è²ªå©ªï¼Œè¬¹æ…\n",
        "        else:\n",
        "            scores.append(50)  # ä¸­æ€§\n",
        "\n",
        "    return np.mean(scores) if scores else 50\n",
        "\n",
        "# =============================================================================\n",
        "# 7. æ™ºèƒ½å»ºè­°ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "def generate_recommendation(combined_score, pattern_report=None, wave_analysis=None):\n",
        "    \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "    try:\n",
        "        combined_score = float(combined_score)\n",
        "    except (ValueError, TypeError):\n",
        "        combined_score = 50.0\n",
        "\n",
        "    recommendation = {\n",
        "        \"action\": \"ä¸­ç«‹è§€å¯Ÿ\",\n",
        "        \"reason\": f\"ç¶œåˆè©•åˆ†ä¸­æ€§ ({combined_score:.2f})ã€‚\",\n",
        "        \"pattern_details\": [],\n",
        "        \"confidence\": 50,\n",
        "        \"risk_level\": \"ä¸­ç­‰\"\n",
        "    }\n",
        "\n",
        "    # åŸºæ–¼è©•åˆ†çš„å»ºè­°\n",
        "    if combined_score >= 80:\n",
        "        recommendation[\"action\"] = \"å¼·çƒˆè²·å…¥\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†æ¥µä½³ ({combined_score:.2f})ï¼Œå¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼·å‹¢ã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä½\"\n",
        "    elif combined_score >= 70:\n",
        "        recommendation[\"action\"] = \"è²·å…¥\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†è‰¯å¥½ ({combined_score:.2f})ï¼ŒæŠ€è¡“é¢åå¤šã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä½-ä¸­ç­‰\"\n",
        "    elif combined_score >= 60:\n",
        "        recommendation[\"action\"] = \"è²·å…¥è§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼· ({combined_score:.2f})ï¼Œå¯è€ƒæ…®åˆ†æ‰¹é€²å ´ã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä¸­ç­‰\"\n",
        "    elif combined_score <= 20:\n",
        "        recommendation[\"action\"] = \"å¼·çƒˆè³£å‡º\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†æ¥µå·® ({combined_score:.2f})ï¼Œå¤šé …æŒ‡æ¨™é¡¯ç¤ºå¼±å‹¢ã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"é«˜\"\n",
        "    elif combined_score <= 30:\n",
        "        recommendation[\"action\"] = \"è³£å‡º\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†ç–²å¼± ({combined_score:.2f})ï¼ŒæŠ€è¡“é¢åç©ºã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä¸­ç­‰-é«˜\"\n",
        "    elif combined_score <= 40:\n",
        "        recommendation[\"action\"] = \"è³£å‡ºè§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼± ({combined_score:.2f})ï¼Œå»ºè­°æ¸›å€‰ã€‚\"\n",
        "        recommendation[\"risk_level\"] = \"ä¸­ç­‰\"\n",
        "\n",
        "    # æ•´åˆKç·šå‹æ…‹åˆ†æ\n",
        "    if pattern_report and \"çœ‹æ¼²\" in pattern_report:\n",
        "        if combined_score >= 60:\n",
        "            recommendation[\"pattern_details\"].append(\"Kç·šå‹æ…‹æ”¯æŒçœ‹æ¼²è§€é»\")\n",
        "        else:\n",
        "            recommendation[\"pattern_details\"].append(\"Kç·šå‹æ…‹çœ‹æ¼²ä½†å…¶ä»–æŒ‡æ¨™åå¼±\")\n",
        "\n",
        "    if pattern_report and \"çœ‹è·Œ\" in pattern_report:\n",
        "        if combined_score <= 40:\n",
        "            recommendation[\"pattern_details\"].append(\"Kç·šå‹æ…‹æ”¯æŒçœ‹è·Œè§€é»\")\n",
        "        else:\n",
        "            recommendation[\"pattern_details\"].append(\"Kç·šå‹æ…‹çœ‹è·Œä½†å…¶ä»–æŒ‡æ¨™åå¼·\")\n",
        "\n",
        "    # æ•´åˆæ³¢æµªç†è«–åˆ†æ\n",
        "    if wave_analysis and wave_analysis[0]:  # å¦‚æœæ³¢æµªåˆ†æç‚ºTrue\n",
        "        recommendation[\"pattern_details\"].append(f\"æ³¢æµªç†è«–: {wave_analysis[1]}\")\n",
        "        if \"4æµªå›æ’¤\" in wave_analysis[1]:\n",
        "            if combined_score >= 60:\n",
        "                recommendation[\"action\"] = \"è²·å…¥\"\n",
        "                recommendation[\"reason\"] += \" æ³¢æµªç†è«–æ”¯æŒ5æµªä¸Šæ¼²ã€‚\"\n",
        "\n",
        "    # è¨ˆç®—ä¿¡å¿ƒåº¦\n",
        "    distance_from_center = abs(combined_score - 50)\n",
        "    base_confidence = min(distance_from_center * 2, 100)\n",
        "\n",
        "    # æ ¹æ“šå‹æ…‹åˆ†æèª¿æ•´ä¿¡å¿ƒåº¦\n",
        "    if recommendation[\"pattern_details\"]:\n",
        "        base_confidence = min(base_confidence + 10, 100)\n",
        "\n",
        "    recommendation['confidence'] = int(base_confidence)\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "# =============================================================================\n",
        "# 8. å¯è¦–åŒ–æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "class StockVisualizer:\n",
        "    def __init__(self, symbol):\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def plot_stock_analysis(self, df):\n",
        "        \"\"\"ç¹ªè£½è‚¡ç¥¨æŠ€è¡“åˆ†æåœ–\"\"\"\n",
        "        fig, axes = plt.subplots(4, 1, figsize=(16, 16), sharex=True)\n",
        "        fig.suptitle(f'{self.symbol} å®Œæ•´æŠ€è¡“åˆ†æç¸½è¦½', fontsize=20, fontweight='bold')\n",
        "\n",
        "        # åƒ¹æ ¼èˆ‡ç§»å‹•å¹³å‡ç·šã€å¸ƒæ—å¸¶\n",
        "        axes[0].plot(df['Date'], df['Close'], label='æ”¶ç›¤åƒ¹', linewidth=2, color='black')\n",
        "        if 'MA5' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['MA5'], label='MA5', alpha=0.8, color='blue')\n",
        "        if 'MA20' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['MA20'], label='MA20', alpha=0.8, color='red')\n",
        "        if 'MA60' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['MA60'], label='MA60', alpha=0.8, color='green')\n",
        "        if 'BB_Upper' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['BB_Upper'], label='å¸ƒæ—ä¸Šè»Œ', linestyle='--', alpha=0.7, color='gray')\n",
        "            axes[0].plot(df['Date'], df['BB_Lower'], label='å¸ƒæ—ä¸‹è»Œ', linestyle='--', alpha=0.7, color='gray')\n",
        "            axes[0].fill_between(df['Date'], df['BB_Lower'], df['BB_Upper'], alpha=0.1, color='gray')\n",
        "        axes[0].set_title('åƒ¹æ ¼èµ°å‹¢èˆ‡ç§»å‹•å¹³å‡ç·š')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # MACD\n",
        "        if 'MACD' in df.columns:\n",
        "            axes[1].plot(df['Date'], df['MACD'], label='MACD', color='blue')\n",
        "            axes[1].plot(df['Date'], df['MACD_Signal'], label='è¨Šè™Ÿç·š', color='red', linestyle='--')\n",
        "            if 'MACD_Hist' in df.columns:\n",
        "                colors = ['green' if x >= 0 else 'red' for x in df['MACD_Hist']]\n",
        "                axes[1].bar(df['Date'], df['MACD_Hist'], label='MACDæŸ±ç‹€åœ–', color=colors, alpha=0.6)\n",
        "        axes[1].set_title('MACD')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        axes[1].axhline(0, color='black', linestyle='-', alpha=0.3)\n",
        "\n",
        "        # RSI å’Œ KD\n",
        "        if 'RSI' in df.columns:\n",
        "            axes[2].plot(df['Date'], df['RSI'], label='RSI', color='purple', linewidth=2)\n",
        "            axes[2].axhline(70, color='red', linestyle='--', alpha=0.7, label='è¶…è²·å€ (70)')\n",
        "            axes[2].axhline(30, color='green', linestyle='--', alpha=0.7, label='è¶…è³£å€ (30)')\n",
        "            axes[2].axhline(50, color='black', linestyle='-', alpha=0.3)\n",
        "        if 'K' in df.columns and 'D' in df.columns:\n",
        "            axes[2].plot(df['Date'], df['K'], label='Kå€¼', color='orange', alpha=0.8)\n",
        "            axes[2].plot(df['Date'], df['D'], label='Då€¼', color='brown', alpha=0.8)\n",
        "        axes[2].set_title('RSI èˆ‡ KD æŒ‡æ¨™')\n",
        "        axes[2].legend()\n",
        "        axes[2].grid(True, alpha=0.3)\n",
        "        axes[2].set_ylim(0, 100)\n",
        "\n",
        "        # æˆäº¤é‡\n",
        "        volume_colors = ['green' if df['Close'].iloc[i] >= df['Open'].iloc[i] else 'red'\n",
        "                        for i in range(len(df))]\n",
        "        axes[3].bar(df['Date'], df['Volume'], color=volume_colors, alpha=0.6, label='æˆäº¤é‡')\n",
        "        if 'Volume_MA' in df.columns:\n",
        "            axes[3].plot(df['Date'], df['Volume_MA'], label='æˆäº¤é‡å‡ç·š', color='blue', linewidth=2)\n",
        "        axes[3].set_title('æˆäº¤é‡')\n",
        "        axes[3].legend()\n",
        "        axes[3].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "        return fig\n",
        "\n",
        "    def plot_future_prediction(self, last_price, last_date, predictions):\n",
        "        \"\"\"ç¹ªè£½æœªä¾†é æ¸¬åœ–\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        pred_dates, pred_prices_avg, pred_prices_std = [], [], []\n",
        "\n",
        "        current_date = last_date\n",
        "        for day, preds in predictions.items():\n",
        "            while True:\n",
        "                current_date += timedelta(days=1)\n",
        "                if current_date.weekday() < 5:  # å·¥ä½œæ—¥\n",
        "                    break\n",
        "\n",
        "            pred_dates.append(current_date)\n",
        "            prices = list(preds.values())\n",
        "            avg_price = np.mean(prices)\n",
        "            std_price = np.std(prices)\n",
        "            pred_prices_avg.append(avg_price)\n",
        "            pred_prices_std.append(std_price)\n",
        "\n",
        "        # ç¹ªè£½å¹³å‡é æ¸¬åƒ¹æ ¼\n",
        "        ax.plot(pred_dates, pred_prices_avg, 'ro-', label='å¹³å‡é æ¸¬åƒ¹æ ¼', linewidth=2, markersize=8)\n",
        "\n",
        "       # ç¹ªè£½ä¿¡å¿ƒå€é–“\n",
        "        upper_bound = np.array(pred_prices_avg) + np.array(pred_prices_std)\n",
        "        lower_bound = np.array(pred_prices_avg) - np.array(pred_prices_std)\n",
        "        ax.fill_between(pred_dates, lower_bound, upper_bound, alpha=0.3, color='blue', label='é æ¸¬å€é–“')\n",
        "\n",
        "        # ç•¶å‰åƒ¹æ ¼ç·š\n",
        "        ax.axhline(last_price, color='gray', linestyle='--', label=f'ç•¶å‰åƒ¹æ ¼ ({last_price:.2f})', linewidth=2)\n",
        "\n",
        "        # æ¨™è¨»é æ¸¬åƒ¹æ ¼\n",
        "        for date, price, std in zip(pred_dates, pred_prices_avg, pred_prices_std):\n",
        "            change_pct = (price / last_price - 1) * 100\n",
        "            ax.text(date, price, f'{price:.2f}\\n({change_pct:+.1f}%)',\n",
        "                   ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "        ax.set_title(f'{self.symbol} æœªä¾†ä¸€é€±è‚¡åƒ¹é æ¸¬', fontsize=16, fontweight='bold')\n",
        "        ax.set_xlabel('æ—¥æœŸ')\n",
        "        ax.set_ylabel('é æ¸¬åƒ¹æ ¼')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # æ ¼å¼åŒ–æ—¥æœŸè»¸\n",
        "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
        "        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_feature_importance(self, importances):\n",
        "        \"\"\"ç¹ªè£½ç‰¹å¾µé‡è¦æ€§åœ–\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "        top_15 = importances.head(15)\n",
        "\n",
        "        bars = ax.barh(top_15['ç‰¹å¾µ'], top_15['é‡è¦æ€§'], color='skyblue', edgecolor='navy', alpha=0.7)\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_title('ç‰¹å¾µé‡è¦æ€§æ’å (éš¨æ©Ÿæ£®æ—)', fontsize=16, fontweight='bold')\n",
        "        ax.set_xlabel('é‡è¦æ€§')\n",
        "\n",
        "        # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
        "        for bar, value in zip(bars, top_15['é‡è¦æ€§']):\n",
        "            ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2,\n",
        "                   f'{value:.3f}', ha='left', va='center', fontweight='bold')\n",
        "\n",
        "        ax.grid(True, alpha=0.3, axis='x')\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "# =============================================================================\n",
        "# 9. é€šçŸ¥ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, chart_files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        if TELEGRAM_TOKEN and TELEGRAM_CHAT_ID:\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_ID:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† è‚¡ç¥¨åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {'chat_id': chat_id, 'text': part}\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id}\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—: {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤: {e}\")\n",
        "\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "                # ç™¼é€åœ–è¡¨æ–‡ä»¶\n",
        "                if chart_files:\n",
        "                    telegram_photo_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                    for chart_file in chart_files:\n",
        "                        if os.path.exists(chart_file):\n",
        "                            try:\n",
        "                                with open(chart_file, 'rb') as photo:\n",
        "                                    files = {'photo': photo}\n",
        "                                    data = {'chat_id': chat_id}\n",
        "\n",
        "                                    import requests\n",
        "                                    response = requests.post(telegram_photo_url, files=files, data=data, timeout=30)\n",
        "\n",
        "                                    if response.status_code == 200:\n",
        "                                        logger.info(f\"æˆåŠŸç™¼é€åœ–è¡¨åˆ° Telegram: {chart_file}\")\n",
        "                                    else:\n",
        "                                        logger.error(f\"ç™¼é€åœ–è¡¨å¤±æ•—: {response.status_code}\")\n",
        "                            except Exception as e:\n",
        "                                logger.error(f\"ç™¼é€åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL:\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "\n",
        "            if chart_files:\n",
        "                for chart_file in chart_files:\n",
        "                    if os.path.exists(chart_file):\n",
        "                        with open(chart_file, \"rb\") as f:\n",
        "                            webhook.add_file(file=f.read(), filename=os.path.basename(chart_file))\n",
        "\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "def format_analysis_message(results: Dict[str, Any], limit: int = 10) -> str:\n",
        "    \"\"\"æ ¼å¼åŒ–åˆ†æçµæœç‚ºé€šçŸ¥è¨Šæ¯\"\"\"\n",
        "    try:\n",
        "        if not results:\n",
        "            return \"âŒ æœªèƒ½ç²å–ä»»ä½•åˆ†æçµæœ\"\n",
        "\n",
        "        # éæ¿¾æˆåŠŸçš„çµæœä¸¦æŒ‰åˆ†æ•¸æ’åº\n",
        "        successful_results = [\n",
        "            result for result in results.values()\n",
        "            if result.get('success', False) and result.get('combined_score', 0) > 0\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        if not successful_results:\n",
        "            return \"âŒ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å„ªè³ªè‚¡ç¥¨\"\n",
        "\n",
        "        # å»ºç«‹è¨Šæ¯\n",
        "        message = f\"ğŸ† å¤šè‚¡ç¥¨æŠ€è¡“åˆ†æå ±å‘Š\\n\"\n",
        "        message += f\"ğŸ“ˆ åˆ†ææ™‚é–“: {datetime.now(taipei_tz).strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "        message += f\"ğŸ“Š æˆåŠŸåˆ†æ: {len(successful_results)} æ”¯è‚¡ç¥¨\\n\\n\"\n",
        "\n",
        "        message += \"ğŸ… å‰ååå„ªè³ªè‚¡ç¥¨:\\n\"\n",
        "        message += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        top_stocks = successful_results[:limit]\n",
        "        for i, result in enumerate(top_stocks, 1):\n",
        "            symbol = result.get('symbol', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            current_price = result.get('last_price', 0)\n",
        "            recommendation = result.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "\n",
        "            message += f\"{i:2d}. {symbol}\\n\"\n",
        "            message += f\"    ğŸ’° åƒ¹æ ¼: {current_price:.2f}\\n\"\n",
        "            message += f\"    ğŸ“Š è©•åˆ†: {score:.1f} | ğŸ¯ {recommendation}\\n\\n\"\n",
        "\n",
        "        # è©³ç´°åˆ†æå‰ä¸‰å\n",
        "        message += \"\\nğŸ“Š è©³ç´°åˆ†æ (å‰ä¸‰å):\\n\"\n",
        "        message += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        for i, result in enumerate(top_stocks[:3], 1):\n",
        "            symbol = result.get('symbol', 'Unknown')\n",
        "\n",
        "            message += f\"\\n{i}. {symbol}\\n\"\n",
        "            if 'data_df' in result and not result['data_df'].empty:\n",
        "                latest = result['data_df'].iloc[-1]\n",
        "                if 'RSI' in result['data_df'].columns:\n",
        "                    message += f\"ğŸ” RSI: {latest['RSI']:.1f}\\n\"\n",
        "                if 'MACD' in result['data_df'].columns:\n",
        "                    macd_signal = \"å¤šé ­\" if latest['MACD'] > latest.get('MACD_Signal', 0) else \"ç©ºé ­\"\n",
        "                    message += f\"ğŸ“ˆ MACD: {macd_signal}\\n\"\n",
        "\n",
        "        message += \"\\nâš ï¸ æŠ•è³‡æé†’:\\n\"\n",
        "        message += \"â€¢ æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšª\\n\"\n",
        "        message += \"â€¢ è«‹çµåˆåŸºæœ¬é¢åˆ†æåšæ±ºç­–\\n\"\n",
        "        message += \"â€¢ å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶é¢¨éšª\"\n",
        "\n",
        "        return message\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        return f\"âŒ æ ¼å¼åŒ–è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "# =============================================================================\n",
        "# 10. è‚¡ç¥¨ç¯©é¸å™¨\n",
        "# =============================================================================\n",
        "\n",
        "def screen_stocks(stock_list, days_back, condition):\n",
        "    \"\"\"ç¯©é¸ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\"\"\"\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=days_back * 2)\n",
        "    results = pd.DataFrame(columns=['ticker', 'close', 'volume', 'change_pct'])\n",
        "\n",
        "    for ticker in stock_list:\n",
        "        try:\n",
        "            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "            if data.empty or len(data) < 20:\n",
        "                continue\n",
        "\n",
        "            data = data.tail(days_back)\n",
        "            data['change_pct'] = data['Close'].pct_change() * 100\n",
        "\n",
        "            if condition == \"çªç ´æ•´ç†å€é–“\":\n",
        "                high_20d = data['High'].rolling(window=20).max().shift(1)\n",
        "                if data['Close'].iloc[-1] > high_20d.iloc[-1]:\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"çˆ†é‡é•·ç´…\":\n",
        "                vol_5d_avg = data['Volume'].rolling(window=5).mean().shift(1)\n",
        "                if (data['Volume'].iloc[-1] > vol_5d_avg.iloc[-1] * 2 and\n",
        "                    data['change_pct'].iloc[-1] > 3):\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"çªç ´å­£ç·š\":\n",
        "                ma60 = data['Close'].rolling(window=60).mean()\n",
        "                if (data['Close'].iloc[-1] > ma60.iloc[-1] and\n",
        "                    data['Close'].iloc[-2] <= ma60.iloc[-2]):\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"å¤šé ­åå™¬\":\n",
        "                if len(data) >= 2:\n",
        "                    prev_candle = data.iloc[-2]\n",
        "                    curr_candle = data.iloc[-1]\n",
        "                    if (prev_candle['Close'] < prev_candle['Open'] and  # å‰ä¸€æ ¹ç‚ºé™°ç·š\n",
        "                        curr_candle['Close'] > curr_candle['Open'] and  # ç•¶å‰ç‚ºé™½ç·š\n",
        "                        curr_candle['Open'] < prev_candle['Close'] and  # ä½é–‹\n",
        "                        curr_candle['Close'] > prev_candle['Open']):    # é«˜æ”¶\n",
        "                        results = pd.concat([results, pd.DataFrame({\n",
        "                            'ticker': [ticker],\n",
        "                            'close': [data['Close'].iloc[-1]],\n",
        "                            'volume': [data['Volume'].iloc[-1]],\n",
        "                            'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                        })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰\":\n",
        "                ma5 = data['Close'].rolling(window=5).mean()\n",
        "                ma20 = data['Close'].rolling(window=20).mean()\n",
        "                if (ma5.iloc[-1] > ma20.iloc[-1] and\n",
        "                    ma5.iloc[-2] <= ma20.iloc[-2]):\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return results\n",
        "\n",
        "# =============================================================================\n",
        "# 11. ä¸»è¦åˆ†æç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "class MultiStockAnalysisSystem:\n",
        "    def __init__(self, symbols, period='1y'):\n",
        "        self.symbols = symbols if isinstance(symbols, list) else [symbols]\n",
        "        self.period = period\n",
        "        self.results = {}\n",
        "\n",
        "    async def analyze_stock(self, symbol):\n",
        "        \"\"\"åˆ†æå–®ä¸€è‚¡ç¥¨\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æ {symbol}...\")\n",
        "\n",
        "            # 1. ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            stock_df = fetch_stock_data(symbol, self.period)\n",
        "            if stock_df is None:\n",
        "                return None\n",
        "\n",
        "            # 2. ç²å–ææ‡¼è²ªå©ªæŒ‡æ•¸\n",
        "            days_needed = len(stock_df)\n",
        "            sentiment_df = get_fear_and_greed_data(days=days_needed + 60)\n",
        "\n",
        "            # 3. åˆä½µæ•¸æ“š\n",
        "            df = pd.merge(stock_df, sentiment_df, on='Date', how='left')\n",
        "\n",
        "            # 4. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—\n",
        "            df = calculate_technical_indicators(df)\n",
        "            df = feature_engineering(df)\n",
        "\n",
        "            # 5. Kç·šå‹æ…‹åˆ†æ\n",
        "            pattern_report = generate_pattern_report(df)\n",
        "\n",
        "            # 6. æ³¢æµªç†è«–åˆ†æ\n",
        "            wave_analysis = wave_theory_analysis(df, symbol)\n",
        "\n",
        "            # 7. ç¶œåˆè©•åˆ†\n",
        "            combined_score = calculate_combined_score(df)\n",
        "\n",
        "            # 8. æ©Ÿå™¨å­¸ç¿’é æ¸¬\n",
        "            predictor = StockPredictor()\n",
        "            predictor.run_backtest(df)\n",
        "            predictor.predict_future(df)\n",
        "\n",
        "            # 9. ç”Ÿæˆå»ºè­°\n",
        "            recommendation = generate_recommendation(combined_score, pattern_report, wave_analysis)\n",
        "\n",
        "            # 10. ç”Ÿæˆåœ–è¡¨\n",
        "            visualizer = StockVisualizer(symbol)\n",
        "\n",
        "            # ä¿å­˜åœ–è¡¨\n",
        "            chart_files = []\n",
        "\n",
        "            # æŠ€è¡“åˆ†æåœ–\n",
        "            fig1 = visualizer.plot_stock_analysis(df)\n",
        "            chart_path1 = os.path.join(CHARTS_DIR, f\"{symbol}_technical.png\")\n",
        "            fig1.savefig(chart_path1, dpi=150, bbox_inches='tight')\n",
        "            chart_files.append(chart_path1)\n",
        "            plt.close(fig1)\n",
        "\n",
        "            # é æ¸¬åœ–\n",
        "            if predictor.future_predictions:\n",
        "                fig2 = visualizer.plot_future_prediction(\n",
        "                    df['Close'].iloc[-1], df['Date'].iloc[-1], predictor.future_predictions\n",
        "                )\n",
        "                chart_path2 = os.path.join(CHARTS_DIR, f\"{symbol}_prediction.png\")\n",
        "                fig2.savefig(chart_path2, dpi=150, bbox_inches='tight')\n",
        "                chart_files.append(chart_path2)\n",
        "                plt.close(fig2)\n",
        "\n",
        "            # ç‰¹å¾µé‡è¦æ€§åœ–\n",
        "            if predictor.feature_importances is not None:\n",
        "                fig3 = visualizer.plot_feature_importance(predictor.feature_importances)\n",
        "                chart_path3 = os.path.join(CHARTS_DIR, f\"{symbol}_features.png\")\n",
        "                fig3.savefig(chart_path3, dpi=150, bbox_inches='tight')\n",
        "                chart_files.append(chart_path3)\n",
        "                plt.close(fig3)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'data_df': df,\n",
        "                'combined_score': combined_score,\n",
        "                'pattern_report': pattern_report,\n",
        "                'wave_analysis': wave_analysis,\n",
        "                'recommendation': recommendation,\n",
        "                'predictor': predictor,\n",
        "                'chart_files': chart_files,\n",
        "                'last_price': df['Close'].iloc[-1],\n",
        "                'last_date': df['Date'].iloc[-1],\n",
        "                'success': True\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ {symbol}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {'symbol': symbol, 'success': False, 'error': str(e)}\n",
        "\n",
        "    async def run_analysis(self):\n",
        "        \"\"\"åŸ·è¡Œå¤šè‚¡ç¥¨åˆ†æ\"\"\"\n",
        "        logger.info(f\"é–‹å§‹åˆ†æ {len(self.symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "        # ä¸¦è¡Œåˆ†ææ‰€æœ‰è‚¡ç¥¨\n",
        "        tasks = [self.analyze_stock(symbol) for symbol in self.symbols]\n",
        "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "        # æ•´ç†çµæœ\n",
        "        for i, result in enumerate(results):\n",
        "            if isinstance(result, Exception):\n",
        "                logger.error(f\"åˆ†æ {self.symbols[i]} æ™‚ç™¼ç”Ÿç•°å¸¸: {result}\")\n",
        "            elif result is not None:\n",
        "                self.results[self.symbols[i]] = result\n",
        "\n",
        "        # ç”Ÿæˆç¸½çµå ±å‘Š\n",
        "        await self.generate_summary_report()\n",
        "\n",
        "    async def generate_summary_report(self):\n",
        "        \"\"\"ç”Ÿæˆç¸½çµå ±å‘Šä¸¦ç™¼é€é€šçŸ¥\"\"\"\n",
        "        if not self.results:\n",
        "            logger.warning(\"æ²’æœ‰æˆåŠŸåˆ†æçš„è‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # ç”Ÿæˆå ±å‘Šæ–‡æœ¬\n",
        "        report_text = format_analysis_message(self.results, limit=10)\n",
        "\n",
        "        # æ”¶é›†æ‰€æœ‰åœ–è¡¨æ–‡ä»¶\n",
        "        all_chart_files = []\n",
        "        for result in self.results.values():\n",
        "            if result.get('success', False):\n",
        "                all_chart_files.extend(result.get('chart_files', []))\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, report_text, all_chart_files)\n",
        "\n",
        "        # çµ‚ç«¯é¡¯ç¤º\n",
        "        print(\"\\n\" + report_text)\n",
        "\n",
        "# =============================================================================\n",
        "# 12. Shioaji æ•´åˆæ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "if SHIOAJI_AVAILABLE:\n",
        "    class ShioajiStockScanner:\n",
        "        def __init__(self, api_key, secret_key, max_retries=3):\n",
        "            self.api_key = api_key\n",
        "            self.secret_key = secret_key\n",
        "            self.max_retries = max_retries\n",
        "            self.api = None\n",
        "            self.connect()\n",
        "\n",
        "        def connect(self):\n",
        "            \"\"\"å»ºç«‹é€£æ¥ä¸¦è™•ç†é‡è©¦é‚è¼¯\"\"\"\n",
        "            retries = 0\n",
        "            while retries < self.max_retries:\n",
        "                try:\n",
        "                    if self.api is not None:\n",
        "                        try:\n",
        "                            self.api.logout()\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                    self.api = sj.Shioaji()\n",
        "                    self.api.login(self.api_key, self.secret_key)\n",
        "                    logger.info(\"Shioaji ç™»å…¥æˆåŠŸ\")\n",
        "                    return True\n",
        "                except Exception as e:\n",
        "                    retries += 1\n",
        "                    logger.error(f\"Shioaji ç™»å…¥å˜—è©¦ {retries} å¤±æ•—: {str(e)}\")\n",
        "                    if \"Too Many Connections\" in str(e):\n",
        "                        logger.info(\"ç­‰å¾…é€£æ¥é‡‹æ”¾...\")\n",
        "                        time.sleep(10 + random.randint(1, 5))\n",
        "                    else:\n",
        "                        time.sleep(2)\n",
        "\n",
        "            logger.error(\"è¶…éæœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œç„¡æ³•å»ºç«‹é€£æ¥\")\n",
        "            return False\n",
        "\n",
        "        def get_stock_list(self, max_stocks=50):\n",
        "            \"\"\"ç²å–å°è‚¡æ¸…å–®\"\"\"\n",
        "            if not self.api:\n",
        "                if not self.connect():\n",
        "                    return pd.DataFrame()\n",
        "\n",
        "            tse_stocks = self.api.Contracts.Stocks.TSE\n",
        "            otc_stocks = self.api.Contracts.Stocks.OTC\n",
        "\n",
        "            stock_list = []\n",
        "            count = 0\n",
        "\n",
        "            # å…ˆå–ä¸Šå¸‚è‚¡ç¥¨\n",
        "            for stock in tse_stocks:\n",
        "                try:\n",
        "                    stock_code = stock.code\n",
        "                    if len(stock_code) == 4 and stock_code.isdigit():\n",
        "                        stock_list.append({\n",
        "                            'code': stock_code,\n",
        "                            'name': stock.name,\n",
        "                            'exchange': stock.exchange\n",
        "                        })\n",
        "                        count += 1\n",
        "                        if count >= max_stocks:\n",
        "                            break\n",
        "                except AttributeError:\n",
        "                    continue\n",
        "\n",
        "            # å¦‚æœä¸Šå¸‚è‚¡ç¥¨ä¸è¶³ï¼Œå†å–ä¸Šæ«ƒè‚¡ç¥¨\n",
        "            if count < max_stocks:\n",
        "                for stock in otc_stocks:\n",
        "                    try:\n",
        "                        stock_code = stock.code\n",
        "                        if len(stock_code) == 4 and stock_code.isdigit():\n",
        "                            stock_list.append({\n",
        "                                'code': stock_code,\n",
        "                                'name': stock.name,\n",
        "                                'exchange': stock.exchange\n",
        "                            })\n",
        "                            count += 1\n",
        "                            if count >= max_stocks:\n",
        "                                break\n",
        "                    except AttributeError:\n",
        "                        continue\n",
        "\n",
        "            df = pd.DataFrame(stock_list)\n",
        "            logger.info(f\"ç²å–åˆ° {len(df)} æ”¯å°è‚¡è³‡æ–™\")\n",
        "            return df\n",
        "\n",
        "        def __del__(self):\n",
        "            \"\"\"æ¸…ç†è³‡æº\"\"\"\n",
        "            if hasattr(self, 'api') and self.api:\n",
        "                try:\n",
        "                    self.api.logout()\n",
        "                    logger.info(\"Shioaji æˆåŠŸç™»å‡º\")\n",
        "                except:\n",
        "                    logger.error(\"Shioaji ç™»å‡ºæ™‚ç™¼ç”ŸéŒ¯èª¤\")\n",
        "\n",
        "# =============================================================================\n",
        "# 13. UI ä»‹é¢ (Jupyter Notebook)\n",
        "# =============================================================================\n",
        "\n",
        "if JUPYTER_AVAILABLE:\n",
        "    def create_stock_analysis_ui():\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨åˆ†æUIä»‹é¢\"\"\"\n",
        "        style = {'description_width': '120px'}\n",
        "        layout = Layout(width='300px')\n",
        "\n",
        "        # æ§åˆ¶å…ƒä»¶\n",
        "        symbol_input = widgets.Text(\n",
        "            value='AAPL,TSLA,2330,2454',\n",
        "            placeholder='è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼Œç”¨é€—è™Ÿåˆ†éš”',\n",
        "            description='è‚¡ç¥¨ä»£ç¢¼:',\n",
        "            style=style,\n",
        "            layout=Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        period_dropdown = widgets.Dropdown(\n",
        "            options=[('1å¹´', '1y'), ('2å¹´', '2y'), ('5å¹´', '5y'), ('æœ€å¤§', 'max')],\n",
        "            value='1y',\n",
        "            description='æ™‚é–“ç¯„åœ:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        analyze_button = widgets.Button(\n",
        "            description='é–‹å§‹åˆ†æ',\n",
        "            button_style='primary',\n",
        "            layout=Layout(width='150px', height='40px')\n",
        "        )\n",
        "\n",
        "        output_area = widgets.Output()\n",
        "\n",
        "        def on_analyze_click(b):\n",
        "            with output_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"ğŸš€ é–‹å§‹åˆ†æ...\")\n",
        "\n",
        "                symbols = [s.strip().upper() for s in symbol_input.value.split(',') if s.strip()]\n",
        "                if not symbols:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    return\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem(symbols, period_dropdown.value)\n",
        "\n",
        "                    # åœ¨ Jupyter ä¸­é‹è¡Œç•°æ­¥ä»£ç¢¼\n",
        "                    loop = asyncio.get_event_loop()\n",
        "                    loop.run_until_complete(system.run_analysis())\n",
        "\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼è«‹æŸ¥çœ‹ç”Ÿæˆçš„åœ–è¡¨å’Œé€šçŸ¥ã€‚\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        analyze_button.on_click(on_analyze_click)\n",
        "\n",
        "        # çµ„åˆUI\n",
        "        ui = VBox([\n",
        "            HTML('<h2>ğŸ“ˆ å¤šè‚¡ç¥¨åˆ†æç³»çµ±</h2>'),\n",
        "            HTML('<p>æ”¯æ´å°è‚¡(è¼¸å…¥æ•¸å­—ä»£ç¢¼å¦‚2330)å’Œç¾è‚¡(è¼¸å…¥å­—æ¯ä»£ç¢¼å¦‚AAPL)</p>'),\n",
        "            symbol_input,\n",
        "            period_dropdown,\n",
        "            analyze_button,\n",
        "            output_area\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "    def create_stock_screener_ui():\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨ç¯©é¸å™¨UI\"\"\"\n",
        "        tw_stocks = [\n",
        "            '2330', '2317', '2454', '2881', '2882', '2883', '2884', '2885',\n",
        "            '2886', '2887', '2888', '2889', '2890', '2891', '2892', '2912'\n",
        "        ]\n",
        "\n",
        "        us_stocks = [\n",
        "            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX',\n",
        "            'JPM', 'JNJ', 'V', 'PG', 'UNH', 'HD', 'MA', 'DIS'\n",
        "        ]\n",
        "\n",
        "        style = {'description_width': '120px'}\n",
        "        layout = Layout(width='300px')\n",
        "\n",
        "        market_dropdown = widgets.Dropdown(\n",
        "            options=[('å°è‚¡', 'tw'), ('ç¾è‚¡', 'us')],\n",
        "            value='tw',\n",
        "            description='å¸‚å ´:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        condition_dropdown = widgets.Dropdown(\n",
        "            options=[\n",
        "                ('çªç ´æ•´ç†å€é–“', 'çªç ´æ•´ç†å€é–“'),\n",
        "                ('çˆ†é‡é•·ç´…', 'çˆ†é‡é•·ç´…'),\n",
        "                ('çªç ´å­£ç·š', 'çªç ´å­£ç·š'),\n",
        "                ('å¤šé ­åå™¬', 'å¤šé ­åå™¬'),\n",
        "                ('5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰', '5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰')\n",
        "            ],\n",
        "            value='çªç ´æ•´ç†å€é–“',\n",
        "            description='ç¯©é¸æ¢ä»¶:',\n",
        "            style=style,\n",
        "            layout=Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        days_slider = widgets.IntSlider(\n",
        "            value=30,\n",
        "            min=10,\n",
        "            max=100,\n",
        "            step=10,\n",
        "            description='å›çœ‹å¤©æ•¸:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        screen_button = widgets.Button(\n",
        "            description='é–‹å§‹ç¯©é¸',\n",
        "            button_style='success',\n",
        "            layout=Layout(width='150px', height='40px')\n",
        "        )\n",
        "\n",
        "        output_area = widgets.Output()\n",
        "\n",
        "        def on_screen_click(b):\n",
        "            with output_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"ğŸ” é–‹å§‹ç¯©é¸è‚¡ç¥¨...\")\n",
        "\n",
        "                stock_list = tw_stocks if market_dropdown.value == 'tw' else us_stocks\n",
        "\n",
        "                try:\n",
        "                    results = screen_stocks(stock_list, days_slider.value, condition_dropdown.value)\n",
        "\n",
        "                    if results.empty:\n",
        "                        print(\"âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "                    else:\n",
        "                        print(f\"âœ… æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨:\")\n",
        "                        print(\"\\n\" + \"=\"*60)\n",
        "                        for _, row in results.iterrows():\n",
        "                            print(f\"è‚¡ç¥¨: {row['ticker']}\")\n",
        "                            print(f\"æ”¶ç›¤åƒ¹: {row['close']:.2f}\")\n",
        "                            print(f\"æˆäº¤é‡: {row['volume']:,.0f}\")\n",
        "                            print(f\"æ¼²è·Œå¹…: {row['change_pct']:.2f}%\")\n",
        "                            print(\"-\" * 30)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ ç¯©é¸éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        screen_button.on_click(on_screen_click)\n",
        "\n",
        "        ui = VBox([\n",
        "            HTML('<h2>ğŸ” è‚¡ç¥¨ç¯©é¸å™¨</h2>'),\n",
        "            market_dropdown,\n",
        "            condition_dropdown,\n",
        "            days_slider,\n",
        "            screen_button,\n",
        "            output_area\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "# =============================================================================\n",
        "# 14. å‘½ä»¤è¡Œä»‹é¢\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"ä¸»å‡½æ•¸ï¼Œé‹è¡Œäº’å‹•å¼ç•Œé¢\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\\nğŸš€ æ­¡è¿ä½¿ç”¨å¤šè‚¡ç¥¨åˆ†æé æ¸¬ç³»çµ±\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"1. å¤šè‚¡ç¥¨åˆ†æèˆ‡é æ¸¬\")\n",
        "        print(\"2. è‚¡ç¥¨ç¯©é¸å™¨\")\n",
        "        print(\"3. å–®è‚¡ç¥¨è©³ç´°åˆ†æ\")\n",
        "        if SHIOAJI_AVAILABLE:\n",
        "            print(\"4. Shioaji å°è‚¡æƒæ\")\n",
        "        if JUPYTER_AVAILABLE:\n",
        "            print(\"5. å•Ÿå‹• Jupyter UI ä»‹é¢\")\n",
        "        print(\"0. é€€å‡ºç¨‹åº\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        try:\n",
        "            choice = input(\"è«‹é¸æ“‡åŠŸèƒ½ (0-5): \").strip()\n",
        "\n",
        "            if choice == '0':\n",
        "                print(\"æ„Ÿè¬ä½¿ç”¨ï¼Œç¨‹åºé€€å‡ºã€‚\")\n",
        "                break\n",
        "\n",
        "            elif choice == '1':\n",
        "                symbols_input = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ (ç”¨é€—è™Ÿåˆ†éš”ï¼Œå¦‚: AAPL,TSLA,2330,2454): \").strip()\n",
        "                if not symbols_input:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    continue\n",
        "\n",
        "                symbols = [s.strip().upper() for s in symbols_input.split(',') if s.strip()]\n",
        "                period = input(\"è«‹è¼¸å…¥æ­·å²æ•¸æ“šå€é–“ (1y, 2y, 5y, max) [é è¨­: 1y]: \").strip().lower()\n",
        "                if not period:\n",
        "                    period = '1y'\n",
        "\n",
        "                print(f\"ğŸš€ é–‹å§‹åˆ†æ {len(symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem(symbols, period)\n",
        "                    asyncio.run(system.run_analysis())\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '2':\n",
        "                print(\"\\nè‚¡ç¥¨ç¯©é¸å™¨\")\n",
        "                print(\"1. å°è‚¡ç¯©é¸\")\n",
        "                print(\"2. ç¾è‚¡ç¯©é¸\")\n",
        "\n",
        "                market_choice = input(\"è«‹é¸æ“‡å¸‚å ´ (1-2): \").strip()\n",
        "                if market_choice not in ['1', '2']:\n",
        "                    print(\"âŒ ç„¡æ•ˆé¸æ“‡\")\n",
        "                    continue\n",
        "\n",
        "                conditions = [\n",
        "                    \"çªç ´æ•´ç†å€é–“\", \"çˆ†é‡é•·ç´…\", \"çªç ´å­£ç·š\", \"å¤šé ­åå™¬\", \"5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰\"\n",
        "                ]\n",
        "\n",
        "                print(\"\\nç¯©é¸æ¢ä»¶:\")\n",
        "                for i, condition in enumerate(conditions, 1):\n",
        "                    print(f\"{i}. {condition}\")\n",
        "\n",
        "                condition_choice = input(\"è«‹é¸æ“‡ç¯©é¸æ¢ä»¶ (1-5): \").strip()\n",
        "                try:\n",
        "                    condition_idx = int(condition_choice) - 1\n",
        "                    if condition_idx < 0 or condition_idx >= len(conditions):\n",
        "                        print(\"âŒ ç„¡æ•ˆé¸æ“‡\")\n",
        "                        continue\n",
        "                    condition = conditions[condition_idx]\n",
        "                except ValueError:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æ•¸å­—\")\n",
        "                    continue\n",
        "\n",
        "                days_input = input(\"è«‹è¼¸å…¥å›çœ‹å¤©æ•¸ [é è¨­: 30]: \").strip()\n",
        "                try:\n",
        "                    days_back = int(days_input) if days_input else 30\n",
        "                except ValueError:\n",
        "                    days_back = 30\n",
        "\n",
        "                # è‚¡ç¥¨æ¸…å–®\n",
        "                tw_stocks = [\n",
        "                    '2330.TW', '2317.TW', '2454.TW', '2881.TW', '2882.TW', '2883.TW',\n",
        "                    '2884.TW', '2885.TW', '2886.TW', '2887.TW', '2888.TW', '2889.TW',\n",
        "                    '2890.TW', '2891.TW', '2892.TW', '2912.TW', '2002.TW', '1303.TW',\n",
        "                    '3711.TW', '1301.TW', '2207.TW', '2357.TW', '2382.TW', '5871.TW'\n",
        "                ]\n",
        "\n",
        "                us_stocks = [\n",
        "                    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX',\n",
        "                    'JPM', 'JNJ', 'V', 'PG', 'UNH', 'HD', 'MA', 'DIS', 'PYPL', 'ADBE',\n",
        "                    'CRM', 'INTC', 'CSCO', 'PFE', 'KO', 'PEP', 'WMT', 'MRK'\n",
        "                ]\n",
        "\n",
        "                stock_list = tw_stocks if market_choice == '1' else us_stocks\n",
        "                market_name = \"å°è‚¡\" if market_choice == '1' else \"ç¾è‚¡\"\n",
        "\n",
        "                print(f\"ğŸ” é–‹å§‹ç¯©é¸ {market_name}ï¼Œæ¢ä»¶: {condition}ï¼Œå›çœ‹: {days_back} å¤©...\")\n",
        "\n",
        "                try:\n",
        "                    results = screen_stocks(stock_list, days_back, condition)\n",
        "\n",
        "                    if results.empty:\n",
        "                        print(\"âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "                    else:\n",
        "                        print(f\"âœ… æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨:\")\n",
        "                        print(\"\\n\" + \"=\"*70)\n",
        "                        for _, row in results.iterrows():\n",
        "                            print(f\"è‚¡ç¥¨: {row['ticker']:<10} | æ”¶ç›¤åƒ¹: {row['close']:>8.2f} | \"\n",
        "                                  f\"æˆäº¤é‡: {row['volume']:>12,.0f} | æ¼²è·Œå¹…: {row['change_pct']:>6.2f}%\")\n",
        "                        print(\"=\"*70)\n",
        "\n",
        "                        # è©¢å•æ˜¯å¦å°ç¯©é¸çµæœé€²è¡Œè©³ç´°åˆ†æ\n",
        "                        analyze_choice = input(\"\\næ˜¯å¦å°ç¯©é¸çµæœé€²è¡Œè©³ç´°åˆ†æï¼Ÿ(y/n): \").strip().lower()\n",
        "                        if analyze_choice == 'y':\n",
        "                            selected_symbols = results['ticker'].tolist()\n",
        "                            print(f\"ğŸš€ é–‹å§‹è©³ç´°åˆ†æ {len(selected_symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "                            system = MultiStockAnalysisSystem(selected_symbols, '1y')\n",
        "                            asyncio.run(system.run_analysis())\n",
        "                            print(\"âœ… è©³ç´°åˆ†æå®Œæˆï¼\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ ç¯©é¸éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '3':\n",
        "                symbol = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ (å¦‚: AAPL æˆ– 2330): \").strip().upper()\n",
        "                if not symbol:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    continue\n",
        "\n",
        "                period = input(\"è«‹è¼¸å…¥æ­·å²æ•¸æ“šå€é–“ (1y, 2y, 5y, max) [é è¨­: 1y]: \").strip().lower()\n",
        "                if not period:\n",
        "                    period = '1y'\n",
        "\n",
        "                print(f\"ğŸš€ é–‹å§‹è©³ç´°åˆ†æ {symbol}...\")\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem([symbol], period)\n",
        "                    asyncio.run(system.run_analysis())\n",
        "\n",
        "                    # é¡¯ç¤ºè©³ç´°çµæœ\n",
        "                    if symbol in system.results:\n",
        "                        result = system.results[symbol]\n",
        "                        if result.get('success', False):\n",
        "                            print(\"\\nğŸ“Š è©³ç´°åˆ†æçµæœ:\")\n",
        "                            print(\"=\"*50)\n",
        "                            print(f\"è‚¡ç¥¨ä»£ç¢¼: {symbol}\")\n",
        "                            print(f\"æœ€æ–°åƒ¹æ ¼: {result['last_price']:.2f}\")\n",
        "                            print(f\"ç¶œåˆè©•åˆ†: {result['combined_score']:.2f}\")\n",
        "                            print(f\"æŠ•è³‡å»ºè­°: {result['recommendation']['action']}\")\n",
        "                            print(f\"å»ºè­°ç†ç”±: {result['recommendation']['reason']}\")\n",
        "                            print(f\"ä¿¡å¿ƒåº¦: {result['recommendation']['confidence']}%\")\n",
        "                            print(f\"é¢¨éšªç­‰ç´š: {result['recommendation']['risk_level']}\")\n",
        "\n",
        "                            print(\"\\nKç·šå‹æ…‹åˆ†æ:\")\n",
        "                            print(result['pattern_report'])\n",
        "\n",
        "                            if result['wave_analysis'][0]:\n",
        "                                print(f\"\\næ³¢æµªç†è«–åˆ†æ: {result['wave_analysis'][1]}\")\n",
        "\n",
        "                            if result['predictor'].future_predictions:\n",
        "                                print(\"\\næœªä¾†ä¸€é€±é æ¸¬:\")\n",
        "                                for day, preds in result['predictor'].future_predictions.items():\n",
        "                                    avg_pred = np.mean(list(preds.values()))\n",
        "                                    change_pct = (avg_pred / result['last_price'] - 1) * 100\n",
        "                                    print(f\"ç¬¬ {day} å¤©: {avg_pred:.2f} ({change_pct:+.1f}%)\")\n",
        "\n",
        "                            print(f\"\\nğŸ“ˆ åœ–è¡¨å·²ä¿å­˜åˆ°: {', '.join(result['chart_files'])}\")\n",
        "                        else:\n",
        "                            print(f\"âŒ åˆ†æ {symbol} å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}\")\n",
        "\n",
        "                    print(\"âœ… è©³ç´°åˆ†æå®Œæˆï¼\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '4' and SHIOAJI_AVAILABLE:\n",
        "                api_key = input(\"è«‹è¼¸å…¥ Shioaji API Key: \").strip()\n",
        "                secret_key = input(\"è«‹è¼¸å…¥ Shioaji Secret Key: \").strip()\n",
        "\n",
        "                if not api_key or not secret_key:\n",
        "                    print(\"âŒ API Key å’Œ Secret Key ä¸èƒ½ç‚ºç©º\")\n",
        "                    continue\n",
        "\n",
        "                max_stocks = input(\"è«‹è¼¸å…¥è¦æƒæçš„è‚¡ç¥¨æ•¸é‡ [é è¨­: 20]: \").strip()\n",
        "                try:\n",
        "                    max_stocks = int(max_stocks) if max_stocks else 20\n",
        "                except ValueError:\n",
        "                    max_stocks = 20\n",
        "\n",
        "                print(f\"ğŸš€ é–‹å§‹æƒæå°è‚¡ï¼Œæ•¸é‡: {max_stocks}...\")\n",
        "\n",
        "                try:\n",
        "                    scanner = ShioajiStockScanner(api_key, secret_key)\n",
        "                    stock_list_df = scanner.get_stock_list(max_stocks)\n",
        "\n",
        "                    if stock_list_df.empty:\n",
        "                        print(\"âŒ ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®\")\n",
        "                        continue\n",
        "\n",
        "                    # è½‰æ›ç‚ºåˆ†æç³»çµ±å¯ç”¨çš„æ ¼å¼\n",
        "                    symbols = [f\"{code}.TW\" for code in stock_list_df['code'].tolist()]\n",
        "\n",
        "                    print(f\"ğŸ“Š ç²å–åˆ° {len(symbols)} æ”¯å°è‚¡ï¼Œé–‹å§‹æŠ€è¡“åˆ†æ...\")\n",
        "\n",
        "                    system = MultiStockAnalysisSystem(symbols, '1y')\n",
        "                    asyncio.run(system.run_analysis())\n",
        "\n",
        "                    print(\"âœ… Shioaji å°è‚¡æƒæå®Œæˆï¼\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ Shioaji æƒæéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '5' and JUPYTER_AVAILABLE:\n",
        "                print(\"ğŸ¯ å•Ÿå‹• Jupyter UI ä»‹é¢...\")\n",
        "                print(\"è«‹åœ¨ Jupyter Notebook ä¸­åŸ·è¡Œä»¥ä¸‹ä»£ç¢¼:\")\n",
        "                print(\"-\"*50)\n",
        "                print(\"# è‚¡ç¥¨åˆ†æUI\")\n",
        "                print(\"analysis_ui = create_stock_analysis_ui()\")\n",
        "                print(\"display(analysis_ui)\")\n",
        "                print()\n",
        "                print(\"# è‚¡ç¥¨ç¯©é¸UI\")\n",
        "                print(\"screener_ui = create_stock_screener_ui()\")\n",
        "                print(\"display(screener_ui)\")\n",
        "                print(\"-\"*50)\n",
        "\n",
        "                # å¦‚æœåœ¨ Jupyter ç’°å¢ƒä¸­ï¼Œç›´æ¥é¡¯ç¤º UI\n",
        "                try:\n",
        "                    from IPython.display import display\n",
        "                    print(\"æª¢æ¸¬åˆ° Jupyter ç’°å¢ƒï¼Œæ­£åœ¨é¡¯ç¤º UI...\")\n",
        "                    analysis_ui = create_stock_analysis_ui()\n",
        "                    screener_ui = create_stock_screener_ui()\n",
        "                    display(analysis_ui)\n",
        "                    display(screener_ui)\n",
        "                except:\n",
        "                    print(\"è«‹åœ¨ Jupyter Notebook ä¸­æ‰‹å‹•åŸ·è¡Œä¸Šè¿°ä»£ç¢¼\")\n",
        "\n",
        "            else:\n",
        "                print(\"âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "# =============================================================================\n",
        "# 15. ç¤ºä¾‹å’Œæ¸¬è©¦\n",
        "# =============================================================================\n",
        "\n",
        "def run_example():\n",
        "    \"\"\"é‹è¡Œç¤ºä¾‹åˆ†æ\"\"\"\n",
        "    print(\"ğŸš€ é‹è¡Œç¤ºä¾‹åˆ†æ...\")\n",
        "\n",
        "    # ç¤ºä¾‹è‚¡ç¥¨çµ„åˆ\n",
        "    example_symbols = ['AAPL', 'TSLA', '2330.TW', '2454.TW']\n",
        "\n",
        "    try:\n",
        "        system = MultiStockAnalysisSystem(example_symbols, '1y')\n",
        "        asyncio.run(system.run_analysis())\n",
        "        print(\"âœ… ç¤ºä¾‹åˆ†æå®Œæˆï¼\")\n",
        "\n",
        "        # é¡¯ç¤ºç°¡è¦çµæœ\n",
        "        print(\"\\nğŸ“Š ç¤ºä¾‹åˆ†æçµæœæ‘˜è¦:\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        successful_results = [\n",
        "            result for result in system.results.values()\n",
        "            if result.get('success', False)\n",
        "        ]\n",
        "\n",
        "        successful_results.sort(key=lambda x: x.get('combined_score', 0), reverse=True)\n",
        "\n",
        "        for i, result in enumerate(successful_results, 1):\n",
        "            symbol = result.get('symbol', 'Unknown')\n",
        "            score = result.get('combined_score', 0)\n",
        "            recommendation = result.get('recommendation', {}).get('action', 'æŒæœ‰')\n",
        "\n",
        "            print(f\"{i}. {symbol:<8} | è©•åˆ†: {score:>5.1f} | å»ºè­°: {recommendation}\")\n",
        "\n",
        "        print(\"=\"*50)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ç¤ºä¾‹åˆ†æå¤±æ•—: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def test_individual_components():\n",
        "    \"\"\"æ¸¬è©¦å„å€‹çµ„ä»¶\"\"\"\n",
        "    print(\"ğŸ§ª æ¸¬è©¦ç³»çµ±çµ„ä»¶...\")\n",
        "\n",
        "    # æ¸¬è©¦æ•¸æ“šç²å–\n",
        "    print(\"1. æ¸¬è©¦è‚¡ç¥¨æ•¸æ“šç²å–...\")\n",
        "    test_df = fetch_stock_data('AAPL', '3mo')\n",
        "    if test_df is not None:\n",
        "        print(f\"âœ… æˆåŠŸç²å– AAPL æ•¸æ“šï¼Œå…± {len(test_df)} ç­†\")\n",
        "    else:\n",
        "        print(\"âŒ è‚¡ç¥¨æ•¸æ“šç²å–å¤±æ•—\")\n",
        "\n",
        "    # æ¸¬è©¦ææ‡¼è²ªå©ªæŒ‡æ•¸\n",
        "    print(\"2. æ¸¬è©¦ææ‡¼è²ªå©ªæŒ‡æ•¸ç²å–...\")\n",
        "    sentiment_df = get_fear_and_greed_data(30)\n",
        "    if sentiment_df is not None:\n",
        "        print(f\"âœ… æˆåŠŸç²å–ææ‡¼è²ªå©ªæŒ‡æ•¸ï¼Œå…± {len(sentiment_df)} ç­†\")\n",
        "    else:\n",
        "        print(\"âŒ ææ‡¼è²ªå©ªæŒ‡æ•¸ç²å–å¤±æ•—\")\n",
        "\n",
        "    # æ¸¬è©¦æŠ€è¡“æŒ‡æ¨™è¨ˆç®—\n",
        "    if test_df is not None:\n",
        "        print(\"3. æ¸¬è©¦æŠ€è¡“æŒ‡æ¨™è¨ˆç®—...\")\n",
        "        try:\n",
        "            test_df = calculate_technical_indicators(test_df)\n",
        "            test_df = feature_engineering(test_df)\n",
        "            print(\"âœ… æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æˆåŠŸ\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—: {e}\")\n",
        "\n",
        "    # æ¸¬è©¦Kç·šå‹æ…‹è­˜åˆ¥\n",
        "    if test_df is not None:\n",
        "        print(\"4. æ¸¬è©¦Kç·šå‹æ…‹è­˜åˆ¥...\")\n",
        "        try:\n",
        "            pattern_report = generate_pattern_report(test_df)\n",
        "            print(\"âœ… Kç·šå‹æ…‹è­˜åˆ¥æˆåŠŸ\")\n",
        "            print(f\"å‹æ…‹å ±å‘Š: {pattern_report[:100]}...\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Kç·šå‹æ…‹è­˜åˆ¥å¤±æ•—: {e}\")\n",
        "\n",
        "    # æ¸¬è©¦è©•åˆ†ç³»çµ±\n",
        "    if test_df is not None:\n",
        "        print(\"5. æ¸¬è©¦è©•åˆ†ç³»çµ±...\")\n",
        "        try:\n",
        "            score = calculate_combined_score(test_df)\n",
        "            print(f\"âœ… è©•åˆ†ç³»çµ±æˆåŠŸï¼Œç¶œåˆè©•åˆ†: {score:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ è©•åˆ†ç³»çµ±å¤±æ•—: {e}\")\n",
        "\n",
        "    print(\"ğŸ§ª çµ„ä»¶æ¸¬è©¦å®Œæˆ\")\n",
        "\n",
        "# =============================================================================\n",
        "# 16. ç¨‹åºå…¥å£é»\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸ¯ å¤šè‚¡ç¥¨åˆ†æé æ¸¬ç³»çµ± v2.0\")\n",
        "    print(\"æ”¯æ´å°è‚¡ã€ç¾è‚¡æŠ€è¡“åˆ†æã€æ©Ÿå™¨å­¸ç¿’é æ¸¬ã€å‹æ…‹è­˜åˆ¥\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # æª¢æŸ¥ç’°å¢ƒ\n",
        "    print(\"ğŸ” æª¢æŸ¥ç³»çµ±ç’°å¢ƒ...\")\n",
        "    print(f\"Jupyter æ”¯æ´: {'âœ…' if JUPYTER_AVAILABLE else 'âŒ'}\")\n",
        "    print(f\"Shioaji æ”¯æ´: {'âœ…' if SHIOAJI_AVAILABLE else 'âŒ'}\")\n",
        "    print(f\"é€šçŸ¥åŠŸèƒ½: {'âœ…' if MESSAGING_AVAILABLE else 'âŒ'}\")\n",
        "\n",
        "    # è©¢å•é‹è¡Œæ¨¡å¼\n",
        "    print(\"\\né¸æ“‡é‹è¡Œæ¨¡å¼:\")\n",
        "    print(\"1. äº’å‹•å¼å‘½ä»¤è¡Œä»‹é¢\")\n",
        "    print(\"2. é‹è¡Œç¤ºä¾‹åˆ†æ\")\n",
        "    print(\"3. æ¸¬è©¦ç³»çµ±çµ„ä»¶\")\n",
        "    print(\"0. é€€å‡º\")\n",
        "\n",
        "    try:\n",
        "        mode = input(\"è«‹é¸æ“‡ (0-3): \").strip()\n",
        "\n",
        "        if mode == '0':\n",
        "            print(\"ç¨‹åºé€€å‡º\")\n",
        "        elif mode == '1':\n",
        "            main()\n",
        "        elif mode == '2':\n",
        "            run_example()\n",
        "        elif mode == '3':\n",
        "            test_individual_components()\n",
        "        else:\n",
        "            print(\"ç„¡æ•ˆé¸æ“‡ï¼Œå•Ÿå‹•äº’å‹•å¼ä»‹é¢...\")\n",
        "            main()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·\")\n",
        "    except Exception as e:\n",
        "        print(f\"ç¨‹åºé‹è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\næ„Ÿè¬ä½¿ç”¨å¤šè‚¡ç¥¨åˆ†æé æ¸¬ç³»çµ±ï¼\")"
      ],
      "metadata": {
        "id": "YwMw7d5jsBap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFJhJswdyCNr"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import seaborn as sns\n",
        "from io import StringIO\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import json\n",
        "import pickle\n",
        "from typing import Dict, List, Any, Optional\n",
        "import random\n",
        "\n",
        "# æ©Ÿå™¨å­¸ç¿’ç›¸é—œ\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# é€šçŸ¥ç›¸é—œ\n",
        "try:\n",
        "    from discord_webhook import DiscordWebhook\n",
        "    MESSAGING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MESSAGING_AVAILABLE = False\n",
        "\n",
        "# Jupyter Notebook æ”¯æ´\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "    import ipywidgets as widgets\n",
        "    from ipywidgets import Layout, HTML, Button, HBox, VBox, Output\n",
        "    from IPython.display import display, clear_output\n",
        "    JUPYTER_AVAILABLE = True\n",
        "except ImportError:\n",
        "    JUPYTER_AVAILABLE = False\n",
        "\n",
        "# =============================================================================\n",
        "# å…¨åŸŸè¨­å®š\n",
        "# =============================================================================\n",
        "\n",
        "# ç¦æ­¢ä¸­æ–‡éŒ¯èª¤è­¦å‘Š\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# è¨­å®šæ—¥èªŒ\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ä¸­æ–‡å­—é«”è¨­å®š\n",
        "plt.rcParams['font.sans-serif'] = [\n",
        "    'Microsoft JhengHei',  # ç¹é«”ä¸­æ–‡\n",
        "    'SimHei',              # ç°¡é«”ä¸­æ–‡\n",
        "    'Arial Unicode MS',    # Unicode å­—é«”\n",
        "    'DejaVu Sans'         # åŸºç¤å­—é«”\n",
        "]\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# é€šçŸ¥è¨­å®š\n",
        "TELEGRAM_TOKEN = \"7902318521:AAEYoDMqwfHabI7L1SRiE4z33aFay42-VGE\"\n",
        "TELEGRAM_CHAT_ID = [879781796, 8113868436]\n",
        "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1362715080734802102/Jma7A3VhEQrrRxIX_JW2l6rATjAZXsGXGfnJuAMqmS1QvqG_2ptg3vr_nsVnuV_PlnBl\"\n",
        "\n",
        "# å°åŒ—æ™‚å€\n",
        "taipei_tz = timezone(timedelta(hours=8))\n",
        "\n",
        "# åœ–è¡¨å„²å­˜ç›®éŒ„\n",
        "CHARTS_DIR = 'charts'\n",
        "if not os.path.exists(CHARTS_DIR):\n",
        "    os.makedirs(CHARTS_DIR)\n",
        "\n",
        "print(\"ğŸš€ ç’°å¢ƒè¨­å®šå®Œæˆï¼Œé–‹å§‹å»ºç«‹åˆ†æç³»çµ±...\")\n",
        "\n",
        "# =============================================================================\n",
        "# 1. æ•¸æ“šç²å–æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def fetch_from_cnn():\n",
        "    \"\"\"å¾CNNç¶²ç«™ç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\"\"\"\n",
        "    url = \"https://money.cnn.com/data/fear-and-greed/\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for element in soup.find_all(['div', 'span']):\n",
        "            if \"Fear & Greed Now:\" in element.get_text():\n",
        "                number_match = re.search(r'(\\d+)', element.get_text())\n",
        "                if number_match:\n",
        "                    value = int(number_match.group(1))\n",
        "                    logger.info(f\"æˆåŠŸå¾CNNç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸: {value}\")\n",
        "                    return value\n",
        "        logger.warning(\"ç„¡æ³•å¾CNNæå–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾CNNç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_from_alternative_me(limit=1):\n",
        "    \"\"\"å¾alternative.me APIç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸\"\"\"\n",
        "    try:\n",
        "        url = f\"https://api.alternative.me/fng/?limit={limit}&format=json\"\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if 'data' in data and len(data['data']) > 0:\n",
        "            if limit == 1:\n",
        "                value = int(data['data'][0]['value'])\n",
        "                logger.info(f\"æˆåŠŸå¾Alternative.me APIç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸: {value}\")\n",
        "                return value\n",
        "            else:\n",
        "                df = pd.DataFrame(data['data'])\n",
        "                df['value'] = pd.to_numeric(df['value'])\n",
        "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
        "                df = df.rename(columns={'timestamp': 'Date', 'value': 'FearGreedIndex'})\n",
        "                df['Date'] = pd.to_datetime(df['Date'])\n",
        "                logger.info(f\"æˆåŠŸç²å– {len(df)} å¤©çš„æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“š\")\n",
        "                return df[['Date', 'FearGreedIndex']]\n",
        "        else:\n",
        "            logger.warning(\"Alternative.me APIè¿”å›çš„æ•¸æ“šæ ¼å¼ä¸æ­£ç¢º\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾Alternative.meç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_fear_and_greed_data(days):\n",
        "    \"\"\"ç²å–å³æ™‚èˆ‡æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“š\"\"\"\n",
        "    logger.info(\"æ­£åœ¨ç²å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸...\")\n",
        "\n",
        "    current_value = fetch_from_cnn()\n",
        "    if current_value is None:\n",
        "        current_value = fetch_from_alternative_me(limit=1)\n",
        "\n",
        "    historical_df = fetch_from_alternative_me(limit=days)\n",
        "\n",
        "    if historical_df is not None:\n",
        "        logger.info(\"å·²æˆåŠŸç²å–çœŸå¯¦æ­·å²ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸æ•¸æ“šã€‚\")\n",
        "        if current_value is not None:\n",
        "            today = pd.to_datetime(datetime.now().date())\n",
        "            if today not in historical_df['Date'].values:\n",
        "                new_row = pd.DataFrame([{'Date': today, 'FearGreedIndex': current_value}])\n",
        "                historical_df = pd.concat([historical_df, new_row], ignore_index=True)\n",
        "        return historical_df.drop_duplicates(subset=['Date'], keep='last')\n",
        "\n",
        "    logger.warning(\"ç„¡æ³•ç²å–çœŸå¯¦æ­·å²æ•¸æ“šï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šä½œç‚ºå‚™æ¡ˆã€‚\")\n",
        "    if current_value is None:\n",
        "        current_value = 50\n",
        "        logger.warning(f\"æ‰€æœ‰å³æ™‚ä¾†æºå‡å¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼ {current_value}\")\n",
        "\n",
        "    dates = pd.to_datetime([datetime.now() - timedelta(days=i) for i in range(days)]).sort_values()\n",
        "    scores = [current_value]\n",
        "    np.random.seed(42)\n",
        "    for _ in range(1, days):\n",
        "        mean_reversion = 0.1 * (50 - scores[-1])\n",
        "        random_change = np.random.normal(0, 3)\n",
        "        new_score = scores[-1] + mean_reversion + random_change\n",
        "        scores.append(max(0, min(100, new_score)))\n",
        "\n",
        "    return pd.DataFrame({'Date': dates, 'FearGreedIndex': scores})\n",
        "\n",
        "def fetch_stock_data(symbol, period='1y'):\n",
        "    \"\"\"å¾Yahoo Financeç²å–è‚¡ç¥¨æ•¸æ“šï¼Œè‡ªå‹•åˆ¤æ–·å°è‚¡/ç¾è‚¡\"\"\"\n",
        "    original_symbol = symbol\n",
        "\n",
        "    # å¦‚æœè¼¸å…¥çš„æ˜¯ç´”æ•¸å­—ï¼Œåˆ¤æ–·ç‚ºå°è‚¡ä»£ç¢¼\n",
        "    if re.match(r'^\\d{4,5}$', symbol):\n",
        "        symbol += \".TW\"\n",
        "        logger.info(f\"æª¢æ¸¬åˆ°å°è‚¡ä»£ç¢¼ï¼Œè½‰æ›ç‚º {symbol}\")\n",
        "\n",
        "    logger.info(f\"æ­£åœ¨å¾Yahoo Financeç²å– {symbol} ({period}) çš„æ•¸æ“š...\")\n",
        "    try:\n",
        "        stock = yf.Ticker(symbol)\n",
        "        df = stock.history(period=period, interval='1d')\n",
        "        if df.empty:\n",
        "            logger.error(f\"ç„¡æ³•ç²å– {symbol} çš„æ•¸æ“šï¼Œè«‹æª¢æŸ¥ä»£ç¢¼æ˜¯å¦æ­£ç¢ºã€‚\")\n",
        "            return None\n",
        "\n",
        "        df.reset_index(inplace=True)\n",
        "        df['Date'] = pd.to_datetime(df['Date'].dt.date)\n",
        "\n",
        "        logger.info(f\"æˆåŠŸç²å– {original_symbol} çš„ {len(df)} ç­†æ•¸æ“š\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"å¾Yahoo Financeç²å– {symbol} çš„æ•¸æ“šæ™‚å‡ºéŒ¯: {e}\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================\n",
        "# 2. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"è¨ˆç®—æ‰€æœ‰éœ€è¦çš„æŠ€è¡“æŒ‡æ¨™\"\"\"\n",
        "    # ç§»å‹•å¹³å‡ç·š\n",
        "    df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "    df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "    df['MA20'] = df['Close'].rolling(window=20).mean()\n",
        "    df['MA60'] = df['Close'].rolling(window=60).mean()\n",
        "\n",
        "    # MACD\n",
        "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "\n",
        "    # RSI\n",
        "    delta = df['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean()\n",
        "    avg_loss = loss.rolling(window=14).mean().replace(0, np.nan)\n",
        "    rs = avg_gain / avg_loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # å¸ƒæ—å¸¶\n",
        "    df['BB_Middle'] = df['MA20']\n",
        "    std_dev = df['Close'].rolling(window=20).std()\n",
        "    df['BB_Upper'] = df['BB_Middle'] + (std_dev * 2)\n",
        "    df['BB_Lower'] = df['BB_Middle'] - (std_dev * 2)\n",
        "\n",
        "    # KDæŒ‡æ¨™\n",
        "    low_min = df['Low'].rolling(window=9).min()\n",
        "    high_max = df['High'].rolling(window=9).max()\n",
        "    rsv = (df['Close'] - low_min) / (high_max - low_min) * 100\n",
        "    df['K'] = rsv.ewm(com=2).mean()\n",
        "    df['D'] = df['K'].ewm(com=2).mean()\n",
        "\n",
        "    # æˆäº¤é‡æŒ‡æ¨™\n",
        "    df['Volume_MA'] = df['Volume'].rolling(window=20).mean()\n",
        "\n",
        "    return df\n",
        "\n",
        "def feature_engineering(df):\n",
        "    \"\"\"å‰µå»ºè¡ç”Ÿç‰¹å¾µ\"\"\"\n",
        "    df['Price_Change_1d'] = df['Close'].pct_change(1)\n",
        "    df['Price_Change_5d'] = df['Close'].pct_change(5)\n",
        "    df['Volatility_5d'] = df['Close'].rolling(5).std()\n",
        "    df['Volatility_20d'] = df['Close'].rolling(20).std()\n",
        "    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']\n",
        "    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower']).replace(0, np.nan)\n",
        "\n",
        "    # å¡«å……NaNå€¼\n",
        "    df.bfill(inplace=True)\n",
        "    df.ffill(inplace=True)\n",
        "    df.fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# =============================================================================\n",
        "# 3. Kç·šå‹æ…‹è­˜åˆ¥æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "def identify_candlestick_patterns(df):\n",
        "    \"\"\"è­˜åˆ¥å¸¸è¦‹çš„Kç·šå‹æ…‹\"\"\"\n",
        "    result_df = df.copy()\n",
        "\n",
        "    # åŸºæœ¬è¨ˆç®—\n",
        "    result_df['body_size'] = abs(result_df['Close'] - result_df['Open'])\n",
        "    result_df['upper_shadow'] = result_df['High'] - result_df[['Open', 'Close']].max(axis=1)\n",
        "    result_df['lower_shadow'] = result_df[['Open', 'Close']].min(axis=1) - result_df['Low']\n",
        "    result_df['total_range'] = result_df['High'] - result_df['Low']\n",
        "\n",
        "    # å‰ä¸€å¤©æ•¸æ“š\n",
        "    result_df['prev_open'] = result_df['Open'].shift(1)\n",
        "    result_df['prev_high'] = result_df['High'].shift(1)\n",
        "    result_df['prev_low'] = result_df['Low'].shift(1)\n",
        "    result_df['prev_close'] = result_df['Close'].shift(1)\n",
        "\n",
        "    # Kç·šè¶¨å‹¢\n",
        "    result_df['is_bullish'] = result_df['Close'] > result_df['Open']\n",
        "    result_df['prev_is_bullish'] = result_df['prev_close'] > result_df['prev_open']\n",
        "\n",
        "    # åˆå§‹åŒ–å‹æ…‹æ¬„ä½\n",
        "    pattern_columns = [\n",
        "        'åå­—æ˜Ÿ_ä¸­æ€§', 'éŒ˜å­ç·š_çœ‹æ¼²', 'éŒ˜å­ç·š_çœ‹è·Œ', 'æµæ˜Ÿç·š_çœ‹è·Œ',\n",
        "        'åå™¬_çœ‹æ¼²', 'åå™¬_çœ‹è·Œ', 'æ¯å­ç·š_çœ‹æ¼²', 'æ¯å­ç·š_çœ‹è·Œ'\n",
        "    ]\n",
        "\n",
        "    for col in pattern_columns:\n",
        "        result_df[col] = 0\n",
        "\n",
        "    # åå­—æ˜Ÿ\n",
        "    doji_condition = result_df['body_size'] <= 0.1 * result_df['total_range']\n",
        "    result_df.loc[doji_condition, 'åå­—æ˜Ÿ_ä¸­æ€§'] = 1\n",
        "\n",
        "    # éŒ˜å­ç·š\n",
        "    hammer_condition = (\n",
        "        (result_df['lower_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['upper_shadow'] <= 0.1 * result_df['total_range'])\n",
        "    )\n",
        "    result_df.loc[hammer_condition, 'éŒ˜å­ç·š_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # æµæ˜Ÿç·š\n",
        "    shooting_star_condition = (\n",
        "        (result_df['upper_shadow'] >= 2 * result_df['body_size']) &\n",
        "        (result_df['lower_shadow'] <= 0.1 * result_df['total_range'])\n",
        "    )\n",
        "    result_df.loc[shooting_star_condition, 'æµæ˜Ÿç·š_çœ‹è·Œ'] = -1\n",
        "\n",
        "    # çœ‹æ¼²åå™¬\n",
        "    bullish_engulfing = (\n",
        "        (~result_df['prev_is_bullish']) &\n",
        "        result_df['is_bullish'] &\n",
        "        (result_df['Open'] < result_df['prev_close']) &\n",
        "        (result_df['Close'] > result_df['prev_open'])\n",
        "    )\n",
        "    result_df.loc[bullish_engulfing, 'åå™¬_çœ‹æ¼²'] = 1\n",
        "\n",
        "    # çœ‹è·Œåå™¬\n",
        "    bearish_engulfing = (\n",
        "        result_df['prev_is_bullish'] &\n",
        "        (~result_df['is_bullish']) &\n",
        "        (result_df['Open'] > result_df['prev_close']) &\n",
        "        (result_df['Close'] < result_df['prev_open'])\n",
        "    )\n",
        "    result_df.loc[bearish_engulfing, 'åå™¬_çœ‹è·Œ'] = -1\n",
        "\n",
        "    return result_df\n",
        "\n",
        "def generate_pattern_report(df, periods=['daily']):\n",
        "    \"\"\"ç”ŸæˆKç·šå‹æ…‹åˆ†æå ±å‘Š\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šæ•¸æ“šç‚ºç©º\"\n",
        "\n",
        "    required_cols = ['Open', 'High', 'Low', 'Close']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        return \"ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼šç¼ºå°‘å¿…è¦æ¬„ä½\"\n",
        "\n",
        "    def detect_patterns(ohlc_data):\n",
        "        patterns = {\"çœ‹æ¼²\": [], \"çœ‹è·Œ\": [], \"ä¸­æ€§\": []}\n",
        "\n",
        "        if len(ohlc_data) < 5:\n",
        "            return patterns\n",
        "\n",
        "        recent = ohlc_data.tail(10).copy()\n",
        "        recent['body_size'] = abs(recent['Close'] - recent['Open'])\n",
        "        recent['is_bullish'] = recent['Close'] > recent['Open']\n",
        "        recent['is_bearish'] = recent['Close'] < recent['Open']\n",
        "\n",
        "        last3 = recent.tail(3)\n",
        "\n",
        "        # ä¸‰ç™½å…µ\n",
        "        if len(last3) == 3 and all(last3['is_bullish']) and \\\n",
        "           last3['Close'].iloc[0] < last3['Close'].iloc[1] < last3['Close'].iloc[2]:\n",
        "            patterns[\"çœ‹æ¼²\"].append(\"ä¸‰ç™½å…µ\")\n",
        "\n",
        "        # ä¸‰é»‘é´‰\n",
        "        if len(last3) == 3 and all(last3['is_bearish']) and \\\n",
        "           last3['Close'].iloc[0] > last3['Close'].iloc[1] > last3['Close'].iloc[2]:\n",
        "            patterns[\"çœ‹è·Œ\"].append(\"ä¸‰é»‘é´‰\")\n",
        "\n",
        "        # åå­—æ˜Ÿ\n",
        "        if any(last3['body_size'] < 0.1 * (last3['High'] - last3['Low'])):\n",
        "            patterns[\"ä¸­æ€§\"].append(\"åå­—æ˜Ÿ\")\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    report_parts = []\n",
        "\n",
        "    for period in periods:\n",
        "        period_name = {'daily': 'æ—¥ç·š', 'weekly': 'é€±ç·š', 'monthly': 'æœˆç·š'}.get(period, period)\n",
        "\n",
        "        try:\n",
        "            patterns = detect_patterns(df)\n",
        "            period_report = [f\"{period_name}åˆ†æ:\"]\n",
        "\n",
        "            for pattern_type, detected_patterns in patterns.items():\n",
        "                if detected_patterns:\n",
        "                    pattern_str = \", \".join(detected_patterns)\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: {pattern_str}\")\n",
        "                else:\n",
        "                    period_report.append(f\"{pattern_type}å‹æ…‹: ç„¡\")\n",
        "\n",
        "            report_parts.append(\"\\n\".join(period_report))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {period_name} å‹æ…‹æ™‚å‡ºéŒ¯: {e}\")\n",
        "            report_parts.append(f\"{period_name}åˆ†æ:\\nåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤\")\n",
        "\n",
        "    return \"\\n\\n\".join(report_parts) if report_parts else \"æœªæª¢æ¸¬åˆ°æ˜é¡¯Kç·šå‹æ…‹\"\n",
        "\n",
        "# =============================================================================\n",
        "# 4. æ©Ÿå™¨å­¸ç¿’é æ¸¬æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "class StockPredictor:\n",
        "    def __init__(self, target_days=7):\n",
        "        self.models = {\n",
        "            'ç·šæ€§è¿´æ­¸': LinearRegression(),\n",
        "            'éš¨æ©Ÿæ£®æ—': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "            'XGBoost': XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "            'LightGBM': LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "        }\n",
        "        self.scalers = {}\n",
        "        self.feature_names = None\n",
        "        self.target_days = target_days\n",
        "        self.backtest_results = {}\n",
        "        self.future_predictions = {}\n",
        "        self.feature_importances = None\n",
        "\n",
        "    def _prepare_data(self, df, predict_day):\n",
        "        \"\"\"æº–å‚™ç‰¹å¾µå’Œç›®æ¨™è®Šé‡\"\"\"\n",
        "        feature_columns = [\n",
        "            'MA5', 'MA10', 'MA20', 'MACD', 'MACD_Signal', 'RSI', 'BB_Width', 'BB_Position',\n",
        "            'Price_Change_1d', 'Price_Change_5d', 'Volatility_5d', 'Volatility_20d',\n",
        "            'FearGreedIndex'\n",
        "        ]\n",
        "        self.feature_names = [col for col in feature_columns if col in df.columns]\n",
        "\n",
        "        X = df[self.feature_names].copy()\n",
        "        y = df['Close'].shift(-predict_day)\n",
        "\n",
        "        valid_idx = ~y.isnull()\n",
        "        X = X[valid_idx]\n",
        "        y = y[valid_idx]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def run_backtest(self, df):\n",
        "        \"\"\"åŸ·è¡Œå›æ¸¬\"\"\"\n",
        "        logger.info(\"åŸ·è¡Œå›æ¸¬...\")\n",
        "        X, y = self._prepare_data(df, predict_day=1)\n",
        "\n",
        "        split_index = int(len(X) * 0.8)\n",
        "        X_train, X_test = X[:split_index], X[split_index:]\n",
        "        y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            y_pred = model.predict(X_test_scaled)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            self.backtest_results[name] = {\n",
        "                'y_test': y_test, 'y_pred': y_pred, 'mse': mse, 'r2': r2\n",
        "            }\n",
        "            logger.info(f\"[å›æ¸¬] {name} - RÂ²: {r2:.4f}, MSE: {mse:.4f}\")\n",
        "\n",
        "        if 'éš¨æ©Ÿæ£®æ—' in self.models:\n",
        "            self.feature_importances = pd.DataFrame({\n",
        "                'ç‰¹å¾µ': self.feature_names,\n",
        "                'é‡è¦æ€§': self.models['éš¨æ©Ÿæ£®æ—'].feature_importances_\n",
        "            }).sort_values('é‡è¦æ€§', ascending=False)\n",
        "\n",
        "    def predict_future(self, df):\n",
        "        \"\"\"é æ¸¬æœªä¾†åƒ¹æ ¼\"\"\"\n",
        "        logger.info(\"è¨“ç·´å®Œæ•´æ•¸æ“šé›†ä¸¦é æ¸¬æœªä¾†åƒ¹æ ¼...\")\n",
        "\n",
        "        for day in range(1, self.target_days + 1):\n",
        "            X, y = self._prepare_data(df, predict_day=day)\n",
        "\n",
        "            if X.empty:\n",
        "                logger.warning(f\"ç„¡æ³•ç‚ºé æ¸¬ç¬¬ {day} å¤©æº–å‚™æ•¸æ“šï¼Œè·³éã€‚\")\n",
        "                continue\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_scaled = scaler.fit_transform(X)\n",
        "            X_last = df[self.feature_names].iloc[-1:].copy()\n",
        "            X_last_scaled = scaler.transform(X_last)\n",
        "\n",
        "            daily_predictions = {}\n",
        "            for name, model in self.models.items():\n",
        "                model.fit(X_scaled, y)\n",
        "                prediction = model.predict(X_last_scaled)[0]\n",
        "                daily_predictions[name] = prediction\n",
        "\n",
        "            self.future_predictions[day] = daily_predictions\n",
        "\n",
        "# =============================================================================\n",
        "# 5. ç¶œåˆè©•åˆ†ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_combined_score(df):\n",
        "    \"\"\"è¨ˆç®—ç¶œåˆè©•åˆ†\"\"\"\n",
        "    if df.empty:\n",
        "        return 50\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    # æŠ€è¡“æŒ‡æ¨™è©•åˆ†\n",
        "    if 'RSI' in df.columns:\n",
        "        rsi = df['RSI'].iloc[-1]\n",
        "        if 30 <= rsi <= 70:\n",
        "            scores.append(60 + (rsi - 50) * 0.8)\n",
        "        elif rsi > 70:\n",
        "            scores.append(80)\n",
        "        else:\n",
        "            scores.append(30)\n",
        "\n",
        "    # ç§»å‹•å¹³å‡ç·šè©•åˆ†\n",
        "    if all(col in df.columns for col in ['MA5', 'MA20']):\n",
        "        if df['MA5'].iloc[-1] > df['MA20'].iloc[-1]:\n",
        "            scores.append(70)\n",
        "        else:\n",
        "            scores.append(40)\n",
        "\n",
        "    # MACDè©•åˆ†\n",
        "    if all(col in df.columns for col in ['MACD', 'MACD_Signal']):\n",
        "        if df['MACD'].iloc[-1] > df['MACD_Signal'].iloc[-1]:\n",
        "            scores.append(65)\n",
        "        else:\n",
        "            scores.append(45)\n",
        "\n",
        "    # åƒ¹æ ¼è¶¨å‹¢è©•åˆ†\n",
        "    if 'Price_Change_5d' in df.columns:\n",
        "        change = df['Price_Change_5d'].iloc[-1]\n",
        "        if change > 0.05:\n",
        "            scores.append(75)\n",
        "        elif change > 0:\n",
        "            scores.append(60)\n",
        "        elif change > -0.05:\n",
        "            scores.append(40)\n",
        "        else:\n",
        "            scores.append(25)\n",
        "\n",
        "    return np.mean(scores) if scores else 50\n",
        "\n",
        "# =============================================================================\n",
        "# 6. æ™ºèƒ½å»ºè­°ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "def generate_recommendation(combined_score, report_summary=None):\n",
        "    \"\"\"ç”ŸæˆæŠ•è³‡å»ºè­°\"\"\"\n",
        "    try:\n",
        "        combined_score = float(combined_score)\n",
        "    except (ValueError, TypeError):\n",
        "        combined_score = 50.0\n",
        "\n",
        "    recommendation = {\n",
        "        \"action\": \"ä¸­ç«‹è§€å¯Ÿ\",\n",
        "        \"reason\": f\"ç¶œåˆè©•åˆ†ä¸­æ€§ ({combined_score:.2f})ã€‚\",\n",
        "        \"pattern_details\": [],\n",
        "        \"confidence\": 50\n",
        "    }\n",
        "\n",
        "    if combined_score >= 70:\n",
        "        recommendation[\"action\"] = \"è²·å…¥\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†å¼·å‹ ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score >= 60:\n",
        "        recommendation[\"action\"] = \"è²·å…¥è§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼· ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score <= 30:\n",
        "        recommendation[\"action\"] = \"è³£å‡º\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†ç–²å¼± ({combined_score:.2f})ã€‚\"\n",
        "    elif combined_score <= 40:\n",
        "        recommendation[\"action\"] = \"è³£å‡ºè§€æœ›\"\n",
        "        recommendation[\"reason\"] = f\"ç¶œåˆè©•åˆ†åå¼± ({combined_score:.2f})ã€‚\"\n",
        "\n",
        "    # è¨ˆç®—ä¿¡å¿ƒåº¦\n",
        "    distance_from_center = abs(combined_score - 50)\n",
        "    base_confidence = min(distance_from_center * 2, 100)\n",
        "    recommendation['confidence'] = int(base_confidence)\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "# =============================================================================\n",
        "# 7. å¯è¦–åŒ–æ¨¡çµ„\n",
        "# =============================================================================\n",
        "\n",
        "class StockVisualizer:\n",
        "    def __init__(self, symbol):\n",
        "        self.symbol = symbol\n",
        "\n",
        "    def plot_stock_analysis(self, df):\n",
        "        \"\"\"ç¹ªè£½è‚¡ç¥¨æŠ€è¡“åˆ†æåœ–\"\"\"\n",
        "        fig, axes = plt.subplots(3, 1, figsize=(16, 12), sharex=True)\n",
        "        fig.suptitle(f'{self.symbol} æŠ€è¡“åˆ†æç¸½è¦½', fontsize=20, fontweight='bold')\n",
        "\n",
        "        # åƒ¹æ ¼èˆ‡å¸ƒæ—å¸¶\n",
        "        axes[0].plot(df['Date'], df['Close'], label='æ”¶ç›¤åƒ¹', linewidth=2)\n",
        "        if 'BB_Upper' in df.columns:\n",
        "            axes[0].plot(df['Date'], df['BB_Upper'], label='å¸ƒæ—ä¸Šè»Œ', linestyle='--', alpha=0.7)\n",
        "            axes[0].plot(df['Date'], df['BB_Lower'], label='å¸ƒæ—ä¸‹è»Œ', linestyle='--', alpha=0.7)\n",
        "            axes[0].fill_between(df['Date'], df['BB_Lower'], df['BB_Upper'], alpha=0.1)\n",
        "        axes[0].set_title('åƒ¹æ ¼èˆ‡å¸ƒæ—é€šé“')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # MACD\n",
        "        if 'MACD' in df.columns:\n",
        "            axes[1].plot(df['Date'], df['MACD'], label='MACD', color='blue')\n",
        "            axes[1].plot(df['Date'], df['MACD_Signal'], label='è¨Šè™Ÿç·š', color='red', linestyle='--')\n",
        "            axes[1].bar(df['Date'], df['MACD'] - df['MACD_Signal'], label='æŸ±ç‹€åœ–', color='gray', alpha=0.5)\n",
        "        axes[1].set_title('MACD')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        # RSI\n",
        "        if 'RSI' in df.columns:\n",
        "            axes[2].plot(df['Date'], df['RSI'], label='RSI', color='purple')\n",
        "            axes[2].axhline(70, color='red', linestyle='--', alpha=0.7, label='è¶…è²·å€ (70)')\n",
        "            axes[2].axhline(30, color='green', linestyle='--', alpha=0.7, label='è¶…è³£å€ (30)')\n",
        "        axes[2].set_title('RSI ç›¸å°å¼·å¼±æŒ‡æ•¸')\n",
        "        axes[2].legend()\n",
        "        axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "        return fig\n",
        "\n",
        "    def plot_future_prediction(self, last_price, last_date, predictions):\n",
        "        \"\"\"ç¹ªè£½æœªä¾†é æ¸¬åœ–\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 7))\n",
        "        pred_dates, pred_prices_avg = [], []\n",
        "\n",
        "        current_date = last_date\n",
        "        for day, preds in predictions.items():\n",
        "            while True:\n",
        "                current_date += timedelta(days=1)\n",
        "                if current_date.weekday() < 5:\n",
        "                    break\n",
        "\n",
        "            pred_dates.append(current_date)\n",
        "            avg_price = np.mean(list(preds.values()))\n",
        "            pred_prices_avg.append(avg_price)\n",
        "\n",
        "        ax.plot(pred_dates, pred_prices_avg, 'ro-', label='å¹³å‡é æ¸¬åƒ¹æ ¼')\n",
        "        ax.axhline(last_price, color='gray', linestyle='--', label=f'ç•¶å‰åƒ¹æ ¼ ({last_price:.2f})')\n",
        "\n",
        "        for date, price in zip(pred_dates, pred_prices_avg):\n",
        "            ax.text(date, price, f'{price:.2f}', ha='center', va='bottom')\n",
        "\n",
        "        ax.set_title(f'{self.symbol} æœªä¾†ä¸€é€±æ¯æ—¥è‚¡åƒ¹é æ¸¬', fontsize=16)\n",
        "        ax.set_xlabel('æ—¥æœŸ')\n",
        "        ax.set_ylabel('é æ¸¬åƒ¹æ ¼')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_feature_importance(self, importances):\n",
        "        \"\"\"ç¹ªè£½ç‰¹å¾µé‡è¦æ€§åœ–\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        top_10 = importances.head(10)\n",
        "        ax.barh(top_10['ç‰¹å¾µ'], top_10['é‡è¦æ€§'], color='skyblue')\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_title('ç‰¹å¾µé‡è¦æ€§æ’å (éš¨æ©Ÿæ£®æ—)', fontsize=16)\n",
        "        ax.set_xlabel('é‡è¦æ€§')\n",
        "        for index, value in enumerate(top_10['é‡è¦æ€§']):\n",
        "            ax.text(value, index, f'{value:.3f}')\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "# =============================================================================\n",
        "# 8. é€šçŸ¥ç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "async def send_notification(session: aiohttp.ClientSession, message: str, chart_files: List[str] = None):\n",
        "    \"\"\"ç™¼é€é€šçŸ¥åˆ° Telegram å’Œ Discord\"\"\"\n",
        "    # Telegram é€šçŸ¥\n",
        "    try:\n",
        "        if TELEGRAM_TOKEN and TELEGRAM_CHAT_ID:\n",
        "            max_length = 4000\n",
        "            if len(message) > max_length:\n",
        "                parts = []\n",
        "                current_part = \"\"\n",
        "                for line in message.split('\\n'):\n",
        "                    if len(current_part + line + '\\n') > max_length:\n",
        "                        if current_part:\n",
        "                            parts.append(current_part.strip())\n",
        "                            current_part = line + '\\n'\n",
        "                        else:\n",
        "                            parts.append(line[:max_length])\n",
        "                    else:\n",
        "                        current_part += line + '\\n'\n",
        "                if current_part:\n",
        "                    parts.append(current_part.strip())\n",
        "            else:\n",
        "                parts = [message]\n",
        "\n",
        "            telegram_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "\n",
        "            for chat_id in TELEGRAM_CHAT_ID:\n",
        "                for i, part in enumerate(parts):\n",
        "                    if i > 0:\n",
        "                        part = f\"ğŸ† è‚¡ç¥¨åˆ†æå ±å‘Š (çºŒ {i+1}/{len(parts)})\\n\\n\" + part\n",
        "\n",
        "                    payload = {'chat_id': chat_id, 'text': part}\n",
        "\n",
        "                    try:\n",
        "                        async with session.post(telegram_url, json=payload, timeout=20) as response:\n",
        "                            if response.status == 200:\n",
        "                                logger.info(f\"æˆåŠŸç™¼é€ Telegram é€šçŸ¥åˆ° {chat_id}\")\n",
        "                            else:\n",
        "                                error_text = await response.text()\n",
        "                                logger.error(f\"ç™¼é€ Telegram é€šçŸ¥å¤±æ•—: {response.status} - {error_text}\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤: {e}\")\n",
        "\n",
        "                    if i < len(parts) - 1:\n",
        "                        await asyncio.sleep(1)\n",
        "\n",
        "                # ç™¼é€åœ–è¡¨æ–‡ä»¶\n",
        "                if chart_files:\n",
        "                    telegram_photo_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                    for chart_file in chart_files:\n",
        "                        if os.path.exists(chart_file):\n",
        "                            try:\n",
        "                                with open(chart_file, 'rb') as photo:\n",
        "                                    files = {'photo': photo}\n",
        "                                    data = {'chat_id': chat_id}\n",
        "\n",
        "                                    import requests\n",
        "                                    response = requests.post(telegram_photo_url, files=files, data=data, timeout=30)\n",
        "\n",
        "                                    if response.status_code == 200:\n",
        "                                        logger.info(f\"æˆåŠŸç™¼é€åœ–è¡¨åˆ° Telegram: {chart_file}\")\n",
        "                                    else:\n",
        "                                        logger.error(f\"ç™¼é€åœ–è¡¨å¤±æ•—: {response.status_code}\")\n",
        "                            except Exception as e:\n",
        "                                logger.error(f\"ç™¼é€åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç™¼é€ Telegram é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "    # Discord é€šçŸ¥\n",
        "    if MESSAGING_AVAILABLE and DISCORD_WEBHOOK_URL:\n",
        "        try:\n",
        "            webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL, content=f\"```\\n{message}\\n```\")\n",
        "\n",
        "            if chart_files:\n",
        "                for chart_file in chart_files:\n",
        "                    if os.path.exists(chart_file):\n",
        "                        with open(chart_file, \"rb\") as f:\n",
        "                            webhook.add_file(file=f.read(), filename=os.path.basename(chart_file))\n",
        "\n",
        "            response = webhook.execute()\n",
        "            if response.ok:\n",
        "                logger.info(\"Discord é€šçŸ¥ç™¼é€æˆåŠŸ\")\n",
        "            else:\n",
        "                logger.error(f\"Discord é€šçŸ¥å¤±æ•—: {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ç™¼é€ Discord é€šçŸ¥æ™‚ç•°å¸¸: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# 9. è‚¡ç¥¨ç¯©é¸å™¨\n",
        "# =============================================================================\n",
        "\n",
        "def screen_stocks(stock_list, days_back, condition):\n",
        "    \"\"\"ç¯©é¸ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\"\"\"\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=days_back * 2)\n",
        "    results = pd.DataFrame(columns=['ticker', 'close', 'volume', 'change_pct'])\n",
        "\n",
        "    for ticker in stock_list:\n",
        "        try:\n",
        "            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "            if data.empty or len(data) < 20:\n",
        "                continue\n",
        "\n",
        "            data = data.tail(days_back)\n",
        "            data['change_pct'] = data['Close'].pct_change() * 100\n",
        "\n",
        "            if condition == \"çªç ´æ•´ç†å€é–“\":\n",
        "                high_20d = data['High'].rolling(window=20).max().shift(1)\n",
        "                if data['Close'].iloc[-1] > high_20d.iloc[-1]:\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "            elif condition == \"çˆ†é‡é•·ç´…\":\n",
        "                vol_5d_avg = data['Volume'].rolling(window=5).mean().shift(1)\n",
        "                if (data['Volume'].iloc[-1] > vol_5d_avg.iloc[-1] * 2 and\n",
        "                    data['change_pct'].iloc[-1] > 3):\n",
        "                    results = pd.concat([results, pd.DataFrame({\n",
        "                        'ticker': [ticker],\n",
        "                        'close': [data['Close'].iloc[-1]],\n",
        "                        'volume': [data['Volume'].iloc[-1]],\n",
        "                        'change_pct': [data['change_pct'].iloc[-1]]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return results\n",
        "\n",
        "# =============================================================================\n",
        "# 10. ä¸»è¦åˆ†æç³»çµ±\n",
        "# =============================================================================\n",
        "\n",
        "class MultiStockAnalysisSystem:\n",
        "    def __init__(self, symbols, period='1y'):\n",
        "        self.symbols = symbols if isinstance(symbols, list) else [symbols]\n",
        "        self.period = period\n",
        "        self.results = {}\n",
        "\n",
        "    async def analyze_stock(self, symbol):\n",
        "        \"\"\"åˆ†æå–®ä¸€è‚¡ç¥¨\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"é–‹å§‹åˆ†æ {symbol}...\")\n",
        "\n",
        "            # 1. ç²å–è‚¡ç¥¨æ•¸æ“š\n",
        "            stock_df = fetch_stock_data(symbol, self.period)\n",
        "            if stock_df is None:\n",
        "                return None\n",
        "\n",
        "            # 2. ç²å–ææ‡¼è²ªå©ªæŒ‡æ•¸\n",
        "            days_needed = len(stock_df)\n",
        "            sentiment_df = get_fear_and_greed_data(days=days_needed + 60)\n",
        "\n",
        "            # 3. åˆä½µæ•¸æ“š\n",
        "            df = pd.merge(stock_df, sentiment_df, on='Date', how='left')\n",
        "\n",
        "            # 4. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—\n",
        "            df = calculate_technical_indicators(df)\n",
        "            df = feature_engineering(df)\n",
        "\n",
        "            # 5. Kç·šå‹æ…‹åˆ†æ\n",
        "            pattern_report = generate_pattern_report(df)\n",
        "\n",
        "            # 6. ç¶œåˆè©•åˆ†\n",
        "            combined_score = calculate_combined_score(df)\n",
        "\n",
        "            # 7. æ©Ÿå™¨å­¸ç¿’é æ¸¬\n",
        "            predictor = StockPredictor()\n",
        "            predictor.run_backtest(df)\n",
        "            predictor.predict_future(df)\n",
        "\n",
        "            # 8. ç”Ÿæˆå»ºè­°\n",
        "            recommendation = generate_recommendation(combined_score)\n",
        "\n",
        "            # 9. ç”Ÿæˆåœ–è¡¨\n",
        "            visualizer = StockVisualizer(symbol)\n",
        "\n",
        "            # ä¿å­˜åœ–è¡¨\n",
        "            chart_files = []\n",
        "\n",
        "            # æŠ€è¡“åˆ†æåœ–\n",
        "            fig1 = visualizer.plot_stock_analysis(df)\n",
        "            chart_path1 = os.path.join(CHARTS_DIR, f\"{symbol}_technical.png\")\n",
        "            fig1.savefig(chart_path1, dpi=150, bbox_inches='tight')\n",
        "            chart_files.append(chart_path1)\n",
        "            plt.close(fig1)\n",
        "\n",
        "            # é æ¸¬åœ–\n",
        "            if predictor.future_predictions:\n",
        "                fig2 = visualizer.plot_future_prediction(\n",
        "                    df['Close'].iloc[-1], df['Date'].iloc[-1], predictor.future_predictions\n",
        "                )\n",
        "                chart_path2 = os.path.join(CHARTS_DIR, f\"{symbol}_prediction.png\")\n",
        "                fig2.savefig(chart_path2, dpi=150, bbox_inches='tight')\n",
        "                chart_files.append(chart_path2)\n",
        "                plt.close(fig2)\n",
        "\n",
        "            # ç‰¹å¾µé‡è¦æ€§åœ–\n",
        "            if predictor.feature_importances is not None:\n",
        "                fig3 = visualizer.plot_feature_importance(predictor.feature_importances)\n",
        "                chart_path3 = os.path.join(CHARTS_DIR, f\"{symbol}_features.png\")\n",
        "                fig3.savefig(chart_path3, dpi=150, bbox_inches='tight')\n",
        "                chart_files.append(chart_path3)\n",
        "                plt.close(fig3)\n",
        "\n",
        "            result = {\n",
        "                'symbol': symbol,\n",
        "                'data_df': df,\n",
        "                'combined_score': combined_score,\n",
        "                'pattern_report': pattern_report,\n",
        "                'recommendation': recommendation,\n",
        "                'predictor': predictor,\n",
        "                'chart_files': chart_files,\n",
        "                'last_price': df['Close'].iloc[-1],\n",
        "                'last_date': df['Date'].iloc[-1]\n",
        "            }\n",
        "\n",
        "            logger.info(f\"å®Œæˆåˆ†æ {symbol}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"åˆ†æ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    async def run_analysis(self):\n",
        "        \"\"\"åŸ·è¡Œå¤šè‚¡ç¥¨åˆ†æ\"\"\"\n",
        "        logger.info(f\"é–‹å§‹åˆ†æ {len(self.symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "        # ä¸¦è¡Œåˆ†ææ‰€æœ‰è‚¡ç¥¨\n",
        "        tasks = [self.analyze_stock(symbol) for symbol in self.symbols]\n",
        "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "        # æ•´ç†çµæœ\n",
        "        for i, result in enumerate(results):\n",
        "            if isinstance(result, Exception):\n",
        "                logger.error(f\"åˆ†æ {self.symbols[i]} æ™‚ç™¼ç”Ÿç•°å¸¸: {result}\")\n",
        "            elif result is not None:\n",
        "                self.results[self.symbols[i]] = result\n",
        "\n",
        "        # ç”Ÿæˆç¸½çµå ±å‘Š\n",
        "        await self.generate_summary_report()\n",
        "\n",
        "    async def generate_summary_report(self):\n",
        "        \"\"\"ç”Ÿæˆç¸½çµå ±å‘Šä¸¦ç™¼é€é€šçŸ¥\"\"\"\n",
        "        if not self.results:\n",
        "            logger.warning(\"æ²’æœ‰æˆåŠŸåˆ†æçš„è‚¡ç¥¨\")\n",
        "            return\n",
        "\n",
        "        # ç”Ÿæˆå ±å‘Šæ–‡æœ¬\n",
        "        report_lines = []\n",
        "        report_lines.append(\"ğŸ“Š å¤šè‚¡ç¥¨åˆ†æå ±å‘Š\")\n",
        "        report_lines.append(\"=\" * 50)\n",
        "        report_lines.append(f\"åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        report_lines.append(f\"åˆ†æè‚¡ç¥¨æ•¸é‡: {len(self.results)}\")\n",
        "        report_lines.append(\"\")\n",
        "\n",
        "        # æŒ‰è©•åˆ†æ’åº\n",
        "        sorted_results = sorted(self.results.items(),\n",
        "                              key=lambda x: x[1]['combined_score'], reverse=True)\n",
        "\n",
        "        for symbol, result in sorted_results:\n",
        "            report_lines.append(f\"ğŸ¢ {symbol}\")\n",
        "            report_lines.append(f\"   ç¶œåˆè©•åˆ†: {result['combined_score']:.2f}\")\n",
        "            report_lines.append(f\"   ç•¶å‰åƒ¹æ ¼: {result['last_price']:.2f}\")\n",
        "            report_lines.append(f\"   æŠ•è³‡å»ºè­°: {result['recommendation']['action']}\")\n",
        "            report_lines.append(f\"   ä¿¡å¿ƒåº¦: {result['recommendation']['confidence']}%\")\n",
        "            report_lines.append(f\"   å»ºè­°åŸå› : {result['recommendation']['reason']}\")\n",
        "\n",
        "            # é æ¸¬åƒ¹æ ¼\n",
        "            if result['predictor'].future_predictions:\n",
        "                pred_1d = result['predictor'].future_predictions.get(1, {})\n",
        "                if pred_1d:\n",
        "                    avg_pred = np.mean(list(pred_1d.values()))\n",
        "                    change_pct = (avg_pred / result['last_price'] - 1) * 100\n",
        "                    report_lines.append(f\"   æ˜æ—¥é æ¸¬: {avg_pred:.2f} ({change_pct:+.2f}%)\")\n",
        "\n",
        "            report_lines.append(\"\")\n",
        "\n",
        "        # å¸‚å ´æ•´é«”åˆ†æ\n",
        "        avg_score = np.mean([r['combined_score'] for r in self.results.values()])\n",
        "        report_lines.append(\"ğŸ“ˆ å¸‚å ´æ•´é«”åˆ†æ\")\n",
        "        report_lines.append(f\"   å¹³å‡è©•åˆ†: {avg_score:.2f}\")\n",
        "\n",
        "        if avg_score >= 60:\n",
        "            market_sentiment = \"æ¨‚è§€\"\n",
        "        elif avg_score >= 40:\n",
        "            market_sentiment = \"ä¸­æ€§\"\n",
        "        else:\n",
        "            market_sentiment = \"è¬¹æ…\"\n",
        "\n",
        "        report_lines.append(f\"   å¸‚å ´æƒ…ç·’: {market_sentiment}\")\n",
        "        report_lines.append(\"\")\n",
        "\n",
        "        # æ¨è–¦è‚¡ç¥¨\n",
        "        buy_stocks = [symbol for symbol, result in sorted_results\n",
        "                     if result['recommendation']['action'] in ['è²·å…¥', 'å¼·çƒˆè²·å…¥']]\n",
        "\n",
        "        if buy_stocks:\n",
        "            report_lines.append(\"ğŸ’° æ¨è–¦è²·å…¥:\")\n",
        "            for stock in buy_stocks[:5]:  # æœ€å¤šæ¨è–¦5æ”¯\n",
        "                score = self.results[stock]['combined_score']\n",
        "                report_lines.append(f\"   â€¢ {stock} (è©•åˆ†: {score:.2f})\")\n",
        "\n",
        "        report_lines.append(\"\")\n",
        "        report_lines.append(\"âš ï¸ å…è²¬è²æ˜: æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…æ±ºç­–ã€‚\")\n",
        "\n",
        "        report_text = \"\\n\".join(report_lines)\n",
        "\n",
        "        # æ”¶é›†æ‰€æœ‰åœ–è¡¨æ–‡ä»¶\n",
        "        all_chart_files = []\n",
        "        for result in self.results.values():\n",
        "            all_chart_files.extend(result.get('chart_files', []))\n",
        "\n",
        "        # ç™¼é€é€šçŸ¥\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            await send_notification(session, report_text, all_chart_files)\n",
        "\n",
        "        # çµ‚ç«¯é¡¯ç¤º\n",
        "        print(\"\\n\" + report_text)\n",
        "\n",
        "# =============================================================================\n",
        "# 11. UI ä»‹é¢ (Jupyter Notebook)\n",
        "# =============================================================================\n",
        "\n",
        "if JUPYTER_AVAILABLE:\n",
        "    def create_stock_analysis_ui():\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨åˆ†æUIä»‹é¢\"\"\"\n",
        "        # æ¨£å¼è¨­å®š\n",
        "        style = {'description_width': '120px'}\n",
        "        layout = Layout(width='300px')\n",
        "\n",
        "        # æ§åˆ¶å…ƒä»¶\n",
        "        symbol_input = widgets.Text(\n",
        "            value='AAPL,TSLA,2330,2454',\n",
        "            placeholder='è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼Œç”¨é€—è™Ÿåˆ†éš”',\n",
        "            description='è‚¡ç¥¨ä»£ç¢¼:',\n",
        "            style=style,\n",
        "            layout=Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        period_dropdown = widgets.Dropdown(\n",
        "            options=[('1å¹´', '1y'), ('2å¹´', '2y'), ('5å¹´', '5y'), ('æœ€å¤§', 'max')],\n",
        "            value='1y',\n",
        "            description='æ™‚é–“ç¯„åœ:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        analyze_button = widgets.Button(\n",
        "            description='é–‹å§‹åˆ†æ',\n",
        "            button_style='primary',\n",
        "            layout=Layout(width='150px', height='40px')\n",
        "        )\n",
        "\n",
        "        output_area = widgets.Output()\n",
        "\n",
        "        def on_analyze_click(b):\n",
        "            with output_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"ğŸš€ é–‹å§‹åˆ†æ...\")\n",
        "\n",
        "                symbols = [s.strip().upper() for s in symbol_input.value.split(',') if s.strip()]\n",
        "                if not symbols:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    return\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem(symbols, period_dropdown.value)\n",
        "\n",
        "                    # åœ¨ Jupyter ä¸­é‹è¡Œç•°æ­¥ä»£ç¢¼\n",
        "                    import asyncio\n",
        "                    loop = asyncio.get_event_loop()\n",
        "                    loop.run_until_complete(system.run_analysis())\n",
        "\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼è«‹æŸ¥çœ‹ç”Ÿæˆçš„åœ–è¡¨å’Œé€šçŸ¥ã€‚\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        analyze_button.on_click(on_analyze_click)\n",
        "\n",
        "        # çµ„åˆUI\n",
        "        ui = VBox([\n",
        "            HTML('<h2>ğŸ“ˆ å¤šè‚¡ç¥¨åˆ†æç³»çµ±</h2>'),\n",
        "            HTML('<p>æ”¯æ´å°è‚¡(è¼¸å…¥æ•¸å­—ä»£ç¢¼å¦‚2330)å’Œç¾è‚¡(è¼¸å…¥å­—æ¯ä»£ç¢¼å¦‚AAPL)</p>'),\n",
        "            symbol_input,\n",
        "            period_dropdown,\n",
        "            analyze_button,\n",
        "            output_area\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "    def create_stock_screener_ui():\n",
        "        \"\"\"å‰µå»ºè‚¡ç¥¨ç¯©é¸å™¨UI\"\"\"\n",
        "        # å°è‚¡ä»£ç¢¼åˆ—è¡¨ (ç°¡åŒ–ç‰ˆ)\n",
        "        tw_stocks = [\n",
        "            '2330', '2317', '2454', '2881', '2882', '2883', '2884', '2885',\n",
        "            '2886', '2887', '2888', '2889', '2890', '2891', '2892', '2912'\n",
        "        ]\n",
        "\n",
        "        # ç¾è‚¡ä»£ç¢¼åˆ—è¡¨ (ç°¡åŒ–ç‰ˆ)\n",
        "        us_stocks = [\n",
        "            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX',\n",
        "            'JPM', 'JNJ', 'V', 'PG', 'UNH', 'HD', 'MA', 'DIS'\n",
        "        ]\n",
        "\n",
        "        style = {'description_width': '120px'}\n",
        "        layout = Layout(width='300px')\n",
        "\n",
        "        market_dropdown = widgets.Dropdown(\n",
        "            options=[('å°è‚¡', 'tw'), ('ç¾è‚¡', 'us')],\n",
        "            value='tw',\n",
        "            description='å¸‚å ´:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        condition_dropdown = widgets.Dropdown(\n",
        "            options=[\n",
        "                ('çªç ´æ•´ç†å€é–“', 'çªç ´æ•´ç†å€é–“'),\n",
        "                ('çˆ†é‡é•·ç´…', 'çˆ†é‡é•·ç´…'),\n",
        "                ('çªç ´å­£ç·š', 'çªç ´å­£ç·š'),\n",
        "                ('å¤šé ­åå™¬', 'å¤šé ­åå™¬'),\n",
        "                ('5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰', '5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰')\n",
        "            ],\n",
        "            value='çªç ´æ•´ç†å€é–“',\n",
        "            description='ç¯©é¸æ¢ä»¶:',\n",
        "            style=style,\n",
        "            layout=Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        days_slider = widgets.IntSlider(\n",
        "            value=30,\n",
        "            min=10,\n",
        "            max=100,\n",
        "            step=10,\n",
        "            description='å›çœ‹å¤©æ•¸:',\n",
        "            style=style,\n",
        "            layout=layout\n",
        "        )\n",
        "\n",
        "        screen_button = widgets.Button(\n",
        "            description='é–‹å§‹ç¯©é¸',\n",
        "            button_style='success',\n",
        "            layout=Layout(width='150px', height='40px')\n",
        "        )\n",
        "\n",
        "        output_area = widgets.Output()\n",
        "\n",
        "        def on_screen_click(b):\n",
        "            with output_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"ğŸ” é–‹å§‹ç¯©é¸è‚¡ç¥¨...\")\n",
        "\n",
        "                stock_list = tw_stocks if market_dropdown.value == 'tw' else us_stocks\n",
        "\n",
        "                try:\n",
        "                    results = screen_stocks(stock_list, days_slider.value, condition_dropdown.value)\n",
        "\n",
        "                    if results.empty:\n",
        "                        print(\"âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "                    else:\n",
        "                        print(f\"âœ… æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨:\")\n",
        "                        print(\"\\n\" + \"=\"*60)\n",
        "                        for _, row in results.iterrows():\n",
        "                            print(f\"è‚¡ç¥¨: {row['ticker']}\")\n",
        "                            print(f\"æ”¶ç›¤åƒ¹: {row['close']:.2f}\")\n",
        "                            print(f\"æˆäº¤é‡: {row['volume']:,.0f}\")\n",
        "                            print(f\"æ¼²è·Œå¹…: {row['change_pct']:.2f}%\")\n",
        "                            print(\"-\" * 30)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ ç¯©é¸éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        screen_button.on_click(on_screen_click)\n",
        "\n",
        "        ui = VBox([\n",
        "            HTML('<h2>ğŸ” è‚¡ç¥¨ç¯©é¸å™¨</h2>'),\n",
        "            market_dropdown,\n",
        "            condition_dropdown,\n",
        "            days_slider,\n",
        "            screen_button,\n",
        "            output_area\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "# =============================================================================\n",
        "# 12. å‘½ä»¤è¡Œä»‹é¢\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"ä¸»å‡½æ•¸ï¼Œé‹è¡Œäº’å‹•å¼ç•Œé¢\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\\nğŸš€ æ­¡è¿ä½¿ç”¨å¤šè‚¡ç¥¨åˆ†æé æ¸¬ç³»çµ±\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"1. å¤šè‚¡ç¥¨åˆ†æèˆ‡é æ¸¬\")\n",
        "        print(\"2. è‚¡ç¥¨ç¯©é¸å™¨\")\n",
        "        print(\"3. å–®è‚¡ç¥¨è©³ç´°åˆ†æ\")\n",
        "        if JUPYTER_AVAILABLE:\n",
        "            print(\"4. å•Ÿå‹• Jupyter UI ä»‹é¢\")\n",
        "        print(\"0. é€€å‡ºç¨‹åº\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        try:\n",
        "            choice = input(\"è«‹é¸æ“‡åŠŸèƒ½ (0-4): \").strip()\n",
        "\n",
        "            if choice == '0':\n",
        "                print(\"æ„Ÿè¬ä½¿ç”¨ï¼Œç¨‹åºé€€å‡ºã€‚\")\n",
        "                break\n",
        "\n",
        "            elif choice == '1':\n",
        "                symbols_input = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ (ç”¨é€—è™Ÿåˆ†éš”ï¼Œå¦‚: AAPL,TSLA,2330,2454): \").strip()\n",
        "                if not symbols_input:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    continue\n",
        "\n",
        "                symbols = [s.strip().upper() for s in symbols_input.split(',') if s.strip()]\n",
        "                period = input(\"è«‹è¼¸å…¥æ­·å²æ•¸æ“šå€é–“ (1y, 2y, 5y, max) [é è¨­: 1y]: \").strip().lower()\n",
        "                if not period:\n",
        "                    period = '1y'\n",
        "\n",
        "                print(f\"ğŸš€ é–‹å§‹åˆ†æ {len(symbols)} æ”¯è‚¡ç¥¨...\")\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem(symbols, period)\n",
        "                    asyncio.run(system.run_analysis())\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            elif choice == '2':\n",
        "                print(\"\\nè‚¡ç¥¨ç¯©é¸å™¨\")\n",
        "                print(\"1. å°è‚¡ç¯©é¸\")\n",
        "                print(\"2. ç¾è‚¡ç¯©é¸\")\n",
        "\n",
        "                market_choice = input(\"è«‹é¸æ“‡å¸‚å ´ (1-2): \").strip()\n",
        "                if market_choice not in ['1', '2']:\n",
        "                    print(\"âŒ ç„¡æ•ˆé¸æ“‡\")\n",
        "                    continue\n",
        "\n",
        "                conditions = [\n",
        "                    \"çªç ´æ•´ç†å€é–“\", \"çˆ†é‡é•·ç´…\", \"çªç ´å­£ç·š\", \"å¤šé ­åå™¬\", \"5èˆ‡20æ—¥å‡ç·šé»ƒé‡‘äº¤å‰\"\n",
        "                ]\n",
        "\n",
        "                print(\"\\nç¯©é¸æ¢ä»¶:\")\n",
        "                for i, condition in enumerate(conditions, 1):\n",
        "                    print(f\"{i}. {condition}\")\n",
        "\n",
        "                condition_choice = input(\"è«‹é¸æ“‡æ¢ä»¶ (1-5): \").strip()\n",
        "                try:\n",
        "                    condition_idx = int(condition_choice) - 1\n",
        "                    if condition_idx < 0 or condition_idx >= len(conditions):\n",
        "                        print(\"âŒ ç„¡æ•ˆé¸æ“‡\")\n",
        "                        continue\n",
        "                    selected_condition = conditions[condition_idx]\n",
        "                except ValueError:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æ•¸å­—\")\n",
        "                    continue\n",
        "\n",
        "                # ç°¡åŒ–çš„è‚¡ç¥¨åˆ—è¡¨\n",
        "                tw_stocks = ['2330.TW', '2317.TW', '2454.TW', '2881.TW', '2882.TW']\n",
        "                us_stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
        "\n",
        "                stock_list = tw_stocks if market_choice == '1' else us_stocks\n",
        "\n",
        "                try:\n",
        "                    results = screen_stocks(stock_list, 30, selected_condition)\n",
        "                    if results.empty:\n",
        "                        print(\"âŒ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨\")\n",
        "                    else:\n",
        "                        print(f\"âœ… æ‰¾åˆ° {len(results)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨:\")\n",
        "                        print(results.to_string(index=False))\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ ç¯©é¸éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "            elif choice == '3':\n",
        "                symbol = input(\"è«‹è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼: \").strip().upper()\n",
        "                if not symbol:\n",
        "                    print(\"âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼\")\n",
        "                    continue\n",
        "\n",
        "                period = input(\"è«‹è¼¸å…¥æ­·å²æ•¸æ“šå€é–“ (1y, 2y, 5y, max) [é è¨­: 1y]: \").strip().lower()\n",
        "                if not period:\n",
        "                    period = '1y'\n",
        "\n",
        "                try:\n",
        "                    system = MultiStockAnalysisSystem([symbol], period)\n",
        "                    asyncio.run(system.run_analysis())\n",
        "                    print(\"âœ… åˆ†æå®Œæˆï¼\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
        "\n",
        "            elif choice == '4' and JUPYTER_AVAILABLE:\n",
        "                print(\"ğŸš€ å•Ÿå‹• Jupyter UI ä»‹é¢...\")\n",
        "                print(\"è«‹åœ¨ Jupyter Notebook ä¸­é‹è¡Œä»¥ä¸‹ä»£ç¢¼:\")\n",
        "                print(\"ui = create_stock_analysis_ui()\")\n",
        "                print(\"display(ui)\")\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                print(\"âŒ ç„¡æ•ˆçš„é¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\næ“ä½œè¢«ä¸­æ–·ã€‚è¿”å›ä¸»é¸å–®...\")\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
        "            input(\"\\næŒ‰Enteréµè¿”å›ä¸»é¸å–®...\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    # å‰µå»ºåˆ†æä»‹é¢\n",
        "    ui = create_stock_analysis_ui()\n",
        "    display(ui)\n",
        "\n",
        "    # å‰µå»ºç¯©é¸ä»‹é¢\n",
        "    screener_ui = create_stock_screener_ui()\n",
        "    display(screener_ui)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1iJnbW11aIPBeZBbYvy8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}